Lmod has detected the following error: These module(s) or extension(s) exist
but cannot be loaded as requested: "cuda/10.2"
   Try: "module spider cuda/10.2" to see how to load the module(s).



created virtual environment CPython3.12.4.final.0-64 in 2866ms
  creator CPython3Posix(dest=/localscratch/aneumann.43529832.0/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/home/aneumann/.local/share/virtualenv)
    added seed packages: pip==24.2+computecanada
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: pip in /localscratch/aneumann.43529832.0/env/lib/python3.12/site-packages (24.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pip-25.0+computecanada-py3-none-any.whl
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 24.2+computecanada
    Uninstalling pip-24.2+computecanada:
      Successfully uninstalled pip-24.2+computecanada
Successfully installed pip-24.2+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/numpy-2.2.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 1))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/pandas-2.2.3+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/seaborn-0.13.2+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 3))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/plotly-6.0.1+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/matplotlib-3.10.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.6.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/torchvision-0.21.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torchaudio-2.6.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 8))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch_geometric-2.6.1+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_dateutil-2.9.0.post0+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pytz-2025.2+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tzdata-2025.2+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/narwhals-1.34.1+computecanada-py3-none-any.whl (from plotly->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/packaging-24.2+computecanada-py3-none-any.whl (from plotly->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/contourpy-1.3.1+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cycler-0.12.1+computecanada-py3-none-any.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fonttools-4.57.0+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/kiwisolver-1.4.8+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/pillow-11.1.0+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyparsing-3.2.1+computecanada-py3-none-any.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.18.0+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.13.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/setuptools-78.1.0+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sympy-1.13.1+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.4.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jinja2-3.1.6+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2025.3.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/mpmath-1.3.0+computecanada-py3-none-any.whl (from sympy==1.13.1->torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/Pillow_SIMD-9.5.0.post2+computecanada-cp312-cp312-linux_x86_64.whl (from torchvision->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/aiohttp-3.11.14+computecanada-cp312-cp312-linux_x86_64.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-6.1.1+computecanada-cp36-abi3-linux_x86_64.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.32.3+computecanada-py3-none-any.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.17.0+computecanada-py2.py3-none-any.whl (from python-dateutil>=2.8.2->pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiohappyeyeballs-2.6.1+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiosignal-1.3.2+computecanada-py2.py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/attrs-25.3.0+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/frozenlist-1.5.0+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/multidict-6.2.0+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/propcache-0.3.1+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/yarl-1.18.3+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-2.1.5+computecanada-cp312-cp312-linux_x86_64.whl (from jinja2->torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-3.4.1+computecanada-cp312-cp312-linux_x86_64.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.10+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-2.4.0+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2025.1.31+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Installing collected packages: pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, sympy, six, setuptools, pyparsing, psutil, propcache, pillow-simd, pillow, packaging, numpy, networkx, narwhals, multidict, MarkupSafe, kiwisolver, idna, fsspec, frozenlist, fonttools, filelock, cycler, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, plotly, jinja2, contourpy, aiosignal, torch, pandas, matplotlib, aiohttp, torchvision, torchaudio, torch_geometric, seaborn
Successfully installed MarkupSafe-2.1.5+computecanada aiohappyeyeballs-2.6.1+computecanada aiohttp-3.11.14+computecanada aiosignal-1.3.2+computecanada attrs-25.3.0+computecanada certifi-2025.1.31+computecanada charset-normalizer-3.4.1+computecanada contourpy-1.3.1+computecanada cycler-0.12.1+computecanada filelock-3.18.0+computecanada fonttools-4.57.0+computecanada frozenlist-1.5.0+computecanada fsspec-2025.3.2+computecanada idna-3.10+computecanada jinja2-3.1.6+computecanada kiwisolver-1.4.8+computecanada matplotlib-3.10.0+computecanada mpmath-1.3.0+computecanada multidict-6.2.0+computecanada narwhals-1.34.1+computecanada networkx-3.4.2+computecanada numpy-2.2.2+computecanada packaging-24.2+computecanada pandas-2.2.3+computecanada pillow-11.1.0+computecanada pillow-simd-9.5.0.post2+computecanada plotly-6.0.1+computecanada propcache-0.3.1+computecanada psutil-6.1.1+computecanada pyparsing-3.2.1+computecanada python-dateutil-2.9.0.post0+computecanada pytz-2025.2+computecanada requests-2.32.3+computecanada seaborn-0.13.2+computecanada setuptools-78.1.0+computecanada six-1.17.0+computecanada sympy-1.13.1+computecanada torch-2.6.0+computecanada torch_geometric-2.6.1+computecanada torchaudio-2.6.0+computecanada torchvision-0.21.0+computecanada tqdm-4.67.1+computecanada typing-extensions-4.13.2+computecanada tzdata-2025.2+computecanada urllib3-2.4.0+computecanada yarl-1.18.3+computecanada
/localscratch/aneumann.43529832.0/env/lib/python3.12/site-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information
  return disable_fn(*args, **kwargs)
Execution mode: prod...
TPU Device: cuda...
Pre-training models with MAPPO (on several instances)...
Loading dataset....
End of loading 150 instances!
Dataset loaded after 4.492169380187988 seconds!
PPO iteration: 1/1000:
	 New training batch of size 20...
	 start solving instance: 57...
	 start solving instance: 102...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 58...
	 start solving instance: 39...
	 start solving instance: 60...
	 start solving instance: 78...
	 start solving instance: 8...
	 start solving instance: 109...
	 start solving instance: 126...
	 start solving instance: 32...
	 start solving instance: 138...
	 start solving instance: 141...
	 start solving instance: 147...
	 start solving instance: 27...
	 start solving instance: 41...
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.087085723876953
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.026503657922148705
		 entropy bonus: 0.329096257686615
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.19303825497627258
		 entropy bonus: 0.09813633561134338
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.35837745666503906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.11193403601646423 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.087085723876953
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.024560844525694847
		 entropy bonus: 0.3290809690952301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.18221953511238098
		 entropy bonus: 0.10373236238956451
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.35837745666503906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.09973055124282837 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.087085723876953
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.033603277057409286
		 entropy bonus: 0.32892197370529175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.18373775482177734
		 entropy bonus: 0.10819562524557114
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.35837745666503906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.1107216477394104 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.871687412261963
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0451555959880352
		 entropy bonus: 0.3232503831386566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08855694532394409
		 entropy bonus: 0.1013161763548851
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14558275043964386
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.1654
PPO iteration: 2/1000:
	 start solving instance: 102...
	 start solving instance: 141...
	 start solving instance: 147...
	 start solving instance: 109...
	 start solving instance: 126...
	 start solving instance: 41...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 60...
	 start solving instance: 27...
	 start solving instance: 7...
	 start solving instance: 38...
	 start solving instance: 39...
	 start solving instance: 8...
	 start solving instance: 90...
	 start solving instance: 57...
	 start solving instance: 138...
	 start solving instance: 35...
	 start solving instance: 58...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4120986461639404
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.050560832023620605
		 entropy bonus: 0.3259592354297638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.055017758160829544
		 entropy bonus: 0.08364029973745346
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21521079540252686
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.19061769545078278 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4120986461639404
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04815028980374336
		 entropy bonus: 0.3103184401988983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05074751377105713
		 entropy bonus: 0.08375709503889084
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21521079540252686
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.18548932671546936 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4120986461639404
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.043772678822278976
		 entropy bonus: 0.3255774676799774
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0469810888171196
		 entropy bonus: 0.0833650603890419
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21521079540252686
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.17585858702659607 - Differentiable computation graph = True!
PPO iteration: 3/1000:
	 start solving instance: 90...
	 start solving instance: 147...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 57...
	 start solving instance: 138...
	 start solving instance: 102...
	 start solving instance: 58...
	 start solving instance: 8...
	 start solving instance: 31...
	 start solving instance: 35...
	 start solving instance: 126...
	 start solving instance: 109...
	 start solving instance: 32...
	 start solving instance: 41...
	 start solving instance: 27...
	 start solving instance: 78...
	 start solving instance: 60...
	 start solving instance: 39...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4542553424835205
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05709463357925415
		 entropy bonus: 0.3206338584423065
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12803715467453003
		 entropy bonus: 0.09064330905675888
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22239771485328674
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.10323169827461243 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4542553424835205
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047776032239198685
		 entropy bonus: 0.30571937561035156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12953324615955353
		 entropy bonus: 0.09034847468137741
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22239771485328674
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.09388822317123413 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4542553424835205
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06243234500288963
		 entropy bonus: 0.3141593039035797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.13199596107006073
		 entropy bonus: 0.09023972600698471
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22239771485328674
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.1118403971195221 - Differentiable computation graph = True!
PPO iteration: 4/1000:
	 start solving instance: 57...
	 start solving instance: 41...
	 start solving instance: 39...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 147...
	 start solving instance: 31...
	 start solving instance: 141...
	 start solving instance: 126...
	 start solving instance: 138...
	 start solving instance: 60...
	 start solving instance: 58...
	 start solving instance: 27...
	 start solving instance: 109...
	 start solving instance: 102...
	 start solving instance: 8...
	 start solving instance: 90...
	 start solving instance: 38...
	 start solving instance: 35...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5578784942626953
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05707448720932007
		 entropy bonus: 0.31951382756233215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1329721063375473
		 entropy bonus: 0.08472222089767456
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08148013800382614
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.2067977786064148 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5578784942626953
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.058631956577301025
		 entropy bonus: 0.32123175263404846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.13614414632320404
		 entropy bonus: 0.08412671834230423
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08148013800382614
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.20195603370666504 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5578784942626953
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07050468027591705
		 entropy bonus: 0.3216266930103302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1381063461303711
		 entropy bonus: 0.08264929801225662
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08148013800382614
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.18822935223579407 - Differentiable computation graph = True!
PPO iteration: 5/1000:
	 start solving instance: 102...
	 start solving instance: 35...
	 start solving instance: 60...
	 start solving instance: 41...
	 start solving instance: 38...
	 start solving instance: 138...
	 start solving instance: 147...
	 start solving instance: 126...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 57...
	 start solving instance: 58...
	 start solving instance: 27...
	 start solving instance: 141...
	 start solving instance: 31...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 109...
	 start solving instance: 8...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6174123287200928
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.031174957752227783
		 entropy bonus: 0.32668572664260864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03622320294380188
		 entropy bonus: 0.05921895429491997
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.033528804779052734
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.2845737338066101 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6174123287200928
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010604679584503174
		 entropy bonus: 0.3289249837398529
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04264507442712784
		 entropy bonus: 0.0607946515083313
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.033528804779052734
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.25720009207725525 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6174123287200928
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007967662997543812
		 entropy bonus: 0.32890716195106506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04370739683508873
		 entropy bonus: 0.061187922954559326
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.033528804779052734
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.2534632086753845 - Differentiable computation graph = True!
PPO iteration: 6/1000:
	 start solving instance: 32...
	 start solving instance: 41...
	 start solving instance: 90...
	 start solving instance: 57...
	 start solving instance: 58...
	 start solving instance: 126...
	 start solving instance: 102...
	 start solving instance: 31...
	 start solving instance: 35...
	 start solving instance: 141...
	 start solving instance: 138...
	 start solving instance: 78...
	 start solving instance: 147...
	 start solving instance: 109...
	 start solving instance: 27...
	 start solving instance: 8...
	 start solving instance: 60...
	 start solving instance: 38...
	 start solving instance: 39...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.428959846496582
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05425001308321953
		 entropy bonus: 0.3203965127468109
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03093983605504036
		 entropy bonus: 0.08832111209630966
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.010357602499425411
		 entropy bonus: 0.01155042089521885
		 -----------------
	 Multi-agent batch loss: 0.3260369300842285 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.428959846496582
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06551838666200638
		 entropy bonus: 0.31036576628685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0316910445690155
		 entropy bonus: 0.08877572417259216
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.007438071072101593
		 entropy bonus: 0.01152766216546297
		 -----------------
	 Multi-agent batch loss: 0.3120577037334442 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.428959846496582
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07165076583623886
		 entropy bonus: 0.31383347511291504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.033126749098300934
		 entropy bonus: 0.08907224982976913
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0002480343100614846
		 entropy bonus: 0.011363321915268898
		 -----------------
	 Multi-agent batch loss: 0.2969396114349365 - Differentiable computation graph = True!
PPO iteration: 7/1000:
	 start solving instance: 32...
	 start solving instance: 7...
	 start solving instance: 27...
	 start solving instance: 8...
	 start solving instance: 109...
	 start solving instance: 78...
	 start solving instance: 31...
	 start solving instance: 138...
	 start solving instance: 141...
	 start solving instance: 35...
	 start solving instance: 147...
	 start solving instance: 58...
	 start solving instance: 38...
	 start solving instance: 57...
	 start solving instance: 60...
	 start solving instance: 102...
	 start solving instance: 41...
	 start solving instance: 90...
	 start solving instance: 39...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.749431610107422
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.040227260440588
		 entropy bonus: 0.32775551080703735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013476461172103882
		 entropy bonus: 0.07731185853481293
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09675227850675583
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.18398043513298035 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.749431610107422
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.058907151222229004
		 entropy bonus: 0.3295004069805145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014933431521058083
		 entropy bonus: 0.07690327614545822
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09675227850675583
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.16370993852615356 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.749431610107422
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.057322483509778976
		 entropy bonus: 0.3286435604095459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.015276456251740456
		 entropy bonus: 0.076603002846241
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09675227850675583
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.16506730020046234 - Differentiable computation graph = True!
PPO iteration: 8/1000:
	 start solving instance: 109...
	 start solving instance: 138...
	 start solving instance: 8...
	 start solving instance: 39...
	 start solving instance: 78...
	 start solving instance: 141...
	 start solving instance: 57...
	 start solving instance: 27...
	 start solving instance: 38...
	 start solving instance: 32...
	 start solving instance: 7...
	 start solving instance: 90...
	 start solving instance: 60...
	 start solving instance: 126...
	 start solving instance: 58...
	 start solving instance: 35...
	 start solving instance: 41...
	 start solving instance: 31...
	 start solving instance: 147...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.522650957107544
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.018594611436128616
		 entropy bonus: 0.3269800841808319
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1722080260515213
		 entropy bonus: 0.06274982541799545
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.043247342109680176
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.20292603969573975 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.522650957107544
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.016059577465057373
		 entropy bonus: 0.3237822949886322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17179901897907257
		 entropy bonus: 0.05941314250230789
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.043247342109680176
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.1693342924118042 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.522650957107544
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015063357539474964
		 entropy bonus: 0.32052063941955566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17503227293491364
		 entropy bonus: 0.058218102902173996
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.043247342109680176
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.1675429344177246 - Differentiable computation graph = True!
PPO iteration: 9/1000:
	 start solving instance: 141...
	 start solving instance: 8...
	 start solving instance: 126...
	 start solving instance: 35...
	 start solving instance: 58...
	 start solving instance: 138...
	 start solving instance: 57...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 147...
	 start solving instance: 109...
	 start solving instance: 7...
	 start solving instance: 27...
	 start solving instance: 78...
	 start solving instance: 41...
	 start solving instance: 60...
	 start solving instance: 32...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.160617351531982
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024239374324679375
		 entropy bonus: 0.3177125155925751
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09025131165981293
		 entropy bonus: 0.10950305312871933
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0866503119468689
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.22067791223526 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.160617351531982
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0015435338718816638
		 entropy bonus: 0.32063359022140503
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09550005197525024
		 entropy bonus: 0.10774550586938858
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0866503119468689
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.1926169991493225 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.160617351531982
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005535352509468794
		 entropy bonus: 0.3213561475276947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09962175041437149
		 entropy bonus: 0.10660304874181747
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0866503119468689
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.18145838379859924 - Differentiable computation graph = True!
PPO iteration: 10/1000:
	 start solving instance: 32...
	 start solving instance: 141...
	 start solving instance: 147...
	 start solving instance: 138...
	 start solving instance: 27...
	 start solving instance: 60...
	 start solving instance: 31...
	 start solving instance: 78...
	 start solving instance: 109...
	 start solving instance: 41...
	 start solving instance: 102...
	 start solving instance: 35...
	 start solving instance: 7...
	 start solving instance: 58...
	 start solving instance: 57...
	 start solving instance: 126...
	 start solving instance: 8...
	 start solving instance: 90...
	 start solving instance: 38...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.338200807571411
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01106537040323019
		 entropy bonus: 0.32672926783561707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12838932871818542
		 entropy bonus: 0.05998542532324791
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20470169186592102
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.02687704563140869 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.338200807571411
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00555911660194397
		 entropy bonus: 0.32653456926345825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1286974996328354
		 entropy bonus: 0.058581650257110596
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20470169186592102
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.04364985227584839 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.338200807571411
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007973146624863148
		 entropy bonus: 0.32663053274154663
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.13135404884815216
		 entropy bonus: 0.05853566154837608
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20470169186592102
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.048725426197052 - Differentiable computation graph = True!
PPO iteration: 11/1000:
	 New training batch of size 20...
	 start solving instance: 106...
	 start solving instance: 22...
	 start solving instance: 33...
	 start solving instance: 26...
	 start solving instance: 15...
	 start solving instance: 115...
	 start solving instance: 99...
	 start solving instance: 57...
	 start solving instance: 60...
	 start solving instance: 111...
	 start solving instance: 110...
	 start solving instance: 29...
	 start solving instance: 135...
	 start solving instance: 3...
	 start solving instance: 76...
	 start solving instance: 65...
	 start solving instance: 120...
	 start solving instance: 78...
	 start solving instance: 142...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.783010959625244
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06707610934972763
		 entropy bonus: 0.31736260652542114
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0076614501886069775
		 entropy bonus: 0.0892530009150505
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09264932572841644
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.6050264239311218 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.783010959625244
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0633445456624031
		 entropy bonus: 0.30538275837898254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0052078962326049805
		 entropy bonus: 0.08698173612356186
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09264932572841644
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.6002664566040039 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.783010959625244
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06299751251935959
		 entropy bonus: 0.29670923948287964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.005302322097122669
		 entropy bonus: 0.09014285355806351
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09264932572841644
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.6005650162696838 - Differentiable computation graph = True!
PPO iteration: 12/1000:
	 start solving instance: 49...
	 start solving instance: 76...
	 start solving instance: 78...
	 start solving instance: 106...
	 start solving instance: 33...
	 start solving instance: 22...
	 start solving instance: 65...
	 start solving instance: 115...
	 start solving instance: 99...
	 start solving instance: 60...
	 start solving instance: 135...
	 start solving instance: 3...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 111...
	 start solving instance: 120...
	 start solving instance: 29...
	 start solving instance: 110...
	 start solving instance: 142...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2556378841400146
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04378867894411087
		 entropy bonus: 0.30721327662467957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.13340306282043457
		 entropy bonus: 0.0375787727534771
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15995380282402039
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.0460609495639801 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2556378841400146
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04683128744363785
		 entropy bonus: 0.30593523383140564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.13582968711853027
		 entropy bonus: 0.03626662492752075
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15995380282402039
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.05127118527889252 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2556378841400146
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04517561197280884
		 entropy bonus: 0.31022295355796814
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1375628113746643
		 entropy bonus: 0.033334970474243164
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15995380282402039
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -0.05148421227931976 - Differentiable computation graph = True!
PPO iteration: 13/1000:
	 start solving instance: 15...
	 start solving instance: 65...
	 start solving instance: 142...
	 start solving instance: 110...
	 start solving instance: 111...
	 start solving instance: 22...
	 start solving instance: 26...
	 start solving instance: 78...
	 start solving instance: 57...
	 start solving instance: 3...
	 start solving instance: 120...
	 start solving instance: 76...
	 start solving instance: 135...
	 start solving instance: 29...
	 start solving instance: 115...
	 start solving instance: 106...
	 start solving instance: 49...
	 start solving instance: 60...
	 start solving instance: 99...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0855681896209717
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14686310291290283
		 entropy bonus: 0.30859634280204773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05450253561139107
		 entropy bonus: 0.06870546191930771
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06258951127529144
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.3005977272987366 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0855681896209717
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14431343972682953
		 entropy bonus: 0.291947603225708
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06008737161755562
		 entropy bonus: 0.06369449198246002
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06258951127529144
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.29462915658950806 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0855681896209717
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14372961223125458
		 entropy bonus: 0.28474900126457214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.061305928975343704
		 entropy bonus: 0.058291852474212646
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06258951127529144
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.29408693313598633 - Differentiable computation graph = True!
PPO iteration: 14/1000:
	 start solving instance: 57...
	 start solving instance: 22...
	 start solving instance: 60...
	 start solving instance: 49...
	 start solving instance: 110...
	 start solving instance: 26...
	 start solving instance: 111...
	 start solving instance: 15...
	 start solving instance: 76...
	 start solving instance: 65...
	 start solving instance: 142...
	 start solving instance: 78...
	 start solving instance: 115...
	 start solving instance: 29...
	 start solving instance: 106...
	 start solving instance: 33...
	 start solving instance: 135...
	 start solving instance: 99...
	 start solving instance: 3...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7261428833007812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11028137058019638
		 entropy bonus: 0.283896267414093
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06357130408287048
		 entropy bonus: 0.04551021382212639
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.024000324308872223
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.3623833954334259 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7261428833007812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10725309699773788
		 entropy bonus: 0.26971495151519775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06840961426496506
		 entropy bonus: 0.041897401213645935
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.024000324308872223
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.35629621148109436 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7261428833007812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10624369233846664
		 entropy bonus: 0.26138967275619507
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06975699216127396
		 entropy bonus: 0.03914734721183777
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.024000324308872223
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.35504698753356934 - Differentiable computation graph = True!
PPO iteration: 15/1000:
	 start solving instance: 26...
	 start solving instance: 49...
	 start solving instance: 110...
	 start solving instance: 29...
	 start solving instance: 115...
	 start solving instance: 78...
	 start solving instance: 99...
	 start solving instance: 22...
	 start solving instance: 106...
	 start solving instance: 15...
	 start solving instance: 76...
	 start solving instance: 60...
	 start solving instance: 142...
	 start solving instance: 111...
	 start solving instance: 120...
	 start solving instance: 65...
	 start solving instance: 57...
	 start solving instance: 135...
	 start solving instance: 33...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.641038417816162
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11331412941217422
		 entropy bonus: 0.2510434091091156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07032123953104019
		 entropy bonus: 0.03956460952758789
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06233857944607735
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.6156973838806152 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.641038417816162
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11291464418172836
		 entropy bonus: 0.2537986636161804
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0721547082066536
		 entropy bonus: 0.04012080654501915
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06233857944607735
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.6131333112716675 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.641038417816162
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11248131096363068
		 entropy bonus: 0.25352540612220764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07294069230556488
		 entropy bonus: 0.040068089962005615
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06233857944607735
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.6119465231895447 - Differentiable computation graph = True!
PPO iteration: 16/1000:
	 start solving instance: 26...
	 start solving instance: 115...
	 start solving instance: 60...
	 start solving instance: 65...
	 start solving instance: 49...
	 start solving instance: 99...
	 start solving instance: 142...
	 start solving instance: 106...
	 start solving instance: 57...
	 start solving instance: 76...
	 start solving instance: 22...
	 start solving instance: 111...
	 start solving instance: 78...
	 start solving instance: 135...
	 start solving instance: 120...
	 start solving instance: 33...
	 start solving instance: 29...
	 start solving instance: 110...
	 start solving instance: 15...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.27121114730835
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12785704433918
		 entropy bonus: 0.2580534517765045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0897364392876625
		 entropy bonus: 0.04502774775028229
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0430900976061821
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.5918434858322144 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.27121114730835
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.126738041639328
		 entropy bonus: 0.26448729634284973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09191739559173584
		 entropy bonus: 0.04581502825021744
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0430900976061821
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.5878214240074158 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.27121114730835
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12733134627342224
		 entropy bonus: 0.2700987458229065
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09473972767591476
		 entropy bonus: 0.04749511554837227
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0430900976061821
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.5848633050918579 - Differentiable computation graph = True!
PPO iteration: 17/1000:
	 start solving instance: 60...
	 start solving instance: 76...
	 start solving instance: 49...
	 start solving instance: 57...
	 start solving instance: 111...
	 start solving instance: 29...
	 start solving instance: 78...
	 start solving instance: 106...
	 start solving instance: 135...
	 start solving instance: 22...
	 start solving instance: 142...
	 start solving instance: 26...
	 start solving instance: 65...
	 start solving instance: 15...
	 start solving instance: 99...
	 start solving instance: 33...
	 start solving instance: 110...
	 start solving instance: 115...
	 start solving instance: 3...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.225564002990723
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09295865893363953
		 entropy bonus: 0.2782677114009857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14200615882873535
		 entropy bonus: 0.04838275909423828
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14535903930664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.5095674991607666 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.225564002990723
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09752433747053146
		 entropy bonus: 0.26650747656822205
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1430240124464035
		 entropy bonus: 0.04839932173490524
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14535903930664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.5051583647727966 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.225564002990723
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09926222264766693
		 entropy bonus: 0.2558738887310028
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1441337913274765
		 entropy bonus: 0.046626944094896317
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14535903930664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.5035512447357178 - Differentiable computation graph = True!
PPO iteration: 18/1000:
	 start solving instance: 49...
	 start solving instance: 142...
	 start solving instance: 76...
	 start solving instance: 65...
	 start solving instance: 26...
	 start solving instance: 3...
	 start solving instance: 115...
	 start solving instance: 135...
	 start solving instance: 29...
	 start solving instance: 33...
	 start solving instance: 110...
	 start solving instance: 22...
	 start solving instance: 78...
	 start solving instance: 106...
	 start solving instance: 57...
	 start solving instance: 120...
	 start solving instance: 111...
	 start solving instance: 99...
	 start solving instance: 60...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 10.858851432800293
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0834597647190094
		 entropy bonus: 0.24860362708568573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03258168697357178
		 entropy bonus: 0.0290461964905262
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14943654835224152
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.9595616459846497 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 10.858851432800293
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07963012903928757
		 entropy bonus: 0.24725034832954407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0341770313680172
		 entropy bonus: 0.029752856120467186
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14943654835224152
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.954201340675354 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 10.858851432800293
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07987046986818314
		 entropy bonus: 0.24450507760047913
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03431515768170357
		 entropy bonus: 0.028698459267616272
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14943654835224152
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.9546835422515869 - Differentiable computation graph = True!
PPO iteration: 19/1000:
	 start solving instance: 135...
	 start solving instance: 111...
	 start solving instance: 57...
	 start solving instance: 49...
	 start solving instance: 3...
	 start solving instance: 15...
	 start solving instance: 110...
	 start solving instance: 142...
	 start solving instance: 60...
	 start solving instance: 99...
	 start solving instance: 115...
	 start solving instance: 65...
	 start solving instance: 26...
	 start solving instance: 78...
	 start solving instance: 29...
	 start solving instance: 120...
	 start solving instance: 106...
	 start solving instance: 76...
	 start solving instance: 22...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.18819522857666
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.089080810546875
		 entropy bonus: 0.24828533828258514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.00091977120609954
		 entropy bonus: 0.044928696006536484
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06116895750164986
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.9183297157287598 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.18819522857666
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08851583302021027
		 entropy bonus: 0.2615256905555725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0024442316498607397
		 entropy bonus: 0.04311254993081093
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06116895750164986
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.9132583737373352 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.18819522857666
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0905034989118576
		 entropy bonus: 0.2719091475009918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0018403650028631091
		 entropy bonus: 0.03849233314394951
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06116895750164986
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.9152736067771912 - Differentiable computation graph = True!
PPO iteration: 20/1000:
	 start solving instance: 120...
	 start solving instance: 99...
	 start solving instance: 65...
	 start solving instance: 76...
	 start solving instance: 33...
	 start solving instance: 26...
	 start solving instance: 115...
	 start solving instance: 111...
	 start solving instance: 142...
	 start solving instance: 135...
	 start solving instance: 78...
	 start solving instance: 110...
	 start solving instance: 57...
	 start solving instance: 15...
	 start solving instance: 3...
	 start solving instance: 49...
	 start solving instance: 29...
	 start solving instance: 60...
	 start solving instance: 22...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.17530345916748
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2540968358516693
		 entropy bonus: 0.26252374053001404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04584429785609245
		 entropy bonus: 0.04034006595611572
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.018587686121463776
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.1685973405838013 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.17530345916748
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.25131624937057495
		 entropy bonus: 0.2700403928756714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03997085243463516
		 entropy bonus: 0.04758899658918381
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.018587686121463776
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.1584668159484863 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.17530345916748
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2522876560688019
		 entropy bonus: 0.27874428033828735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03834855929017067
		 entropy bonus: 0.05230170488357544
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.018587686121463776
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.156474232673645 - Differentiable computation graph = True!
PPO iteration: 21/1000:
	 New training batch of size 20...
	 start solving instance: 45...
	 start solving instance: 106...
	 start solving instance: 122...
	 start solving instance: 107...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 128...
	 start solving instance: 139...
	 start solving instance: 114...
	 start solving instance: 141...
	 start solving instance: 46...
	 start solving instance: 101...
	 start solving instance: 28...
	 start solving instance: 66...
	 start solving instance: 22...
	 start solving instance: 8...
	 start solving instance: 129...
	 start solving instance: 3...
	 start solving instance: 15...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.729334354400635
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10683486610651016
		 entropy bonus: 0.2774295508861542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.031125495210289955
		 entropy bonus: 0.05958903580904007
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.061626702547073364
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.4533142149448395 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.729334354400635
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07683386653661728
		 entropy bonus: 0.32411321997642517
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03884885832667351
		 entropy bonus: 0.06188732385635376
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.061626702547073364
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.41069167852401733 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.729334354400635
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0805036649107933
		 entropy bonus: 0.3290696144104004
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04346105456352234
		 entropy bonus: 0.06226759031414986
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.061626702547073364
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.40921562910079956 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 3.9636311531066895
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10123280435800552
		 entropy bonus: 0.30732378363609314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.19248634576797485
		 entropy bonus: 0.09309430420398712
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.055197663605213165
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.1178
PPO iteration: 22/1000:
	 start solving instance: 46...
	 start solving instance: 107...
	 start solving instance: 45...
	 start solving instance: 122...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 66...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 101...
	 start solving instance: 30...
	 start solving instance: 141...
	 start solving instance: 8...
	 start solving instance: 22...
	 start solving instance: 139...
	 start solving instance: 28...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 15...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3780744075775146
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.005163514520972967
		 entropy bonus: 0.323971152305603
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.007191565819084644
		 entropy bonus: 0.049239613115787506
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12939828634262085
		 entropy bonus: 0.0016680044354870915
		 -----------------
	 Multi-agent batch loss: 0.18327635526657104 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3780744075775146
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007345020771026611
		 entropy bonus: 0.32168513536453247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.001021978328935802
		 entropy bonus: 0.051270850002765656
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13166150450706482
		 entropy bonus: 0.00010381898755440488
		 -----------------
	 Multi-agent batch loss: 0.17516300082206726 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3780744075775146
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0014150500064715743
		 entropy bonus: 0.31927165389060974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0036780089139938354
		 entropy bonus: 0.05081517621874809
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13166150450706482
		 entropy bonus: 1.569587766425684e-06
		 -----------------
	 Multi-agent batch loss: 0.16687412559986115 - Differentiable computation graph = True!
PPO iteration: 23/1000:
	 start solving instance: 107...
	 start solving instance: 3...
	 start solving instance: 141...
	 start solving instance: 142...
	 start solving instance: 8...
	 start solving instance: 139...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 101...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 45...
	 start solving instance: 106...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 28...
	 start solving instance: 46...
	 start solving instance: 15...
	 start solving instance: 66...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.902441501617432
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04967435821890831
		 entropy bonus: 0.3158324956893921
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09602029621601105
		 entropy bonus: 0.039495646953582764
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10891266167163849
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.2001040130853653 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.902441501617432
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0626266822218895
		 entropy bonus: 0.3197460174560547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09786820411682129
		 entropy bonus: 0.03938601166009903
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10891266167163849
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.18492341041564941 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.902441501617432
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0645180344581604
		 entropy bonus: 0.31750011444091797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09979026019573212
		 entropy bonus: 0.03925624489784241
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10891266167163849
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.1813475489616394 - Differentiable computation graph = True!
PPO iteration: 24/1000:
	 start solving instance: 122...
	 start solving instance: 112...
	 start solving instance: 28...
	 start solving instance: 107...
	 start solving instance: 46...
	 start solving instance: 45...
	 start solving instance: 66...
	 start solving instance: 15...
	 start solving instance: 142...
	 start solving instance: 139...
	 start solving instance: 8...
	 start solving instance: 101...
	 start solving instance: 22...
	 start solving instance: 128...
	 start solving instance: 106...
	 start solving instance: 114...
	 start solving instance: 30...
	 start solving instance: 3...
	 start solving instance: 141...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.836116313934326
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06447460502386093
		 entropy bonus: 0.3174557387828827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10999425500631332
		 entropy bonus: 0.03361827880144119
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15892869234085083
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.21510669589042664 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.836116313934326
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07312376797199249
		 entropy bonus: 0.3138805329799652
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1145252138376236
		 entropy bonus: 0.0337647907435894
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15892869234085083
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.20226946473121643 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.836116313934326
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07692472636699677
		 entropy bonus: 0.31082019209861755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11748063564300537
		 entropy bonus: 0.03363703191280365
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15892869234085083
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.19583189487457275 - Differentiable computation graph = True!
PPO iteration: 25/1000:
	 start solving instance: 66...
	 start solving instance: 22...
	 start solving instance: 112...
	 start solving instance: 122...
	 start solving instance: 46...
	 start solving instance: 30...
	 start solving instance: 114...
	 start solving instance: 106...
	 start solving instance: 107...
	 start solving instance: 101...
	 start solving instance: 141...
	 start solving instance: 128...
	 start solving instance: 45...
	 start solving instance: 28...
	 start solving instance: 8...
	 start solving instance: 142...
	 start solving instance: 15...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.614076137542725
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.042904555797576904
		 entropy bonus: 0.3146135210990906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17264997959136963
		 entropy bonus: 0.060765814036130905
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.052130259573459625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.46044543385505676 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.614076137542725
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05480283498764038
		 entropy bonus: 0.30230194330215454
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.18297123908996582
		 entropy bonus: 0.061672575771808624
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.052130259573459625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.4393664002418518 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.614076137542725
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0622374527156353
		 entropy bonus: 0.30193963646888733
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1853271722793579
		 entropy bonus: 0.06170959025621414
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.052130259573459625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.4296083450317383 - Differentiable computation graph = True!
PPO iteration: 26/1000:
	 start solving instance: 129...
	 start solving instance: 128...
	 start solving instance: 107...
	 start solving instance: 3...
	 start solving instance: 106...
	 start solving instance: 45...
	 start solving instance: 114...
	 start solving instance: 141...
	 start solving instance: 22...
	 start solving instance: 122...
	 start solving instance: 8...
	 start solving instance: 30...
	 start solving instance: 112...
	 start solving instance: 101...
	 start solving instance: 28...
	 start solving instance: 66...
	 start solving instance: 142...
	 start solving instance: 46...
	 start solving instance: 15...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.78240966796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06327338516712189
		 entropy bonus: 0.309952050447464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05102352052927017
		 entropy bonus: 0.04906615614891052
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08414892852306366
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.4438932538032532 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.78240966796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07643955200910568
		 entropy bonus: 0.32311898469924927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05273839831352234
		 entropy bonus: 0.0494084469974041
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08414892852306366
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.42766129970550537 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.78240966796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09422680735588074
		 entropy bonus: 0.31972718238830566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.055165838450193405
		 entropy bonus: 0.049443021416664124
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08414892852306366
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.40778234601020813 - Differentiable computation graph = True!
PPO iteration: 27/1000:
	 start solving instance: 30...
	 start solving instance: 15...
	 start solving instance: 3...
	 start solving instance: 66...
	 start solving instance: 141...
	 start solving instance: 142...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 28...
	 start solving instance: 128...
	 start solving instance: 122...
	 start solving instance: 46...
	 start solving instance: 8...
	 start solving instance: 106...
	 start solving instance: 101...
	 start solving instance: 112...
	 start solving instance: 45...
	 start solving instance: 107...
	 start solving instance: 114...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 8.563484191894531
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08003266900777817
		 entropy bonus: 0.30381932854652405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05895223096013069
		 entropy bonus: 0.03559442237019539
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.047600820660591125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.8910883069038391 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8.563484191894531
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0463225357234478
		 entropy bonus: 0.31795987486839294
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06122928857803345
		 entropy bonus: 0.03455847129225731
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.047600820660591125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.8537907004356384 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8.563484191894531
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04883251339197159
		 entropy bonus: 0.3201444745063782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06376837939023972
		 entropy bonus: 0.032657917588949203
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.047600820660591125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 0.8537331819534302 - Differentiable computation graph = True!
PPO iteration: 28/1000:
	 start solving instance: 101...
	 start solving instance: 28...
	 start solving instance: 114...
	 start solving instance: 3...
	 start solving instance: 141...
	 start solving instance: 106...
	 start solving instance: 142...
	 start solving instance: 139...
	 start solving instance: 66...
	 start solving instance: 8...
	 start solving instance: 15...
	 start solving instance: 45...
	 start solving instance: 112...
	 start solving instance: 129...
	 start solving instance: 107...
	 start solving instance: 22...
	 start solving instance: 122...
	 start solving instance: 30...
	 start solving instance: 46...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 10.181914329528809
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04579278454184532
		 entropy bonus: 0.3226303160190582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06352265924215317
		 entropy bonus: 0.061740946024656296
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0943252220749855
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.1833950281143188 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 10.181914329528809
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024913271889090538
		 entropy bonus: 0.309578537940979
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06211024522781372
		 entropy bonus: 0.05323481187224388
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0943252220749855
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.1632587909698486 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 10.181914329528809
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.022358322516083717
		 entropy bonus: 0.32042500376701355
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06196408346295357
		 entropy bonus: 0.04844530299305916
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0943252220749855
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.1599520444869995 - Differentiable computation graph = True!
PPO iteration: 29/1000:
	 start solving instance: 66...
	 start solving instance: 46...
	 start solving instance: 45...
	 start solving instance: 22...
	 start solving instance: 15...
	 start solving instance: 128...
	 start solving instance: 107...
	 start solving instance: 139...
	 start solving instance: 112...
	 start solving instance: 8...
	 start solving instance: 101...
	 start solving instance: 141...
	 start solving instance: 142...
	 start solving instance: 106...
	 start solving instance: 28...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 12.42951488494873
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03689901903271675
		 entropy bonus: 0.3195459842681885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0062510729767382145
		 entropy bonus: 0.057819195091724396
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.022129841148853302
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2704949378967285 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 12.42951488494873
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03241359815001488
		 entropy bonus: 0.322347491979599
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0018100321758538485
		 entropy bonus: 0.056366294622421265
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.022129841148853302
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2614336013793945 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 12.42951488494873
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037138283252716064
		 entropy bonus: 0.31180238723754883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0009274602052755654
		 entropy bonus: 0.055560141801834106
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.022129841148853302
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2645559310913086 - Differentiable computation graph = True!
PPO iteration: 30/1000:
	 start solving instance: 112...
	 start solving instance: 22...
	 start solving instance: 122...
	 start solving instance: 30...
	 start solving instance: 28...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 114...
	 start solving instance: 46...
	 start solving instance: 101...
	 start solving instance: 107...
	 start solving instance: 128...
	 start solving instance: 106...
	 start solving instance: 15...
	 start solving instance: 139...
	 start solving instance: 8...
	 start solving instance: 66...
	 start solving instance: 45...
	 start solving instance: 141...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 13.94311809539795
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.054208576679229736
		 entropy bonus: 0.32083040475845337
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04226591810584068
		 entropy bonus: 0.03740791976451874
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07360108196735382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5285634994506836 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 13.94311809539795
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.051593463867902756
		 entropy bonus: 0.32248425483703613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04020288214087486
		 entropy bonus: 0.03431099280714989
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07360108196735382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5240297317504883 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 13.94311809539795
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.048461731523275375
		 entropy bonus: 0.3236425817012787
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039815664291381836
		 entropy bonus: 0.029786163941025734
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07360108196735382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5208473205566406 - Differentiable computation graph = True!
PPO iteration: 31/1000:
	 New training batch of size 20...
	 start solving instance: 11...
	 start solving instance: 120...
	 start solving instance: 55...
	 start solving instance: 33...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 106...
	 start solving instance: 54...
	 start solving instance: 72...
	 start solving instance: 145...
	 start solving instance: 122...
	 start solving instance: 110...
	 start solving instance: 44...
	 start solving instance: 38...
	 start solving instance: 108...
	 start solving instance: 87...
	 start solving instance: 141...
	 start solving instance: 125...
	 start solving instance: 117...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 15.930941581726074
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29344627261161804
		 entropy bonus: 0.3193614184856415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.011437416076660156
		 entropy bonus: 0.03844210132956505
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.033001821488142014
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.8723245859146118 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 15.930941581726074
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29127946496009827
		 entropy bonus: 0.3163992762565613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.015765680000185966
		 entropy bonus: 0.030135378241539
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.033001821488142014
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.866956353187561 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 15.930941581726074
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2920343577861786
		 entropy bonus: 0.30727508664131165
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019289124757051468
		 entropy bonus: 0.025528401136398315
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.033001821488142014
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.8655610084533691 - Differentiable computation graph = True!
PPO iteration: 32/1000:
	 start solving instance: 91...
	 start solving instance: 108...
	 start solving instance: 125...
	 start solving instance: 120...
	 start solving instance: 38...
	 start solving instance: 68...
	 start solving instance: 44...
	 start solving instance: 55...
	 start solving instance: 113...
	 start solving instance: 141...
	 start solving instance: 87...
	 start solving instance: 54...
	 start solving instance: 117...
	 start solving instance: 122...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 145...
	 start solving instance: 72...
	 start solving instance: 33...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 13.856398582458496
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11593625694513321
		 entropy bonus: 0.3099159300327301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02626914344727993
		 entropy bonus: 0.01708376221358776
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06928457319736481
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5118917226791382 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 13.856398582458496
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11618243902921677
		 entropy bonus: 0.31829386949539185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02626301720738411
		 entropy bonus: 0.02599240653216839
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06928457319736481
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5104153156280518 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 13.856398582458496
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11600632965564728
		 entropy bonus: 0.32014408707618713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.027501869946718216
		 entropy bonus: 0.026317596435546875
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06928457319736481
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5087827444076538 - Differentiable computation graph = True!
PPO iteration: 33/1000:
	 start solving instance: 33...
	 start solving instance: 108...
	 start solving instance: 113...
	 start solving instance: 87...
	 start solving instance: 91...
	 start solving instance: 125...
	 start solving instance: 110...
	 start solving instance: 145...
	 start solving instance: 54...
	 start solving instance: 55...
	 start solving instance: 68...
	 start solving instance: 141...
	 start solving instance: 72...
	 start solving instance: 11...
	 start solving instance: 122...
	 start solving instance: 120...
	 start solving instance: 44...
	 start solving instance: 117...
	 start solving instance: 106...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 14.187914848327637
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3251677453517914
		 entropy bonus: 0.32435041666030884
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03042677603662014
		 entropy bonus: 0.05590970441699028
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03983774408698082
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7153441905975342 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 14.187914848327637
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3213701844215393
		 entropy bonus: 0.32495686411857605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.031138433143496513
		 entropy bonus: 0.019873062148690224
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03983774408698082
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.714377999305725 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 14.187914848327637
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.31905242800712585
		 entropy bonus: 0.32378003001213074
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.030276929959654808
		 entropy bonus: 0.013063265942037106
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03983774408698082
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7137205600738525 - Differentiable computation graph = True!
PPO iteration: 34/1000:
	 start solving instance: 72...
	 start solving instance: 44...
	 start solving instance: 125...
	 start solving instance: 145...
	 start solving instance: 87...
	 start solving instance: 11...
	 start solving instance: 120...
	 start solving instance: 33...
	 start solving instance: 117...
	 start solving instance: 55...
	 start solving instance: 110...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 54...
	 start solving instance: 106...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 108...
	 start solving instance: 122...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 22.03870964050293
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11677541583776474
		 entropy bonus: 0.31463661789894104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17590074241161346
		 entropy bonus: 0.005934265907853842
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06742802262306213
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.045260429382324 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 22.03870964050293
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11553450673818588
		 entropy bonus: 0.3122878074645996
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17765337228775024
		 entropy bonus: 0.005595383699983358
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06742802262306213
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.0425357818603516 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 22.03870964050293
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11424487084150314
		 entropy bonus: 0.311026930809021
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17803369462490082
		 entropy bonus: 0.005238746292889118
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06742802262306213
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.041027784347534 - Differentiable computation graph = True!
PPO iteration: 35/1000:
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 108...
	 start solving instance: 68...
	 start solving instance: 11...
	 start solving instance: 106...
	 start solving instance: 110...
	 start solving instance: 125...
	 start solving instance: 87...
	 start solving instance: 113...
	 start solving instance: 120...
	 start solving instance: 33...
	 start solving instance: 54...
	 start solving instance: 38...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 141...
	 start solving instance: 145...
	 start solving instance: 117...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 23.49188804626465
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13502191007137299
		 entropy bonus: 0.31212806701660156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03839383274316788
		 entropy bonus: 0.008150818757712841
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10986786335706711
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.3039212226867676 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 23.49188804626465
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13316941261291504
		 entropy bonus: 0.3105158805847168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03975103050470352
		 entropy bonus: 0.004326036665588617
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10986786335706711
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.301254987716675 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 23.49188804626465
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13097991049289703
		 entropy bonus: 0.3058427572250366
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03965015336871147
		 entropy bonus: 0.004283096641302109
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10986786335706711
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.299638271331787 - Differentiable computation graph = True!
PPO iteration: 36/1000:
	 start solving instance: 145...
	 start solving instance: 117...
	 start solving instance: 68...
	 start solving instance: 106...
	 start solving instance: 87...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 125...
	 start solving instance: 54...
	 start solving instance: 122...
	 start solving instance: 120...
	 start solving instance: 38...
	 start solving instance: 44...
	 start solving instance: 33...
	 start solving instance: 108...
	 start solving instance: 110...
	 start solving instance: 141...
	 start solving instance: 72...
	 start solving instance: 11...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 23.055301666259766
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3020401895046234
		 entropy bonus: 0.300913006067276
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04992020130157471
		 entropy bonus: 0.010615603998303413
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13441531360149384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.3920819759368896 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 23.055301666259766
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2989608347415924
		 entropy bonus: 0.30404767394065857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05531108379364014
		 entropy bonus: 0.005054590757936239
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13441531360149384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.383854627609253 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 23.055301666259766
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.295014351606369
		 entropy bonus: 0.3086604177951813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05578106641769409
		 entropy bonus: 0.0035084865521639585
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13441531360149384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.379131317138672 - Differentiable computation graph = True!
PPO iteration: 37/1000:
	 start solving instance: 108...
	 start solving instance: 110...
	 start solving instance: 117...
	 start solving instance: 68...
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 125...
	 start solving instance: 120...
	 start solving instance: 38...
	 start solving instance: 113...
	 start solving instance: 11...
	 start solving instance: 141...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 33...
	 start solving instance: 87...
	 start solving instance: 145...
	 start solving instance: 44...
	 start solving instance: 54...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 29.078815460205078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.27049335837364197
		 entropy bonus: 0.3207458555698395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.01629464700818062
		 entropy bonus: 0.0011055161012336612
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0763104259967804
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0861740112304688 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 29.078815460205078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.27015620470046997
		 entropy bonus: 0.3192131519317627
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.016300583258271217
		 entropy bonus: 0.0006593824946321547
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0763104259967804
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.086040735244751 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 29.078815460205078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.27051815390586853
		 entropy bonus: 0.3187466859817505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.016260970383882523
		 entropy bonus: 0.00023694585252087563
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0763104259967804
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.086451768875122 - Differentiable computation graph = True!
PPO iteration: 38/1000:
	 start solving instance: 141...
	 start solving instance: 91...
	 start solving instance: 38...
	 start solving instance: 44...
	 start solving instance: 113...
	 start solving instance: 72...
	 start solving instance: 68...
	 start solving instance: 55...
	 start solving instance: 33...
	 start solving instance: 117...
	 start solving instance: 106...
	 start solving instance: 120...
	 start solving instance: 122...
	 start solving instance: 110...
	 start solving instance: 54...
	 start solving instance: 125...
	 start solving instance: 145...
	 start solving instance: 11...
	 start solving instance: 108...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 27.793760299682617
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015822136774659157
		 entropy bonus: 0.3096230924129486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.22964398562908173
		 entropy bonus: 0.003301712218672037
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09147949516773224
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.4111380577087402 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 27.793760299682617
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015560925006866455
		 entropy bonus: 0.31680163741111755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.2298438996076584
		 entropy bonus: 0.00258984649553895
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09147949516773224
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.410552740097046 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 27.793760299682617
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.016483521088957787
		 entropy bonus: 0.31687530875205994
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.22997502982616425
		 entropy bonus: 0.0022577568888664246
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09147949516773224
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.40952467918396 - Differentiable computation graph = True!
PPO iteration: 39/1000:
	 start solving instance: 54...
	 start solving instance: 68...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 87...
	 start solving instance: 44...
	 start solving instance: 125...
	 start solving instance: 91...
	 start solving instance: 122...
	 start solving instance: 106...
	 start solving instance: 145...
	 start solving instance: 11...
	 start solving instance: 33...
	 start solving instance: 113...
	 start solving instance: 38...
	 start solving instance: 110...
	 start solving instance: 141...
	 start solving instance: 72...
	 start solving instance: 120...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 28.73334312438965
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29031744599342346
		 entropy bonus: 0.3132638931274414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09052294492721558
		 entropy bonus: 0.0019275471568107605
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02088242955505848
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2435381412506104 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 28.73334312438965
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2871471643447876
		 entropy bonus: 0.30089709162712097
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08947698026895523
		 entropy bonus: 1.8336230596105452e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02088242955505848
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.240751028060913 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 28.73334312438965
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.28650379180908203
		 entropy bonus: 0.30081531405448914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08941960334777832
		 entropy bonus: 0.00016533902089577168
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02088242955505848
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.240042209625244 - Differentiable computation graph = True!
PPO iteration: 40/1000:
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 110...
	 start solving instance: 68...
	 start solving instance: 87...
	 start solving instance: 54...
	 start solving instance: 106...
	 start solving instance: 141...
	 start solving instance: 113...
	 start solving instance: 55...
	 start solving instance: 38...
	 start solving instance: 125...
	 start solving instance: 145...
	 start solving instance: 11...
	 start solving instance: 44...
	 start solving instance: 120...
	 start solving instance: 72...
	 start solving instance: 33...
	 start solving instance: 122...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 26.11372947692871
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14071190357208252
		 entropy bonus: 0.31889045238494873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07938913255929947
		 entropy bonus: 0.004200229421257973
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0795288234949112
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.5608577728271484 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 26.11372947692871
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14077983796596527
		 entropy bonus: 0.3214881420135498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08020861446857452
		 entropy bonus: 0.004527290817350149
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0795288234949112
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.559813976287842 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 26.11372947692871
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13971136510372162
		 entropy bonus: 0.3249543011188507
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08029281347990036
		 entropy bonus: 0.004374904092401266
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0795288234949112
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.5583295822143555 - Differentiable computation graph = True!
PPO iteration: 41/1000:
	 New training batch of size 20...
	 start solving instance: 17...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 123...
	 start solving instance: 93...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 33...
	 start solving instance: 144...
	 start solving instance: 71...
	 start solving instance: 18...
	 start solving instance: 16...
	 start solving instance: 68...
	 start solving instance: 1...
	 start solving instance: 52...
	 start solving instance: 124...
	 start solving instance: 35...
	 start solving instance: 102...
	 start solving instance: 29...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 23.747434616088867
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29428353905677795
		 entropy bonus: 0.3180050849914551
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10908129066228867
		 entropy bonus: 0.022189997136592865
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1375989317893982
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.881687879562378 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 23.747434616088867
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2969059348106384
		 entropy bonus: 0.31859728693962097
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11374413967132568
		 entropy bonus: 0.025080537423491478
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1375989317893982
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.888624668121338 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 23.747434616088867
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2914135456085205
		 entropy bonus: 0.31567883491516113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10672628879547119
		 entropy bonus: 0.009363587014377117
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1375989317893982
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.8779780864715576 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 31.45930290222168
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009806550107896328
		 entropy bonus: 0.3174417018890381
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.011097446084022522
		 entropy bonus: 0.006581250578165054
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.056368663907051086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1686
PPO iteration: 42/1000:
	 start solving instance: 35...
	 start solving instance: 46...
	 start solving instance: 21...
	 start solving instance: 29...
	 start solving instance: 124...
	 start solving instance: 18...
	 start solving instance: 20...
	 start solving instance: 102...
	 start solving instance: 14...
	 start solving instance: 52...
	 start solving instance: 123...
	 start solving instance: 68...
	 start solving instance: 17...
	 start solving instance: 16...
	 start solving instance: 33...
	 start solving instance: 71...
	 start solving instance: 1...
	 start solving instance: 144...
	 start solving instance: 147...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 30.194416046142578
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3171033263206482
		 entropy bonus: 0.30596020817756653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03457879647612572
		 entropy bonus: 0.00860944576561451
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18511724472045898
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0853919982910156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 30.194416046142578
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3145774304866791
		 entropy bonus: 0.30061960220336914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0302850604057312
		 entropy bonus: 0.007934998720884323
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18511724472045898
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.087761163711548 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 30.194416046142578
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.313559353351593
		 entropy bonus: 0.29861196875572205
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03442293033003807
		 entropy bonus: 0.005540021695196629
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18511724472045898
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.083045482635498 - Differentiable computation graph = True!
PPO iteration: 43/1000:
	 start solving instance: 102...
	 start solving instance: 124...
	 start solving instance: 123...
	 start solving instance: 144...
	 start solving instance: 33...
	 start solving instance: 71...
	 start solving instance: 18...
	 start solving instance: 16...
	 start solving instance: 17...
	 start solving instance: 68...
	 start solving instance: 46...
	 start solving instance: 20...
	 start solving instance: 21...
	 start solving instance: 14...
	 start solving instance: 147...
	 start solving instance: 1...
	 start solving instance: 93...
	 start solving instance: 52...
	 start solving instance: 29...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 37.085994720458984
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.003927343990653753
		 entropy bonus: 0.3052012622356415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.011694133281707764
		 entropy bonus: 0.0021193658467382193
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06438204646110535
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5978639125823975 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 37.085994720458984
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006393802352249622
		 entropy bonus: 0.30371952056884766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01032206416130066
		 entropy bonus: 0.004204744007438421
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06438204646110535
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5967092514038086 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 37.085994720458984
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00656095752492547
		 entropy bonus: 0.3024703562259674
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0095493970438838
		 entropy bonus: 0.0039250790141522884
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06438204646110535
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5974676609039307 - Differentiable computation graph = True!
PPO iteration: 44/1000:
	 start solving instance: 124...
	 start solving instance: 17...
	 start solving instance: 33...
	 start solving instance: 68...
	 start solving instance: 35...
	 start solving instance: 93...
	 start solving instance: 16...
	 start solving instance: 123...
	 start solving instance: 21...
	 start solving instance: 52...
	 start solving instance: 18...
	 start solving instance: 14...
	 start solving instance: 102...
	 start solving instance: 46...
	 start solving instance: 29...
	 start solving instance: 71...
	 start solving instance: 20...
	 start solving instance: 1...
	 start solving instance: 147...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 40.29752731323242
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.019534606486558914
		 entropy bonus: 0.29848000407218933
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01992328278720379
		 entropy bonus: 0.0032745504286140203
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.026488807052373886
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9866080284118652 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 40.29752731323242
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01995803788304329
		 entropy bonus: 0.30024486780166626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021532703191041946
		 entropy bonus: 0.0008021794492378831
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.026488807052373886
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9846460819244385 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 40.29752731323242
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02016816847026348
		 entropy bonus: 0.29826322197914124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021781517192721367
		 entropy bonus: 0.0016380333108827472
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.026488807052373886
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.984301805496216 - Differentiable computation graph = True!
PPO iteration: 45/1000:
	 start solving instance: 93...
	 start solving instance: 124...
	 start solving instance: 1...
	 start solving instance: 102...
	 start solving instance: 144...
	 start solving instance: 68...
	 start solving instance: 46...
	 start solving instance: 71...
	 start solving instance: 20...
	 start solving instance: 123...
	 start solving instance: 29...
	 start solving instance: 35...
	 start solving instance: 33...
	 start solving instance: 147...
	 start solving instance: 14...
	 start solving instance: 17...
	 start solving instance: 18...
	 start solving instance: 16...
	 start solving instance: 21...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 40.467769622802734
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.293470174074173
		 entropy bonus: 0.30712470412254333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07039441913366318
		 entropy bonus: 0.002557153580710292
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.055327415466308594
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.435001373291016 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 40.467769622802734
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2933640480041504
		 entropy bonus: 0.30650457739830017
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09636949002742767
		 entropy bonus: 0.0075142877176404
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.055327415466308594
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4604363441467285 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 40.467769622802734
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2930452823638916
		 entropy bonus: 0.3079925775527954
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09421306848526001
		 entropy bonus: 0.004199412651360035
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.055327415466308594
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.458143711090088 - Differentiable computation graph = True!
PPO iteration: 46/1000:
	 start solving instance: 20...
	 start solving instance: 18...
	 start solving instance: 1...
	 start solving instance: 93...
	 start solving instance: 68...
	 start solving instance: 123...
	 start solving instance: 124...
	 start solving instance: 33...
	 start solving instance: 144...
	 start solving instance: 102...
	 start solving instance: 29...
	 start solving instance: 21...
	 start solving instance: 71...
	 start solving instance: 16...
	 start solving instance: 17...
	 start solving instance: 14...
	 start solving instance: 35...
	 start solving instance: 46...
	 start solving instance: 52...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 37.644134521484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1427534818649292
		 entropy bonus: 0.29537856578826904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1184055432677269
		 entropy bonus: 0.00021125543571542948
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05067506805062294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.046688556671143 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 37.644134521484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14364898204803467
		 entropy bonus: 0.29697734117507935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11844616383314133
		 entropy bonus: 0.0006036526174284518
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05067506805062294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.047425746917725 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 37.644134521484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14152291417121887
		 entropy bonus: 0.2944270074367523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11944909393787384
		 entropy bonus: 0.0005306427483446896
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05067506805062294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.046565055847168 - Differentiable computation graph = True!
PPO iteration: 47/1000:
	 start solving instance: 16...
	 start solving instance: 102...
	 start solving instance: 1...
	 start solving instance: 17...
	 start solving instance: 21...
	 start solving instance: 46...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 123...
	 start solving instance: 35...
	 start solving instance: 71...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 18...
	 start solving instance: 147...
	 start solving instance: 144...
	 start solving instance: 20...
	 start solving instance: 29...
	 start solving instance: 68...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 40.36139678955078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08230596780776978
		 entropy bonus: 0.3013310134410858
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12080714851617813
		 entropy bonus: 0.002229513367637992
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06430525332689285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.738365411758423 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 40.36139678955078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08443751186132431
		 entropy bonus: 0.2986711263656616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12052380293607712
		 entropy bonus: 0.00382954441010952
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06430525332689285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7366232872009277 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 40.36139678955078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0850788801908493
		 entropy bonus: 0.29578402638435364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12119429558515549
		 entropy bonus: 0.0022270670160651207
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06430525332689285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.73576021194458 - Differentiable computation graph = True!
PPO iteration: 48/1000:
	 start solving instance: 123...
	 start solving instance: 17...
	 start solving instance: 20...
	 start solving instance: 68...
	 start solving instance: 33...
	 start solving instance: 71...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 52...
	 start solving instance: 16...
	 start solving instance: 35...
	 start solving instance: 1...
	 start solving instance: 29...
	 start solving instance: 93...
	 start solving instance: 144...
	 start solving instance: 124...
	 start solving instance: 46...
	 start solving instance: 14...
	 start solving instance: 18...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 42.6313362121582
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11461436748504639
		 entropy bonus: 0.2975098192691803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09829854965209961
		 entropy bonus: 0.0023955311626195908
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06893344968557358
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.514989376068115 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 42.6313362121582
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11488219350576401
		 entropy bonus: 0.30098268389701843
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09727324545383453
		 entropy bonus: 0.0015736224595457315
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06893344968557358
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.513967037200928 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 42.6313362121582
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11569321155548096
		 entropy bonus: 0.3023672103881836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09726360440254211
		 entropy bonus: 0.0012559167807921767
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06893344968557358
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5146613121032715 - Differentiable computation graph = True!
PPO iteration: 49/1000:
	 start solving instance: 124...
	 start solving instance: 71...
	 start solving instance: 35...
	 start solving instance: 21...
	 start solving instance: 93...
	 start solving instance: 17...
	 start solving instance: 18...
	 start solving instance: 16...
	 start solving instance: 33...
	 start solving instance: 14...
	 start solving instance: 52...
	 start solving instance: 20...
	 start solving instance: 144...
	 start solving instance: 102...
	 start solving instance: 147...
	 start solving instance: 29...
	 start solving instance: 68...
	 start solving instance: 46...
	 start solving instance: 123...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 44.571746826171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2590121328830719
		 entropy bonus: 0.2965507507324219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.183196023106575
		 entropy bonus: 0.004421786405146122
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011226961389183998
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.858058929443359 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 44.571746826171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.25711166858673096
		 entropy bonus: 0.29631122946739197
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19680659472942352
		 entropy bonus: 0.004813248757272959
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011226961389183998
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.869753360748291 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 44.571746826171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.25341254472732544
		 entropy bonus: 0.30246689915657043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19836066663265228
		 entropy bonus: 0.0029734435956925154
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011226961389183998
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8671770095825195 - Differentiable computation graph = True!
PPO iteration: 50/1000:
	 start solving instance: 21...
	 start solving instance: 68...
	 start solving instance: 123...
	 start solving instance: 14...
	 start solving instance: 29...
	 start solving instance: 35...
	 start solving instance: 1...
	 start solving instance: 124...
	 start solving instance: 16...
	 start solving instance: 71...
	 start solving instance: 18...
	 start solving instance: 102...
	 start solving instance: 147...
	 start solving instance: 17...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 93...
	 start solving instance: 144...
	 start solving instance: 46...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 43.40534210205078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10982006043195724
		 entropy bonus: 0.32199710607528687
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.01571204699575901
		 entropy bonus: 0.0017109018517658114
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02500629425048828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.458702087402344 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 43.40534210205078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10947203636169434
		 entropy bonus: 0.32719001173973083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.015550113283097744
		 entropy bonus: 0.0012720137601718307
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02500629425048828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.457716464996338 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 43.40534210205078
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11030817031860352
		 entropy bonus: 0.32768377661705017
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0154259679839015
		 entropy bonus: 0.0010352591052651405
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02500629425048828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.458402633666992 - Differentiable computation graph = True!
PPO iteration: 51/1000:
	 New training batch of size 20...
	 start solving instance: 148...
	 start solving instance: 91...
	 start solving instance: 150...
	 start solving instance: 99...
	 start solving instance: 3...
	 start solving instance: 42...
	 start solving instance: 139...
	 start solving instance: 44...
	 start solving instance: 46...
	 start solving instance: 7...
	 start solving instance: 144...
	 start solving instance: 129...
	 start solving instance: 119...
	 start solving instance: 21...
	 start solving instance: 22...
	 start solving instance: 28...
	 start solving instance: 104...
	 start solving instance: 50...
	 start solving instance: 89...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 39.40376663208008
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04180726408958435
		 entropy bonus: 0.3237684369087219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0011744260555133224
		 entropy bonus: 0.00044085626723244786
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.018057605251669884
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.93287992477417 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 39.40376663208008
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03933384642004967
		 entropy bonus: 0.3236861824989319
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0011847794521600008
		 entropy bonus: 0.00042001038673333824
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.018057605251669884
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.930427074432373 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 39.40376663208008
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.048236485570669174
		 entropy bonus: 0.3135867118835449
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0019270748598501086
		 entropy bonus: 0.0018674753373488784
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.018057605251669884
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9409372806549072 - Differentiable computation graph = True!
PPO iteration: 52/1000:
	 start solving instance: 89...
	 start solving instance: 28...
	 start solving instance: 46...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 3...
	 start solving instance: 99...
	 start solving instance: 22...
	 start solving instance: 21...
	 start solving instance: 42...
	 start solving instance: 7...
	 start solving instance: 91...
	 start solving instance: 50...
	 start solving instance: 119...
	 start solving instance: 129...
	 start solving instance: 150...
	 start solving instance: 144...
	 start solving instance: 104...
	 start solving instance: 44...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 42.513240814208984
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.00764098484069109
		 entropy bonus: 0.3210981488227844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06949054449796677
		 entropy bonus: 0.00010656757513061166
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15946875512599945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.997885227203369 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 42.513240814208984
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.001169616007246077
		 entropy bonus: 0.3238447606563568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07024671137332916
		 entropy bonus: 0.0013527491828426719
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15946875512599945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9902586936950684 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 42.513240814208984
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.004341647028923035
		 entropy bonus: 0.32424235343933105
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07024619728326797
		 entropy bonus: 0.00010674689110601321
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15946875512599945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.984832525253296 - Differentiable computation graph = True!
PPO iteration: 53/1000:
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 44...
	 start solving instance: 150...
	 start solving instance: 46...
	 start solving instance: 40...
	 start solving instance: 42...
	 start solving instance: 22...
	 start solving instance: 7...
	 start solving instance: 148...
	 start solving instance: 89...
	 start solving instance: 3...
	 start solving instance: 119...
	 start solving instance: 129...
	 start solving instance: 50...
	 start solving instance: 28...
	 start solving instance: 99...
	 start solving instance: 144...
	 start solving instance: 21...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 49.35091781616211
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04614245146512985
		 entropy bonus: 0.3188912570476532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08027626574039459
		 entropy bonus: 0.0006633251323364675
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006802602671086788
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.875804901123047 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 49.35091781616211
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04411997273564339
		 entropy bonus: 0.31427034735679626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08013886213302612
		 entropy bonus: 0.0018232014263048768
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006802602671086788
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.874266147613525 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 49.35091781616211
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04205694794654846
		 entropy bonus: 0.3182334303855896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07897398620843887
		 entropy bonus: 0.004326301161199808
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006802602671086788
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.872721195220947 - Differentiable computation graph = True!
PPO iteration: 54/1000:
	 start solving instance: 7...
	 start solving instance: 129...
	 start solving instance: 46...
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 3...
	 start solving instance: 89...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 22...
	 start solving instance: 150...
	 start solving instance: 28...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 119...
	 start solving instance: 139...
	 start solving instance: 42...
	 start solving instance: 99...
	 start solving instance: 50...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 50.22087097167969
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06941606849431992
		 entropy bonus: 0.327358216047287
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11969640105962753
		 entropy bonus: 0.0009468332282267511
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08251740783452988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.85645866394043 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 50.22087097167969
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.038236405700445175
		 entropy bonus: 0.3246324956417084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11959578841924667
		 entropy bonus: 0.002109881956130266
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08251740783452988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.825535774230957 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 50.22087097167969
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03620976209640503
		 entropy bonus: 0.3215976357460022
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12052462249994278
		 entropy bonus: 0.0004925921675749123
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08251740783452988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.82304573059082 - Differentiable computation graph = True!
PPO iteration: 55/1000:
	 start solving instance: 150...
	 start solving instance: 50...
	 start solving instance: 46...
	 start solving instance: 28...
	 start solving instance: 144...
	 start solving instance: 3...
	 start solving instance: 40...
	 start solving instance: 91...
	 start solving instance: 42...
	 start solving instance: 119...
	 start solving instance: 129...
	 start solving instance: 104...
	 start solving instance: 21...
	 start solving instance: 89...
	 start solving instance: 148...
	 start solving instance: 139...
	 start solving instance: 44...
	 start solving instance: 99...
	 start solving instance: 22...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 39.696205139160156
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.049794793128967285
		 entropy bonus: 0.30964943766593933
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.19064019620418549
		 entropy bonus: 0.0014833929017186165
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06797966361045837
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6300926208496094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 39.696205139160156
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06114916130900383
		 entropy bonus: 0.3082141578197479
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1864304542541504
		 entropy bonus: 0.0034207128919661045
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06797966361045837
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6228976249694824 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 39.696205139160156
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06489404290914536
		 entropy bonus: 0.30260875821113586
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.18627440929412842
		 entropy bonus: 0.008812892250716686
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06797966361045837
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6193301677703857 - Differentiable computation graph = True!
PPO iteration: 56/1000:
	 start solving instance: 44...
	 start solving instance: 129...
	 start solving instance: 104...
	 start solving instance: 40...
	 start solving instance: 148...
	 start solving instance: 46...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 42...
	 start solving instance: 150...
	 start solving instance: 119...
	 start solving instance: 28...
	 start solving instance: 91...
	 start solving instance: 22...
	 start solving instance: 139...
	 start solving instance: 7...
	 start solving instance: 99...
	 start solving instance: 21...
	 start solving instance: 50...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 29.499317169189453
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06149217113852501
		 entropy bonus: 0.3145408034324646
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.022642964497208595
		 entropy bonus: 0.014428275637328625
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13081683218479156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.702082872390747 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 29.499317169189453
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07610640674829483
		 entropy bonus: 0.2696574628353119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01251556258648634
		 entropy bonus: 0.026119351387023926
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13081683218479156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.7009153366088867 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 29.499317169189453
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08053087443113327
		 entropy bonus: 0.27680251002311707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.008039421401917934
		 entropy bonus: 0.029119795188307762
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13081683218479156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.6999526023864746 - Differentiable computation graph = True!
PPO iteration: 57/1000:
	 start solving instance: 7...
	 start solving instance: 44...
	 start solving instance: 129...
	 start solving instance: 42...
	 start solving instance: 3...
	 start solving instance: 28...
	 start solving instance: 50...
	 start solving instance: 40...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 148...
	 start solving instance: 46...
	 start solving instance: 22...
	 start solving instance: 104...
	 start solving instance: 99...
	 start solving instance: 139...
	 start solving instance: 119...
	 start solving instance: 21...
	 start solving instance: 91...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 30.846410751342773
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08363926410675049
		 entropy bonus: 0.2862022817134857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.148879274725914
		 entropy bonus: 0.031244700774550438
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09655710309743881
		 entropy bonus: 0.006415142212063074
		 -----------------
	 Multi-agent batch loss: 2.723179340362549 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 30.846410751342773
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0971936509013176
		 entropy bonus: 0.26193976402282715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14881585538387299
		 entropy bonus: 0.027971789240837097
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0991566851735115
		 entropy bonus: 0.009329821914434433
		 -----------------
	 Multi-agent batch loss: 2.7095508575439453 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 30.846410751342773
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10771975666284561
		 entropy bonus: 0.2713799774646759
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14856883883476257
		 entropy bonus: 0.03945869207382202
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0991566851735115
		 entropy bonus: 0.00912256259471178
		 -----------------
	 Multi-agent batch loss: 2.697199821472168 - Differentiable computation graph = True!
PPO iteration: 58/1000:
	 start solving instance: 119...
	 start solving instance: 148...
	 start solving instance: 7...
	 start solving instance: 22...
	 start solving instance: 21...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 99...
	 start solving instance: 3...
	 start solving instance: 46...
	 start solving instance: 150...
	 start solving instance: 40...
	 start solving instance: 50...
	 start solving instance: 104...
	 start solving instance: 44...
	 start solving instance: 139...
	 start solving instance: 42...
	 start solving instance: 129...
	 start solving instance: 28...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 40.90269088745117
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11732257902622223
		 entropy bonus: 0.2915303409099579
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0036359571386128664
		 entropy bonus: 0.039576709270477295
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05034291744232178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.885857105255127 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 40.90269088745117
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05434570461511612
		 entropy bonus: 0.2644321918487549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0016471408307552338
		 entropy bonus: 0.0433618389070034
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05034291744232178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9531538486480713 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 40.90269088745117
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1184014230966568
		 entropy bonus: 0.2591420114040375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012317705899477005
		 entropy bonus: 0.027822529897093773
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05034291744232178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9051458835601807 - Differentiable computation graph = True!
PPO iteration: 59/1000:
	 start solving instance: 42...
	 start solving instance: 40...
	 start solving instance: 139...
	 start solving instance: 99...
	 start solving instance: 44...
	 start solving instance: 28...
	 start solving instance: 50...
	 start solving instance: 3...
	 start solving instance: 89...
	 start solving instance: 46...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 91...
	 start solving instance: 7...
	 start solving instance: 129...
	 start solving instance: 144...
	 start solving instance: 21...
	 start solving instance: 22...
	 start solving instance: 150...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 60.4949836730957
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03594183921813965
		 entropy bonus: 0.24951131641864777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1668514460325241
		 entropy bonus: 0.02036290429532528
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07811196893453598
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.741605758666992 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 60.4949836730957
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0427195206284523
		 entropy bonus: 0.24908232688903809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.16545145213603973
		 entropy bonus: 0.02518428862094879
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07811196893453598
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.735788822174072 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 60.4949836730957
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0463607981801033
		 entropy bonus: 0.26713162660598755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.16336822509765625
		 entropy bonus: 0.010636492632329464
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07811196893453598
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.733880996704102 - Differentiable computation graph = True!
PPO iteration: 60/1000:
	 start solving instance: 28...
	 start solving instance: 50...
	 start solving instance: 139...
	 start solving instance: 44...
	 start solving instance: 119...
	 start solving instance: 148...
	 start solving instance: 144...
	 start solving instance: 129...
	 start solving instance: 150...
	 start solving instance: 42...
	 start solving instance: 40...
	 start solving instance: 99...
	 start solving instance: 104...
	 start solving instance: 89...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 7...
	 start solving instance: 21...
	 start solving instance: 22...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 68.67031860351562
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00891646184027195
		 entropy bonus: 0.2602965533733368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10153629630804062
		 entropy bonus: 0.022336652502417564
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1859746128320694
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.542341709136963 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 68.67031860351562
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04800741747021675
		 entropy bonus: 0.24962325394153595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05265085771679878
		 entropy bonus: 0.003999417182058096
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1859746128320694
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.6510515213012695 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 68.67031860351562
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04764299467206001
		 entropy bonus: 0.24533458054065704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.051332321017980576
		 entropy bonus: 0.0013975012116134167
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1859746128320694
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.6526947021484375 - Differentiable computation graph = True!
PPO iteration: 61/1000:
	 New training batch of size 20...
	 start solving instance: 127...
	 start solving instance: 1...
	 start solving instance: 79...
	 start solving instance: 132...
	 start solving instance: 54...
	 start solving instance: 35...
	 start solving instance: 88...
	 start solving instance: 99...
	 start solving instance: 27...
	 start solving instance: 150...
	 start solving instance: 84...
	 start solving instance: 142...
	 start solving instance: 31...
	 start solving instance: 70...
	 start solving instance: 85...
	 start solving instance: 12...
	 start solving instance: 121...
	 start solving instance: 38...
	 start solving instance: 149...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 86.1436767578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10258259624242783
		 entropy bonus: 0.24861977994441986
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10306817293167114
		 entropy bonus: 0.0003682735550682992
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18046650290489197
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.203351974487305 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 86.1436767578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11177792400121689
		 entropy bonus: 0.25404009222984314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10310059785842896
		 entropy bonus: 0.0001632450585020706
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18046650290489197
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.193601608276367 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 86.1436767578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1141299232840538
		 entropy bonus: 0.24970166385173798
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10311213880777359
		 entropy bonus: 7.60818729759194e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18046650290489197
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.191680908203125 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 84.80670166015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08504897356033325
		 entropy bonus: 0.2518171966075897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09917396306991577
		 entropy bonus: 4.5473629143089056e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.4384238123893738
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.8328
PPO iteration: 62/1000:
	 start solving instance: 149...
	 start solving instance: 88...
	 start solving instance: 84...
	 start solving instance: 12...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 132...
	 start solving instance: 99...
	 start solving instance: 150...
	 start solving instance: 85...
	 start solving instance: 27...
	 start solving instance: 35...
	 start solving instance: 121...
	 start solving instance: 31...
	 start solving instance: 89...
	 start solving instance: 142...
	 start solving instance: 54...
	 start solving instance: 127...
	 start solving instance: 70...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 96.98868560791016
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11882241070270538
		 entropy bonus: 0.24986043572425842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1526571661233902
		 entropy bonus: 3.633373853517696e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14534221589565277
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.257057189941406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 96.98868560791016
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1152464970946312
		 entropy bonus: 0.23363235592842102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1526622772216797
		 entropy bonus: 7.385367098322604e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14534221589565277
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.262253761291504 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 96.98868560791016
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11392942816019058
		 entropy bonus: 0.2260598987340927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.15266293287277222
		 entropy bonus: 3.384807996553718e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14534221589565277
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.264328002929688 - Differentiable computation graph = True!
PPO iteration: 63/1000:
	 start solving instance: 27...
	 start solving instance: 54...
	 start solving instance: 127...
	 start solving instance: 84...
	 start solving instance: 38...
	 start solving instance: 149...
	 start solving instance: 142...
	 start solving instance: 85...
	 start solving instance: 12...
	 start solving instance: 88...
	 start solving instance: 132...
	 start solving instance: 89...
	 start solving instance: 1...
	 start solving instance: 70...
	 start solving instance: 35...
	 start solving instance: 150...
	 start solving instance: 79...
	 start solving instance: 31...
	 start solving instance: 99...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 109.58229064941406
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0874922052025795
		 entropy bonus: 0.21104510128498077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.22663012146949768
		 entropy bonus: 0.0009925339836627245
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.066067174077034
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.556836128234863 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 109.58229064941406
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.082321397960186
		 entropy bonus: 0.22283171117305756
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.22324541211128235
		 entropy bonus: 0.0006147301173768938
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.066067174077034
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.564249992370605 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 109.58229064941406
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07842801511287689
		 entropy bonus: 0.22487659752368927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.22285662591457367
		 entropy bonus: 4.167088627582416e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.066067174077034
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.568385124206543 - Differentiable computation graph = True!
PPO iteration: 64/1000:
	 start solving instance: 84...
	 start solving instance: 70...
	 start solving instance: 12...
	 start solving instance: 54...
	 start solving instance: 79...
	 start solving instance: 38...
	 start solving instance: 132...
	 start solving instance: 35...
	 start solving instance: 88...
	 start solving instance: 142...
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 85...
	 start solving instance: 150...
	 start solving instance: 27...
	 start solving instance: 121...
	 start solving instance: 149...
	 start solving instance: 31...
	 start solving instance: 99...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 108.31733703613281
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.15449579060077667
		 entropy bonus: 0.2337191104888916
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.21362273395061493
		 entropy bonus: 0.00022093723237048835
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.329511821269989
		 entropy bonus: 1.734667368987691e-41
		 -----------------
	 Multi-agent batch loss: 10.110709190368652 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 108.31733703613281
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.15976659953594208
		 entropy bonus: 0.23015885055065155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.212908074259758
		 entropy bonus: 0.0010145765263587236
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.329511821269989
		 entropy bonus: 9.513415274301183e-41
		 -----------------
	 Multi-agent batch loss: 10.106430053710938 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 108.31733703613281
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16347797214984894
		 entropy bonus: 0.22770491242408752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.21391434967517853
		 entropy bonus: 9.69499524217099e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.329511821269989
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.102048873901367 - Differentiable computation graph = True!
PPO iteration: 65/1000:
	 start solving instance: 84...
	 start solving instance: 54...
	 start solving instance: 85...
	 start solving instance: 150...
	 start solving instance: 127...
	 start solving instance: 27...
	 start solving instance: 1...
	 start solving instance: 142...
	 start solving instance: 89...
	 start solving instance: 88...
	 start solving instance: 149...
	 start solving instance: 121...
	 start solving instance: 31...
	 start solving instance: 35...
	 start solving instance: 12...
	 start solving instance: 132...
	 start solving instance: 99...
	 start solving instance: 70...
	 start solving instance: 38...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 126.55156707763672
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07021037489175797
		 entropy bonus: 0.22752462327480316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17949239909648895
		 entropy bonus: 2.033092187048169e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18587331473827362
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.19682788848877 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 126.55156707763672
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07484721392393112
		 entropy bonus: 0.22526732087135315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.17949004471302032
		 entropy bonus: 1.870134292403236e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18587331473827362
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.192418098449707 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 126.55156707763672
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.075344018638134
		 entropy bonus: 0.2234400510787964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1794910430908203
		 entropy bonus: 1.2150433576607611e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18587331473827362
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.192103385925293 - Differentiable computation graph = True!
PPO iteration: 66/1000:
	 start solving instance: 54...
	 start solving instance: 150...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 99...
	 start solving instance: 27...
	 start solving instance: 88...
	 start solving instance: 127...
	 start solving instance: 31...
	 start solving instance: 1...
	 start solving instance: 12...
	 start solving instance: 35...
	 start solving instance: 79...
	 start solving instance: 38...
	 start solving instance: 84...
	 start solving instance: 142...
	 start solving instance: 70...
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 123.60841369628906
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.058784034103155136
		 entropy bonus: 0.21690641343593597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08579511940479279
		 entropy bonus: 2.1294412363204174e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05201626569032669
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.26012134552002 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 123.60841369628906
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05579952150583267
		 entropy bonus: 0.21892979741096497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08579361438751221
		 entropy bonus: 6.800366492143439e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05201626569032669
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.256938934326172 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 123.60841369628906
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05515415593981743
		 entropy bonus: 0.22046294808387756
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08579361438751221
		 entropy bonus: 3.458787700694188e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05201626569032669
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.256139755249023 - Differentiable computation graph = True!
PPO iteration: 67/1000:
	 start solving instance: 132...
	 start solving instance: 88...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 31...
	 start solving instance: 89...
	 start solving instance: 84...
	 start solving instance: 121...
	 start solving instance: 12...
	 start solving instance: 79...
	 start solving instance: 150...
	 start solving instance: 35...
	 start solving instance: 27...
	 start solving instance: 54...
	 start solving instance: 99...
	 start solving instance: 127...
	 start solving instance: 38...
	 start solving instance: 149...
	 start solving instance: 85...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 108.9722671508789
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11375006288290024
		 entropy bonus: 0.21658210456371307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.16290263831615448
		 entropy bonus: 0.0016879432369023561
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2390279322862625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.359719276428223 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 108.9722671508789
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11395587772130966
		 entropy bonus: 0.21875201165676117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14524134993553162
		 entropy bonus: 3.3054190894804547e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2390279322862625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.377126693725586 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 108.9722671508789
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11596150696277618
		 entropy bonus: 0.21743439137935638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14350146055221558
		 entropy bonus: 1.1756868616430438e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2390279322862625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.376993179321289 - Differentiable computation graph = True!
PPO iteration: 68/1000:
	 start solving instance: 149...
	 start solving instance: 35...
	 start solving instance: 27...
	 start solving instance: 79...
	 start solving instance: 121...
	 start solving instance: 132...
	 start solving instance: 150...
	 start solving instance: 38...
	 start solving instance: 127...
	 start solving instance: 89...
	 start solving instance: 88...
	 start solving instance: 70...
	 start solving instance: 31...
	 start solving instance: 142...
	 start solving instance: 54...
	 start solving instance: 99...
	 start solving instance: 85...
	 start solving instance: 12...
	 start solving instance: 1...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 131.1104278564453
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.17591631412506104
		 entropy bonus: 0.21139994263648987
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14471900463104248
		 entropy bonus: 0.0011391472071409225
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.015333150513470173
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.784486770629883 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 131.1104278564453
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.17840123176574707
		 entropy bonus: 0.21301844716072083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.14536374807357788
		 entropy bonus: 2.9270871837461243e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.015333150513470173
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.781309127807617 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 131.1104278564453
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.17812108993530273
		 entropy bonus: 0.22040598094463348
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.140921488404274
		 entropy bonus: 1.879055383513517e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.015333150513470173
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.785292625427246 - Differentiable computation graph = True!
PPO iteration: 69/1000:
	 start solving instance: 142...
	 start solving instance: 12...
	 start solving instance: 27...
	 start solving instance: 127...
	 start solving instance: 99...
	 start solving instance: 132...
	 start solving instance: 35...
	 start solving instance: 84...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 85...
	 start solving instance: 79...
	 start solving instance: 121...
	 start solving instance: 88...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 54...
	 start solving instance: 150...
	 start solving instance: 70...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 145.61477661132812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09462722390890121
		 entropy bonus: 0.23105525970458984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06528066098690033
		 entropy bonus: 0.0026485295966267586
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18771369755268097
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14.190485000610352 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 145.61477661132812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09765876829624176
		 entropy bonus: 0.23335938155651093
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06311466544866562
		 entropy bonus: 3.392523414968984e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18771369755268097
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14.189654350280762 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 145.61477661132812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09702416509389877
		 entropy bonus: 0.2351469099521637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06294886767864227
		 entropy bonus: 1.6429348761448637e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18771369755268097
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14.190276145935059 - Differentiable computation graph = True!
PPO iteration: 70/1000:
	 start solving instance: 127...
	 start solving instance: 35...
	 start solving instance: 85...
	 start solving instance: 88...
	 start solving instance: 132...
	 start solving instance: 89...
	 start solving instance: 27...
	 start solving instance: 84...
	 start solving instance: 70...
	 start solving instance: 12...
	 start solving instance: 99...
	 start solving instance: 54...
	 start solving instance: 31...
	 start solving instance: 150...
	 start solving instance: 79...
	 start solving instance: 121...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 142...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 167.8033447265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1819353848695755
		 entropy bonus: 0.22563977539539337
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11821835488080978
		 entropy bonus: 0.0003018980787601322
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20425499975681305
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16.25333023071289 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 167.8033447265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.18336687982082367
		 entropy bonus: 0.21654334664344788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11831706017255783
		 entropy bonus: 0.00011641206219792366
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20425499975681305
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16.252729415893555 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 167.8033447265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.18488872051239014
		 entropy bonus: 0.21688807010650635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11856341361999512
		 entropy bonus: 3.340952389407903e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20425499975681305
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16.250938415527344 - Differentiable computation graph = True!
PPO iteration: 71/1000:
	 New training batch of size 20...
	 start solving instance: 43...
	 start solving instance: 141...
	 start solving instance: 52...
	 start solving instance: 23...
	 start solving instance: 100...
	 start solving instance: 4...
	 start solving instance: 92...
	 start solving instance: 145...
	 start solving instance: 113...
	 start solving instance: 57...
	 start solving instance: 118...
	 start solving instance: 74...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 127...
	 start solving instance: 24...
	 start solving instance: 28...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 137.63365173339844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10572776943445206
		 entropy bonus: 0.23890626430511475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08186839520931244
		 entropy bonus: 2.432252358630649e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2794257402420044
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.483907699584961 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 137.63365173339844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10520940274000168
		 entropy bonus: 0.24190261960029602
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08186846971511841
		 entropy bonus: 1.1233847629910088e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2794257402420044
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.483091354370117 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 137.63365173339844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10585763305425644
		 entropy bonus: 0.2420916110277176
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08180686086416245
		 entropy bonus: 0.0006979138706810772
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2794257402420044
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.483712196350098 - Differentiable computation graph = True!
PPO iteration: 72/1000:
	 start solving instance: 141...
	 start solving instance: 43...
	 start solving instance: 121...
	 start solving instance: 100...
	 start solving instance: 57...
	 start solving instance: 9...
	 start solving instance: 145...
	 start solving instance: 92...
	 start solving instance: 127...
	 start solving instance: 24...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 74...
	 start solving instance: 113...
	 start solving instance: 4...
	 start solving instance: 23...
	 start solving instance: 28...
	 start solving instance: 36...
	 start solving instance: 10...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 104.3359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0500091090798378
		 entropy bonus: 0.2557252049446106
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1266956776380539
		 entropy bonus: 3.5252469388069585e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19804437458515167
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.13329029083252 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 104.3359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04581272602081299
		 entropy bonus: 0.25856930017471313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12331872433423996
		 entropy bonus: 1.1877372116941842e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19804437458515167
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.132185935974121 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 104.3359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04658353328704834
		 entropy bonus: 0.25986286997795105
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12041620165109634
		 entropy bonus: 5.617111673927866e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19804437458515167
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10.135725021362305 - Differentiable computation graph = True!
PPO iteration: 73/1000:
	 start solving instance: 100...
	 start solving instance: 127...
	 start solving instance: 113...
	 start solving instance: 141...
	 start solving instance: 92...
	 start solving instance: 121...
	 start solving instance: 28...
	 start solving instance: 43...
	 start solving instance: 52...
	 start solving instance: 74...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 46...
	 start solving instance: 57...
	 start solving instance: 9...
	 start solving instance: 118...
	 start solving instance: 10...
	 start solving instance: 23...
	 start solving instance: 4...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 94.27411651611328
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10828449577093124
		 entropy bonus: 0.24821949005126953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.16823998093605042
		 entropy bonus: 0.0001874730660347268
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3520257771015167
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.99059009552002 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 94.27411651611328
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1084572821855545
		 entropy bonus: 0.248132586479187
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.16556178033351898
		 entropy bonus: 0.0013675246154889464
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3520257771015167
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.993331909179688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 94.27411651611328
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10630180686712265
		 entropy bonus: 0.2483169585466385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.16710366308689117
		 entropy bonus: 6.049489002180053e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3520257771015167
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.989752769470215 - Differentiable computation graph = True!
PPO iteration: 74/1000:
	 start solving instance: 57...
	 start solving instance: 145...
	 start solving instance: 74...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 92...
	 start solving instance: 141...
	 start solving instance: 23...
	 start solving instance: 118...
	 start solving instance: 46...
	 start solving instance: 113...
	 start solving instance: 127...
	 start solving instance: 28...
	 start solving instance: 100...
	 start solving instance: 52...
	 start solving instance: 36...
	 start solving instance: 4...
	 start solving instance: 121...
	 start solving instance: 24...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 96.5545883178711
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1908315122127533
		 entropy bonus: 0.2453632801771164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.11711788177490234
		 entropy bonus: 0.001794100389815867
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22671878337860107
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.477738380432129 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 96.5545883178711
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19046318531036377
		 entropy bonus: 0.2452632039785385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10882551968097687
		 entropy bonus: 5.239271558821201e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22671878337860107
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.485851287841797 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 96.5545883178711
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19079454243183136
		 entropy bonus: 0.2452765554189682
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.10881998389959335
		 entropy bonus: 2.5688292225822806e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22671878337860107
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.486184120178223 - Differentiable computation graph = True!
PPO iteration: 75/1000:
	 start solving instance: 9...
	 start solving instance: 23...
	 start solving instance: 28...
	 start solving instance: 113...
	 start solving instance: 52...
	 start solving instance: 92...
	 start solving instance: 118...
	 start solving instance: 74...
	 start solving instance: 145...
	 start solving instance: 141...
	 start solving instance: 46...
	 start solving instance: 57...
	 start solving instance: 10...
	 start solving instance: 121...
	 start solving instance: 4...
	 start solving instance: 36...
	 start solving instance: 127...
	 start solving instance: 100...
	 start solving instance: 24...
	 start solving instance: 43...
	 Optimization epoch: 1/3
		 value loss (over batch): 123.5544204711914
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08790849894285202
		 entropy bonus: 0.2413698434829712
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12898308038711548
		 entropy bonus: 3.344040777619739e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22635045647621155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.888063430786133 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 123.5544204711914
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09619667381048203
		 entropy bonus: 0.23965683579444885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12898308038711548
		 entropy bonus: 2.6652875462218617e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22635045647621155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.8799467086792 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 123.5544204711914
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09611048549413681
		 entropy bonus: 0.237850621342659
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.12898308038711548
		 entropy bonus: 3.0017908159152284e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22635045647621155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.880212783813477 - Differentiable computation graph = True!
PPO iteration: 76/1000:
	 start solving instance: 113...
	 start solving instance: 23...
	 start solving instance: 127...
	 start solving instance: 24...
	 start solving instance: 52...
	 start solving instance: 57...
	 start solving instance: 118...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 36...
	 start solving instance: 10...
	 start solving instance: 141...
	 start solving instance: 92...
	 start solving instance: 145...
	 start solving instance: 4...
	 start solving instance: 28...
	 start solving instance: 74...
	 start solving instance: 121...
	 start solving instance: 46...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 125.84735107421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20436835289001465
		 entropy bonus: 0.24888165295124054
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.017759626731276512
		 entropy bonus: 5.56647228311391e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11338251829147339
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.633073806762695 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 125.84735107421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20431630313396454
		 entropy bonus: 0.2476649135351181
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.017759621143341064
		 entropy bonus: 5.3621601381337314e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11338251829147339
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.633142471313477 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 125.84735107421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20432670414447784
		 entropy bonus: 0.24706725776195526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01775868609547615
		 entropy bonus: 5.3126082093513105e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11338251829147339
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.63321304321289 - Differentiable computation graph = True!
PPO iteration: 77/1000:
	 start solving instance: 52...
	 start solving instance: 118...
	 start solving instance: 74...
	 start solving instance: 28...
	 start solving instance: 24...
	 start solving instance: 46...
	 start solving instance: 9...
	 start solving instance: 92...
	 start solving instance: 113...
	 start solving instance: 127...
	 start solving instance: 145...
	 start solving instance: 141...
	 start solving instance: 100...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 23...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 57...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 135.16343688964844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07989328354597092
		 entropy bonus: 0.24224801361560822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07177730649709702
		 entropy bonus: 8.940096449805424e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2251773476600647
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.275049209594727 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 135.16343688964844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07849174737930298
		 entropy bonus: 0.2434282749891281
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07177983969449997
		 entropy bonus: 7.822008774382994e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2251773476600647
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.273528099060059 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 135.16343688964844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07876887172460556
		 entropy bonus: 0.2441672533750534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07178306579589844
		 entropy bonus: 6.520251918118447e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2251773476600647
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.27372932434082 - Differentiable computation graph = True!
PPO iteration: 78/1000:
	 start solving instance: 145...
	 start solving instance: 118...
	 start solving instance: 10...
	 start solving instance: 113...
	 start solving instance: 4...
	 start solving instance: 52...
	 start solving instance: 9...
	 start solving instance: 127...
	 start solving instance: 121...
	 start solving instance: 74...
	 start solving instance: 23...
	 start solving instance: 92...
	 start solving instance: 100...
	 start solving instance: 24...
	 start solving instance: 141...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 124.80500793457031
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09303944557905197
		 entropy bonus: 0.24781234562397003
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.012395995669066906
		 entropy bonus: 6.297742220340297e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10003045946359634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.43632698059082 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 124.80500793457031
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09164474159479141
		 entropy bonus: 0.24867816269397736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01240167673677206
		 entropy bonus: 4.4922209781361744e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10003045946359634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.434842109680176 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 124.80500793457031
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09135281294584274
		 entropy bonus: 0.2496878206729889
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01240526419132948
		 entropy bonus: 6.851946091046557e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10003045946359634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12.434442520141602 - Differentiable computation graph = True!
PPO iteration: 79/1000:
	 start solving instance: 24...
	 start solving instance: 121...
	 start solving instance: 10...
	 start solving instance: 23...
	 start solving instance: 28...
	 start solving instance: 36...
	 start solving instance: 113...
	 start solving instance: 118...
	 start solving instance: 141...
	 start solving instance: 43...
	 start solving instance: 145...
	 start solving instance: 4...
	 start solving instance: 74...
	 start solving instance: 46...
	 start solving instance: 52...
	 start solving instance: 100...
	 start solving instance: 9...
	 start solving instance: 57...
	 start solving instance: 92...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 122.6773681640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08531846106052399
		 entropy bonus: 0.24882833659648895
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04793928191065788
		 entropy bonus: 4.247937823720349e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11657293885946274
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.993023872375488 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 122.6773681640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0876423642039299
		 entropy bonus: 0.2505677342414856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04793928191065788
		 entropy bonus: 7.633975229737189e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11657293885946274
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.990525245666504 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 122.6773681640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09011352807283401
		 entropy bonus: 0.2527253329753876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04793928191065788
		 entropy bonus: 2.696330048124196e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11657293885946274
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.987838745117188 - Differentiable computation graph = True!
PPO iteration: 80/1000:
	 start solving instance: 28...
	 start solving instance: 24...
	 start solving instance: 36...
	 start solving instance: 52...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 145...
	 start solving instance: 43...
	 start solving instance: 127...
	 start solving instance: 23...
	 start solving instance: 46...
	 start solving instance: 100...
	 start solving instance: 118...
	 start solving instance: 141...
	 start solving instance: 113...
	 start solving instance: 74...
	 start solving instance: 57...
	 start solving instance: 92...
	 start solving instance: 4...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 121.80183410644531
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.058110784739255905
		 entropy bonus: 0.24753490090370178
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1069667860865593
		 entropy bonus: 1.8083261466017575e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.217197448015213
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.889376640319824 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 121.80183410644531
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05536936596035957
		 entropy bonus: 0.24717512726783752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1069667860865593
		 entropy bonus: 9.942304046717254e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.217197448015213
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.88667106628418 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 121.80183410644531
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05378227308392525
		 entropy bonus: 0.2463918775320053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.1069667860865593
		 entropy bonus: 1.6602565722223517e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.217197448015213
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11.885162353515625 - Differentiable computation graph = True!
PPO iteration: 81/1000:
	 New training batch of size 20...
	 start solving instance: 72...
	 start solving instance: 3...
	 start solving instance: 35...
	 start solving instance: 128...
	 start solving instance: 44...
	 start solving instance: 104...
	 start solving instance: 98...
	 start solving instance: 106...
	 start solving instance: 42...
	 start solving instance: 91...
	 start solving instance: 6...
	 start solving instance: 67...
	 start solving instance: 111...
	 start solving instance: 127...
	 start solving instance: 16...
	 start solving instance: 55...
	 start solving instance: 99...
	 start solving instance: 121...
	 start solving instance: 52...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 133.57119750976562
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.053712647408246994
		 entropy bonus: 0.23228393495082855
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01419130153954029
		 entropy bonus: 0.0024086222983896732
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13710710406303406
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.128639221191406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 133.57119750976562
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05271558091044426
		 entropy bonus: 0.23446503281593323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01502932608127594
		 entropy bonus: 2.785889421375032e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13710710406303406
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.128820419311523 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 133.57119750976562
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05346158891916275
		 entropy bonus: 0.23384752869606018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0132967634126544
		 entropy bonus: 0.0010615227511152625
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13710710406303406
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13.12976360321045 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 201.6966552734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.15906739234924316
		 entropy bonus: 0.24225948750972748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09477266669273376
		 entropy bonus: 0.0005050645559094846
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.027253733947873116
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19.8643
PPO iteration: 82/1000:
	 start solving instance: 72...
	 start solving instance: 16...
	 start solving instance: 52...
	 start solving instance: 111...
	 start solving instance: 35...
	 start solving instance: 99...
	 start solving instance: 127...
	 start solving instance: 6...
	 start solving instance: 121...
	 start solving instance: 91...
	 start solving instance: 104...
	 start solving instance: 106...
	 start solving instance: 55...
	 start solving instance: 128...
	 start solving instance: 145...
	 start solving instance: 3...
	 start solving instance: 42...
	 start solving instance: 44...
	 start solving instance: 67...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 192.9668426513672
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11243730783462524
		 entropy bonus: 0.23990757763385773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0706777423620224
		 entropy bonus: 1.0765908164955817e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1932382583618164
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18.896339416503906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 192.9668426513672
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11495742946863174
		 entropy bonus: 0.24026215076446533
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.070677749812603
		 entropy bonus: 1.4491158923865544e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1932382583618164
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18.89378547668457 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 192.9668426513672
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11481349915266037
		 entropy bonus: 0.2406599074602127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.070677749812603
		 entropy bonus: 2.1069711253485224e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1932382583618164
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18.893888473510742 - Differentiable computation graph = True!
PPO iteration: 83/1000:
	 start solving instance: 16...
	 start solving instance: 3...
	 start solving instance: 72...
	 start solving instance: 128...
	 start solving instance: 44...
	 start solving instance: 111...
	 start solving instance: 35...
	 start solving instance: 104...
	 start solving instance: 145...
	 start solving instance: 42...
	 start solving instance: 121...
	 start solving instance: 55...
	 start solving instance: 99...
	 start solving instance: 98...
	 start solving instance: 67...
	 start solving instance: 106...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 127...
	 start solving instance: 6...
	 Optimization epoch: 1/3
		 value loss (over batch): 204.69586181640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02946445345878601
		 entropy bonus: 0.2344881296157837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.052954256534576416
		 entropy bonus: 0.0013803619658574462
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09563102573156357
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20.326879501342773 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 204.69586181640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.027059702202677727
		 entropy bonus: 0.23451785743236542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04983511194586754
		 entropy bonus: 0.0016960134962573647
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09563102573156357
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20.327560424804688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 204.69586181640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.023946577683091164
		 entropy bonus: 0.23438313603401184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04059194028377533
		 entropy bonus: 0.0013955541653558612
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09563102573156357
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20.33373260498047 - Differentiable computation graph = True!
PPO iteration: 84/1000:
	 start solving instance: 72...
	 start solving instance: 104...
	 start solving instance: 127...
	 start solving instance: 6...
	 start solving instance: 121...
	 start solving instance: 3...
	 start solving instance: 98...
	 start solving instance: 128...
	 start solving instance: 55...
	 start solving instance: 52...
	 start solving instance: 111...
	 start solving instance: 67...
	 start solving instance: 44...
	 start solving instance: 106...
	 start solving instance: 99...
	 start solving instance: 42...
	 start solving instance: 91...
	 start solving instance: 16...
	 start solving instance: 35...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 215.8811492919922
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08299105614423752
		 entropy bonus: 0.23084819316864014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0640348568558693
		 entropy bonus: 5.0850917432399e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006210896652191877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21.424217224121094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 215.8811492919922
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08537663519382477
		 entropy bonus: 0.23109178245067596
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06401807814836502
		 entropy bonus: 4.67910103907343e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006210896652191877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21.421817779541016 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 215.8811492919922
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08859304338693619
		 entropy bonus: 0.23078763484954834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05972288176417351
		 entropy bonus: 0.004240832291543484
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006210896652191877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21.422508239746094 - Differentiable computation graph = True!
PPO iteration: 85/1000:
	 start solving instance: 55...
	 start solving instance: 106...
	 start solving instance: 145...
	 start solving instance: 91...
	 start solving instance: 98...
	 start solving instance: 121...
	 start solving instance: 104...
	 start solving instance: 52...
	 start solving instance: 127...
	 start solving instance: 3...
	 start solving instance: 128...
	 start solving instance: 16...
	 start solving instance: 99...
	 start solving instance: 72...
	 start solving instance: 42...
	 start solving instance: 111...
	 start solving instance: 6...
	 start solving instance: 67...
	 start solving instance: 35...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 242.7986297607422
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0676850900053978
		 entropy bonus: 0.2406426966190338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02186737023293972
		 entropy bonus: 0.0016534917522221804
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0975472554564476
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24.442733764648438 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 242.7986297607422
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06655751913785934
		 entropy bonus: 0.24136820435523987
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.023915577679872513
		 entropy bonus: 1.1580669196446521e-18
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0975472554564476
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24.443748474121094 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 242.7986297607422
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06634598970413208
		 entropy bonus: 0.2411889135837555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.023915577679872513
		 entropy bonus: 1.401298464324817e-45
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0975472554564476
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24.443553924560547 - Differentiable computation graph = True!
PPO iteration: 86/1000:
	 start solving instance: 35...
	 start solving instance: 44...
	 start solving instance: 16...
	 start solving instance: 127...
	 start solving instance: 99...
	 start solving instance: 72...
	 start solving instance: 3...
	 start solving instance: 104...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 98...
	 start solving instance: 42...
	 start solving instance: 52...
	 start solving instance: 6...
	 start solving instance: 111...
	 start solving instance: 106...
	 start solving instance: 67...
	 start solving instance: 91...
	 start solving instance: 128...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 331.461669921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1622624695301056
		 entropy bonus: 0.2377346009016037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012047952972352505
		 entropy bonus: 9.385608734646667e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.027067359536886215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 33.26963806152344 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 331.461669921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15903741121292114
		 entropy bonus: 0.23962977528572083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012047943659126759
		 entropy bonus: 3.712899044071077e-15
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.027067359536886215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 33.2662239074707 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 331.461669921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15425615012645721
		 entropy bonus: 0.23756800591945648
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012047943659126759
		 entropy bonus: 4.422054886567921e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.027067359536886215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 33.26165008544922 - Differentiable computation graph = True!
PPO iteration: 87/1000:
	 start solving instance: 3...
	 start solving instance: 111...
	 start solving instance: 52...
	 start solving instance: 44...
	 start solving instance: 6...
	 start solving instance: 42...
	 start solving instance: 127...
	 start solving instance: 72...
	 start solving instance: 98...
	 start solving instance: 35...
	 start solving instance: 121...
	 start solving instance: 99...
	 start solving instance: 128...
	 start solving instance: 16...
	 start solving instance: 55...
	 start solving instance: 91...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 104...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 478.19287109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2698248326778412
		 entropy bonus: 0.23249678313732147
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03385522961616516
		 entropy bonus: 4.863603582004365e-23
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11576507240533829
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 47.983951568603516 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 478.19287109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.266685426235199
		 entropy bonus: 0.23011913895606995
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03385522961616516
		 entropy bonus: 5.1988883993850205e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11576507240533829
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 47.98105239868164 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 478.19287109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.26599064469337463
		 entropy bonus: 0.22910669445991516
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03385522961616516
		 entropy bonus: 1.4945604635921739e-25
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11576507240533829
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 47.9804573059082 - Differentiable computation graph = True!
PPO iteration: 88/1000:
	 start solving instance: 128...
	 start solving instance: 67...
	 start solving instance: 99...
	 start solving instance: 121...
	 start solving instance: 111...
	 start solving instance: 35...
	 start solving instance: 104...
	 start solving instance: 106...
	 start solving instance: 6...
	 start solving instance: 55...
	 start solving instance: 16...
	 start solving instance: 145...
	 start solving instance: 3...
	 start solving instance: 72...
	 start solving instance: 127...
	 start solving instance: 44...
	 start solving instance: 42...
	 start solving instance: 52...
	 start solving instance: 91...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 590.51904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21594694256782532
		 entropy bonus: 0.22691182792186737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.00885151606053114
		 entropy bonus: 1.143358803808943e-31
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1935422420501709
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59.06047058105469 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 590.51904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2150869220495224
		 entropy bonus: 0.22591765224933624
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.00885151606053114
		 entropy bonus: 1.2926699787009548e-32
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1935422420501709
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59.05970764160156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 590.51904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2135000079870224
		 entropy bonus: 0.22429011762142181
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.00885151606053114
		 entropy bonus: 4.2794262693557025e-32
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1935422420501709
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59.058284759521484 - Differentiable computation graph = True!
PPO iteration: 89/1000:
	 start solving instance: 128...
	 start solving instance: 67...
	 start solving instance: 111...
	 start solving instance: 91...
	 start solving instance: 98...
	 start solving instance: 72...
	 start solving instance: 145...
	 start solving instance: 52...
	 start solving instance: 42...
	 start solving instance: 121...
	 start solving instance: 55...
	 start solving instance: 6...
	 start solving instance: 99...
	 start solving instance: 106...
	 start solving instance: 104...
	 start solving instance: 16...
	 start solving instance: 127...
	 start solving instance: 35...
	 start solving instance: 44...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 639.2203369140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1123918816447258
		 entropy bonus: 0.21882514655590057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.005325490143150091
		 entropy bonus: 1.2075941863172541e-29
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10133523494005203
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 63.9058837890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 639.2203369140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11087806522846222
		 entropy bonus: 0.21753530204296112
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.005325490143150091
		 entropy bonus: 2.63634019980951e-29
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10133523494005203
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 63.904502868652344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 639.2203369140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11075347661972046
		 entropy bonus: 0.2170340120792389
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.005325490143150091
		 entropy bonus: 3.850290932954542e-30
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10133523494005203
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 63.90442657470703 - Differentiable computation graph = True!
PPO iteration: 90/1000:
	 start solving instance: 72...
	 start solving instance: 104...
	 start solving instance: 44...
	 start solving instance: 16...
	 start solving instance: 52...
	 start solving instance: 99...
	 start solving instance: 111...
	 start solving instance: 145...
	 start solving instance: 106...
	 start solving instance: 6...
	 start solving instance: 128...
	 start solving instance: 35...
	 start solving instance: 121...
	 start solving instance: 91...
	 start solving instance: 3...
	 start solving instance: 98...
	 start solving instance: 55...
	 start solving instance: 127...
	 start solving instance: 42...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 710.96484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09498883783817291
		 entropy bonus: 0.2103734314441681
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.018087496981024742
		 entropy bonus: 4.363001364038509e-19
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22625456750392914
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 70.92610168457031 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 710.96484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09454547613859177
		 entropy bonus: 0.20980492234230042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.018087496981024742
		 entropy bonus: 4.1303719884415446e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22625456750392914
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 70.92571258544922 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 710.96484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09429202973842621
		 entropy bonus: 0.20943580567836761
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.018087496981024742
		 entropy bonus: 1.552460133780187e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22625456750392914
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 70.92549896240234 - Differentiable computation graph = True!
PPO iteration: 91/1000:
	 New training batch of size 20...
	 start solving instance: 79...
	 start solving instance: 145...
	 start solving instance: 70...
	 start solving instance: 107...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 76...
	 start solving instance: 67...
	 start solving instance: 129...
	 start solving instance: 120...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 87...
	 start solving instance: 146...
	 start solving instance: 24...
	 start solving instance: 1...
	 start solving instance: 56...
	 start solving instance: 36...
	 start solving instance: 72...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 781.7938842773438
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14373497664928436
		 entropy bonus: 0.2248004972934723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06898238509893417
		 entropy bonus: 2.9008665735321207e-19
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10162900388240814
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 78.26799774169922 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 781.7938842773438
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14192882180213928
		 entropy bonus: 0.2245609611272812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06898238509893417
		 entropy bonus: 1.9738771850457083e-19
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10162900388240814
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 78.26622009277344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 781.7938842773438
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1392253190279007
		 entropy bonus: 0.2242099493741989
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06898238509893417
		 entropy bonus: 1.2077859286812531e-19
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10162900388240814
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 78.2635498046875 - Differentiable computation graph = True!
PPO iteration: 92/1000:
	 start solving instance: 120...
	 start solving instance: 87...
	 start solving instance: 79...
	 start solving instance: 24...
	 start solving instance: 134...
	 start solving instance: 129...
	 start solving instance: 146...
	 start solving instance: 70...
	 start solving instance: 107...
	 start solving instance: 67...
	 start solving instance: 56...
	 start solving instance: 76...
	 start solving instance: 103...
	 start solving instance: 1...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 118...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 794.396484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11923954635858536
		 entropy bonus: 0.2256845086812973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.030114948749542236
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08970504254102707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.41650390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 794.396484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11713764816522598
		 entropy bonus: 0.22563789784908295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.030114948749542236
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08970504254102707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.4144058227539 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 794.396484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11599278450012207
		 entropy bonus: 0.22575874626636505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.030114948749542236
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08970504254102707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.41324615478516 - Differentiable computation graph = True!
PPO iteration: 93/1000:
	 start solving instance: 87...
	 start solving instance: 120...
	 start solving instance: 79...
	 start solving instance: 24...
	 start solving instance: 146...
	 start solving instance: 36...
	 start solving instance: 56...
	 start solving instance: 70...
	 start solving instance: 67...
	 start solving instance: 107...
	 start solving instance: 114...
	 start solving instance: 1...
	 start solving instance: 96...
	 start solving instance: 134...
	 start solving instance: 103...
	 start solving instance: 72...
	 start solving instance: 76...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 786.0645751953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29141661524772644
		 entropy bonus: 0.2401323765516281
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011799067258834839
		 entropy bonus: 1.3004041713328389e-34
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22670233249664307
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 78.6589584350586 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 786.0645751953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29169729351997375
		 entropy bonus: 0.24009762704372406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011799067258834839
		 entropy bonus: 1.0308276716598096e-30
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22670233249664307
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 78.65924072265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 786.0645751953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2910204827785492
		 entropy bonus: 0.24013100564479828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011799067258834839
		 entropy bonus: 6.60247604461386e-29
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22670233249664307
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 78.65856170654297 - Differentiable computation graph = True!
PPO iteration: 94/1000:
	 start solving instance: 146...
	 start solving instance: 129...
	 start solving instance: 67...
	 start solving instance: 87...
	 start solving instance: 145...
	 start solving instance: 103...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 70...
	 start solving instance: 118...
	 start solving instance: 79...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 56...
	 start solving instance: 134...
	 start solving instance: 120...
	 start solving instance: 24...
	 start solving instance: 72...
	 start solving instance: 76...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 795.3921508789062
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10472037643194199
		 entropy bonus: 0.2308778017759323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0024615288712084293
		 entropy bonus: 4.152041566542375e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08438841998577118
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.53399658203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 795.3921508789062
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10441341251134872
		 entropy bonus: 0.2308613359928131
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0024615288712084293
		 entropy bonus: 4.172364844893178e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08438841998577118
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.53369140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 795.3921508789062
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10277249664068222
		 entropy bonus: 0.23084001243114471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0024615288712084293
		 entropy bonus: 4.46974192966096e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08438841998577118
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.53205108642578 - Differentiable computation graph = True!
PPO iteration: 95/1000:
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 120...
	 start solving instance: 24...
	 start solving instance: 72...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 70...
	 start solving instance: 145...
	 start solving instance: 76...
	 start solving instance: 67...
	 start solving instance: 96...
	 start solving instance: 56...
	 start solving instance: 36...
	 start solving instance: 114...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 79...
	 start solving instance: 129...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 806.2189331054688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18108254671096802
		 entropy bonus: 0.22719994187355042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06449615955352783
		 entropy bonus: 2.3464748109228595e-15
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.009741179645061493
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 80.83501434326172 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 806.2189331054688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.17887790501117706
		 entropy bonus: 0.22710923850536346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06449615955352783
		 entropy bonus: 1.3826330705346557e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.009741179645061493
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 80.83281707763672 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 806.2189331054688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1767011433839798
		 entropy bonus: 0.22698675096035004
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06449615955352783
		 entropy bonus: 4.918258689201593e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.009741179645061493
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 80.83065032958984 - Differentiable computation graph = True!
PPO iteration: 96/1000:
	 start solving instance: 76...
	 start solving instance: 36...
	 start solving instance: 118...
	 start solving instance: 79...
	 start solving instance: 114...
	 start solving instance: 146...
	 start solving instance: 70...
	 start solving instance: 134...
	 start solving instance: 107...
	 start solving instance: 67...
	 start solving instance: 103...
	 start solving instance: 120...
	 start solving instance: 129...
	 start solving instance: 145...
	 start solving instance: 87...
	 start solving instance: 56...
	 start solving instance: 24...
	 start solving instance: 72...
	 start solving instance: 96...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 794.1069946289062
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07961522042751312
		 entropy bonus: 0.22678056359291077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0007937818882055581
		 entropy bonus: 2.061230297556449e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.29434067010879517
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.17250061035156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 794.1069946289062
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07861620932817459
		 entropy bonus: 0.22666068375110626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0007937818882055581
		 entropy bonus: 1.859803533399429e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.29434067010879517
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.1715087890625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 794.1069946289062
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07745834439992905
		 entropy bonus: 0.22648806869983673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0007937818882055581
		 entropy bonus: 1.89865653852251e-14
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.29434067010879517
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 79.17037200927734 - Differentiable computation graph = True!
PPO iteration: 97/1000:
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 134...
	 start solving instance: 114...
	 start solving instance: 70...
	 start solving instance: 107...
	 start solving instance: 129...
	 start solving instance: 120...
	 start solving instance: 72...
	 start solving instance: 67...
	 start solving instance: 56...
	 start solving instance: 1...
	 start solving instance: 36...
	 start solving instance: 76...
	 start solving instance: 145...
	 start solving instance: 79...
	 start solving instance: 24...
	 start solving instance: 96...
	 start solving instance: 118...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 839.0785522460938
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04375256225466728
		 entropy bonus: 0.2277430295944214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.061896052211523056
		 entropy bonus: 1.0084527201500488e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.30563512444496155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 83.56130981445312 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 839.0785522460938
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04348089173436165
		 entropy bonus: 0.22766152024269104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.061896052211523056
		 entropy bonus: 6.266126164670206e-26
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.30563512444496155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 83.56104278564453 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 839.0785522460938
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0429251566529274
		 entropy bonus: 0.22750885784626007
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.061896052211523056
		 entropy bonus: 1.504755843311059e-31
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.30563512444496155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 83.56050109863281 - Differentiable computation graph = True!
PPO iteration: 98/1000:
	 start solving instance: 87...
	 start solving instance: 120...
	 start solving instance: 96...
	 start solving instance: 67...
	 start solving instance: 107...
	 start solving instance: 114...
	 start solving instance: 145...
	 start solving instance: 1...
	 start solving instance: 146...
	 start solving instance: 70...
	 start solving instance: 79...
	 start solving instance: 36...
	 start solving instance: 72...
	 start solving instance: 76...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 134...
	 start solving instance: 56...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 889.05615234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08091621845960617
		 entropy bonus: 0.22605080902576447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0010791242821142077
		 entropy bonus: 2.6670608748948406e-37
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17251595854759216
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 88.79248809814453 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 889.05615234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08080196380615234
		 entropy bonus: 0.22602605819702148
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0010791242821142077
		 entropy bonus: 5.100726410142334e-43
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17251595854759216
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 88.79237365722656 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 889.05615234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08039291203022003
		 entropy bonus: 0.2258894294500351
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0010791242821142077
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17251595854759216
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 88.79197692871094 - Differentiable computation graph = True!
PPO iteration: 99/1000:
	 start solving instance: 56...
	 start solving instance: 134...
	 start solving instance: 72...
	 start solving instance: 79...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 129...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 118...
	 start solving instance: 96...
	 start solving instance: 36...
	 start solving instance: 24...
	 start solving instance: 120...
	 start solving instance: 114...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 872.4566650390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.23530983924865723
		 entropy bonus: 0.2301636040210724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11707701534032822
		 entropy bonus: 7.556174534430433e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16934801638126373
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 87.40569305419922 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 872.4566650390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2353363335132599
		 entropy bonus: 0.23012475669384003
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11707701534032822
		 entropy bonus: 3.082345088541368e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16934801638126373
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 87.40572357177734 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 872.4566650390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.23536930978298187
		 entropy bonus: 0.23009715974330902
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11707701534032822
		 entropy bonus: 9.13166231098371e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16934801638126373
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 87.40575408935547 - Differentiable computation graph = True!
PPO iteration: 100/1000:
	 start solving instance: 103...
	 start solving instance: 1...
	 start solving instance: 67...
	 start solving instance: 114...
	 start solving instance: 56...
	 start solving instance: 120...
	 start solving instance: 76...
	 start solving instance: 107...
	 start solving instance: 79...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 87...
	 start solving instance: 118...
	 start solving instance: 145...
	 start solving instance: 72...
	 start solving instance: 146...
	 start solving instance: 134...
	 start solving instance: 24...
	 start solving instance: 70...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 897.97265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0575273334980011
		 entropy bonus: 0.22195017337799072
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05028459057211876
		 entropy bonus: 1.0508284230766507e-25
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15771260857582092
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 89.62459564208984 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 897.97265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05750961974263191
		 entropy bonus: 0.221941277384758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05028459057211876
		 entropy bonus: 1.7048299820241537e-25
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15771260857582092
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 89.62458038330078 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 897.97265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05747037008404732
		 entropy bonus: 0.22195687890052795
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05028459057211876
		 entropy bonus: 2.4817243603510285e-25
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15771260857582092
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 89.62454223632812 - Differentiable computation graph = True!
PPO iteration: 101/1000:
	 New training batch of size 20...
	 start solving instance: 31...
	 start solving instance: 25...
	 start solving instance: 17...
	 start solving instance: 50...
	 start solving instance: 120...
	 start solving instance: 55...
	 start solving instance: 74...
	 start solving instance: 78...
	 start solving instance: 76...
	 start solving instance: 106...
	 start solving instance: 12...
	 start solving instance: 41...
	 start solving instance: 125...
	 start solving instance: 72...
	 start solving instance: 14...
	 start solving instance: 149...
	 start solving instance: 124...
	 start solving instance: 119...
	 start solving instance: 22...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 936.4278564453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1672937124967575
		 entropy bonus: 0.21291330456733704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14892427623271942
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03518088534474373
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 93.97289276123047 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 936.4278564453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.17677931487560272
		 entropy bonus: 0.21245670318603516
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14892427623271942
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03518088534474373
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 93.982421875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 936.4278564453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1655033826828003
		 entropy bonus: 0.21196268498897552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14892427623271942
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03518088534474373
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 93.97119903564453 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 917.751953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21421901881694794
		 entropy bonus: 0.21573053300380707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09575032442808151
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09709233790636063
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 91.9665
PPO iteration: 102/1000:
	 start solving instance: 41...
	 start solving instance: 12...
	 start solving instance: 125...
	 start solving instance: 124...
	 start solving instance: 50...
	 start solving instance: 106...
	 start solving instance: 78...
	 start solving instance: 22...
	 start solving instance: 149...
	 start solving instance: 72...
	 start solving instance: 120...
	 start solving instance: 76...
	 start solving instance: 119...
	 start solving instance: 31...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 25...
	 start solving instance: 74...
	 start solving instance: 17...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 925.8917236328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015513933263719082
		 entropy bonus: 0.21420417726039886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06946761906147003
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2543881833553314
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.36731719970703 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 925.8917236328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015508532524108887
		 entropy bonus: 0.2141118347644806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06946761906147003
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2543881833553314
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.3673324584961 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 925.8917236328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01552619319409132
		 entropy bonus: 0.21406367421150208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06946761906147003
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2543881833553314
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.36731719970703 - Differentiable computation graph = True!
PPO iteration: 103/1000:
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 14...
	 start solving instance: 17...
	 start solving instance: 120...
	 start solving instance: 106...
	 start solving instance: 76...
	 start solving instance: 31...
	 start solving instance: 78...
	 start solving instance: 22...
	 start solving instance: 12...
	 start solving instance: 125...
	 start solving instance: 124...
	 start solving instance: 119...
	 start solving instance: 50...
	 start solving instance: 72...
	 start solving instance: 41...
	 start solving instance: 149...
	 start solving instance: 55...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 933.0724487304688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05686340481042862
		 entropy bonus: 0.20930390059947968
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.057950735092163086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17750681936740875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 93.22362518310547 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 933.0724487304688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.056710150092840195
		 entropy bonus: 0.209028959274292
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.057950735092163086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17750681936740875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 93.22349548339844 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 933.0724487304688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.056689001619815826
		 entropy bonus: 0.20902590453624725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.057950735092163086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17750681936740875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 93.22348022460938 - Differentiable computation graph = True!
PPO iteration: 104/1000:
	 start solving instance: 76...
	 start solving instance: 125...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 119...
	 start solving instance: 74...
	 start solving instance: 12...
	 start solving instance: 78...
	 start solving instance: 17...
	 start solving instance: 72...
	 start solving instance: 31...
	 start solving instance: 20...
	 start solving instance: 149...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 120...
	 start solving instance: 50...
	 start solving instance: 25...
	 start solving instance: 106...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 929.5059814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14564958214759827
		 entropy bonus: 0.20821790397167206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07821699976921082
		 entropy bonus: 0.0009528050431981683
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25376641750335693
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.8997802734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 929.5059814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14558446407318115
		 entropy bonus: 0.20818853378295898
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07769458740949631
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25376641750335693
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.8992919921875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 929.5059814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14559273421764374
		 entropy bonus: 0.20829248428344727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07769458740949631
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25376641750335693
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.8992919921875 - Differentiable computation graph = True!
PPO iteration: 105/1000:
	 start solving instance: 17...
	 start solving instance: 41...
	 start solving instance: 120...
	 start solving instance: 72...
	 start solving instance: 12...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 106...
	 start solving instance: 125...
	 start solving instance: 31...
	 start solving instance: 78...
	 start solving instance: 50...
	 start solving instance: 119...
	 start solving instance: 76...
	 start solving instance: 149...
	 start solving instance: 74...
	 start solving instance: 25...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 929.2609252929688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.00605128426104784
		 entropy bonus: 0.20915070176124573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.029991058632731438
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13658766448497772
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.80463409423828 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 929.2609252929688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.006101596634835005
		 entropy bonus: 0.20922179520130157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.029991058632731438
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13658766448497772
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.80467224121094 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 929.2609252929688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.006129807326942682
		 entropy bonus: 0.2091604322195053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.029991058632731438
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13658766448497772
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 92.8047103881836 - Differentiable computation graph = True!
PPO iteration: 106/1000:
	 start solving instance: 50...
	 start solving instance: 20...
	 start solving instance: 76...
	 start solving instance: 78...
	 start solving instance: 125...
	 start solving instance: 22...
	 start solving instance: 41...
	 start solving instance: 31...
	 start solving instance: 74...
	 start solving instance: 55...
	 start solving instance: 106...
	 start solving instance: 25...
	 start solving instance: 12...
	 start solving instance: 149...
	 start solving instance: 17...
	 start solving instance: 72...
	 start solving instance: 124...
	 start solving instance: 120...
	 start solving instance: 14...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 900.8287353515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028059078380465508
		 entropy bonus: 0.2207171767950058
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06159483268857002
		 entropy bonus: 9.090878343157695e-32
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11607089638710022
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 89.978271484375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 900.8287353515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028116369619965553
		 entropy bonus: 0.22071848809719086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06159483268857002
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11607089638710022
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 89.97821807861328 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 900.8287353515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028026962652802467
		 entropy bonus: 0.2207144796848297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06159483268857002
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11607089638710022
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 89.97830963134766 - Differentiable computation graph = True!
PPO iteration: 107/1000:
	 start solving instance: 119...
	 start solving instance: 72...
	 start solving instance: 25...
	 start solving instance: 41...
	 start solving instance: 106...
	 start solving instance: 31...
	 start solving instance: 12...
	 start solving instance: 120...
	 start solving instance: 76...
	 start solving instance: 14...
	 start solving instance: 17...
	 start solving instance: 74...
	 start solving instance: 149...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 125...
	 start solving instance: 78...
	 start solving instance: 20...
	 start solving instance: 50...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 873.3788452148438
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.008546781726181507
		 entropy bonus: 0.20363616943359375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.045969732105731964
		 entropy bonus: 1.2315403772868378e-15
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15247386693954468
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 87.21955871582031 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 873.3788452148438
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02996199205517769
		 entropy bonus: 0.20549216866493225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04999290034174919
		 entropy bonus: 5.9890331757292795e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15247386693954468
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 87.24481964111328 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 873.3788452148438
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.015191174112260342
		 entropy bonus: 0.20389409363269806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04999290034174919
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15247386693954468
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 87.23020935058594 - Differentiable computation graph = True!
PPO iteration: 108/1000:
	 start solving instance: 124...
	 start solving instance: 125...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 31...
	 start solving instance: 78...
	 start solving instance: 17...
	 start solving instance: 119...
	 start solving instance: 12...
	 start solving instance: 22...
	 start solving instance: 106...
	 start solving instance: 41...
	 start solving instance: 50...
	 start solving instance: 74...
	 start solving instance: 76...
	 start solving instance: 149...
	 start solving instance: 120...
	 start solving instance: 72...
	 start solving instance: 25...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 264.23883056640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14537015557289124
		 entropy bonus: 0.21314339339733124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0012648225529119372
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17263096570968628
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26.083303451538086 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 264.23883056640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13447628915309906
		 entropy bonus: 0.21947956085205078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0006170719861984253
		 entropy bonus: 9.14880175176975e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17263096570968628
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26.09421157836914 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 264.23883056640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1318884938955307
		 entropy bonus: 0.2278737872838974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0006170719861984253
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17263096570968628
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26.095958709716797 - Differentiable computation graph = True!
PPO iteration: 109/1000:
	 start solving instance: 50...
	 start solving instance: 22...
	 start solving instance: 31...
	 start solving instance: 106...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 76...
	 start solving instance: 149...
	 start solving instance: 41...
	 start solving instance: 78...
	 start solving instance: 125...
	 start solving instance: 72...
	 start solving instance: 74...
	 start solving instance: 119...
	 start solving instance: 25...
	 start solving instance: 124...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 183.8673553466797
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03939668461680412
		 entropy bonus: 0.22384443879127502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.042521893978118896
		 entropy bonus: 2.883606100567704e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08912312984466553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18.27835464477539 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 183.8673553466797
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04010346159338951
		 entropy bonus: 0.22386407852172852
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04252208396792412
		 entropy bonus: 3.1110150757740485e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08912312984466553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18.27764320373535 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 183.8673553466797
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03688246011734009
		 entropy bonus: 0.23073823750019073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04252399131655693
		 entropy bonus: 2.368700734223239e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08912312984466553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18.28017807006836 - Differentiable computation graph = True!
PPO iteration: 110/1000:
	 start solving instance: 17...
	 start solving instance: 55...
	 start solving instance: 125...
	 start solving instance: 119...
	 start solving instance: 31...
	 start solving instance: 41...
	 start solving instance: 12...
	 start solving instance: 22...
	 start solving instance: 72...
	 start solving instance: 124...
	 start solving instance: 74...
	 start solving instance: 106...
	 start solving instance: 120...
	 start solving instance: 20...
	 start solving instance: 50...
	 start solving instance: 76...
	 start solving instance: 149...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 163.05442810058594
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05334511026740074
		 entropy bonus: 0.2216116487979889
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1797485500574112
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.023103946819901466
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16.539478302001953 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 163.05442810058594
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0423237681388855
		 entropy bonus: 0.21008096635341644
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1797485500574112
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.023103946819901466
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16.529611587524414 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 163.05442810058594
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04257867485284805
		 entropy bonus: 0.20767705142498016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1797485500574112
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.023103946819901466
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16.530105590820312 - Differentiable computation graph = True!
PPO iteration: 111/1000:
	 New training batch of size 20...
	 start solving instance: 134...
	 start solving instance: 116...
	 start solving instance: 57...
	 start solving instance: 126...
	 start solving instance: 50...
	 start solving instance: 72...
	 start solving instance: 104...
	 start solving instance: 39...
	 start solving instance: 101...
	 start solving instance: 44...
	 start solving instance: 146...
	 start solving instance: 16...
	 start solving instance: 123...
	 start solving instance: 100...
	 start solving instance: 18...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 90...
	 start solving instance: 142...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 339.2636413574219
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14618586003780365
		 entropy bonus: 0.2242862731218338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09180944412946701
		 entropy bonus: 1.4614577992233535e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0017081568948924541
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34.143638610839844 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 339.2636413574219
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1459270566701889
		 entropy bonus: 0.2241104692220688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09180944412946701
		 entropy bonus: 1.0420882290418376e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0017081568948924541
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34.14339828491211 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 339.2636413574219
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14610213041305542
		 entropy bonus: 0.22394905984401703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09180944412946701
		 entropy bonus: 2.5341827836200537e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0017081568948924541
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34.14358901977539 - Differentiable computation graph = True!
PPO iteration: 112/1000:
	 start solving instance: 87...
	 start solving instance: 104...
	 start solving instance: 100...
	 start solving instance: 9...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 18...
	 start solving instance: 146...
	 start solving instance: 123...
	 start solving instance: 116...
	 start solving instance: 57...
	 start solving instance: 142...
	 start solving instance: 88...
	 start solving instance: 44...
	 start solving instance: 39...
	 start solving instance: 16...
	 start solving instance: 90...
	 start solving instance: 101...
	 start solving instance: 72...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 458.0308532714844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09716206043958664
		 entropy bonus: 0.21732640266418457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10798859596252441
		 entropy bonus: 0.0021432924550026655
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0869402065873146
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46.07322692871094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 458.0308532714844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09653480350971222
		 entropy bonus: 0.21725688874721527
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1264970600605011
		 entropy bonus: 0.002063542837277055
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0869402065873146
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46.09112548828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 458.0308532714844
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09623856842517853
		 entropy bonus: 0.2171405404806137
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12895901501178741
		 entropy bonus: 0.00392686715349555
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0869402065873146
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46.093116760253906 - Differentiable computation graph = True!
PPO iteration: 113/1000:
	 start solving instance: 88...
	 start solving instance: 134...
	 start solving instance: 44...
	 start solving instance: 90...
	 start solving instance: 9...
	 start solving instance: 39...
	 start solving instance: 123...
	 start solving instance: 116...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 18...
	 start solving instance: 50...
	 start solving instance: 126...
	 start solving instance: 72...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 100...
	 start solving instance: 57...
	 start solving instance: 16...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 461.8556823730469
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12697891891002655
		 entropy bonus: 0.22419868409633636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0016056419117376208
		 entropy bonus: 7.22259865142405e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.061349496245384216
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46.23038101196289 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 461.8556823730469
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12701630592346191
		 entropy bonus: 0.2242460548877716
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03686276823282242
		 entropy bonus: 8.662328582431655e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.061349496245384216
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46.26567459106445 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 461.8556823730469
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1261197328567505
		 entropy bonus: 0.22423265874385834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04070540890097618
		 entropy bonus: 1.9830104225349032e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.061349496245384216
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46.268619537353516 - Differentiable computation graph = True!
PPO iteration: 114/1000:
	 start solving instance: 39...
	 start solving instance: 18...
	 start solving instance: 16...
	 start solving instance: 44...
	 start solving instance: 50...
	 start solving instance: 87...
	 start solving instance: 100...
	 start solving instance: 123...
	 start solving instance: 101...
	 start solving instance: 57...
	 start solving instance: 126...
	 start solving instance: 116...
	 start solving instance: 88...
	 start solving instance: 90...
	 start solving instance: 72...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 134...
	 start solving instance: 146...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 538.1843872070312
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3832956850528717
		 entropy bonus: 0.22448816895484924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2498653382062912
		 entropy bonus: 0.0031868622172623873
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18711639940738678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 54.24171829223633 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 538.1843872070312
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3819940686225891
		 entropy bonus: 0.22415554523468018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2627173960208893
		 entropy bonus: 9.43650206863822e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18711639940738678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 54.25361633300781 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 538.1843872070312
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.38020291924476624
		 entropy bonus: 0.22357873618602753
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2639784514904022
		 entropy bonus: 2.8045567432855023e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18711639940738678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 54.25314712524414 - Differentiable computation graph = True!
PPO iteration: 115/1000:
	 start solving instance: 104...
	 start solving instance: 126...
	 start solving instance: 101...
	 start solving instance: 72...
	 start solving instance: 57...
	 start solving instance: 87...
	 start solving instance: 44...
	 start solving instance: 90...
	 start solving instance: 142...
	 start solving instance: 50...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 134...
	 start solving instance: 88...
	 start solving instance: 100...
	 start solving instance: 18...
	 start solving instance: 123...
	 start solving instance: 9...
	 start solving instance: 146...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 394.7571716308594
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.24930942058563232
		 entropy bonus: 0.22205114364624023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11155503988265991
		 entropy bonus: 2.047262569249142e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.036959800869226456
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 39.85133743286133 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 394.7571716308594
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.24878521263599396
		 entropy bonus: 0.22223535180091858
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11280007660388947
		 entropy bonus: 0.0005825746338814497
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.036959800869226456
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 39.85198211669922 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 394.7571716308594
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2466365098953247
		 entropy bonus: 0.22299933433532715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11255688965320587
		 entropy bonus: 0.00027431041235104203
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.036959800869226456
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 39.849544525146484 - Differentiable computation graph = True!
PPO iteration: 116/1000:
	 start solving instance: 123...
	 start solving instance: 50...
	 start solving instance: 18...
	 start solving instance: 146...
	 start solving instance: 90...
	 start solving instance: 100...
	 start solving instance: 44...
	 start solving instance: 134...
	 start solving instance: 9...
	 start solving instance: 116...
	 start solving instance: 126...
	 start solving instance: 16...
	 start solving instance: 101...
	 start solving instance: 57...
	 start solving instance: 88...
	 start solving instance: 104...
	 start solving instance: 39...
	 start solving instance: 72...
	 start solving instance: 87...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 302.3764343261719
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1390713006258011
		 entropy bonus: 0.23139257729053497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07297807186841965
		 entropy bonus: 2.796504077196005e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013531804084777832
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 30.294130325317383 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 302.3764343261719
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13804806768894196
		 entropy bonus: 0.22822248935699463
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06408907473087311
		 entropy bonus: 0.0003179078921675682
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013531804084777832
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 30.302282333374023 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 302.3764343261719
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14309479296207428
		 entropy bonus: 0.22821931540966034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06352074444293976
		 entropy bonus: 0.001796542084775865
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013531804084777832
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 30.307748794555664 - Differentiable computation graph = True!
PPO iteration: 117/1000:
	 start solving instance: 18...
	 start solving instance: 44...
	 start solving instance: 57...
	 start solving instance: 90...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 87...
	 start solving instance: 72...
	 start solving instance: 101...
	 start solving instance: 50...
	 start solving instance: 100...
	 start solving instance: 39...
	 start solving instance: 88...
	 start solving instance: 134...
	 start solving instance: 126...
	 start solving instance: 116...
	 start solving instance: 123...
	 start solving instance: 9...
	 start solving instance: 146...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 242.6594696044922
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20874205231666565
		 entropy bonus: 0.22180627286434174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09246599674224854
		 entropy bonus: 4.8797723138704896e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.00047391653060913086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24.360511779785156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 242.6594696044922
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20843052864074707
		 entropy bonus: 0.21698705852031708
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07691097259521484
		 entropy bonus: 1.3219068895065078e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.00047391653060913086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24.37624168395996 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 242.6594696044922
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20820008218288422
		 entropy bonus: 0.22002553939819336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.07520603388547897
		 entropy bonus: 5.141824294696562e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.00047391653060913086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24.37740707397461 - Differentiable computation graph = True!
PPO iteration: 118/1000:
	 start solving instance: 87...
	 start solving instance: 16...
	 start solving instance: 104...
	 start solving instance: 101...
	 start solving instance: 90...
	 start solving instance: 50...
	 start solving instance: 44...
	 start solving instance: 146...
	 start solving instance: 9...
	 start solving instance: 134...
	 start solving instance: 57...
	 start solving instance: 142...
	 start solving instance: 72...
	 start solving instance: 39...
	 start solving instance: 126...
	 start solving instance: 123...
	 start solving instance: 116...
	 start solving instance: 18...
	 start solving instance: 100...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 554.0546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.4196084439754486
		 entropy bonus: 0.22959311306476593
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2821876108646393
		 entropy bonus: 0.0017620561411604285
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02574458345770836
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 56.05838394165039 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 554.0546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.4180050790309906
		 entropy bonus: 0.22909985482692719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29332247376441956
		 entropy bonus: 0.0006351014599204063
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02574458345770836
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 56.068077087402344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 554.0546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.4200621545314789
		 entropy bonus: 0.2337835282087326
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2905581593513489
		 entropy bonus: 8.401203344110542e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02574458345770836
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 56.06696319580078 - Differentiable computation graph = True!
PPO iteration: 119/1000:
	 start solving instance: 44...
	 start solving instance: 72...
	 start solving instance: 134...
	 start solving instance: 39...
	 start solving instance: 126...
	 start solving instance: 50...
	 start solving instance: 18...
	 start solving instance: 100...
	 start solving instance: 123...
	 start solving instance: 88...
	 start solving instance: 57...
	 start solving instance: 146...
	 start solving instance: 104...
	 start solving instance: 116...
	 start solving instance: 101...
	 start solving instance: 16...
	 start solving instance: 90...
	 start solving instance: 142...
	 start solving instance: 9...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 663.5932006835938
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2765219807624817
		 entropy bonus: 0.2414577454328537
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20565061271190643
		 entropy bonus: 2.5230891594757443e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002293013036251068
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 66.81964111328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 663.5932006835938
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2736278474330902
		 entropy bonus: 0.24023328721523285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2060999870300293
		 entropy bonus: 0.00012841699935961515
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002293013036251068
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 66.81730651855469 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 663.5932006835938
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.273730605840683
		 entropy bonus: 0.24172864854335785
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20610380172729492
		 entropy bonus: 9.063192184523522e-16
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002293013036251068
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 66.81727600097656 - Differentiable computation graph = True!
PPO iteration: 120/1000:
	 start solving instance: 116...
	 start solving instance: 88...
	 start solving instance: 126...
	 start solving instance: 9...
	 start solving instance: 18...
	 start solving instance: 57...
	 start solving instance: 104...
	 start solving instance: 39...
	 start solving instance: 44...
	 start solving instance: 72...
	 start solving instance: 90...
	 start solving instance: 87...
	 start solving instance: 146...
	 start solving instance: 134...
	 start solving instance: 50...
	 start solving instance: 16...
	 start solving instance: 101...
	 start solving instance: 142...
	 start solving instance: 123...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 606.0569458007812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13300786912441254
		 entropy bonus: 0.2274438440799713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0006038785213604569
		 entropy bonus: 3.147994639748157e-17
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.014091983437538147
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 60.73065185546875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 606.0569458007812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1280106157064438
		 entropy bonus: 0.22556281089782715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0005463481065817177
		 entropy bonus: 0.00021906651090830564
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.014091983437538147
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 60.725765228271484 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 606.0569458007812
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12748347222805023
		 entropy bonus: 0.2246570587158203
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.013996017165482044
		 entropy bonus: 1.0843969197841335e-25
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.014091983437538147
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 60.738800048828125 - Differentiable computation graph = True!
PPO iteration: 121/1000:
	 New training batch of size 20...
	 start solving instance: 94...
	 start solving instance: 87...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 69...
	 start solving instance: 93...
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 33...
	 start solving instance: 5...
	 start solving instance: 129...
	 start solving instance: 32...
	 start solving instance: 113...
	 start solving instance: 61...
	 start solving instance: 34...
	 start solving instance: 36...
	 start solving instance: 124...
	 start solving instance: 66...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 602.2413940429688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16152532398700714
		 entropy bonus: 0.22770261764526367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10562670230865479
		 entropy bonus: 5.548395076715451e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0400242805480957
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 60.428497314453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 602.2413940429688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16023865342140198
		 entropy bonus: 0.22625327110290527
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12400633096694946
		 entropy bonus: 5.3583448789140675e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0400242805480957
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 60.445735931396484 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 602.2413940429688
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1591659039258957
		 entropy bonus: 0.22620069980621338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14004385471343994
		 entropy bonus: 1.865824401647842e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0400242805480957
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 60.4607048034668 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 1324.4227294921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.44834837317466736
		 entropy bonus: 0.2127830535173416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.5049923062324524
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12597671151161194
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 133.2484
PPO iteration: 122/1000:
	 start solving instance: 150...
	 start solving instance: 69...
	 start solving instance: 66...
	 start solving instance: 113...
	 start solving instance: 94...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 124...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 5...
	 start solving instance: 129...
	 start solving instance: 87...
	 start solving instance: 32...
	 start solving instance: 36...
	 start solving instance: 61...
	 start solving instance: 67...
	 start solving instance: 91...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 1351.1904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2613562047481537
		 entropy bonus: 0.2352341264486313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23753264546394348
		 entropy bonus: 4.865347708049583e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.020429981872439384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 135.57398986816406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1351.1904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2575492858886719
		 entropy bonus: 0.23519420623779297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23753264546394348
		 entropy bonus: 2.3803523388488124e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.020429981872439384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 135.57017517089844 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1351.1904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.25733718276023865
		 entropy bonus: 0.2351754754781723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23753264546394348
		 entropy bonus: 3.6555129583060175e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.020429981872439384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 135.56997680664062 - Differentiable computation graph = True!
PPO iteration: 123/1000:
	 start solving instance: 124...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 61...
	 start solving instance: 103...
	 start solving instance: 36...
	 start solving instance: 33...
	 start solving instance: 87...
	 start solving instance: 66...
	 start solving instance: 5...
	 start solving instance: 150...
	 start solving instance: 129...
	 start solving instance: 69...
	 start solving instance: 93...
	 start solving instance: 94...
	 start solving instance: 32...
	 start solving instance: 91...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 1773.1693115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0997486338019371
		 entropy bonus: 0.21917228400707245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04113280400633812
		 entropy bonus: 8.112159775919281e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.224361851811409
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 177.1292724609375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1773.1693115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1001388356089592
		 entropy bonus: 0.21915140748023987
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.041128240525722504
		 entropy bonus: 3.436983024585061e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.224361851811409
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 177.12966918945312 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1773.1693115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10094302892684937
		 entropy bonus: 0.2191367894411087
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04112754762172699
		 entropy bonus: 3.796399323618971e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.224361851811409
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 177.13047790527344 - Differentiable computation graph = True!
PPO iteration: 124/1000:
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 129...
	 start solving instance: 32...
	 start solving instance: 66...
	 start solving instance: 113...
	 start solving instance: 61...
	 start solving instance: 33...
	 start solving instance: 69...
	 start solving instance: 145...
	 start solving instance: 94...
	 start solving instance: 5...
	 start solving instance: 34...
	 start solving instance: 124...
	 start solving instance: 91...
	 start solving instance: 67...
	 start solving instance: 87...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 2012.6951904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0961807519197464
		 entropy bonus: 0.22436745464801788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10117287933826447
		 entropy bonus: 4.8768097199447524e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16120123863220215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 201.28323364257812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2012.6951904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09677284210920334
		 entropy bonus: 0.2243644744157791
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10117287933826447
		 entropy bonus: 1.5045606427399605e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16120123863220215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 201.28382873535156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2012.6951904296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09636106342077255
		 entropy bonus: 0.22434425354003906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10117287933826447
		 entropy bonus: 1.1653190912230826e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16120123863220215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 201.28341674804688 - Differentiable computation graph = True!
PPO iteration: 125/1000:
	 start solving instance: 66...
	 start solving instance: 91...
	 start solving instance: 103...
	 start solving instance: 124...
	 start solving instance: 94...
	 start solving instance: 5...
	 start solving instance: 33...
	 start solving instance: 113...
	 start solving instance: 87...
	 start solving instance: 145...
	 start solving instance: 69...
	 start solving instance: 61...
	 start solving instance: 129...
	 start solving instance: 36...
	 start solving instance: 150...
	 start solving instance: 121...
	 start solving instance: 67...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 2080.810302734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21828269958496094
		 entropy bonus: 0.2309526950120926
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17429247498512268
		 entropy bonus: 0.0009037178242579103
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16279494762420654
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 208.2876434326172 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2080.810302734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21719951927661896
		 entropy bonus: 0.2309321016073227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1936090588569641
		 entropy bonus: 1.6450756447738968e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16279494762420654
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 208.3059539794922 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2080.810302734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21722331643104553
		 entropy bonus: 0.23091593384742737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1974678933620453
		 entropy bonus: 3.7758886151095794e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16279494762420654
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 208.30984497070312 - Differentiable computation graph = True!
PPO iteration: 126/1000:
	 start solving instance: 34...
	 start solving instance: 129...
	 start solving instance: 66...
	 start solving instance: 36...
	 start solving instance: 32...
	 start solving instance: 33...
	 start solving instance: 94...
	 start solving instance: 121...
	 start solving instance: 87...
	 start solving instance: 145...
	 start solving instance: 150...
	 start solving instance: 124...
	 start solving instance: 5...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 91...
	 start solving instance: 61...
	 start solving instance: 69...
	 start solving instance: 67...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 3057.627197265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10360922664403915
		 entropy bonus: 0.23198406398296356
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07463329285383224
		 entropy bonus: 3.8712570926691114e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16306187212467194
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 305.75469970703125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3057.627197265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10340575128793716
		 entropy bonus: 0.23195062577724457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09358005970716476
		 entropy bonus: 7.152125908760354e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16306187212467194
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 305.7734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3057.627197265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10300066322088242
		 entropy bonus: 0.23189043998718262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08175497502088547
		 entropy bonus: 8.994628153402573e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16306187212467194
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 305.76123046875 - Differentiable computation graph = True!
PPO iteration: 127/1000:
	 start solving instance: 103...
	 start solving instance: 5...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 113...
	 start solving instance: 94...
	 start solving instance: 93...
	 start solving instance: 87...
	 start solving instance: 33...
	 start solving instance: 150...
	 start solving instance: 124...
	 start solving instance: 32...
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 129...
	 start solving instance: 61...
	 start solving instance: 66...
	 start solving instance: 69...
	 start solving instance: 34...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 3674.173583984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.22447748482227325
		 entropy bonus: 0.24200944602489471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1789766401052475
		 entropy bonus: 0.0001739875879138708
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13741832971572876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 367.6591796875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3674.173583984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.22391414642333984
		 entropy bonus: 0.24192027747631073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17894862592220306
		 entropy bonus: 9.038798301043384e-31
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13741832971572876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 367.6585998535156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3674.173583984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2230263203382492
		 entropy bonus: 0.2418144792318344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17894862592220306
		 entropy bonus: 3.1833306043763403e-16
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13741832971572876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 367.6577453613281 - Differentiable computation graph = True!
PPO iteration: 128/1000:
	 start solving instance: 33...
	 start solving instance: 91...
	 start solving instance: 103...
	 start solving instance: 5...
	 start solving instance: 129...
	 start solving instance: 150...
	 start solving instance: 145...
	 start solving instance: 69...
	 start solving instance: 87...
	 start solving instance: 94...
	 start solving instance: 121...
	 start solving instance: 93...
	 start solving instance: 61...
	 start solving instance: 34...
	 start solving instance: 124...
	 start solving instance: 66...
	 start solving instance: 113...
	 start solving instance: 36...
	 start solving instance: 32...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 3987.138427734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10285574197769165
		 entropy bonus: 0.22417962551116943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0034411370288580656
		 entropy bonus: 5.986760243104072e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10844961553812027
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 398.68927001953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3987.138427734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10310514271259308
		 entropy bonus: 0.22407512366771698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0034424723125994205
		 entropy bonus: 9.402946488989983e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10844961553812027
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 398.68951416015625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3987.138427734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10307785123586655
		 entropy bonus: 0.2240009754896164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0034422457683831453
		 entropy bonus: 8.838514077069703e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10844961553812027
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 398.68951416015625 - Differentiable computation graph = True!
PPO iteration: 129/1000:
	 start solving instance: 34...
	 start solving instance: 103...
	 start solving instance: 33...
	 start solving instance: 93...
	 start solving instance: 129...
	 start solving instance: 32...
	 start solving instance: 67...
	 start solving instance: 69...
	 start solving instance: 94...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 36...
	 start solving instance: 87...
	 start solving instance: 150...
	 start solving instance: 61...
	 start solving instance: 124...
	 start solving instance: 5...
	 start solving instance: 66...
	 start solving instance: 91...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4170.61279296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09973931312561035
		 entropy bonus: 0.22931161522865295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10534606128931046
		 entropy bonus: 1.58431237196055e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.23199112713336945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 417.0114440917969 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4170.61279296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09859577566385269
		 entropy bonus: 0.22919845581054688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10534578561782837
		 entropy bonus: 9.968717904484947e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.23199112713336945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 417.01031494140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4170.61279296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09849011152982712
		 entropy bonus: 0.2291068583726883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10534566640853882
		 entropy bonus: 7.370531989181472e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.23199112713336945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 417.0102233886719 - Differentiable computation graph = True!
PPO iteration: 130/1000:
	 start solving instance: 61...
	 start solving instance: 93...
	 start solving instance: 36...
	 start solving instance: 124...
	 start solving instance: 150...
	 start solving instance: 5...
	 start solving instance: 121...
	 start solving instance: 69...
	 start solving instance: 103...
	 start solving instance: 91...
	 start solving instance: 67...
	 start solving instance: 145...
	 start solving instance: 129...
	 start solving instance: 33...
	 start solving instance: 87...
	 start solving instance: 113...
	 start solving instance: 34...
	 start solving instance: 94...
	 start solving instance: 66...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4209.11376953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09040053933858871
		 entropy bonus: 0.23504363000392914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06261265277862549
		 entropy bonus: 1.867030391622393e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10719256103038788
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 420.9336853027344 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4209.11376953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08973965793848038
		 entropy bonus: 0.2348509579896927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06261241436004639
		 entropy bonus: 1.2127572972531198e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10719256103038788
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 420.93304443359375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4209.11376953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08988889306783676
		 entropy bonus: 0.23469960689544678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06261228770017624
		 entropy bonus: 8.756026659284544e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10719256103038788
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 420.9331970214844 - Differentiable computation graph = True!
PPO iteration: 131/1000:
	 New training batch of size 20...
	 start solving instance: 40...
	 start solving instance: 4...
	 start solving instance: 120...
	 start solving instance: 46...
	 start solving instance: 38...
	 start solving instance: 6...
	 start solving instance: 101...
	 start solving instance: 108...
	 start solving instance: 134...
	 start solving instance: 135...
	 start solving instance: 117...
	 start solving instance: 115...
	 start solving instance: 91...
	 start solving instance: 100...
	 start solving instance: 23...
	 start solving instance: 123...
	 start solving instance: 29...
	 start solving instance: 139...
	 start solving instance: 112...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 3863.95703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3207486569881439
		 entropy bonus: 0.22845105826854706
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.30428004264831543
		 entropy bonus: 1.8252160316478694e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15873318910598755
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 387.1566467285156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3863.95703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3154763877391815
		 entropy bonus: 0.22821597754955292
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3042796552181244
		 entropy bonus: 4.571510601181217e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15873318910598755
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 387.1513977050781 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3863.95703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3123510777950287
		 entropy bonus: 0.22795484960079193
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3042795658111572
		 entropy bonus: 1.3982484858843236e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15873318910598755
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 387.1482849121094 - Differentiable computation graph = True!
PPO iteration: 132/1000:
	 start solving instance: 100...
	 start solving instance: 101...
	 start solving instance: 4...
	 start solving instance: 134...
	 start solving instance: 23...
	 start solving instance: 6...
	 start solving instance: 40...
	 start solving instance: 135...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 117...
	 start solving instance: 29...
	 start solving instance: 139...
	 start solving instance: 123...
	 start solving instance: 91...
	 start solving instance: 38...
	 start solving instance: 115...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 3826.718017578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18892821669578552
		 entropy bonus: 0.2154487818479538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18428324162960052
		 entropy bonus: 3.764004742501359e-28
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.20911704003810883
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 383.23260498046875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3826.718017578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.184421569108963
		 entropy bonus: 0.21504071354866028
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18428324162960052
		 entropy bonus: 1.3411144556486248e-28
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.20911704003810883
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 383.2281188964844 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3826.718017578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18161039054393768
		 entropy bonus: 0.21458514034748077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18428324162960052
		 entropy bonus: 5.510308858394809e-29
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.20911704003810883
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 383.2253723144531 - Differentiable computation graph = True!
PPO iteration: 133/1000:
	 start solving instance: 123...
	 start solving instance: 135...
	 start solving instance: 6...
	 start solving instance: 101...
	 start solving instance: 100...
	 start solving instance: 120...
	 start solving instance: 115...
	 start solving instance: 29...
	 start solving instance: 23...
	 start solving instance: 139...
	 start solving instance: 46...
	 start solving instance: 112...
	 start solving instance: 38...
	 start solving instance: 20...
	 start solving instance: 134...
	 start solving instance: 91...
	 start solving instance: 108...
	 start solving instance: 40...
	 start solving instance: 117...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 3814.122802734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16709297895431519
		 entropy bonus: 0.2224595844745636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19010300934314728
		 entropy bonus: 2.8362858936481494e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2357475608587265
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 381.98297119140625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3814.122802734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16206684708595276
		 entropy bonus: 0.2217898666858673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19010300934314728
		 entropy bonus: 2.711698053603495e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2357475608587265
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 381.97802734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3814.122802734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16015592217445374
		 entropy bonus: 0.22110095620155334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19010300934314728
		 entropy bonus: 2.6592511287622245e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2357475608587265
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 381.9761657714844 - Differentiable computation graph = True!
PPO iteration: 134/1000:
	 start solving instance: 108...
	 start solving instance: 101...
	 start solving instance: 29...
	 start solving instance: 20...
	 start solving instance: 135...
	 start solving instance: 4...
	 start solving instance: 38...
	 start solving instance: 134...
	 start solving instance: 6...
	 start solving instance: 112...
	 start solving instance: 46...
	 start solving instance: 100...
	 start solving instance: 139...
	 start solving instance: 123...
	 start solving instance: 120...
	 start solving instance: 91...
	 start solving instance: 23...
	 start solving instance: 40...
	 start solving instance: 115...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 3827.26611328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2288070172071457
		 entropy bonus: 0.2143566608428955
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2737635672092438
		 entropy bonus: 9.139104795843735e-22
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15125665068626404
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 383.3590087890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3827.26611328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21862363815307617
		 entropy bonus: 0.2133312225341797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2737635672092438
		 entropy bonus: 3.804736780885559e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15125665068626404
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 383.34893798828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3827.26611328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21094642579555511
		 entropy bonus: 0.2121507227420807
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2737635672092438
		 entropy bonus: 9.36179914391502e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15125665068626404
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 383.34136962890625 - Differentiable computation graph = True!
PPO iteration: 135/1000:
	 start solving instance: 135...
	 start solving instance: 6...
	 start solving instance: 134...
	 start solving instance: 91...
	 start solving instance: 38...
	 start solving instance: 123...
	 start solving instance: 117...
	 start solving instance: 29...
	 start solving instance: 139...
	 start solving instance: 120...
	 start solving instance: 4...
	 start solving instance: 46...
	 start solving instance: 20...
	 start solving instance: 100...
	 start solving instance: 112...
	 start solving instance: 101...
	 start solving instance: 23...
	 start solving instance: 108...
	 start solving instance: 40...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 3781.501220703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04201977327466011
		 entropy bonus: 0.20764563977718353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09046447277069092
		 entropy bonus: 4.3700715797793736e-35
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16236612200737
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 378.4241943359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3781.501220703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04045815393328667
		 entropy bonus: 0.20626144111156464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09046447277069092
		 entropy bonus: 1.8798250814848183e-34
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16236612200737
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 378.42279052734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3781.501220703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03824096918106079
		 entropy bonus: 0.20493967831134796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09046447277069092
		 entropy bonus: 6.497471096595787e-34
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16236612200737
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 378.42071533203125 - Differentiable computation graph = True!
PPO iteration: 136/1000:
	 start solving instance: 135...
	 start solving instance: 117...
	 start solving instance: 115...
	 start solving instance: 101...
	 start solving instance: 120...
	 start solving instance: 23...
	 start solving instance: 112...
	 start solving instance: 46...
	 start solving instance: 139...
	 start solving instance: 40...
	 start solving instance: 38...
	 start solving instance: 20...
	 start solving instance: 29...
	 start solving instance: 100...
	 start solving instance: 123...
	 start solving instance: 91...
	 start solving instance: 4...
	 start solving instance: 6...
	 start solving instance: 108...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 3856.91650390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10349459946155548
		 entropy bonus: 0.2186143398284912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12846653163433075
		 entropy bonus: 7.773335863880959e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04961768165230751
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 385.95135498046875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3856.91650390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09852329641580582
		 entropy bonus: 0.21698258817195892
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12846653163433075
		 entropy bonus: 3.6685790516521877e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04961768165230751
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 385.946533203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3856.91650390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09405763447284698
		 entropy bonus: 0.21507219970226288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12846653163433075
		 entropy bonus: 1.778920205586232e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04961768165230751
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 385.9422607421875 - Differentiable computation graph = True!
PPO iteration: 137/1000:
	 start solving instance: 139...
	 start solving instance: 29...
	 start solving instance: 6...
	 start solving instance: 134...
	 start solving instance: 123...
	 start solving instance: 46...
	 start solving instance: 112...
	 start solving instance: 4...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 100...
	 start solving instance: 117...
	 start solving instance: 20...
	 start solving instance: 38...
	 start solving instance: 135...
	 start solving instance: 23...
	 start solving instance: 115...
	 start solving instance: 40...
	 start solving instance: 101...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 3943.02587890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0410417802631855
		 entropy bonus: 0.20665676891803741
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0510435588657856
		 entropy bonus: 1.0452529813909095e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10272284597158432
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 394.47674560546875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3943.02587890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03978100046515465
		 entropy bonus: 0.20438602566719055
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0510435588657856
		 entropy bonus: 1.1061222077168864e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10272284597158432
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 394.4757080078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3943.02587890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03222603723406792
		 entropy bonus: 0.2015881985425949
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0510435588657856
		 entropy bonus: 1.2738604615591953e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10272284597158432
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 394.4684143066406 - Differentiable computation graph = True!
PPO iteration: 138/1000:
	 start solving instance: 40...
	 start solving instance: 4...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 38...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 23...
	 start solving instance: 117...
	 start solving instance: 29...
	 start solving instance: 139...
	 start solving instance: 91...
	 start solving instance: 108...
	 start solving instance: 115...
	 start solving instance: 6...
	 start solving instance: 100...
	 start solving instance: 134...
	 start solving instance: 120...
	 start solving instance: 101...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 3924.433349609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.22949746251106262
		 entropy bonus: 0.1984763890504837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2060328722000122
		 entropy bonus: 5.566555246264149e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16775187849998474
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 393.0267639160156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3924.433349609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21537397801876068
		 entropy bonus: 0.1956230252981186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2060328722000122
		 entropy bonus: 5.942923562117508e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16775187849998474
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 393.0129089355469 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3924.433349609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.22897008061408997
		 entropy bonus: 0.19379423558712006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2060328722000122
		 entropy bonus: 4.5455688366981273e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16775187849998474
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 393.0267028808594 - Differentiable computation graph = True!
PPO iteration: 139/1000:
	 start solving instance: 38...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 46...
	 start solving instance: 29...
	 start solving instance: 91...
	 start solving instance: 115...
	 start solving instance: 117...
	 start solving instance: 4...
	 start solving instance: 101...
	 start solving instance: 6...
	 start solving instance: 108...
	 start solving instance: 120...
	 start solving instance: 134...
	 start solving instance: 23...
	 start solving instance: 40...
	 start solving instance: 100...
	 start solving instance: 123...
	 start solving instance: 139...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 3914.09423828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10834991931915283
		 entropy bonus: 0.1854943037033081
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1682959496974945
		 entropy bonus: 6.489347392779621e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19775843620300293
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 391.86529541015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3914.09423828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09695646911859512
		 entropy bonus: 0.18211419880390167
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1682959496974945
		 entropy bonus: 4.0001837953163033e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19775843620300293
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 391.8542175292969 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3914.09423828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07870771735906601
		 entropy bonus: 0.1774444282054901
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1682959496974945
		 entropy bonus: 2.5710686357705015e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19775843620300293
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 391.8364562988281 - Differentiable computation graph = True!
PPO iteration: 140/1000:
	 start solving instance: 108...
	 start solving instance: 46...
	 start solving instance: 23...
	 start solving instance: 135...
	 start solving instance: 38...
	 start solving instance: 112...
	 start solving instance: 100...
	 start solving instance: 40...
	 start solving instance: 91...
	 start solving instance: 20...
	 start solving instance: 4...
	 start solving instance: 134...
	 start solving instance: 115...
	 start solving instance: 117...
	 start solving instance: 6...
	 start solving instance: 101...
	 start solving instance: 120...
	 start solving instance: 29...
	 start solving instance: 139...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 3880.51220703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12113072723150253
		 entropy bonus: 0.1727554053068161
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16190893948078156
		 entropy bonus: 3.0519831284436805e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1599094718694687
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 388.4768981933594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3880.51220703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10348240286111832
		 entropy bonus: 0.16668234765529633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16190889477729797
		 entropy bonus: 9.036235648629543e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1599094718694687
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 388.4598693847656 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3880.51220703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.087436243891716
		 entropy bonus: 0.16022813320159912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16190890967845917
		 entropy bonus: 1.0634994396241382e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1599094718694687
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 388.4444580078125 - Differentiable computation graph = True!
PPO iteration: 141/1000:
	 New training batch of size 20...
	 start solving instance: 103...
	 start solving instance: 40...
	 start solving instance: 32...
	 start solving instance: 52...
	 start solving instance: 42...
	 start solving instance: 8...
	 start solving instance: 93...
	 start solving instance: 55...
	 start solving instance: 30...
	 start solving instance: 107...
	 start solving instance: 22...
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 118...
	 start solving instance: 5...
	 start solving instance: 44...
	 start solving instance: 112...
	 start solving instance: 74...
	 start solving instance: 9...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 4207.78662109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.012248492799699306
		 entropy bonus: 0.15633128583431244
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03518171235918999
		 entropy bonus: 0.0006197129841893911
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.04608229920268059
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 420.7643127441406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4207.78662109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.005541181657463312
		 entropy bonus: 0.15009449422359467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06698619574308395
		 entropy bonus: 1.2922287240257901e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.04608229920268059
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 420.79010009765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4207.78662109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.003450751304626465
		 entropy bonus: 0.1421441286802292
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07522276788949966
		 entropy bonus: 0.0012725061969831586
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.04608229920268059
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 420.7900085449219 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4234.31494140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0409422293305397
		 entropy bonus: 0.12583251297473907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10057663917541504
		 entropy bonus: 0.005097703076899052
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3567987382411957
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 423.9167
PPO iteration: 142/1000:
	 start solving instance: 8...
	 start solving instance: 112...
	 start solving instance: 55...
	 start solving instance: 44...
	 start solving instance: 42...
	 start solving instance: 5...
	 start solving instance: 32...
	 start solving instance: 130...
	 start solving instance: 107...
	 start solving instance: 22...
	 start solving instance: 91...
	 start solving instance: 104...
	 start solving instance: 93...
	 start solving instance: 40...
	 start solving instance: 74...
	 start solving instance: 103...
	 start solving instance: 52...
	 start solving instance: 9...
	 start solving instance: 30...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 4291.67041015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.380401074886322
		 entropy bonus: 0.14261320233345032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3419555127620697
		 entropy bonus: 0.005001389887183905
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0957670733332634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 429.9704284667969 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4291.67041015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3429647982120514
		 entropy bonus: 0.13440975546836853
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3817344903945923
		 entropy bonus: 0.00011253343109274283
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0957670733332634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 429.97406005859375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4291.67041015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.28811103105545044
		 entropy bonus: 0.12516479194164276
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.38488468527793884
		 entropy bonus: 0.002505877986550331
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0957670733332634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 429.9230651855469 - Differentiable computation graph = True!
PPO iteration: 143/1000:
	 start solving instance: 104...
	 start solving instance: 40...
	 start solving instance: 91...
	 start solving instance: 55...
	 start solving instance: 130...
	 start solving instance: 8...
	 start solving instance: 9...
	 start solving instance: 32...
	 start solving instance: 112...
	 start solving instance: 5...
	 start solving instance: 93...
	 start solving instance: 42...
	 start solving instance: 30...
	 start solving instance: 118...
	 start solving instance: 74...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 52...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4050.735107421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06641016155481339
		 entropy bonus: 0.11105146259069443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08342184126377106
		 entropy bonus: 0.0007276569376699626
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.122136190533638
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 405.33428955078125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4050.735107421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05662650987505913
		 entropy bonus: 0.10233569145202637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08250697702169418
		 entropy bonus: 0.0007447266834788024
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.122136190533638
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 405.324462890625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4050.735107421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.051430679857730865
		 entropy bonus: 0.09487777203321457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08166835457086563
		 entropy bonus: 0.0004157346847932786
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.122136190533638
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 405.3192138671875 - Differentiable computation graph = True!
PPO iteration: 144/1000:
	 start solving instance: 130...
	 start solving instance: 32...
	 start solving instance: 103...
	 start solving instance: 42...
	 start solving instance: 44...
	 start solving instance: 55...
	 start solving instance: 118...
	 start solving instance: 30...
	 start solving instance: 107...
	 start solving instance: 104...
	 start solving instance: 22...
	 start solving instance: 93...
	 start solving instance: 52...
	 start solving instance: 74...
	 start solving instance: 9...
	 start solving instance: 8...
	 start solving instance: 112...
	 start solving instance: 91...
	 start solving instance: 5...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 3968.699951171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030503464862704277
		 entropy bonus: 0.09134895354509354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03948114067316055
		 entropy bonus: 3.1378542189486325e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.20102636516094208
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 397.1318664550781 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3968.699951171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.031535953283309937
		 entropy bonus: 0.08656658977270126
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039485495537519455
		 entropy bonus: 4.370376336737536e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.20102636516094208
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 397.1333923339844 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3968.699951171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.029720520600676537
		 entropy bonus: 0.0827496275305748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039588309824466705
		 entropy bonus: 0.0003468013892415911
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.20102636516094208
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 397.13201904296875 - Differentiable computation graph = True!
PPO iteration: 145/1000:
	 start solving instance: 9...
	 start solving instance: 74...
	 start solving instance: 93...
	 start solving instance: 40...
	 start solving instance: 118...
	 start solving instance: 44...
	 start solving instance: 8...
	 start solving instance: 130...
	 start solving instance: 55...
	 start solving instance: 52...
	 start solving instance: 32...
	 start solving instance: 30...
	 start solving instance: 22...
	 start solving instance: 107...
	 start solving instance: 104...
	 start solving instance: 112...
	 start solving instance: 42...
	 start solving instance: 5...
	 start solving instance: 91...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 4062.101318359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.047091830521821976
		 entropy bonus: 0.07908356189727783
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09074302762746811
		 entropy bonus: 0.00016341939044650644
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08938220143318176
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 406.429443359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4062.101318359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03967487812042236
		 entropy bonus: 0.07622678577899933
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09232065081596375
		 entropy bonus: 0.00017556606326252222
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08938220143318176
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 406.4238586425781 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4062.101318359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04065065458416939
		 entropy bonus: 0.07271082699298859
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09228101372718811
		 entropy bonus: 0.00035543148987926543
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08938220143318176
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 406.4251708984375 - Differentiable computation graph = True!
PPO iteration: 146/1000:
	 start solving instance: 103...
	 start solving instance: 107...
	 start solving instance: 8...
	 start solving instance: 74...
	 start solving instance: 112...
	 start solving instance: 93...
	 start solving instance: 55...
	 start solving instance: 44...
	 start solving instance: 22...
	 start solving instance: 91...
	 start solving instance: 9...
	 start solving instance: 52...
	 start solving instance: 40...
	 start solving instance: 32...
	 start solving instance: 130...
	 start solving instance: 5...
	 start solving instance: 104...
	 start solving instance: 118...
	 start solving instance: 42...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 3918.130126953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09085893630981445
		 entropy bonus: 0.07273328304290771
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09156035631895065
		 entropy bonus: 0.0004345076740719378
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08757253736257553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 392.07568359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3918.130126953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07419737428426743
		 entropy bonus: 0.0679108276963234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09167353063821793
		 entropy bonus: 0.0012441589497029781
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08757253736257553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 392.0595397949219 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3918.130126953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07077497243881226
		 entropy bonus: 0.062066107988357544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0915086418390274
		 entropy bonus: 0.001470153103582561
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08757253736257553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 392.0565185546875 - Differentiable computation graph = True!
PPO iteration: 147/1000:
	 start solving instance: 91...
	 start solving instance: 8...
	 start solving instance: 52...
	 start solving instance: 5...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 22...
	 start solving instance: 40...
	 start solving instance: 32...
	 start solving instance: 74...
	 start solving instance: 118...
	 start solving instance: 130...
	 start solving instance: 104...
	 start solving instance: 42...
	 start solving instance: 93...
	 start solving instance: 55...
	 start solving instance: 9...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3940.835693359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1393406242132187
		 entropy bonus: 0.058991849422454834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09056641161441803
		 entropy bonus: 0.001053779968060553
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.003808471839874983
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 394.3113098144531 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3940.835693359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12765851616859436
		 entropy bonus: 0.054537948220968246
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0909452885389328
		 entropy bonus: 0.0014465980930253863
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.003808471839874983
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 394.3003845214844 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3940.835693359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11795466393232346
		 entropy bonus: 0.051724549382925034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09147617965936661
		 entropy bonus: 0.0014458730584010482
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.003808471839874983
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 394.2915344238281 - Differentiable computation graph = True!
PPO iteration: 148/1000:
	 start solving instance: 74...
	 start solving instance: 9...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 40...
	 start solving instance: 32...
	 start solving instance: 22...
	 start solving instance: 118...
	 start solving instance: 130...
	 start solving instance: 5...
	 start solving instance: 104...
	 start solving instance: 112...
	 start solving instance: 44...
	 start solving instance: 42...
	 start solving instance: 55...
	 start solving instance: 8...
	 start solving instance: 30...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 5085.30419921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07560431957244873
		 entropy bonus: 0.04748072475194931
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07155667990446091
		 entropy bonus: 0.0013217962114140391
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09128274768590927
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508.7640075683594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5085.30419921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05737818032503128
		 entropy bonus: 0.05598824843764305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09144604206085205
		 entropy bonus: 0.0003261420351918787
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09128274768590927
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508.7649230957031 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5085.30419921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05853995308279991
		 entropy bonus: 0.0605989471077919
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09466147422790527
		 entropy bonus: 0.0011173499515280128
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09128274768590927
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508.76873779296875 - Differentiable computation graph = True!
PPO iteration: 149/1000:
	 start solving instance: 44...
	 start solving instance: 52...
	 start solving instance: 40...
	 start solving instance: 107...
	 start solving instance: 55...
	 start solving instance: 103...
	 start solving instance: 5...
	 start solving instance: 93...
	 start solving instance: 9...
	 start solving instance: 118...
	 start solving instance: 91...
	 start solving instance: 8...
	 start solving instance: 130...
	 start solving instance: 32...
	 start solving instance: 74...
	 start solving instance: 22...
	 start solving instance: 42...
	 start solving instance: 104...
	 start solving instance: 30...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4985.32421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0248374342918396
		 entropy bonus: 0.05393485352396965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.004383265972137451
		 entropy bonus: 6.416775022444199e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11550989001989365
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 498.6629943847656 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4985.32421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.035912640392780304
		 entropy bonus: 0.05357472971081734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02013172022998333
		 entropy bonus: 1.14231106635998e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11550989001989365
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 498.6986389160156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4985.32421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037282343953847885
		 entropy bonus: 0.05827417969703674
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.022513795644044876
		 entropy bonus: 1.9240324036218226e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11550989001989365
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 498.7019348144531 - Differentiable computation graph = True!
PPO iteration: 150/1000:
	 start solving instance: 32...
	 start solving instance: 40...
	 start solving instance: 8...
	 start solving instance: 103...
	 start solving instance: 9...
	 start solving instance: 107...
	 start solving instance: 93...
	 start solving instance: 52...
	 start solving instance: 55...
	 start solving instance: 5...
	 start solving instance: 118...
	 start solving instance: 74...
	 start solving instance: 112...
	 start solving instance: 42...
	 start solving instance: 30...
	 start solving instance: 22...
	 start solving instance: 91...
	 start solving instance: 104...
	 start solving instance: 44...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 4280.81982421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.043851256370544434
		 entropy bonus: 0.06417055428028107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09333648532629013
		 entropy bonus: 0.0004104553663637489
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10731544345617294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 428.320068359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4280.81982421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04287924990057945
		 entropy bonus: 0.06954460591077805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13330157101154327
		 entropy bonus: 0.0013240863336250186
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10731544345617294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 428.3583984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4280.81982421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.045306671410799026
		 entropy bonus: 0.07101843506097794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.230905219912529
		 entropy bonus: 0.0034030904062092304
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10731544345617294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 428.4580993652344 - Differentiable computation graph = True!
PPO iteration: 151/1000:
	 New training batch of size 20...
	 start solving instance: 61...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 5...
	 start solving instance: 48...
	 start solving instance: 70...
	 start solving instance: 121...
	 start solving instance: 119...
	 start solving instance: 128...
	 start solving instance: 115...
	 start solving instance: 141...
	 start solving instance: 9...
	 start solving instance: 1...
	 start solving instance: 93...
	 start solving instance: 32...
	 start solving instance: 17...
	 start solving instance: 27...
	 start solving instance: 51...
	 start solving instance: 112...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 3894.846435546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024141177535057068
		 entropy bonus: 0.09470122307538986
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08398817479610443
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.27136150002479553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 389.85467529296875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3894.846435546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06073105335235596
		 entropy bonus: 0.11063676327466965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08960594236850739
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.27136150002479553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 389.8952941894531 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3894.846435546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06275924295186996
		 entropy bonus: 0.11891286820173264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10151906311511993
		 entropy bonus: 3.8025570843070925e-33
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.27136150002479553
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 389.9084167480469 - Differentiable computation graph = True!
PPO iteration: 152/1000:
	 start solving instance: 14...
	 start solving instance: 1...
	 start solving instance: 112...
	 start solving instance: 27...
	 start solving instance: 9...
	 start solving instance: 128...
	 start solving instance: 119...
	 start solving instance: 48...
	 start solving instance: 121...
	 start solving instance: 141...
	 start solving instance: 51...
	 start solving instance: 93...
	 start solving instance: 70...
	 start solving instance: 90...
	 start solving instance: 115...
	 start solving instance: 5...
	 start solving instance: 32...
	 start solving instance: 104...
	 start solving instance: 61...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 2840.333251953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07916607707738876
		 entropy bonus: 0.12661537528038025
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17410515248775482
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.21499237418174744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 284.4889221191406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2840.333251953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0915091261267662
		 entropy bonus: 0.12739424407482147
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17667323350906372
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.21499237418174744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 284.5037536621094 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2840.333251953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09749554097652435
		 entropy bonus: 0.1272115707397461
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17667323350906372
		 entropy bonus: 1.326041655088049e-25
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.21499237418174744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 284.509765625 - Differentiable computation graph = True!
PPO iteration: 153/1000:
	 start solving instance: 119...
	 start solving instance: 1...
	 start solving instance: 93...
	 start solving instance: 141...
	 start solving instance: 61...
	 start solving instance: 5...
	 start solving instance: 27...
	 start solving instance: 17...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 104...
	 start solving instance: 48...
	 start solving instance: 14...
	 start solving instance: 112...
	 start solving instance: 128...
	 start solving instance: 70...
	 start solving instance: 51...
	 start solving instance: 9...
	 start solving instance: 115...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 2556.0703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0933869406580925
		 entropy bonus: 0.12424397468566895
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24233727157115936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.41942542791366577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 256.3497619628906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2556.0703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10215587913990021
		 entropy bonus: 0.12473709881305695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24233727157115936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.41942542791366577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 256.3584899902344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2556.0703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11098618805408478
		 entropy bonus: 0.12427065521478653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24233727157115936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.41942542791366577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 256.36737060546875 - Differentiable computation graph = True!
PPO iteration: 154/1000:
	 start solving instance: 93...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 104...
	 start solving instance: 17...
	 start solving instance: 48...
	 start solving instance: 32...
	 start solving instance: 1...
	 start solving instance: 112...
	 start solving instance: 121...
	 start solving instance: 90...
	 start solving instance: 141...
	 start solving instance: 9...
	 start solving instance: 14...
	 start solving instance: 27...
	 start solving instance: 115...
	 start solving instance: 119...
	 start solving instance: 5...
	 start solving instance: 61...
	 start solving instance: 70...
	 Optimization epoch: 1/3
		 value loss (over batch): 2407.84765625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0312969945371151
		 entropy bonus: 0.12108714878559113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09947525709867477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3221617341041565
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 241.22560119628906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2407.84765625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030875561758875847
		 entropy bonus: 0.1206253319978714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09947525709867477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3221617341041565
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 241.2252197265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2407.84765625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02967040054500103
		 entropy bonus: 0.12056951969861984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09947525709867477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3221617341041565
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 241.22401428222656 - Differentiable computation graph = True!
PPO iteration: 155/1000:
	 start solving instance: 27...
	 start solving instance: 115...
	 start solving instance: 51...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 14...
	 start solving instance: 70...
	 start solving instance: 61...
	 start solving instance: 112...
	 start solving instance: 90...
	 start solving instance: 5...
	 start solving instance: 93...
	 start solving instance: 48...
	 start solving instance: 17...
	 start solving instance: 128...
	 start solving instance: 9...
	 start solving instance: 141...
	 start solving instance: 121...
	 start solving instance: 1...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 2357.89501953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.27871859073638916
		 entropy bonus: 0.12579679489135742
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3381846249103546
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3507295846939087
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 236.74456787109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2357.89501953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2993544042110443
		 entropy bonus: 0.12456555664539337
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3381846249103546
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3507295846939087
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 236.76531982421875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2357.89501953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2864808142185211
		 entropy bonus: 0.11964740604162216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3381846249103546
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.3507295846939087
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 236.75294494628906 - Differentiable computation graph = True!
PPO iteration: 156/1000:
	 start solving instance: 27...
	 start solving instance: 9...
	 start solving instance: 32...
	 start solving instance: 70...
	 start solving instance: 51...
	 start solving instance: 14...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 48...
	 start solving instance: 17...
	 start solving instance: 104...
	 start solving instance: 141...
	 start solving instance: 5...
	 start solving instance: 1...
	 start solving instance: 115...
	 start solving instance: 61...
	 start solving instance: 119...
	 start solving instance: 121...
	 start solving instance: 93...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 2312.9677734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05105368047952652
		 entropy bonus: 0.115891233086586
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13320505619049072
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2910943925380707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 231.7605438232422 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2312.9677734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.044489432126283646
		 entropy bonus: 0.11136888712644577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13320505619049072
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2910943925380707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 231.7544403076172 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2312.9677734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03682911396026611
		 entropy bonus: 0.10735554993152618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13320505619049072
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2910943925380707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 231.74717712402344 - Differentiable computation graph = True!
PPO iteration: 157/1000:
	 start solving instance: 115...
	 start solving instance: 51...
	 start solving instance: 32...
	 start solving instance: 5...
	 start solving instance: 14...
	 start solving instance: 141...
	 start solving instance: 121...
	 start solving instance: 27...
	 start solving instance: 112...
	 start solving instance: 61...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 90...
	 start solving instance: 93...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 9...
	 start solving instance: 48...
	 start solving instance: 128...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 2336.951171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.011470806784927845
		 entropy bonus: 0.0995234027504921
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06666719168424606
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.35350847244262695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 234.1168212890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2336.951171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.016114598140120506
		 entropy bonus: 0.09570707380771637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06666719168424606
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.35350847244262695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 234.12184143066406 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2336.951171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.012195557355880737
		 entropy bonus: 0.089065320789814
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06666719168424606
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.35350847244262695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 234.11859130859375 - Differentiable computation graph = True!
PPO iteration: 158/1000:
	 start solving instance: 51...
	 start solving instance: 14...
	 start solving instance: 141...
	 start solving instance: 93...
	 start solving instance: 48...
	 start solving instance: 17...
	 start solving instance: 119...
	 start solving instance: 121...
	 start solving instance: 115...
	 start solving instance: 32...
	 start solving instance: 27...
	 start solving instance: 5...
	 start solving instance: 61...
	 start solving instance: 9...
	 start solving instance: 70...
	 start solving instance: 112...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 104...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 2309.91796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1497478187084198
		 entropy bonus: 0.09641169011592865
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21564121544361115
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2795242965221405
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 231.6270751953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2309.91796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13033246994018555
		 entropy bonus: 0.09180109947919846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21564121544361115
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2795242965221405
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 231.60812377929688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2309.91796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10874833911657333
		 entropy bonus: 0.08448868989944458
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21564121544361115
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2795242965221405
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 231.58726501464844 - Differentiable computation graph = True!
PPO iteration: 159/1000:
	 start solving instance: 90...
	 start solving instance: 112...
	 start solving instance: 27...
	 start solving instance: 1...
	 start solving instance: 32...
	 start solving instance: 121...
	 start solving instance: 5...
	 start solving instance: 48...
	 start solving instance: 93...
	 start solving instance: 17...
	 start solving instance: 119...
	 start solving instance: 9...
	 start solving instance: 141...
	 start solving instance: 51...
	 start solving instance: 70...
	 start solving instance: 61...
	 start solving instance: 115...
	 start solving instance: 104...
	 start solving instance: 128...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 2319.041015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1610213965177536
		 entropy bonus: 0.07573474943637848
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22863808274269104
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.22115854918956757
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 232.50733947753906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2319.041015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11000864952802658
		 entropy bonus: 0.046711649745702744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23136667907238007
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.22115854918956757
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 232.4619598388672 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2319.041015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11594393104314804
		 entropy bonus: 0.030837280675768852
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23136667907238007
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.22115854918956757
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 232.469482421875 - Differentiable computation graph = True!
PPO iteration: 160/1000:
	 start solving instance: 61...
	 start solving instance: 14...
	 start solving instance: 32...
	 start solving instance: 119...
	 start solving instance: 90...
	 start solving instance: 141...
	 start solving instance: 121...
	 start solving instance: 27...
	 start solving instance: 17...
	 start solving instance: 9...
	 start solving instance: 104...
	 start solving instance: 93...
	 start solving instance: 128...
	 start solving instance: 51...
	 start solving instance: 48...
	 start solving instance: 1...
	 start solving instance: 5...
	 start solving instance: 112...
	 start solving instance: 115...
	 start solving instance: 70...
	 Optimization epoch: 1/3
		 value loss (over batch): 8474.8076171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.003690099809318781
		 entropy bonus: 0.025623703375458717
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04217768833041191
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.27926239371299744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 847.7959594726562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8474.8076171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0038255334366112947
		 entropy bonus: 0.02176155336201191
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04217768833041191
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.27926239371299744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 847.7962036132812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8474.8076171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.004397165961563587
		 entropy bonus: 0.02034829556941986
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04217768833041191
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.27926239371299744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 847.7957763671875 - Differentiable computation graph = True!
PPO iteration: 161/1000:
	 New training batch of size 20...
	 start solving instance: 105...
	 start solving instance: 1...
	 start solving instance: 74...
	 start solving instance: 127...
	 start solving instance: 26...
	 start solving instance: 14...
	 start solving instance: 126...
	 start solving instance: 2...
	 start solving instance: 60...
	 start solving instance: 135...
	 start solving instance: 63...
	 start solving instance: 89...
	 start solving instance: 9...
	 start solving instance: 109...
	 start solving instance: 138...
	 start solving instance: 117...
	 start solving instance: 115...
	 start solving instance: 87...
	 start solving instance: 69...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 10483.6865234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05908142402768135
		 entropy bonus: 0.016560016199946404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06720060855150223
		 entropy bonus: 1.6902588193547733e-39
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.053969480097293854
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1048.5472412109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 10483.6865234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05809676647186279
		 entropy bonus: 0.014607342891395092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06702741980552673
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.053969480097293854
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1048.5462646484375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 10483.6865234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08631832152605057
		 entropy bonus: 0.0129056666046381
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07151849567890167
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.053969480097293854
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1048.5792236328125 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 11425.5693359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.024188851937651634
		 entropy bonus: 0.011165744625031948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03167806938290596
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.2606062889099121
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1142.8240
PPO iteration: 162/1000:
	 start solving instance: 115...
	 start solving instance: 69...
	 start solving instance: 135...
	 start solving instance: 105...
	 start solving instance: 74...
	 start solving instance: 87...
	 start solving instance: 126...
	 start solving instance: 127...
	 start solving instance: 109...
	 start solving instance: 60...
	 start solving instance: 138...
	 start solving instance: 9...
	 start solving instance: 1...
	 start solving instance: 63...
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 26...
	 start solving instance: 14...
	 start solving instance: 2...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 11505.8701171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009218478575348854
		 entropy bonus: 0.01061647292226553
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.010527551174163818
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06405580043792725
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1150.6513671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 11505.8701171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009431958198547363
		 entropy bonus: 0.008819879963994026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.010527551174163818
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06405580043792725
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1150.6513671875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 11505.8701171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009259700775146484
		 entropy bonus: 0.007371052633970976
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.010527551174163818
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06405580043792725
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1150.651611328125 - Differentiable computation graph = True!
PPO iteration: 163/1000:
	 start solving instance: 117...
	 start solving instance: 127...
	 start solving instance: 77...
	 start solving instance: 2...
	 start solving instance: 115...
	 start solving instance: 60...
	 start solving instance: 9...
	 start solving instance: 126...
	 start solving instance: 87...
	 start solving instance: 109...
	 start solving instance: 14...
	 start solving instance: 89...
	 start solving instance: 74...
	 start solving instance: 135...
	 start solving instance: 1...
	 start solving instance: 105...
	 start solving instance: 69...
	 start solving instance: 63...
	 start solving instance: 138...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 12045.708984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009491482749581337
		 entropy bonus: 0.0063652279786765575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.01109644491225481
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06538736820220947
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1204.6373291015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 12045.708984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00950249470770359
		 entropy bonus: 0.005626096855849028
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012168332934379578
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06538736820220947
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1204.638427734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 12045.708984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009426012635231018
		 entropy bonus: 0.004910457879304886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012168332934379578
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06538736820220947
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1204.6385498046875 - Differentiable computation graph = True!
PPO iteration: 164/1000:
	 start solving instance: 1...
	 start solving instance: 14...
	 start solving instance: 109...
	 start solving instance: 9...
	 start solving instance: 2...
	 start solving instance: 87...
	 start solving instance: 138...
	 start solving instance: 77...
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 105...
	 start solving instance: 60...
	 start solving instance: 115...
	 start solving instance: 26...
	 start solving instance: 63...
	 start solving instance: 69...
	 start solving instance: 126...
	 start solving instance: 74...
	 start solving instance: 127...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 12257.0654296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009527898393571377
		 entropy bonus: 0.004548926372081041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011384940706193447
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06294842064380646
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1225.7708740234375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 12257.0654296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.010334610939025879
		 entropy bonus: 0.004307021852582693
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011384940706193447
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06294842064380646
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1225.7701416015625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 12257.0654296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.010328221134841442
		 entropy bonus: 0.004132320173084736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011384940706193447
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06294842064380646
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1225.7701416015625 - Differentiable computation graph = True!
PPO iteration: 165/1000:
	 start solving instance: 105...
	 start solving instance: 87...
	 start solving instance: 109...
	 start solving instance: 26...
	 start solving instance: 74...
	 start solving instance: 89...
	 start solving instance: 63...
	 start solving instance: 2...
	 start solving instance: 69...
	 start solving instance: 1...
	 start solving instance: 115...
	 start solving instance: 138...
	 start solving instance: 126...
	 start solving instance: 117...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 9...
	 start solving instance: 60...
	 start solving instance: 14...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 12420.8955078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009530371986329556
		 entropy bonus: 0.00413045147433877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011666077189147472
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06374357640743256
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1242.1551513671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 12420.8955078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00955191534012556
		 entropy bonus: 0.004629208240658045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011666077189147472
		 entropy bonus: 1.39377281894813e-37
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06374357640743256
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1242.155029296875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 12420.8955078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0106606874614954
		 entropy bonus: 0.005336443427950144
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.014087405987083912
		 entropy bonus: 0.0011520169209688902
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06374357640743256
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1242.1561279296875 - Differentiable computation graph = True!
PPO iteration: 166/1000:
	 start solving instance: 109...
	 start solving instance: 115...
	 start solving instance: 105...
	 start solving instance: 63...
	 start solving instance: 74...
	 start solving instance: 60...
	 start solving instance: 138...
	 start solving instance: 9...
	 start solving instance: 14...
	 start solving instance: 26...
	 start solving instance: 2...
	 start solving instance: 69...
	 start solving instance: 117...
	 start solving instance: 126...
	 start solving instance: 87...
	 start solving instance: 135...
	 start solving instance: 127...
	 start solving instance: 77...
	 start solving instance: 1...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 20320.328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021999835968017578
		 entropy bonus: 0.0054423012770712376
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.004293394275009632
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.025583554059267044
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2031.989013671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 20320.328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.016582464799284935
		 entropy bonus: 0.005253676325082779
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.004293394275009632
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.025583554059267044
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2031.9945068359375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 20320.328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021929431706666946
		 entropy bonus: 0.00504406588152051
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.006415355484932661
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.025583554059267044
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2031.9912109375 - Differentiable computation graph = True!
PPO iteration: 167/1000:
	 start solving instance: 115...
	 start solving instance: 9...
	 start solving instance: 74...
	 start solving instance: 60...
	 start solving instance: 126...
	 start solving instance: 138...
	 start solving instance: 117...
	 start solving instance: 135...
	 start solving instance: 127...
	 start solving instance: 69...
	 start solving instance: 109...
	 start solving instance: 63...
	 start solving instance: 105...
	 start solving instance: 1...
	 start solving instance: 87...
	 start solving instance: 2...
	 start solving instance: 77...
	 start solving instance: 89...
	 start solving instance: 26...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 41791.27734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021750403568148613
		 entropy bonus: 0.0048624384216964245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.005357575602829456
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.037310827523469925
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4179.06298828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 41791.27734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009997570887207985
		 entropy bonus: 0.004872982855886221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.005357575602829456
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.037310827523469925
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4179.0751953125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 41791.27734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.013677793554961681
		 entropy bonus: 0.004886772017925978
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.005357575602829456
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.037310827523469925
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4179.0712890625 - Differentiable computation graph = True!
PPO iteration: 168/1000:
	 start solving instance: 14...
	 start solving instance: 69...
	 start solving instance: 89...
	 start solving instance: 109...
	 start solving instance: 117...
	 start solving instance: 9...
	 start solving instance: 2...
	 start solving instance: 26...
	 start solving instance: 63...
	 start solving instance: 1...
	 start solving instance: 115...
	 start solving instance: 105...
	 start solving instance: 77...
	 start solving instance: 127...
	 start solving instance: 60...
	 start solving instance: 87...
	 start solving instance: 126...
	 start solving instance: 74...
	 start solving instance: 135...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 54297.59375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02138059213757515
		 entropy bonus: 0.004548646043986082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0019869746174663305
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03655507043004036
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5429.70263671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 54297.59375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021428117528557777
		 entropy bonus: 0.004558473825454712
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0019869746174663305
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03655507043004036
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5429.70263671875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 54297.59375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02132067084312439
		 entropy bonus: 0.004804691765457392
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0019869746174663305
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03655507043004036
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5429.70263671875 - Differentiable computation graph = True!
PPO iteration: 169/1000:
	 start solving instance: 117...
	 start solving instance: 138...
	 start solving instance: 87...
	 start solving instance: 126...
	 start solving instance: 26...
	 start solving instance: 109...
	 start solving instance: 69...
	 start solving instance: 2...
	 start solving instance: 63...
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 1...
	 start solving instance: 9...
	 start solving instance: 14...
	 start solving instance: 115...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 74...
	 start solving instance: 105...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 63310.27734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02108750306069851
		 entropy bonus: 0.004745136480778456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.001794036477804184
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03695328161120415
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6330.97119140625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 63310.27734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02085346356034279
		 entropy bonus: 0.0052087861113250256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.001794036477804184
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03695328161120415
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6330.97119140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 63310.27734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.020720798522233963
		 entropy bonus: 0.005422105547040701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.001794036477804184
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03695328161120415
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6330.97119140625 - Differentiable computation graph = True!
PPO iteration: 170/1000:
	 start solving instance: 126...
	 start solving instance: 2...
	 start solving instance: 69...
	 start solving instance: 105...
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 60...
	 start solving instance: 109...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 74...
	 start solving instance: 63...
	 start solving instance: 77...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 138...
	 start solving instance: 117...
	 start solving instance: 14...
	 start solving instance: 115...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 73720.8984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0097312331199646
		 entropy bonus: 0.005246256943792105
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.014746153727173805
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03688564524054527
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7372.0576171875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 73720.8984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009760284796357155
		 entropy bonus: 0.005900555290281773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.014746153727173805
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03688564524054527
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7372.0576171875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 73720.8984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00034412145032547414
		 entropy bonus: 0.007257557008415461
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.014746153727173805
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03688564524054527
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7372.06689453125 - Differentiable computation graph = True!
PPO iteration: 171/1000:
	 New training batch of size 20...
	 start solving instance: 22...
	 start solving instance: 133...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 138...
	 start solving instance: 53...
	 start solving instance: 122...
	 start solving instance: 73...
	 start solving instance: 7...
	 start solving instance: 142...
	 start solving instance: 51...
	 start solving instance: 34...
	 start solving instance: 125...
	 start solving instance: 96...
	 start solving instance: 24...
	 start solving instance: 17...
	 start solving instance: 15...
	 start solving instance: 132...
	 start solving instance: 148...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 84660.7421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01939213275909424
		 entropy bonus: 0.0065901861526072025
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01946978084743023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14867085218429565
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8465.9248046875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 84660.7421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0244210846722126
		 entropy bonus: 0.006404508836567402
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019049352034926414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14867085218429565
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8465.9296875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 84660.7421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.017549240961670876
		 entropy bonus: 0.008026284165680408
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019049352034926414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14867085218429565
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8465.9228515625 - Differentiable computation graph = True!
PPO iteration: 172/1000:
	 start solving instance: 22...
	 start solving instance: 138...
	 start solving instance: 72...
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 51...
	 start solving instance: 15...
	 start solving instance: 148...
	 start solving instance: 118...
	 start solving instance: 96...
	 start solving instance: 122...
	 start solving instance: 53...
	 start solving instance: 125...
	 start solving instance: 24...
	 start solving instance: 65...
	 start solving instance: 34...
	 start solving instance: 17...
	 start solving instance: 7...
	 start solving instance: 73...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 99856.8671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.020345771685242653
		 entropy bonus: 0.010098724626004696
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.022564148530364037
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14727799594402313
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9985.5361328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 99856.8671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.021155918017029762
		 entropy bonus: 0.010339145548641682
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.022564148530364037
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14727799594402313
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9985.537109375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 99856.8671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02049585059285164
		 entropy bonus: 0.009289982728660107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.022564148530364037
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14727799594402313
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9985.5361328125 - Differentiable computation graph = True!
PPO iteration: 173/1000:
	 start solving instance: 73...
	 start solving instance: 118...
	 start solving instance: 148...
	 start solving instance: 7...
	 start solving instance: 65...
	 start solving instance: 53...
	 start solving instance: 51...
	 start solving instance: 96...
	 start solving instance: 133...
	 start solving instance: 24...
	 start solving instance: 142...
	 start solving instance: 125...
	 start solving instance: 132...
	 start solving instance: 22...
	 start solving instance: 122...
	 start solving instance: 34...
	 start solving instance: 17...
	 start solving instance: 72...
	 start solving instance: 15...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 105906.2421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.020800292491912842
		 entropy bonus: 0.010808825492858887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02250908687710762
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14767155051231384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10590.4736328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 105906.2421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03200516849756241
		 entropy bonus: 0.010315584018826485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02250908687710762
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14767155051231384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10590.4853515625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 105906.2421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1277327984571457
		 entropy bonus: 0.013986227102577686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02250908687710762
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14767155051231384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10590.580078125 - Differentiable computation graph = True!
PPO iteration: 174/1000:
	 start solving instance: 118...
	 start solving instance: 138...
	 start solving instance: 34...
	 start solving instance: 7...
	 start solving instance: 65...
	 start solving instance: 24...
	 start solving instance: 22...
	 start solving instance: 51...
	 start solving instance: 72...
	 start solving instance: 122...
	 start solving instance: 133...
	 start solving instance: 132...
	 start solving instance: 73...
	 start solving instance: 125...
	 start solving instance: 15...
	 start solving instance: 96...
	 start solving instance: 142...
	 start solving instance: 53...
	 start solving instance: 148...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 102563.890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02184227481484413
		 entropy bonus: 0.012204566970467567
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021611720323562622
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15460209548473358
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10256.234375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 102563.890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.021415147930383682
		 entropy bonus: 0.016188696026802063
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021611720323562622
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15460209548473358
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10256.2333984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 102563.890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.026935739442706108
		 entropy bonus: 0.009225013665854931
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021611720323562622
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15460209548473358
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10256.240234375 - Differentiable computation graph = True!
PPO iteration: 175/1000:
	 start solving instance: 22...
	 start solving instance: 138...
	 start solving instance: 122...
	 start solving instance: 142...
	 start solving instance: 132...
	 start solving instance: 53...
	 start solving instance: 118...
	 start solving instance: 34...
	 start solving instance: 125...
	 start solving instance: 148...
	 start solving instance: 65...
	 start solving instance: 96...
	 start solving instance: 24...
	 start solving instance: 15...
	 start solving instance: 7...
	 start solving instance: 73...
	 start solving instance: 51...
	 start solving instance: 133...
	 start solving instance: 72...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 89075.7265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.028280138969421387
		 entropy bonus: 0.009557156823575497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.016174329444766045
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1502869874238968
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8907.4345703125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 89075.7265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0289290901273489
		 entropy bonus: 0.009136953391134739
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.016174329444766045
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1502869874238968
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8907.435546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 89075.7265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07741998881101608
		 entropy bonus: 0.008573642931878567
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013434267602860928
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1502869874238968
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8907.4853515625 - Differentiable computation graph = True!
PPO iteration: 176/1000:
	 start solving instance: 24...
	 start solving instance: 125...
	 start solving instance: 96...
	 start solving instance: 73...
	 start solving instance: 122...
	 start solving instance: 148...
	 start solving instance: 15...
	 start solving instance: 17...
	 start solving instance: 65...
	 start solving instance: 22...
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 133...
	 start solving instance: 34...
	 start solving instance: 138...
	 start solving instance: 7...
	 start solving instance: 53...
	 start solving instance: 51...
	 start solving instance: 118...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 73602.2890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.023234762251377106
		 entropy bonus: 0.008716239593923092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02119351737201214
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1522989571094513
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7360.078125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 73602.2890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.022073952481150627
		 entropy bonus: 0.010467566549777985
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02119351737201214
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1522989571094513
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7360.07666015625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 73602.2890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024612339213490486
		 entropy bonus: 0.007563417311757803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02119351737201214
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1522989571094513
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7360.07958984375 - Differentiable computation graph = True!
PPO iteration: 177/1000:
	 start solving instance: 15...
	 start solving instance: 96...
	 start solving instance: 17...
	 start solving instance: 65...
	 start solving instance: 142...
	 start solving instance: 133...
	 start solving instance: 138...
	 start solving instance: 51...
	 start solving instance: 122...
	 start solving instance: 125...
	 start solving instance: 22...
	 start solving instance: 132...
	 start solving instance: 7...
	 start solving instance: 24...
	 start solving instance: 34...
	 start solving instance: 73...
	 start solving instance: 72...
	 start solving instance: 53...
	 start solving instance: 148...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 69291.3359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08797913789749146
		 entropy bonus: 0.007354571018368006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06417873501777649
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14280585944652557
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6929.142578125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 69291.3359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08724776655435562
		 entropy bonus: 0.008246753364801407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06417873501777649
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14280585944652557
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6929.1416015625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 69291.3359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08014219254255295
		 entropy bonus: 0.005558289121836424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06417873501777649
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14280585944652557
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6929.134765625 - Differentiable computation graph = True!
PPO iteration: 178/1000:
	 start solving instance: 72...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 7...
	 start solving instance: 96...
	 start solving instance: 51...
	 start solving instance: 34...
	 start solving instance: 53...
	 start solving instance: 122...
	 start solving instance: 148...
	 start solving instance: 24...
	 start solving instance: 15...
	 start solving instance: 132...
	 start solving instance: 133...
	 start solving instance: 73...
	 start solving instance: 118...
	 start solving instance: 17...
	 start solving instance: 125...
	 start solving instance: 22...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 73149.1015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025489484891295433
		 entropy bonus: 0.007346016820520163
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02105599083006382
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.153591126203537
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7314.76025390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 73149.1015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024988099932670593
		 entropy bonus: 0.007364470046013594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02105599083006382
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.153591126203537
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7314.759765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 73149.1015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02561965025961399
		 entropy bonus: 0.007112424820661545
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02105599083006382
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.153591126203537
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7314.76025390625 - Differentiable computation graph = True!
PPO iteration: 179/1000:
	 start solving instance: 65...
	 start solving instance: 133...
	 start solving instance: 15...
	 start solving instance: 73...
	 start solving instance: 132...
	 start solving instance: 53...
	 start solving instance: 24...
	 start solving instance: 17...
	 start solving instance: 122...
	 start solving instance: 51...
	 start solving instance: 22...
	 start solving instance: 118...
	 start solving instance: 96...
	 start solving instance: 72...
	 start solving instance: 148...
	 start solving instance: 142...
	 start solving instance: 125...
	 start solving instance: 138...
	 start solving instance: 34...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 88585.2421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025388633832335472
		 entropy bonus: 0.008429164998233318
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0215363260358572
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15224945545196533
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8858.375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 88585.2421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02704569138586521
		 entropy bonus: 0.009205317124724388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0215363260358572
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15224945545196533
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8858.376953125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 88585.2421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02653256617486477
		 entropy bonus: 0.0077753253281116486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0215363260358572
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15224945545196533
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8858.3759765625 - Differentiable computation graph = True!
PPO iteration: 180/1000:
	 start solving instance: 65...
	 start solving instance: 17...
	 start solving instance: 122...
	 start solving instance: 24...
	 start solving instance: 22...
	 start solving instance: 53...
	 start solving instance: 125...
	 start solving instance: 7...
	 start solving instance: 138...
	 start solving instance: 34...
	 start solving instance: 142...
	 start solving instance: 132...
	 start solving instance: 133...
	 start solving instance: 72...
	 start solving instance: 15...
	 start solving instance: 51...
	 start solving instance: 96...
	 start solving instance: 148...
	 start solving instance: 73...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 96424.7421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02580893039703369
		 entropy bonus: 0.010355941019952297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021580461412668228
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15267705917358398
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9642.3251953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 96424.7421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024952664971351624
		 entropy bonus: 0.006934858858585358
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019933709874749184
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15267705917358398
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9642.326171875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 96424.7421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025360478088259697
		 entropy bonus: 0.008719808422029018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.018903592601418495
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15267705917358398
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9642.3271484375 - Differentiable computation graph = True!
PPO iteration: 181/1000:
	 New training batch of size 20...
	 start solving instance: 107...
	 start solving instance: 29...
	 start solving instance: 4...
	 start solving instance: 3...
	 start solving instance: 34...
	 start solving instance: 133...
	 start solving instance: 1...
	 start solving instance: 148...
	 start solving instance: 5...
	 start solving instance: 123...
	 start solving instance: 96...
	 start solving instance: 104...
	 start solving instance: 42...
	 start solving instance: 86...
	 start solving instance: 41...
	 start solving instance: 149...
	 start solving instance: 6...
	 start solving instance: 102...
	 start solving instance: 116...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 76187.6484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03273267671465874
		 entropy bonus: 0.006417975760996342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013446569442749023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06304067373275757
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7618.78173828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 76187.6484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03738885000348091
		 entropy bonus: 0.01022758986800909
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013446569442749023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06304067373275757
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7618.7763671875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 76187.6484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03285864740610123
		 entropy bonus: 0.006046549882739782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013446569442749023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06304067373275757
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7618.78125 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 75273.5859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.013822865672409534
		 entropy bonus: 0.006982904858887196
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.010421955958008766
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10182776302099228
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7527.4565
PPO iteration: 182/1000:
	 start solving instance: 123...
	 start solving instance: 29...
	 start solving instance: 1...
	 start solving instance: 34...
	 start solving instance: 17...
	 start solving instance: 41...
	 start solving instance: 86...
	 start solving instance: 96...
	 start solving instance: 102...
	 start solving instance: 149...
	 start solving instance: 3...
	 start solving instance: 107...
	 start solving instance: 148...
	 start solving instance: 116...
	 start solving instance: 4...
	 start solving instance: 6...
	 start solving instance: 104...
	 start solving instance: 133...
	 start solving instance: 5...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 73007.5859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03272465616464615
		 entropy bonus: 0.0076624020002782345
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019315768033266068
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06362124532461166
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7300.76953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 73007.5859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021820200607180595
		 entropy bonus: 0.009194713085889816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019315768033266068
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06362124532461166
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7300.7802734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 73007.5859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03253048658370972
		 entropy bonus: 0.008067063987255096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019315768033266068
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06362124532461166
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7300.77001953125 - Differentiable computation graph = True!
PPO iteration: 183/1000:
	 start solving instance: 4...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 42...
	 start solving instance: 41...
	 start solving instance: 96...
	 start solving instance: 123...
	 start solving instance: 104...
	 start solving instance: 1...
	 start solving instance: 149...
	 start solving instance: 148...
	 start solving instance: 133...
	 start solving instance: 17...
	 start solving instance: 86...
	 start solving instance: 29...
	 start solving instance: 6...
	 start solving instance: 34...
	 start solving instance: 3...
	 start solving instance: 102...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 78407.375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03270028159022331
		 entropy bonus: 0.006698638200759888
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014231729321181774
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0692465752363205
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7840.759765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 78407.375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03325284272432327
		 entropy bonus: 0.009637737646698952
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014231729321181774
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0692465752363205
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7840.7587890625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 78407.375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03362865373492241
		 entropy bonus: 0.00910013634711504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014231729321181774
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0692465752363205
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7840.75830078125 - Differentiable computation graph = True!
PPO iteration: 184/1000:
	 start solving instance: 1...
	 start solving instance: 4...
	 start solving instance: 41...
	 start solving instance: 104...
	 start solving instance: 133...
	 start solving instance: 34...
	 start solving instance: 107...
	 start solving instance: 96...
	 start solving instance: 123...
	 start solving instance: 3...
	 start solving instance: 6...
	 start solving instance: 29...
	 start solving instance: 5...
	 start solving instance: 102...
	 start solving instance: 17...
	 start solving instance: 148...
	 start solving instance: 149...
	 start solving instance: 116...
	 start solving instance: 42...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 86478.0390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08321019262075424
		 entropy bonus: 0.026691872626543045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11201447248458862
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.027552392333745956
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8648.0234375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 86478.0390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05273869261145592
		 entropy bonus: 0.009229426272213459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11201447248458862
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.027552392333745956
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8647.9951171875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 86478.0390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.050702955573797226
		 entropy bonus: 0.009882359765470028
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11201447248458862
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.027552392333745956
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8647.9931640625 - Differentiable computation graph = True!
PPO iteration: 185/1000:
	 start solving instance: 148...
	 start solving instance: 41...
	 start solving instance: 29...
	 start solving instance: 4...
	 start solving instance: 6...
	 start solving instance: 123...
	 start solving instance: 96...
	 start solving instance: 116...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 133...
	 start solving instance: 86...
	 start solving instance: 17...
	 start solving instance: 42...
	 start solving instance: 1...
	 start solving instance: 5...
	 start solving instance: 107...
	 start solving instance: 34...
	 start solving instance: 149...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 91955.265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.003186047077178955
		 entropy bonus: 0.015762927010655403
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05206037312746048
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10855501890182495
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9195.681640625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 91955.265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02240450493991375
		 entropy bonus: 0.011684209108352661
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05464710667729378
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10855501890182495
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9195.7109375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 91955.265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03059585765004158
		 entropy bonus: 0.008762183599174023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05661526322364807
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10855501890182495
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9195.720703125 - Differentiable computation graph = True!
PPO iteration: 186/1000:
	 start solving instance: 107...
	 start solving instance: 4...
	 start solving instance: 5...
	 start solving instance: 104...
	 start solving instance: 123...
	 start solving instance: 3...
	 start solving instance: 17...
	 start solving instance: 148...
	 start solving instance: 29...
	 start solving instance: 133...
	 start solving instance: 149...
	 start solving instance: 102...
	 start solving instance: 86...
	 start solving instance: 34...
	 start solving instance: 96...
	 start solving instance: 41...
	 start solving instance: 6...
	 start solving instance: 1...
	 start solving instance: 42...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 85021.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05384686216711998
		 entropy bonus: 0.007196843158453703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019227391108870506
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12121088802814484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8502.197265625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 85021.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04346753656864166
		 entropy bonus: 0.010123173706233501
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019227391108870506
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12121088802814484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8502.20703125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 85021.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04368881508708
		 entropy bonus: 0.008349954150617123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.019227391108870506
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12121088802814484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8502.20703125 - Differentiable computation graph = True!
PPO iteration: 187/1000:
	 start solving instance: 133...
	 start solving instance: 1...
	 start solving instance: 5...
	 start solving instance: 34...
	 start solving instance: 96...
	 start solving instance: 17...
	 start solving instance: 29...
	 start solving instance: 107...
	 start solving instance: 6...
	 start solving instance: 42...
	 start solving instance: 41...
	 start solving instance: 102...
	 start solving instance: 104...
	 start solving instance: 148...
	 start solving instance: 116...
	 start solving instance: 4...
	 start solving instance: 123...
	 start solving instance: 3...
	 start solving instance: 149...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 83192.3671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03597893938422203
		 entropy bonus: 0.009987483732402325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014747858047485352
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12410445511341095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8319.3095703125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 83192.3671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0358225516974926
		 entropy bonus: 0.011125961318612099
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014747858047485352
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12410445511341095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8319.3095703125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 83192.3671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.030434245243668556
		 entropy bonus: 0.008526447229087353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01332106627523899
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12410445511341095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8319.31640625 - Differentiable computation graph = True!
PPO iteration: 188/1000:
	 start solving instance: 96...
	 start solving instance: 86...
	 start solving instance: 42...
	 start solving instance: 102...
	 start solving instance: 34...
	 start solving instance: 17...
	 start solving instance: 4...
	 start solving instance: 107...
	 start solving instance: 5...
	 start solving instance: 3...
	 start solving instance: 6...
	 start solving instance: 1...
	 start solving instance: 123...
	 start solving instance: 104...
	 start solving instance: 116...
	 start solving instance: 149...
	 start solving instance: 148...
	 start solving instance: 41...
	 start solving instance: 29...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 83334.8359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03598528727889061
		 entropy bonus: 0.0071978881023824215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01480460911989212
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12654606997966766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8333.5576171875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 83334.8359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.036883074790239334
		 entropy bonus: 0.011163432151079178
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01480460911989212
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12654606997966766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8333.556640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 83334.8359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.042481184005737305
		 entropy bonus: 0.015087227337062359
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01480460911989212
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12654606997966766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8333.55078125 - Differentiable computation graph = True!
PPO iteration: 189/1000:
	 start solving instance: 41...
	 start solving instance: 6...
	 start solving instance: 34...
	 start solving instance: 149...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 107...
	 start solving instance: 5...
	 start solving instance: 29...
	 start solving instance: 1...
	 start solving instance: 116...
	 start solving instance: 148...
	 start solving instance: 123...
	 start solving instance: 17...
	 start solving instance: 133...
	 start solving instance: 104...
	 start solving instance: 86...
	 start solving instance: 42...
	 start solving instance: 96...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 86284.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.035425230860710144
		 entropy bonus: 0.0066560679115355015
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014721736311912537
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12477066367864609
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8628.5185546875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 86284.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.036061495542526245
		 entropy bonus: 0.00926864705979824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013946316204965115
		 entropy bonus: 1.615642194377163e-32
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12477066367864609
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8628.517578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 86284.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03465116396546364
		 entropy bonus: 0.007272303104400635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.011122575961053371
		 entropy bonus: 2.165385740227066e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12477066367864609
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8628.5224609375 - Differentiable computation graph = True!
PPO iteration: 190/1000:
	 start solving instance: 42...
	 start solving instance: 1...
	 start solving instance: 123...
	 start solving instance: 86...
	 start solving instance: 17...
	 start solving instance: 133...
	 start solving instance: 6...
	 start solving instance: 116...
	 start solving instance: 102...
	 start solving instance: 107...
	 start solving instance: 3...
	 start solving instance: 41...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 96...
	 start solving instance: 148...
	 start solving instance: 29...
	 start solving instance: 5...
	 start solving instance: 4...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 76049.4765625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03570825979113579
		 entropy bonus: 0.00936907809227705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014655262231826782
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13249807059764862
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7605.02880859375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 76049.4765625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.022791564464569092
		 entropy bonus: 0.009127991273999214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0016307234764099121
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13249807059764862
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7605.0546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 76049.4765625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0228483434766531
		 entropy bonus: 0.00752374529838562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0016307234764099121
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13249807059764862
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7605.05517578125 - Differentiable computation graph = True!
PPO iteration: 191/1000:
	 New training batch of size 20...
	 start solving instance: 6...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 130...
	 start solving instance: 116...
	 start solving instance: 123...
	 start solving instance: 2...
	 start solving instance: 11...
	 start solving instance: 7...
	 start solving instance: 100...
	 start solving instance: 48...
	 start solving instance: 96...
	 start solving instance: 139...
	 start solving instance: 89...
	 start solving instance: 110...
	 start solving instance: 80...
	 start solving instance: 101...
	 start solving instance: 142...
	 start solving instance: 67...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 66539.0390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.010418313555419445
		 entropy bonus: 0.007004651706665754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.059190262109041214
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03840186074376106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6653.794921875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 66539.0390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01190185546875
		 entropy bonus: 0.00843813642859459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05793426185846329
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03840186074376106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6653.794921875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 66539.0390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.003278970718383789
		 entropy bonus: 0.007222976069897413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05793426185846329
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03840186074376106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6653.8037109375 - Differentiable computation graph = True!
PPO iteration: 192/1000:
	 start solving instance: 129...
	 start solving instance: 110...
	 start solving instance: 139...
	 start solving instance: 142...
	 start solving instance: 48...
	 start solving instance: 2...
	 start solving instance: 100...
	 start solving instance: 99...
	 start solving instance: 96...
	 start solving instance: 11...
	 start solving instance: 7...
	 start solving instance: 89...
	 start solving instance: 80...
	 start solving instance: 116...
	 start solving instance: 6...
	 start solving instance: 67...
	 start solving instance: 95...
	 start solving instance: 123...
	 start solving instance: 130...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 68527.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.010707435198128223
		 entropy bonus: 0.00941759254783392
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.055993568152189255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05495674908161163
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6852.57763671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 68527.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0024922655429691076
		 entropy bonus: 0.006236858665943146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05309278890490532
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05495674908161163
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6852.58935546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 68527.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.003299373434856534
		 entropy bonus: 0.007744632661342621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05223030596971512
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05495674908161163
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6852.5888671875 - Differentiable computation graph = True!
PPO iteration: 193/1000:
	 start solving instance: 7...
	 start solving instance: 95...
	 start solving instance: 80...
	 start solving instance: 110...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 11...
	 start solving instance: 101...
	 start solving instance: 123...
	 start solving instance: 99...
	 start solving instance: 139...
	 start solving instance: 89...
	 start solving instance: 6...
	 start solving instance: 129...
	 start solving instance: 2...
	 start solving instance: 48...
	 start solving instance: 142...
	 start solving instance: 116...
	 start solving instance: 67...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 60768.20703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01011350192129612
		 entropy bonus: 0.006813825108110905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05215216800570488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07108669728040695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6076.68701171875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 60768.20703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.014904260635375977
		 entropy bonus: 0.009657155722379684
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05215216800570488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07108669728040695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6076.681640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 60768.20703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009759831242263317
		 entropy bonus: 0.007393857929855585
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04965406656265259
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07108669728040695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6076.689453125 - Differentiable computation graph = True!
PPO iteration: 194/1000:
	 start solving instance: 7...
	 start solving instance: 101...
	 start solving instance: 110...
	 start solving instance: 95...
	 start solving instance: 116...
	 start solving instance: 2...
	 start solving instance: 48...
	 start solving instance: 6...
	 start solving instance: 11...
	 start solving instance: 139...
	 start solving instance: 123...
	 start solving instance: 80...
	 start solving instance: 99...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 67...
	 start solving instance: 89...
	 start solving instance: 96...
	 start solving instance: 100...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 61643.6640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00980454683303833
		 entropy bonus: 0.009047632105648518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.050430115312337875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07763713598251343
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6164.22802734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 61643.6640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006997787859290838
		 entropy bonus: 0.004958255682140589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04911481961607933
		 entropy bonus: 1.2065421903760531e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07763713598251343
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6164.232421875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 61643.6640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008299040608108044
		 entropy bonus: 0.008828971534967422
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.050430115312337875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07763713598251343
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6164.2294921875 - Differentiable computation graph = True!
PPO iteration: 195/1000:
	 start solving instance: 95...
	 start solving instance: 48...
	 start solving instance: 116...
	 start solving instance: 139...
	 start solving instance: 7...
	 start solving instance: 89...
	 start solving instance: 6...
	 start solving instance: 129...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 110...
	 start solving instance: 142...
	 start solving instance: 123...
	 start solving instance: 67...
	 start solving instance: 101...
	 start solving instance: 99...
	 start solving instance: 96...
	 start solving instance: 2...
	 start solving instance: 11...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 68936.3046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.010048878379166126
		 entropy bonus: 0.006383317057043314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04894677922129631
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08095747977495193
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6893.48974609375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 68936.3046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011271798983216286
		 entropy bonus: 0.010136127471923828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04894677922129631
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08095747977495193
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6893.48828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 68936.3046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.008016753010451794
		 entropy bonus: 0.009556177072227001
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04894677922129631
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08095747977495193
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6893.50732421875 - Differentiable computation graph = True!
PPO iteration: 196/1000:
	 start solving instance: 95...
	 start solving instance: 142...
	 start solving instance: 100...
	 start solving instance: 110...
	 start solving instance: 129...
	 start solving instance: 116...
	 start solving instance: 123...
	 start solving instance: 130...
	 start solving instance: 67...
	 start solving instance: 6...
	 start solving instance: 11...
	 start solving instance: 139...
	 start solving instance: 96...
	 start solving instance: 7...
	 start solving instance: 99...
	 start solving instance: 2...
	 start solving instance: 48...
	 start solving instance: 101...
	 start solving instance: 89...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 63943.2265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008893812075257301
		 entropy bonus: 0.0066835954785346985
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.046522580087184906
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08235803991556168
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6394.18408203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 63943.2265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010248133912682533
		 entropy bonus: 0.006654720287770033
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04653932899236679
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08235803991556168
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6394.20361328125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 63943.2265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010833337903022766
		 entropy bonus: 0.005976449698209763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04335980489850044
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08235803991556168
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6394.20751953125 - Differentiable computation graph = True!
PPO iteration: 197/1000:
	 start solving instance: 101...
	 start solving instance: 130...
	 start solving instance: 116...
	 start solving instance: 142...
	 start solving instance: 95...
	 start solving instance: 129...
	 start solving instance: 89...
	 start solving instance: 110...
	 start solving instance: 11...
	 start solving instance: 139...
	 start solving instance: 99...
	 start solving instance: 2...
	 start solving instance: 67...
	 start solving instance: 123...
	 start solving instance: 48...
	 start solving instance: 7...
	 start solving instance: 6...
	 start solving instance: 80...
	 start solving instance: 100...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 66520.4921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.006315088365226984
		 entropy bonus: 0.006794088985770941
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.031545091420412064
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0447288453578949
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6651.97900390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 66520.4921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0076233865693211555
		 entropy bonus: 0.013520401902496815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.031545091420412064
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0447288453578949
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6651.96435546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 66520.4921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02225707843899727
		 entropy bonus: 0.010348428972065449
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.031425416469573975
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0447288453578949
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6651.994140625 - Differentiable computation graph = True!
PPO iteration: 198/1000:
	 start solving instance: 101...
	 start solving instance: 48...
	 start solving instance: 142...
	 start solving instance: 96...
	 start solving instance: 116...
	 start solving instance: 11...
	 start solving instance: 2...
	 start solving instance: 130...
	 start solving instance: 95...
	 start solving instance: 110...
	 start solving instance: 80...
	 start solving instance: 99...
	 start solving instance: 139...
	 start solving instance: 100...
	 start solving instance: 6...
	 start solving instance: 89...
	 start solving instance: 7...
	 start solving instance: 67...
	 start solving instance: 123...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 33513.0234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0008188128704205155
		 entropy bonus: 0.005282494705170393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.039659757167100906
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0887124091386795
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3351.172607421875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 33513.0234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08427350223064423
		 entropy bonus: 0.00389088480733335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07053494453430176
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0887124091386795
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3351.368408203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 33513.0234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07532241195440292
		 entropy bonus: 0.0038134311325848103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09417291730642319
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0887124091386795
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3351.3828125 - Differentiable computation graph = True!
PPO iteration: 199/1000:
	 start solving instance: 142...
	 start solving instance: 89...
	 start solving instance: 100...
	 start solving instance: 123...
	 start solving instance: 95...
	 start solving instance: 11...
	 start solving instance: 48...
	 start solving instance: 80...
	 start solving instance: 130...
	 start solving instance: 6...
	 start solving instance: 129...
	 start solving instance: 101...
	 start solving instance: 139...
	 start solving instance: 2...
	 start solving instance: 110...
	 start solving instance: 99...
	 start solving instance: 67...
	 start solving instance: 116...
	 start solving instance: 7...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 18585.26953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00567705649882555
		 entropy bonus: 0.004464470781385899
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01296622771769762
		 entropy bonus: 0.0009172146092168987
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031075026839971542
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1858.4766845703125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 18585.26953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02117111161351204
		 entropy bonus: 0.004205680917948484
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07874604314565659
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031075026839971542
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1858.595458984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 18585.26953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05315931513905525
		 entropy bonus: 0.0061329263262450695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12368621677160263
		 entropy bonus: 5.605193857299268e-45
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031075026839971542
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1858.672119140625 - Differentiable computation graph = True!
PPO iteration: 200/1000:
	 start solving instance: 110...
	 start solving instance: 129...
	 start solving instance: 99...
	 start solving instance: 100...
	 start solving instance: 80...
	 start solving instance: 139...
	 start solving instance: 95...
	 start solving instance: 123...
	 start solving instance: 11...
	 start solving instance: 48...
	 start solving instance: 116...
	 start solving instance: 6...
	 start solving instance: 67...
	 start solving instance: 101...
	 start solving instance: 89...
	 start solving instance: 96...
	 start solving instance: 2...
	 start solving instance: 142...
	 start solving instance: 7...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 70994.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01432811003178358
		 entropy bonus: 0.007876619696617126
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03744246065616608
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0696198046207428
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7099.37158203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 70994.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010710692964494228
		 entropy bonus: 0.01649550534784794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.007869372144341469
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0696198046207428
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7099.44140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 70994.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04953128099441528
		 entropy bonus: 0.011354952119290829
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02122041955590248
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0696198046207428
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7099.49365234375 - Differentiable computation graph = True!
PPO iteration: 201/1000:
	 New training batch of size 20...
	 start solving instance: 68...
	 start solving instance: 135...
	 start solving instance: 39...
	 start solving instance: 72...
	 start solving instance: 130...
	 start solving instance: 79...
	 start solving instance: 65...
	 start solving instance: 10...
	 start solving instance: 104...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 77...
	 start solving instance: 15...
	 start solving instance: 142...
	 start solving instance: 56...
	 start solving instance: 53...
	 start solving instance: 88...
	 start solving instance: 121...
	 start solving instance: 66...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 112167.515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.011280241422355175
		 entropy bonus: 0.025861015543341637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.004195049405097961
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.024752987548708916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11216.78125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 112167.515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12148686498403549
		 entropy bonus: 0.011371991597115993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.006717613432556391
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.024752987548708916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11216.9033203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 112167.515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09254368394613266
		 entropy bonus: 0.023971712216734886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.006717613432556391
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.024752987548708916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11216.873046875 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 135250.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06930184364318848
		 entropy bonus: 0.02889331616461277
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1627744883298874
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11580906808376312
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13525.3945
PPO iteration: 202/1000:
	 start solving instance: 88...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 68...
	 start solving instance: 15...
	 start solving instance: 65...
	 start solving instance: 56...
	 start solving instance: 66...
	 start solving instance: 72...
	 start solving instance: 142...
	 start solving instance: 79...
	 start solving instance: 77...
	 start solving instance: 135...
	 start solving instance: 10...
	 start solving instance: 129...
	 start solving instance: 53...
	 start solving instance: 130...
	 start solving instance: 121...
	 start solving instance: 104...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 135682.609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009467807598412037
		 entropy bonus: 0.01904749870300293
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.008197634480893612
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.024696161970496178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13568.2353515625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 135682.609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.005293726921081543
		 entropy bonus: 0.03204735741019249
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0049698129296302795
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.024696161970496178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13568.2333984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 135682.609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0007728874916210771
		 entropy bonus: 0.03250725194811821
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.002853399608284235
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.024696161970496178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13568.2294921875 - Differentiable computation graph = True!
PPO iteration: 203/1000:
	 start solving instance: 66...
	 start solving instance: 130...
	 start solving instance: 142...
	 start solving instance: 10...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 121...
	 start solving instance: 116...
	 start solving instance: 68...
	 start solving instance: 129...
	 start solving instance: 53...
	 start solving instance: 56...
	 start solving instance: 15...
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 65...
	 start solving instance: 39...
	 start solving instance: 72...
	 start solving instance: 79...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 165182.171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1471109539270401
		 entropy bonus: 0.06111321598291397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24298851191997528
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03717537596821785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16518.5625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 165182.171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15233388543128967
		 entropy bonus: 0.03560572490096092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24298851191997528
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03717537596821785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16518.5703125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 165182.171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.252971351146698
		 entropy bonus: 0.06365399807691574
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24298851191997528
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03717537596821785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16518.66796875 - Differentiable computation graph = True!
PPO iteration: 204/1000:
	 start solving instance: 91...
	 start solving instance: 116...
	 start solving instance: 77...
	 start solving instance: 15...
	 start solving instance: 39...
	 start solving instance: 10...
	 start solving instance: 68...
	 start solving instance: 129...
	 start solving instance: 88...
	 start solving instance: 121...
	 start solving instance: 66...
	 start solving instance: 53...
	 start solving instance: 130...
	 start solving instance: 65...
	 start solving instance: 104...
	 start solving instance: 79...
	 start solving instance: 72...
	 start solving instance: 135...
	 start solving instance: 56...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 200426.796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07829035818576813
		 entropy bonus: 0.05480311065912247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08275475353002548
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05208655074238777
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20042.783203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 200426.796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10257114470005035
		 entropy bonus: 0.05918845161795616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08776459842920303
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05208655074238777
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20042.810546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 200426.796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08861131221055984
		 entropy bonus: 0.09553136676549911
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08776459842920303
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05208655074238777
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20042.79296875 - Differentiable computation graph = True!
PPO iteration: 205/1000:
	 start solving instance: 66...
	 start solving instance: 15...
	 start solving instance: 53...
	 start solving instance: 88...
	 start solving instance: 10...
	 start solving instance: 130...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 129...
	 start solving instance: 68...
	 start solving instance: 65...
	 start solving instance: 116...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 142...
	 start solving instance: 56...
	 start solving instance: 79...
	 start solving instance: 39...
	 start solving instance: 104...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 230794.953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03131904453039169
		 entropy bonus: 0.05940833315253258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.044882066547870636
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03401118144392967
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23079.599609375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 230794.953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13280780613422394
		 entropy bonus: 0.08988054096698761
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04789331182837486
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03401118144392967
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23079.701171875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 230794.953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11257494986057281
		 entropy bonus: 0.09143995493650436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05146775767207146
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03401118144392967
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23079.685546875 - Differentiable computation graph = True!
PPO iteration: 206/1000:
	 start solving instance: 142...
	 start solving instance: 65...
	 start solving instance: 15...
	 start solving instance: 130...
	 start solving instance: 88...
	 start solving instance: 68...
	 start solving instance: 79...
	 start solving instance: 56...
	 start solving instance: 66...
	 start solving instance: 53...
	 start solving instance: 10...
	 start solving instance: 121...
	 start solving instance: 104...
	 start solving instance: 72...
	 start solving instance: 135...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 77...
	 start solving instance: 129...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 314166.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10092561691999435
		 entropy bonus: 0.09743734449148178
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1406417042016983
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1118941456079483
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 31416.765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 314166.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1495686024427414
		 entropy bonus: 0.09751180559396744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1406417042016983
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1118941456079483
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 31416.814453125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 314166.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12352757900953293
		 entropy bonus: 0.0831219032406807
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1406417042016983
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1118941456079483
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 31416.7890625 - Differentiable computation graph = True!
PPO iteration: 207/1000:
	 start solving instance: 65...
	 start solving instance: 88...
	 start solving instance: 72...
	 start solving instance: 104...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 53...
	 start solving instance: 77...
	 start solving instance: 68...
	 start solving instance: 116...
	 start solving instance: 79...
	 start solving instance: 10...
	 start solving instance: 15...
	 start solving instance: 66...
	 start solving instance: 39...
	 start solving instance: 129...
	 start solving instance: 91...
	 start solving instance: 56...
	 start solving instance: 121...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 270135.09375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09928437322378159
		 entropy bonus: 0.09778019785881042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10914482921361923
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07089026272296906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 27013.638671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 270135.09375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2177792638540268
		 entropy bonus: 0.07308187335729599
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10914482921361923
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07089026272296906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 27013.759765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 270135.09375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.23505447804927826
		 entropy bonus: 0.09477947652339935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10913155227899551
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07089026272296906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 27013.7734375 - Differentiable computation graph = True!
PPO iteration: 208/1000:
	 start solving instance: 129...
	 start solving instance: 91...
	 start solving instance: 77...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 79...
	 start solving instance: 88...
	 start solving instance: 53...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 65...
	 start solving instance: 66...
	 start solving instance: 104...
	 start solving instance: 68...
	 start solving instance: 15...
	 start solving instance: 116...
	 start solving instance: 56...
	 start solving instance: 39...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 349876.53125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14174380898475647
		 entropy bonus: 0.1333397626876831
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2034674733877182
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10175402462482452
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34987.8828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 349876.53125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.27728474140167236
		 entropy bonus: 0.10002000629901886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.207447811961174
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10175402462482452
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34988.0234375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 349876.53125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19751577079296112
		 entropy bonus: 0.13872520625591278
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.207447811961174
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10175402462482452
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34987.94140625 - Differentiable computation graph = True!
PPO iteration: 209/1000:
	 start solving instance: 66...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 116...
	 start solving instance: 77...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 91...
	 start solving instance: 135...
	 start solving instance: 104...
	 start solving instance: 129...
	 start solving instance: 88...
	 start solving instance: 79...
	 start solving instance: 56...
	 start solving instance: 39...
	 start solving instance: 68...
	 start solving instance: 121...
	 start solving instance: 65...
	 start solving instance: 15...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 496225.40625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13415923714637756
		 entropy bonus: 0.1671196073293686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2145296335220337
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.018179388716816902
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 49622.89453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 496225.40625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.23747365176677704
		 entropy bonus: 0.16724132001399994
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2145296335220337
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.018179388716816902
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 49623.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 496225.40625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1680251806974411
		 entropy bonus: 0.20131273567676544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2145296335220337
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.018179388716816902
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 49622.92578125 - Differentiable computation graph = True!
PPO iteration: 210/1000:
	 start solving instance: 72...
	 start solving instance: 53...
	 start solving instance: 77...
	 start solving instance: 142...
	 start solving instance: 56...
	 start solving instance: 65...
	 start solving instance: 116...
	 start solving instance: 104...
	 start solving instance: 66...
	 start solving instance: 135...
	 start solving instance: 121...
	 start solving instance: 88...
	 start solving instance: 15...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 10...
	 start solving instance: 68...
	 start solving instance: 130...
	 start solving instance: 39...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 1688233.625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09644051641225815
		 entropy bonus: 0.1940675675868988
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10051386803388596
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09706199914216995
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 168823.4375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1688233.625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1359962522983551
		 entropy bonus: 0.21224215626716614
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10051386803388596
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09706199914216995
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 168823.46875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1688233.625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16326744854450226
		 entropy bonus: 0.21178102493286133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10595562309026718
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09706199914216995
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 168823.515625 - Differentiable computation graph = True!
PPO iteration: 211/1000:
	 New training batch of size 20...
	 start solving instance: 70...
	 start solving instance: 20...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 146...
	 start solving instance: 31...
	 start solving instance: 22...
	 start solving instance: 49...
	 start solving instance: 47...
	 start solving instance: 137...
	 start solving instance: 87...
	 start solving instance: 1...
	 start solving instance: 38...
	 start solving instance: 132...
	 start solving instance: 24...
	 start solving instance: 134...
	 start solving instance: 89...
	 start solving instance: 106...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 32860624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15838347375392914
		 entropy bonus: 0.22001519799232483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.28647154569625854
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12545305490493774
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3286063.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 32860624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2923915684223175
		 entropy bonus: 0.24038730561733246
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2874051332473755
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12545305490493774
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3286063.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 32860624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3380753993988037
		 entropy bonus: 0.23158545792102814
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.28647154569625854
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12545305490493774
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3286063.0 - Differentiable computation graph = True!
PPO iteration: 212/1000:
	 start solving instance: 22...
	 start solving instance: 106...
	 start solving instance: 85...
	 start solving instance: 24...
	 start solving instance: 87...
	 start solving instance: 33...
	 start solving instance: 137...
	 start solving instance: 20...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 52...
	 start solving instance: 91...
	 start solving instance: 134...
	 start solving instance: 89...
	 start solving instance: 1...
	 start solving instance: 49...
	 start solving instance: 146...
	 start solving instance: 47...
	 start solving instance: 132...
	 start solving instance: 70...
	 Optimization epoch: 1/3
		 value loss (over batch): 6546599.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18792256712913513
		 entropy bonus: 0.20380453765392303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2757985591888428
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03303392603993416
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 654660.375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6546599.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19257600605487823
		 entropy bonus: 0.20411396026611328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2757985591888428
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03303392603993416
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 654660.375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6546599.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21713022887706757
		 entropy bonus: 0.1849474012851715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2757985591888428
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03303392603993416
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 654660.375 - Differentiable computation graph = True!
PPO iteration: 213/1000:
	 start solving instance: 22...
	 start solving instance: 20...
	 start solving instance: 1...
	 start solving instance: 38...
	 start solving instance: 31...
	 start solving instance: 47...
	 start solving instance: 134...
	 start solving instance: 132...
	 start solving instance: 70...
	 start solving instance: 91...
	 start solving instance: 85...
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 146...
	 start solving instance: 24...
	 start solving instance: 137...
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 87...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 1643397.375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05634713172912598
		 entropy bonus: 0.20577652752399445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16042731702327728
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16424329578876495
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 164339.765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1643397.375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10102174431085587
		 entropy bonus: 0.18094561994075775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1632820963859558
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16424329578876495
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 164339.8125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1643397.375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15141670405864716
		 entropy bonus: 0.14996717870235443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1632820963859558
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16424329578876495
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 164339.875 - Differentiable computation graph = True!
PPO iteration: 214/1000:
	 start solving instance: 52...
	 start solving instance: 70...
	 start solving instance: 87...
	 start solving instance: 85...
	 start solving instance: 89...
	 start solving instance: 1...
	 start solving instance: 146...
	 start solving instance: 91...
	 start solving instance: 20...
	 start solving instance: 38...
	 start solving instance: 49...
	 start solving instance: 137...
	 start solving instance: 134...
	 start solving instance: 31...
	 start solving instance: 22...
	 start solving instance: 33...
	 start solving instance: 47...
	 start solving instance: 106...
	 start solving instance: 132...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 813049.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.28795096278190613
		 entropy bonus: 0.1615372747182846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.45001181960105896
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12370828539133072
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 81305.8203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 813049.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3284458816051483
		 entropy bonus: 0.1527150720357895
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.45525693893432617
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12370828539133072
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 81305.8671875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 813049.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.31658491492271423
		 entropy bonus: 0.17657314240932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.4561549127101898
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12370828539133072
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 81305.8515625 - Differentiable computation graph = True!
PPO iteration: 215/1000:
	 start solving instance: 132...
	 start solving instance: 106...
	 start solving instance: 1...
	 start solving instance: 33...
	 start solving instance: 31...
	 start solving instance: 137...
	 start solving instance: 134...
	 start solving instance: 52...
	 start solving instance: 20...
	 start solving instance: 24...
	 start solving instance: 47...
	 start solving instance: 85...
	 start solving instance: 38...
	 start solving instance: 89...
	 start solving instance: 70...
	 start solving instance: 49...
	 start solving instance: 22...
	 start solving instance: 91...
	 start solving instance: 87...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 621526.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07677813619375229
		 entropy bonus: 0.16993403434753418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25726208090782166
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05003538355231285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 62152.94921875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 621526.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2035450041294098
		 entropy bonus: 0.13863423466682434
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2587004601955414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05003538355231285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 62153.08203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 621526.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13669775426387787
		 entropy bonus: 0.16908128559589386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2587004601955414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05003538355231285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 62153.01171875 - Differentiable computation graph = True!
PPO iteration: 216/1000:
	 start solving instance: 1...
	 start solving instance: 38...
	 start solving instance: 52...
	 start solving instance: 47...
	 start solving instance: 20...
	 start solving instance: 31...
	 start solving instance: 70...
	 start solving instance: 106...
	 start solving instance: 134...
	 start solving instance: 22...
	 start solving instance: 49...
	 start solving instance: 132...
	 start solving instance: 137...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 91...
	 start solving instance: 33...
	 start solving instance: 85...
	 start solving instance: 24...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 596690.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11733689159154892
		 entropy bonus: 0.1364218294620514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16689132153987885
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.001139181898906827
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59669.26953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 596690.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12345894426107407
		 entropy bonus: 0.1434454470872879
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1704176366329193
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.001139181898906827
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59669.27734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 596690.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1881355196237564
		 entropy bonus: 0.14879672229290009
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1704176366329193
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.001139181898906827
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59669.33984375 - Differentiable computation graph = True!
PPO iteration: 217/1000:
	 start solving instance: 49...
	 start solving instance: 146...
	 start solving instance: 31...
	 start solving instance: 87...
	 start solving instance: 137...
	 start solving instance: 106...
	 start solving instance: 89...
	 start solving instance: 85...
	 start solving instance: 134...
	 start solving instance: 70...
	 start solving instance: 20...
	 start solving instance: 52...
	 start solving instance: 38...
	 start solving instance: 24...
	 start solving instance: 1...
	 start solving instance: 132...
	 start solving instance: 47...
	 start solving instance: 91...
	 start solving instance: 33...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 657079.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.056925274431705475
		 entropy bonus: 0.1519259661436081
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14919593930244446
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0003817458054982126
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 65708.171875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 657079.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1174217015504837
		 entropy bonus: 0.15170340240001678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14919593930244446
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0003817458054982126
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 65708.234375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 657079.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09541530907154083
		 entropy bonus: 0.13646550476551056
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14919593930244446
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0003817458054982126
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 65708.2109375 - Differentiable computation graph = True!
PPO iteration: 218/1000:
	 start solving instance: 22...
	 start solving instance: 146...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 85...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 33...
	 start solving instance: 87...
	 start solving instance: 24...
	 start solving instance: 52...
	 start solving instance: 134...
	 start solving instance: 91...
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 106...
	 start solving instance: 20...
	 start solving instance: 137...
	 start solving instance: 47...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 614385.1875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10349347442388535
		 entropy bonus: 0.15724265575408936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22716717422008514
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.009351558052003384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 61438.84375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 614385.1875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16991248726844788
		 entropy bonus: 0.15263037383556366
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22716717422008514
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.009351558052003384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 61438.9140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 614385.1875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1481027454137802
		 entropy bonus: 0.11909027397632599
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22716717422008514
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.009351558052003384
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 61438.89453125 - Differentiable computation graph = True!
PPO iteration: 219/1000:
	 start solving instance: 1...
	 start solving instance: 24...
	 start solving instance: 38...
	 start solving instance: 89...
	 start solving instance: 31...
	 start solving instance: 47...
	 start solving instance: 91...
	 start solving instance: 146...
	 start solving instance: 33...
	 start solving instance: 22...
	 start solving instance: 49...
	 start solving instance: 85...
	 start solving instance: 132...
	 start solving instance: 20...
	 start solving instance: 137...
	 start solving instance: 87...
	 start solving instance: 106...
	 start solving instance: 70...
	 start solving instance: 52...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 522527.34375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1905098557472229
		 entropy bonus: 0.1502518653869629
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2620222866535187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.009688163176178932
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 52253.18359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 522527.34375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2756338119506836
		 entropy bonus: 0.11001420021057129
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2620222866535187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.009688163176178932
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 52253.2734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 522527.34375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.26621949672698975
		 entropy bonus: 0.14683733880519867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2620222866535187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.009688163176178932
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 52253.2578125 - Differentiable computation graph = True!
PPO iteration: 220/1000:
	 start solving instance: 24...
	 start solving instance: 52...
	 start solving instance: 134...
	 start solving instance: 31...
	 start solving instance: 137...
	 start solving instance: 20...
	 start solving instance: 106...
	 start solving instance: 1...
	 start solving instance: 91...
	 start solving instance: 47...
	 start solving instance: 132...
	 start solving instance: 33...
	 start solving instance: 85...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 70...
	 start solving instance: 49...
	 start solving instance: 38...
	 start solving instance: 22...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 497735.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.002083742758259177
		 entropy bonus: 0.11559700965881348
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07398485392332077
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004557057283818722
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 49773.578125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 497735.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03504527732729912
		 entropy bonus: 0.14260070025920868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07370884716510773
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004557057283818722
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 49773.60546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 497735.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0751214399933815
		 entropy bonus: 0.120988629758358
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07370884716510773
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004557057283818722
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 49773.6484375 - Differentiable computation graph = True!
PPO iteration: 221/1000:
	 New training batch of size 20...
	 start solving instance: 104...
	 start solving instance: 84...
	 start solving instance: 147...
	 start solving instance: 146...
	 start solving instance: 117...
	 start solving instance: 13...
	 start solving instance: 110...
	 start solving instance: 78...
	 start solving instance: 48...
	 start solving instance: 102...
	 start solving instance: 1...
	 start solving instance: 36...
	 start solving instance: 3...
	 start solving instance: 8...
	 start solving instance: 80...
	 start solving instance: 69...
	 start solving instance: 120...
	 start solving instance: 134...
	 start solving instance: 133...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 524445.3125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16178028285503387
		 entropy bonus: 0.16677293181419373
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24254536628723145
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08602216839790344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 52444.83203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 524445.3125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.27867957949638367
		 entropy bonus: 0.12808078527450562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24254536628723145
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08602216839790344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 52444.953125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 524445.3125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2247852385044098
		 entropy bonus: 0.1563652604818344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24254536628723145
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08602216839790344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 52444.8984375 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 433887.59375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09567859023809433
		 entropy bonus: 0.12241072952747345
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19969239830970764
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02064877189695835
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43389.0625
PPO iteration: 222/1000:
	 start solving instance: 134...
	 start solving instance: 36...
	 start solving instance: 8...
	 start solving instance: 69...
	 start solving instance: 1...
	 start solving instance: 80...
	 start solving instance: 87...
	 start solving instance: 78...
	 start solving instance: 84...
	 start solving instance: 133...
	 start solving instance: 3...
	 start solving instance: 120...
	 start solving instance: 13...
	 start solving instance: 117...
	 start solving instance: 110...
	 start solving instance: 147...
	 start solving instance: 102...
	 start solving instance: 104...
	 start solving instance: 146...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 459821.71875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.29325005412101746
		 entropy bonus: 0.1628095656633377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.36640846729278564
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.061482399702072144
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45982.87890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 459821.71875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3330328166484833
		 entropy bonus: 0.12555967271327972
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.36640846729278564
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.061482399702072144
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45982.921875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 459821.71875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.32538485527038574
		 entropy bonus: 0.10924079269170761
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.36626213788986206
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.061482399702072144
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45982.91796875 - Differentiable computation graph = True!
PPO iteration: 223/1000:
	 start solving instance: 87...
	 start solving instance: 117...
	 start solving instance: 3...
	 start solving instance: 134...
	 start solving instance: 36...
	 start solving instance: 133...
	 start solving instance: 147...
	 start solving instance: 69...
	 start solving instance: 102...
	 start solving instance: 1...
	 start solving instance: 8...
	 start solving instance: 104...
	 start solving instance: 80...
	 start solving instance: 110...
	 start solving instance: 146...
	 start solving instance: 78...
	 start solving instance: 84...
	 start solving instance: 48...
	 start solving instance: 13...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 379043.6875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13282646238803864
		 entropy bonus: 0.11726301163434982
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.213918074965477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02914365939795971
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 37904.734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 379043.6875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2178487330675125
		 entropy bonus: 0.11560707539319992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.213918074965477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02914365939795971
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 37904.8203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 379043.6875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20372724533081055
		 entropy bonus: 0.10889387130737305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.213918074965477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.02914365939795971
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 37904.8046875 - Differentiable computation graph = True!
PPO iteration: 224/1000:
	 start solving instance: 13...
	 start solving instance: 134...
	 start solving instance: 48...
	 start solving instance: 146...
	 start solving instance: 147...
	 start solving instance: 84...
	 start solving instance: 78...
	 start solving instance: 120...
	 start solving instance: 87...
	 start solving instance: 80...
	 start solving instance: 8...
	 start solving instance: 110...
	 start solving instance: 133...
	 start solving instance: 104...
	 start solving instance: 69...
	 start solving instance: 36...
	 start solving instance: 1...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 310933.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0022764087188988924
		 entropy bonus: 0.0861736312508583
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1867230385541916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08885974436998367
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 31093.412109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 310933.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08683338016271591
		 entropy bonus: 0.10112013667821884
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18784789741039276
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08885974436998367
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 31093.501953125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 310933.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09920523315668106
		 entropy bonus: 0.09295017272233963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18784789741039276
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08885974436998367
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 31093.515625 - Differentiable computation graph = True!
PPO iteration: 225/1000:
	 start solving instance: 36...
	 start solving instance: 134...
	 start solving instance: 133...
	 start solving instance: 78...
	 start solving instance: 110...
	 start solving instance: 48...
	 start solving instance: 117...
	 start solving instance: 13...
	 start solving instance: 146...
	 start solving instance: 147...
	 start solving instance: 3...
	 start solving instance: 1...
	 start solving instance: 102...
	 start solving instance: 104...
	 start solving instance: 8...
	 start solving instance: 87...
	 start solving instance: 69...
	 start solving instance: 84...
	 start solving instance: 80...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 226096.859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037277329713106155
		 entropy bonus: 0.05638449266552925
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08298172801733017
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10207987576723099
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 22609.697265625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 226096.859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09717676788568497
		 entropy bonus: 0.04671872779726982
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09248939901590347
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10207987576723099
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 22609.767578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 226096.859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10608638823032379
		 entropy bonus: 0.03017408214509487
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09723509103059769
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10207987576723099
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 22609.78515625 - Differentiable computation graph = True!
PPO iteration: 226/1000:
	 start solving instance: 80...
	 start solving instance: 117...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 102...
	 start solving instance: 36...
	 start solving instance: 133...
	 start solving instance: 134...
	 start solving instance: 87...
	 start solving instance: 104...
	 start solving instance: 147...
	 start solving instance: 69...
	 start solving instance: 3...
	 start solving instance: 110...
	 start solving instance: 8...
	 start solving instance: 1...
	 start solving instance: 13...
	 start solving instance: 48...
	 start solving instance: 78...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 187413.71875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11491632461547852
		 entropy bonus: 0.05417104437947273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24967725574970245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.022693343460559845
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18741.708984375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 187413.71875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12538211047649384
		 entropy bonus: 0.034843023866415024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2501772940158844
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.022693343460559845
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18741.720703125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 187413.71875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.130318745970726
		 entropy bonus: 0.03981334716081619
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25123172998428345
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.022693343460559845
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18741.728515625 - Differentiable computation graph = True!
PPO iteration: 227/1000:
	 start solving instance: 8...
	 start solving instance: 69...
	 start solving instance: 147...
	 start solving instance: 1...
	 start solving instance: 133...
	 start solving instance: 117...
	 start solving instance: 146...
	 start solving instance: 80...
	 start solving instance: 78...
	 start solving instance: 102...
	 start solving instance: 13...
	 start solving instance: 134...
	 start solving instance: 48...
	 start solving instance: 84...
	 start solving instance: 104...
	 start solving instance: 36...
	 start solving instance: 87...
	 start solving instance: 110...
	 start solving instance: 3...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 189003.265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10620730370283127
		 entropy bonus: 0.06132165342569351
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17979814112186432
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10844092816114426
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18900.71484375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 189003.265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19263188540935516
		 entropy bonus: 0.03640328720211983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1818426102399826
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10844092816114426
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18900.806640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 189003.265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12349534034729004
		 entropy bonus: 0.04329496994614601
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18420371413230896
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10844092816114426
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18900.73828125 - Differentiable computation graph = True!
PPO iteration: 228/1000:
	 start solving instance: 3...
	 start solving instance: 84...
	 start solving instance: 104...
	 start solving instance: 80...
	 start solving instance: 134...
	 start solving instance: 147...
	 start solving instance: 117...
	 start solving instance: 1...
	 start solving instance: 110...
	 start solving instance: 8...
	 start solving instance: 78...
	 start solving instance: 69...
	 start solving instance: 102...
	 start solving instance: 13...
	 start solving instance: 133...
	 start solving instance: 87...
	 start solving instance: 120...
	 start solving instance: 48...
	 start solving instance: 146...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 235029.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1274685263633728
		 entropy bonus: 0.07128997147083282
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22677075862884521
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04035814478993416
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23503.318359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 235029.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14205294847488403
		 entropy bonus: 0.07529237121343613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22677075862884521
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04035814478993416
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23503.33203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 235029.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14467640221118927
		 entropy bonus: 0.09008852392435074
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22677075862884521
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04035814478993416
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23503.33203125 - Differentiable computation graph = True!
PPO iteration: 229/1000:
	 start solving instance: 36...
	 start solving instance: 48...
	 start solving instance: 80...
	 start solving instance: 117...
	 start solving instance: 3...
	 start solving instance: 8...
	 start solving instance: 120...
	 start solving instance: 147...
	 start solving instance: 133...
	 start solving instance: 69...
	 start solving instance: 134...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 78...
	 start solving instance: 87...
	 start solving instance: 104...
	 start solving instance: 110...
	 start solving instance: 102...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 226635.90625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06645271927118301
		 entropy bonus: 0.05822037532925606
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1641789674758911
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14123450219631195
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 22663.67578125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 226635.90625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09735383093357086
		 entropy bonus: 0.056304898113012314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16622784733772278
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14123450219631195
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 22663.708984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 226635.90625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10146244615316391
		 entropy bonus: 0.04785657674074173
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16954615712165833
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14123450219631195
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 22663.71484375 - Differentiable computation graph = True!
PPO iteration: 230/1000:
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 147...
	 start solving instance: 133...
	 start solving instance: 1...
	 start solving instance: 102...
	 start solving instance: 48...
	 start solving instance: 80...
	 start solving instance: 84...
	 start solving instance: 78...
	 start solving instance: 87...
	 start solving instance: 104...
	 start solving instance: 146...
	 start solving instance: 3...
	 start solving instance: 36...
	 start solving instance: 69...
	 start solving instance: 13...
	 start solving instance: 110...
	 start solving instance: 8...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 164640.921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005774140357971191
		 entropy bonus: 0.021367516368627548
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.01780940406024456
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.057339418679475784
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16464.044921875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 164640.921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0029442310333251953
		 entropy bonus: 0.03853149712085724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.022176051512360573
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.057339418679475784
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16464.05078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 164640.921875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.005064439959824085
		 entropy bonus: 0.0404568687081337
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02414771355688572
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.057339418679475784
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16464.060546875 - Differentiable computation graph = True!
PPO iteration: 231/1000:
	 New training batch of size 20...
	 start solving instance: 117...
	 start solving instance: 118...
	 start solving instance: 8...
	 start solving instance: 69...
	 start solving instance: 15...
	 start solving instance: 72...
	 start solving instance: 133...
	 start solving instance: 112...
	 start solving instance: 68...
	 start solving instance: 28...
	 start solving instance: 22...
	 start solving instance: 127...
	 start solving instance: 65...
	 start solving instance: 55...
	 start solving instance: 141...
	 start solving instance: 36...
	 start solving instance: 103...
	 start solving instance: 10...
	 start solving instance: 21...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 211309.671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12854954600334167
		 entropy bonus: 0.06527990102767944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.28293678164482117
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09357840567827225
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21131.46484375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 211309.671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14230088889598846
		 entropy bonus: 0.02606264315545559
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.28293678164482117
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09357840567827225
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21131.484375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 211309.671875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14799396693706512
		 entropy bonus: 0.05709495767951012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.28293678164482117
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09357840567827225
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21131.486328125 - Differentiable computation graph = True!
PPO iteration: 232/1000:
	 start solving instance: 28...
	 start solving instance: 22...
	 start solving instance: 72...
	 start solving instance: 133...
	 start solving instance: 118...
	 start solving instance: 55...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 127...
	 start solving instance: 8...
	 start solving instance: 117...
	 start solving instance: 15...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 31...
	 start solving instance: 112...
	 start solving instance: 68...
	 start solving instance: 65...
	 start solving instance: 69...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 210000.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06968885660171509
		 entropy bonus: 0.060764212161302567
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11859443038702011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.029750648885965347
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21000.228515625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 210000.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12458866089582443
		 entropy bonus: 0.034565333276987076
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11859443038702011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.029750648885965347
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21000.28515625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 210000.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13691535592079163
		 entropy bonus: 0.06893125921487808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11859443038702011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.029750648885965347
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21000.294921875 - Differentiable computation graph = True!
PPO iteration: 233/1000:
	 start solving instance: 8...
	 start solving instance: 141...
	 start solving instance: 21...
	 start solving instance: 68...
	 start solving instance: 15...
	 start solving instance: 36...
	 start solving instance: 65...
	 start solving instance: 127...
	 start solving instance: 103...
	 start solving instance: 69...
	 start solving instance: 31...
	 start solving instance: 117...
	 start solving instance: 55...
	 start solving instance: 28...
	 start solving instance: 118...
	 start solving instance: 22...
	 start solving instance: 72...
	 start solving instance: 112...
	 start solving instance: 10...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 211012.421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03847266361117363
		 entropy bonus: 0.05295811966061592
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13826249539852142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.031173398718237877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21101.4453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 211012.421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06719443947076797
		 entropy bonus: 0.050230350345373154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13826249539852142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.031173398718237877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21101.474609375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 211012.421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05872480943799019
		 entropy bonus: 0.05344431474804878
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13826249539852142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.031173398718237877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21101.46484375 - Differentiable computation graph = True!
PPO iteration: 234/1000:
	 start solving instance: 117...
	 start solving instance: 72...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 68...
	 start solving instance: 21...
	 start solving instance: 118...
	 start solving instance: 141...
	 start solving instance: 31...
	 start solving instance: 15...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 133...
	 start solving instance: 127...
	 start solving instance: 69...
	 start solving instance: 10...
	 start solving instance: 65...
	 start solving instance: 8...
	 start solving instance: 103...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 208199.515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16301904618740082
		 entropy bonus: 0.061623502522706985
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25271889567375183
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.049818191677331924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20820.41015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 208199.515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.17062637209892273
		 entropy bonus: 0.03139231726527214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25271889567375183
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.049818191677331924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20820.421875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 208199.515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14312231540679932
		 entropy bonus: 0.029354095458984375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25271889567375183
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.049818191677331924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20820.39453125 - Differentiable computation graph = True!
PPO iteration: 235/1000:
	 start solving instance: 8...
	 start solving instance: 31...
	 start solving instance: 112...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 36...
	 start solving instance: 15...
	 start solving instance: 117...
	 start solving instance: 133...
	 start solving instance: 103...
	 start solving instance: 68...
	 start solving instance: 55...
	 start solving instance: 28...
	 start solving instance: 72...
	 start solving instance: 22...
	 start solving instance: 10...
	 start solving instance: 65...
	 start solving instance: 69...
	 start solving instance: 118...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 196839.53125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06265176832675934
		 entropy bonus: 0.05385781452059746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12459307909011841
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.013647757470607758
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19684.12109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 196839.53125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06178784370422363
		 entropy bonus: 0.04613034054636955
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12982779741287231
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.013647757470607758
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19684.125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 196839.53125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12112944573163986
		 entropy bonus: 0.059825386852025986
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12982779741287231
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.013647757470607758
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19684.18359375 - Differentiable computation graph = True!
PPO iteration: 236/1000:
	 start solving instance: 72...
	 start solving instance: 8...
	 start solving instance: 112...
	 start solving instance: 10...
	 start solving instance: 68...
	 start solving instance: 69...
	 start solving instance: 22...
	 start solving instance: 55...
	 start solving instance: 103...
	 start solving instance: 65...
	 start solving instance: 141...
	 start solving instance: 28...
	 start solving instance: 118...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 15...
	 start solving instance: 117...
	 start solving instance: 133...
	 start solving instance: 36...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 212171.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1667424887418747
		 entropy bonus: 0.08849316835403442
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2895338535308838
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.026544949039816856
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21217.60546875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 212171.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16837887465953827
		 entropy bonus: 0.040377177298069
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2895338535308838
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.026544949039816856
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21217.611328125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 212171.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14066050946712494
		 entropy bonus: 0.03199348598718643
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2895338535308838
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.026544949039816856
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21217.583984375 - Differentiable computation graph = True!
PPO iteration: 237/1000:
	 start solving instance: 133...
	 start solving instance: 103...
	 start solving instance: 28...
	 start solving instance: 31...
	 start solving instance: 8...
	 start solving instance: 21...
	 start solving instance: 22...
	 start solving instance: 117...
	 start solving instance: 36...
	 start solving instance: 68...
	 start solving instance: 15...
	 start solving instance: 55...
	 start solving instance: 141...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 69...
	 start solving instance: 127...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 216949.125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13765929639339447
		 entropy bonus: 0.06099085882306099
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23240642249584198
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10515494644641876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21695.380859375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 216949.125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.17254430055618286
		 entropy bonus: 0.058630943298339844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23240642249584198
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10515494644641876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21695.416015625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 216949.125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1226530596613884
		 entropy bonus: 0.03281329199671745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.23240642249584198
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10515494644641876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21695.369140625 - Differentiable computation graph = True!
PPO iteration: 238/1000:
	 start solving instance: 28...
	 start solving instance: 68...
	 start solving instance: 72...
	 start solving instance: 8...
	 start solving instance: 103...
	 start solving instance: 141...
	 start solving instance: 112...
	 start solving instance: 31...
	 start solving instance: 117...
	 start solving instance: 65...
	 start solving instance: 22...
	 start solving instance: 10...
	 start solving instance: 69...
	 start solving instance: 127...
	 start solving instance: 55...
	 start solving instance: 36...
	 start solving instance: 133...
	 start solving instance: 118...
	 start solving instance: 15...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 196464.359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2081669569015503
		 entropy bonus: 0.0711769238114357
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.34105753898620605
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10170826315879822
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19647.080078125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 196464.359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1855529099702835
		 entropy bonus: 0.03889491409063339
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.34105753898620605
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10170826315879822
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19647.060546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 196464.359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18998563289642334
		 entropy bonus: 0.037563126534223557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.34105753898620605
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10170826315879822
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19647.064453125 - Differentiable computation graph = True!
PPO iteration: 239/1000:
	 start solving instance: 112...
	 start solving instance: 69...
	 start solving instance: 36...
	 start solving instance: 133...
	 start solving instance: 21...
	 start solving instance: 8...
	 start solving instance: 72...
	 start solving instance: 65...
	 start solving instance: 10...
	 start solving instance: 117...
	 start solving instance: 141...
	 start solving instance: 22...
	 start solving instance: 31...
	 start solving instance: 28...
	 start solving instance: 118...
	 start solving instance: 15...
	 start solving instance: 68...
	 start solving instance: 127...
	 start solving instance: 55...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 174173.984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.012527704238891602
		 entropy bonus: 0.027718504890799522
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05887913331389427
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06728063523769379
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 17417.400390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 174173.984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05141511559486389
		 entropy bonus: 0.032366793602705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05887913331389427
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06728063523769379
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 17417.439453125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 174173.984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03886525705456734
		 entropy bonus: 0.03315804898738861
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05887913331389427
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06728063523769379
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 17417.42578125 - Differentiable computation graph = True!
PPO iteration: 240/1000:
	 start solving instance: 117...
	 start solving instance: 8...
	 start solving instance: 127...
	 start solving instance: 68...
	 start solving instance: 31...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 36...
	 start solving instance: 65...
	 start solving instance: 15...
	 start solving instance: 103...
	 start solving instance: 28...
	 start solving instance: 10...
	 start solving instance: 141...
	 start solving instance: 133...
	 start solving instance: 112...
	 start solving instance: 72...
	 start solving instance: 69...
	 start solving instance: 21...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 199942.734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008811227045953274
		 entropy bonus: 0.06470540910959244
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0895528644323349
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11039416491985321
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19994.236328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 199942.734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0622103288769722
		 entropy bonus: 0.047663502395153046
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0895528644323349
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11039416491985321
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19994.30859375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 199942.734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04411343112587929
		 entropy bonus: 0.04943925514817238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0895528644323349
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11039416491985321
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19994.291015625 - Differentiable computation graph = True!
PPO iteration: 241/1000:
	 New training batch of size 20...
	 start solving instance: 25...
	 start solving instance: 4...
	 start solving instance: 102...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 23...
	 start solving instance: 26...
	 start solving instance: 48...
	 start solving instance: 132...
	 start solving instance: 20...
	 start solving instance: 33...
	 start solving instance: 105...
	 start solving instance: 123...
	 start solving instance: 78...
	 start solving instance: 115...
	 start solving instance: 76...
	 start solving instance: 58...
	 start solving instance: 150...
	 start solving instance: 93...
	 start solving instance: 71...
	 Optimization epoch: 1/3
		 value loss (over batch): 200123.546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.013908005319535732
		 entropy bonus: 0.062494028359651566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.029159074649214745
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13638047873973846
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20012.228515625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 200123.546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.015565454959869385
		 entropy bonus: 0.04923127964138985
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.029159074649214745
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13638047873973846
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20012.2578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 200123.546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04558012634515762
		 entropy bonus: 0.04688018560409546
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03354461118578911
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13638047873973846
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20012.29296875 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 245657.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19143322110176086
		 entropy bonus: 0.06460750102996826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.28088098764419556
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11793442815542221
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24566.0488
PPO iteration: 242/1000:
	 start solving instance: 102...
	 start solving instance: 71...
	 start solving instance: 76...
	 start solving instance: 26...
	 start solving instance: 132...
	 start solving instance: 115...
	 start solving instance: 105...
	 start solving instance: 33...
	 start solving instance: 20...
	 start solving instance: 22...
	 start solving instance: 4...
	 start solving instance: 48...
	 start solving instance: 144...
	 start solving instance: 58...
	 start solving instance: 150...
	 start solving instance: 23...
	 start solving instance: 123...
	 start solving instance: 78...
	 start solving instance: 93...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 240920.578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16568318009376526
		 entropy bonus: 0.07619096338748932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2635354697704315
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11065741628408432
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24092.591796875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 240920.578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12126219272613525
		 entropy bonus: 0.07413502782583237
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2635354697704315
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11065741628408432
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24092.546875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 240920.578125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14438387751579285
		 entropy bonus: 0.06008383259177208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2678774297237396
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11065741628408432
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 24092.576171875 - Differentiable computation graph = True!
PPO iteration: 243/1000:
	 start solving instance: 58...
	 start solving instance: 26...
	 start solving instance: 25...
	 start solving instance: 76...
	 start solving instance: 33...
	 start solving instance: 78...
	 start solving instance: 48...
	 start solving instance: 132...
	 start solving instance: 4...
	 start solving instance: 123...
	 start solving instance: 105...
	 start solving instance: 20...
	 start solving instance: 71...
	 start solving instance: 23...
	 start solving instance: 150...
	 start solving instance: 22...
	 start solving instance: 115...
	 start solving instance: 102...
	 start solving instance: 144...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 272402.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18554989993572235
		 entropy bonus: 0.09098844975233078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22220082581043243
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.016758162528276443
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 27240.658203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 272402.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.21759481728076935
		 entropy bonus: 0.08543119579553604
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22644861042499542
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.016758162528276443
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 27240.697265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 272402.4375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.18593977391719818
		 entropy bonus: 0.10041866451501846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22644861042499542
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.016758162528276443
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 27240.6640625 - Differentiable computation graph = True!
PPO iteration: 244/1000:
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 102...
	 start solving instance: 22...
	 start solving instance: 132...
	 start solving instance: 105...
	 start solving instance: 71...
	 start solving instance: 58...
	 start solving instance: 33...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 123...
	 start solving instance: 93...
	 start solving instance: 23...
	 start solving instance: 76...
	 start solving instance: 20...
	 start solving instance: 115...
	 start solving instance: 150...
	 start solving instance: 48...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 340914.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16871778666973114
		 entropy bonus: 0.13125164806842804
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22270964086055756
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.046760257333517075
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34091.75 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 340914.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.3158312737941742
		 entropy bonus: 0.10435428470373154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22775201499462128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.046760257333517075
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34091.90234375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 340914.15625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2336689531803131
		 entropy bonus: 0.08768109232187271
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22775201499462128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.046760257333517075
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 34091.82421875 - Differentiable computation graph = True!
PPO iteration: 245/1000:
	 start solving instance: 102...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 48...
	 start solving instance: 4...
	 start solving instance: 71...
	 start solving instance: 26...
	 start solving instance: 78...
	 start solving instance: 23...
	 start solving instance: 115...
	 start solving instance: 22...
	 start solving instance: 123...
	 start solving instance: 25...
	 start solving instance: 132...
	 start solving instance: 58...
	 start solving instance: 144...
	 start solving instance: 33...
	 start solving instance: 150...
	 start solving instance: 20...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 560020.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11784771829843521
		 entropy bonus: 0.1726411134004593
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27894291281700134
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07393405586481094
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 56002.3984375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 560020.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15149883925914764
		 entropy bonus: 0.1661810725927353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27894291281700134
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07393405586481094
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 56002.43359375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 560020.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15713216364383698
		 entropy bonus: 0.12308814376592636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27894291281700134
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07393405586481094
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 56002.44140625 - Differentiable computation graph = True!
PPO iteration: 246/1000:
	 start solving instance: 78...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 76...
	 start solving instance: 71...
	 start solving instance: 48...
	 start solving instance: 115...
	 start solving instance: 22...
	 start solving instance: 26...
	 start solving instance: 4...
	 start solving instance: 93...
	 start solving instance: 123...
	 start solving instance: 150...
	 start solving instance: 33...
	 start solving instance: 23...
	 start solving instance: 20...
	 start solving instance: 144...
	 start solving instance: 58...
	 start solving instance: 102...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 953083.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19568076729774475
		 entropy bonus: 0.18166685104370117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1496996134519577
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02424144186079502
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 95308.6875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 953083.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.20902621746063232
		 entropy bonus: 0.1967041939496994
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1496996134519577
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02424144186079502
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 95308.6953125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 953083.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.24574537575244904
		 entropy bonus: 0.18798503279685974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1496996134519577
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02424144186079502
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 95308.734375 - Differentiable computation graph = True!
PPO iteration: 247/1000:
	 start solving instance: 22...
	 start solving instance: 71...
	 start solving instance: 123...
	 start solving instance: 20...
	 start solving instance: 132...
	 start solving instance: 58...
	 start solving instance: 23...
	 start solving instance: 4...
	 start solving instance: 93...
	 start solving instance: 115...
	 start solving instance: 144...
	 start solving instance: 76...
	 start solving instance: 33...
	 start solving instance: 78...
	 start solving instance: 102...
	 start solving instance: 48...
	 start solving instance: 150...
	 start solving instance: 26...
	 start solving instance: 105...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 2357616.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.28589606285095215
		 entropy bonus: 0.2223455160856247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2879749834537506
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.022771770134568214
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 235762.1875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2357616.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.2943883538246155
		 entropy bonus: 0.2246483564376831
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29323694109916687
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.022771770134568214
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 235762.1875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2357616.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.32135701179504395
		 entropy bonus: 0.2271590530872345
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29323694109916687
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.022771770134568214
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 235762.21875 - Differentiable computation graph = True!
PPO iteration: 248/1000:
	 start solving instance: 150...
	 start solving instance: 115...
	 start solving instance: 4...
	 start solving instance: 123...
	 start solving instance: 33...
	 start solving instance: 132...
	 start solving instance: 71...
	 start solving instance: 22...
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 26...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 102...
	 start solving instance: 144...
	 start solving instance: 58...
	 start solving instance: 78...
	 start solving instance: 76...
	 start solving instance: 23...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 12973623.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.31404685974121094
		 entropy bonus: 0.2234737128019333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2788030803203583
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09509094804525375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1297363.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 12973623.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.31215789914131165
		 entropy bonus: 0.22636185586452484
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2854742705821991
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09509094804525375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1297363.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 12973623.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.31215789914131165
		 entropy bonus: 0.22636185586452484
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2854742705821991
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09509094804525375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1297363.0 - Differentiable computation graph = True!
PPO iteration: 249/1000:
	 start solving instance: 33...
	 start solving instance: 115...
	 start solving instance: 58...
	 start solving instance: 26...
	 start solving instance: 23...
	 start solving instance: 48...
	 start solving instance: 76...
	 start solving instance: 132...
	 start solving instance: 105...
	 start solving instance: 4...
	 start solving instance: 20...
	 start solving instance: 102...
	 start solving instance: 150...
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 93...
	 start solving instance: 71...
	 start solving instance: 25...
	 start solving instance: 78...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 138579632.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13152532279491425
		 entropy bonus: 0.22130770981311798
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10596325248479843
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10500071942806244
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13857963.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 138579632.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13253505527973175
		 entropy bonus: 0.21899722516536713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10935299843549728
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10500071942806244
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13857963.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 138579632.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.13152532279491425
		 entropy bonus: 0.22130770981311798
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11337709426879883
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10500071942806244
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13857963.0 - Differentiable computation graph = True!
PPO iteration: 250/1000:
	 start solving instance: 93...
	 start solving instance: 144...
	 start solving instance: 71...
	 start solving instance: 20...
	 start solving instance: 4...
	 start solving instance: 48...
	 start solving instance: 105...
	 start solving instance: 26...
	 start solving instance: 25...
	 start solving instance: 33...
	 start solving instance: 115...
	 start solving instance: 58...
	 start solving instance: 102...
	 start solving instance: 123...
	 start solving instance: 78...
	 start solving instance: 23...
	 start solving instance: 132...
	 start solving instance: 150...
	 start solving instance: 22...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 820349120.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19300435483455658
		 entropy bonus: 0.23129574954509735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26264524459838867
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12143375724554062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 82034912.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 820349120.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19066332280635834
		 entropy bonus: 0.22744493186473846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2721305787563324
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12143375724554062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 82034912.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 820349120.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.19300435483455658
		 entropy bonus: 0.23129574954509735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27761873602867126
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12143375724554062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 82034912.0 - Differentiable computation graph = True!
PPO iteration: 251/1000:
	 New training batch of size 20...
	 start solving instance: 7...
	 start solving instance: 61...
	 start solving instance: 53...
	 start solving instance: 14...
	 start solving instance: 39...
	 start solving instance: 146...
	 start solving instance: 126...
	 start solving instance: 43...
	 start solving instance: 138...
	 start solving instance: 54...
	 start solving instance: 142...
	 start solving instance: 31...
	 start solving instance: 124...
	 start solving instance: 80...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 89...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 45078032.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03222131356596947
		 entropy bonus: 0.22464290261268616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.182793527841568
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006273730657994747
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4507803.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 45078032.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030956584960222244
		 entropy bonus: 0.22319884598255157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1838884800672531
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006273730657994747
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4507803.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 45078032.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02703307382762432
		 entropy bonus: 0.21516923606395721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1838884800672531
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.006273730657994747
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4507803.5 - Differentiable computation graph = True!
PPO iteration: 252/1000:
	 start solving instance: 142...
	 start solving instance: 33...
	 start solving instance: 70...
	 start solving instance: 126...
	 start solving instance: 39...
	 start solving instance: 31...
	 start solving instance: 61...
	 start solving instance: 14...
	 start solving instance: 1...
	 start solving instance: 43...
	 start solving instance: 7...
	 start solving instance: 54...
	 start solving instance: 146...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 112...
	 start solving instance: 93...
	 start solving instance: 138...
	 start solving instance: 80...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 8605143.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.036388903856277466
		 entropy bonus: 0.20837266743183136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15961673855781555
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011741199530661106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 860514.375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8605143.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.020919783040881157
		 entropy bonus: 0.20668792724609375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1632113754749298
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011741199530661106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 860514.375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8605143.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.00019703507132362574
		 entropy bonus: 0.2010561227798462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16632357239723206
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011741199530661106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 860514.4375 - Differentiable computation graph = True!
PPO iteration: 253/1000:
	 start solving instance: 33...
	 start solving instance: 80...
	 start solving instance: 142...
	 start solving instance: 7...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 39...
	 start solving instance: 43...
	 start solving instance: 54...
	 start solving instance: 124...
	 start solving instance: 126...
	 start solving instance: 146...
	 start solving instance: 53...
	 start solving instance: 70...
	 start solving instance: 138...
	 start solving instance: 112...
	 start solving instance: 93...
	 start solving instance: 89...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4757542.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028380800038576126
		 entropy bonus: 0.20346565544605255
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17746992409229279
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07906661182641983
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 475754.40625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4757542.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02567007578909397
		 entropy bonus: 0.1936960220336914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18208985030651093
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07906661182641983
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 475754.46875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4757542.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011686933226883411
		 entropy bonus: 0.21308763325214386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18424472212791443
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07906661182641983
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 475754.4375 - Differentiable computation graph = True!
PPO iteration: 254/1000:
	 start solving instance: 112...
	 start solving instance: 142...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 33...
	 start solving instance: 39...
	 start solving instance: 53...
	 start solving instance: 138...
	 start solving instance: 61...
	 start solving instance: 93...
	 start solving instance: 7...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 54...
	 start solving instance: 89...
	 start solving instance: 126...
	 start solving instance: 146...
	 start solving instance: 43...
	 start solving instance: 80...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 3968426.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07432784885168076
		 entropy bonus: 0.19065169990062714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17830580472946167
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.015221762470901012
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 396842.65625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3968426.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.031118346378207207
		 entropy bonus: 0.20585249364376068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18051649630069733
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.01692781411111355
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 396842.75 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3968426.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0010218024253845215
		 entropy bonus: 0.20240233838558197
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18051649630069733
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.01692781411111355
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 396842.71875 - Differentiable computation graph = True!
PPO iteration: 255/1000:
	 start solving instance: 89...
	 start solving instance: 146...
	 start solving instance: 70...
	 start solving instance: 43...
	 start solving instance: 1...
	 start solving instance: 7...
	 start solving instance: 112...
	 start solving instance: 126...
	 start solving instance: 61...
	 start solving instance: 54...
	 start solving instance: 33...
	 start solving instance: 53...
	 start solving instance: 142...
	 start solving instance: 39...
	 start solving instance: 31...
	 start solving instance: 80...
	 start solving instance: 93...
	 start solving instance: 124...
	 start solving instance: 138...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 3476374.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.017426595091819763
		 entropy bonus: 0.19962893426418304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16290219128131866
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1006522849202156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 347637.53125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3476374.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0222223699092865
		 entropy bonus: 0.20504970848560333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16290219128131866
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1006522849202156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 347637.53125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3476374.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03857060894370079
		 entropy bonus: 0.19828325510025024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16290219128131866
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1006522849202156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 347637.5625 - Differentiable computation graph = True!
PPO iteration: 256/1000:
	 start solving instance: 33...
	 start solving instance: 7...
	 start solving instance: 126...
	 start solving instance: 14...
	 start solving instance: 61...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 39...
	 start solving instance: 31...
	 start solving instance: 1...
	 start solving instance: 70...
	 start solving instance: 124...
	 start solving instance: 54...
	 start solving instance: 43...
	 start solving instance: 138...
	 start solving instance: 89...
	 start solving instance: 93...
	 start solving instance: 80...
	 start solving instance: 142...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 3846803.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0734739825129509
		 entropy bonus: 0.19433003664016724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17659513652324677
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11954178661108017
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 384680.3125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3846803.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.010855639353394508
		 entropy bonus: 0.20580124855041504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18082420527935028
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11954178661108017
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 384680.375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3846803.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021865064278244972
		 entropy bonus: 0.17284753918647766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18082420527935028
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11954178661108017
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 384680.375 - Differentiable computation graph = True!
PPO iteration: 257/1000:
	 start solving instance: 14...
	 start solving instance: 80...
	 start solving instance: 43...
	 start solving instance: 93...
	 start solving instance: 146...
	 start solving instance: 39...
	 start solving instance: 31...
	 start solving instance: 61...
	 start solving instance: 138...
	 start solving instance: 54...
	 start solving instance: 126...
	 start solving instance: 142...
	 start solving instance: 1...
	 start solving instance: 124...
	 start solving instance: 89...
	 start solving instance: 70...
	 start solving instance: 33...
	 start solving instance: 7...
	 start solving instance: 53...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 3607553.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05196870490908623
		 entropy bonus: 0.21227455139160156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13372600078582764
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05135096237063408
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 360755.375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3607553.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.006953645031899214
		 entropy bonus: 0.16431774199008942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14169788360595703
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05135096237063408
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 360755.4375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3607553.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.013466346077620983
		 entropy bonus: 0.2033250331878662
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14164100587368011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05135096237063408
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 360755.40625 - Differentiable computation graph = True!
PPO iteration: 258/1000:
	 start solving instance: 138...
	 start solving instance: 54...
	 start solving instance: 7...
	 start solving instance: 142...
	 start solving instance: 43...
	 start solving instance: 14...
	 start solving instance: 39...
	 start solving instance: 146...
	 start solving instance: 112...
	 start solving instance: 126...
	 start solving instance: 93...
	 start solving instance: 31...
	 start solving instance: 70...
	 start solving instance: 61...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 33...
	 start solving instance: 80...
	 start solving instance: 124...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4033247.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.039279092103242874
		 entropy bonus: 0.22282449901103973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20328179001808167
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06951314955949783
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 403324.9375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4033247.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.025772083550691605
		 entropy bonus: 0.21175847947597504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20328179001808167
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06951314955949783
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 403324.9375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4033247.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.018784528598189354
		 entropy bonus: 0.20246262848377228
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2124340981245041
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06951314955949783
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 403324.96875 - Differentiable computation graph = True!
PPO iteration: 259/1000:
	 start solving instance: 146...
	 start solving instance: 54...
	 start solving instance: 1...
	 start solving instance: 126...
	 start solving instance: 61...
	 start solving instance: 70...
	 start solving instance: 93...
	 start solving instance: 7...
	 start solving instance: 89...
	 start solving instance: 80...
	 start solving instance: 112...
	 start solving instance: 39...
	 start solving instance: 53...
	 start solving instance: 31...
	 start solving instance: 142...
	 start solving instance: 124...
	 start solving instance: 33...
	 start solving instance: 43...
	 start solving instance: 138...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4744114.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0468740276992321
		 entropy bonus: 0.2158297598361969
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12498106807470322
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0687008947134018
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 474411.6875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4744114.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1595291644334793
		 entropy bonus: 0.19518031179904938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12965475022792816
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0687008947134018
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 474411.78125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4744114.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11801949888467789
		 entropy bonus: 0.20828261971473694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13244323432445526
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0687008947134018
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 474411.75 - Differentiable computation graph = True!
PPO iteration: 260/1000:
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 146...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 70...
	 start solving instance: 124...
	 start solving instance: 126...
	 start solving instance: 39...
	 start solving instance: 43...
	 start solving instance: 89...
	 start solving instance: 7...
	 start solving instance: 1...
	 start solving instance: 54...
	 start solving instance: 112...
	 start solving instance: 53...
	 start solving instance: 93...
	 start solving instance: 80...
	 start solving instance: 14...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 7208102.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1050511822104454
		 entropy bonus: 0.22687838971614838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20542417466640472
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.019481265917420387
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 720810.3125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7208102.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10668802261352539
		 entropy bonus: 0.2234126627445221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20943598449230194
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.019481265917420387
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 720810.3125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7208102.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04237830266356468
		 entropy bonus: 0.210734561085701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21275129914283752
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.019481265917420387
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 720810.375 - Differentiable computation graph = True!
PPO iteration: 261/1000:
	 New training batch of size 20...
	 start solving instance: 50...
	 start solving instance: 55...
	 start solving instance: 2...
	 start solving instance: 88...
	 start solving instance: 68...
	 start solving instance: 112...
	 start solving instance: 24...
	 start solving instance: 69...
	 start solving instance: 125...
	 start solving instance: 132...
	 start solving instance: 119...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 148...
	 start solving instance: 123...
	 start solving instance: 87...
	 start solving instance: 110...
	 start solving instance: 65...
	 start solving instance: 72...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 7688117.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.12438654899597168
		 entropy bonus: 0.2145770639181137
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17569443583488464
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03604176640510559
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 768811.6875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7688117.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.018105918541550636
		 entropy bonus: 0.19105593860149384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17562176287174225
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03604176640510559
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 768811.8125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7688117.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02672463096678257
		 entropy bonus: 0.21325679123401642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17562176287174225
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03604176640510559
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 768811.75 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 8470369.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06487467885017395
		 entropy bonus: 0.20464344322681427
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13685081899166107
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.27071136236190796
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 847036.8750
PPO iteration: 262/1000:
	 start solving instance: 50...
	 start solving instance: 106...
	 start solving instance: 132...
	 start solving instance: 110...
	 start solving instance: 68...
	 start solving instance: 148...
	 start solving instance: 88...
	 start solving instance: 123...
	 start solving instance: 125...
	 start solving instance: 72...
	 start solving instance: 2...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 24...
	 start solving instance: 112...
	 start solving instance: 52...
	 start solving instance: 119...
	 start solving instance: 69...
	 start solving instance: 55...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 8362493.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07700017839670181
		 entropy bonus: 0.1999291330575943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1928742378950119
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06720668077468872
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 836249.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8362493.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12350098043680191
		 entropy bonus: 0.20368368923664093
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1928742378950119
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06720668077468872
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 836249.5625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8362493.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0791952833533287
		 entropy bonus: 0.20342111587524414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1928742378950119
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06720668077468872
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 836249.5 - Differentiable computation graph = True!
PPO iteration: 263/1000:
	 start solving instance: 125...
	 start solving instance: 69...
	 start solving instance: 72...
	 start solving instance: 2...
	 start solving instance: 132...
	 start solving instance: 65...
	 start solving instance: 119...
	 start solving instance: 24...
	 start solving instance: 118...
	 start solving instance: 68...
	 start solving instance: 87...
	 start solving instance: 123...
	 start solving instance: 110...
	 start solving instance: 88...
	 start solving instance: 50...
	 start solving instance: 148...
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 55...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 9156274.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.018414050340652466
		 entropy bonus: 0.1945102959871292
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1724444478750229
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12001076340675354
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 915627.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9156274.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06700903922319412
		 entropy bonus: 0.19833149015903473
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1724444478750229
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12001076340675354
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 915627.5625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9156274.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06745510548353195
		 entropy bonus: 0.19522123038768768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1724444478750229
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12001076340675354
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 915627.5625 - Differentiable computation graph = True!
PPO iteration: 264/1000:
	 start solving instance: 123...
	 start solving instance: 148...
	 start solving instance: 69...
	 start solving instance: 65...
	 start solving instance: 88...
	 start solving instance: 106...
	 start solving instance: 87...
	 start solving instance: 132...
	 start solving instance: 118...
	 start solving instance: 112...
	 start solving instance: 2...
	 start solving instance: 72...
	 start solving instance: 24...
	 start solving instance: 68...
	 start solving instance: 52...
	 start solving instance: 110...
	 start solving instance: 50...
	 start solving instance: 55...
	 start solving instance: 125...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 11427987.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09295611828565598
		 entropy bonus: 0.21480850875377655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1925918310880661
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20746204257011414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1142798.625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 11427987.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09301365911960602
		 entropy bonus: 0.22053013741970062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1925918310880661
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20746204257011414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1142798.625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 11427987.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10050062090158463
		 entropy bonus: 0.22069516777992249
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1925918310880661
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20746204257011414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1142798.625 - Differentiable computation graph = True!
PPO iteration: 265/1000:
	 start solving instance: 68...
	 start solving instance: 87...
	 start solving instance: 119...
	 start solving instance: 132...
	 start solving instance: 24...
	 start solving instance: 52...
	 start solving instance: 118...
	 start solving instance: 65...
	 start solving instance: 112...
	 start solving instance: 2...
	 start solving instance: 88...
	 start solving instance: 55...
	 start solving instance: 125...
	 start solving instance: 69...
	 start solving instance: 110...
	 start solving instance: 148...
	 start solving instance: 50...
	 start solving instance: 123...
	 start solving instance: 106...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 16080453.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010936769656836987
		 entropy bonus: 0.2093818634748459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06645872443914413
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08204073458909988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1608045.375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 16080453.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01028411090373993
		 entropy bonus: 0.20514598488807678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06645872443914413
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08204073458909988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1608045.375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 16080453.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.023756012320518494
		 entropy bonus: 0.20649376511573792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06645872443914413
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08204073458909988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1608045.375 - Differentiable computation graph = True!
PPO iteration: 266/1000:
	 start solving instance: 119...
	 start solving instance: 87...
	 start solving instance: 148...
	 start solving instance: 50...
	 start solving instance: 65...
	 start solving instance: 110...
	 start solving instance: 69...
	 start solving instance: 106...
	 start solving instance: 72...
	 start solving instance: 24...
	 start solving instance: 88...
	 start solving instance: 112...
	 start solving instance: 55...
	 start solving instance: 123...
	 start solving instance: 132...
	 start solving instance: 68...
	 start solving instance: 2...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 25405606.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.020183635875582695
		 entropy bonus: 0.2053402215242386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21242068707942963
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17418482899665833
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2540560.75 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 25405606.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.019770706072449684
		 entropy bonus: 0.20684705674648285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21595335006713867
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17418482899665833
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2540560.75 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 25405606.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.017142534255981445
		 entropy bonus: 0.20034880936145782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22027163207530975
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17418482899665833
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2540560.75 - Differentiable computation graph = True!
PPO iteration: 267/1000:
	 start solving instance: 119...
	 start solving instance: 72...
	 start solving instance: 87...
	 start solving instance: 69...
	 start solving instance: 50...
	 start solving instance: 2...
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 55...
	 start solving instance: 132...
	 start solving instance: 118...
	 start solving instance: 125...
	 start solving instance: 65...
	 start solving instance: 112...
	 start solving instance: 68...
	 start solving instance: 88...
	 start solving instance: 110...
	 start solving instance: 148...
	 start solving instance: 24...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 28930366.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.022890491411089897
		 entropy bonus: 0.20898154377937317
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09693854302167892
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01378550287336111
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2893036.75 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 28930366.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.001080375979654491
		 entropy bonus: 0.20631559193134308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09693854302167892
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01378550287336111
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2893036.75 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 28930366.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.012909049168229103
		 entropy bonus: 0.2060934156179428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09693854302167892
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01378550287336111
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2893036.75 - Differentiable computation graph = True!
PPO iteration: 268/1000:
	 start solving instance: 125...
	 start solving instance: 55...
	 start solving instance: 148...
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 69...
	 start solving instance: 68...
	 start solving instance: 123...
	 start solving instance: 119...
	 start solving instance: 87...
	 start solving instance: 132...
	 start solving instance: 2...
	 start solving instance: 110...
	 start solving instance: 24...
	 start solving instance: 65...
	 start solving instance: 88...
	 start solving instance: 50...
	 start solving instance: 112...
	 start solving instance: 118...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 59390524.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.034376803785562515
		 entropy bonus: 0.22380684316158295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16482432186603546
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2894905209541321
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5939052.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 59390524.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02940424345433712
		 entropy bonus: 0.22727258503437042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16767477989196777
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2894905209541321
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5939052.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 59390524.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02940424345433712
		 entropy bonus: 0.22727258503437042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16767477989196777
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2894905209541321
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5939052.5 - Differentiable computation graph = True!
PPO iteration: 269/1000:
	 start solving instance: 125...
	 start solving instance: 148...
	 start solving instance: 123...
	 start solving instance: 87...
	 start solving instance: 72...
	 start solving instance: 110...
	 start solving instance: 24...
	 start solving instance: 112...
	 start solving instance: 88...
	 start solving instance: 50...
	 start solving instance: 2...
	 start solving instance: 106...
	 start solving instance: 118...
	 start solving instance: 65...
	 start solving instance: 69...
	 start solving instance: 55...
	 start solving instance: 132...
	 start solving instance: 52...
	 start solving instance: 68...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 187190384.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04064119979739189
		 entropy bonus: 0.20370745658874512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2447262853384018
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1325332671403885
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18719038.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 187190384.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04234495386481285
		 entropy bonus: 0.20618298649787903
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2512785494327545
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1325332671403885
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18719038.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 187190384.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04234495386481285
		 entropy bonus: 0.20618298649787903
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2512785494327545
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1325332671403885
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18719038.0 - Differentiable computation graph = True!
PPO iteration: 270/1000:
	 start solving instance: 65...
	 start solving instance: 24...
	 start solving instance: 106...
	 start solving instance: 148...
	 start solving instance: 88...
	 start solving instance: 123...
	 start solving instance: 132...
	 start solving instance: 87...
	 start solving instance: 118...
	 start solving instance: 68...
	 start solving instance: 69...
	 start solving instance: 119...
	 start solving instance: 52...
	 start solving instance: 55...
	 start solving instance: 2...
	 start solving instance: 50...
	 start solving instance: 125...
	 start solving instance: 112...
	 start solving instance: 72...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 2296906240.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.058707814663648605
		 entropy bonus: 0.2328595221042633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25364944338798523
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05376819893717766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 229690624.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2296906240.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.058707814663648605
		 entropy bonus: 0.2328595221042633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25364944338798523
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06054551526904106
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 229690624.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2296906240.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.058707814663648605
		 entropy bonus: 0.2328595221042633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25364944338798523
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.062280893325805664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 229690624.0 - Differentiable computation graph = True!
PPO iteration: 271/1000:
	 New training batch of size 20...
	 start solving instance: 36...
	 start solving instance: 113...
	 start solving instance: 74...
	 start solving instance: 48...
	 start solving instance: 115...
	 start solving instance: 121...
	 start solving instance: 80...
	 start solving instance: 96...
	 start solving instance: 122...
	 start solving instance: 146...
	 start solving instance: 114...
	 start solving instance: 89...
	 start solving instance: 14...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 55386742784.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006939136888831854
		 entropy bonus: 0.2081991285085678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1521061658859253
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.017668448388576508
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5538674176.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 55386742784.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006939136888831854
		 entropy bonus: 0.2081991285085678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1521061658859253
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.017668448388576508
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5538674176.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 55386742784.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006939136888831854
		 entropy bonus: 0.2081991285085678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15846337378025055
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.017668448388576508
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5538674176.0 - Differentiable computation graph = True!
PPO iteration: 272/1000:
	 start solving instance: 114...
	 start solving instance: 80...
	 start solving instance: 107...
	 start solving instance: 141...
	 start solving instance: 146...
	 start solving instance: 36...
	 start solving instance: 95...
	 start solving instance: 96...
	 start solving instance: 113...
	 start solving instance: 14...
	 start solving instance: 115...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 122...
	 start solving instance: 63...
	 start solving instance: 38...
	 start solving instance: 89...
	 start solving instance: 121...
	 start solving instance: 48...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 952627953664.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11498724669218063
		 entropy bonus: 0.2130708247423172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19275040924549103
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0057707056403160095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 95262793728.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 952627953664.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11498724669218063
		 entropy bonus: 0.2130708247423172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19275040924549103
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0057707056403160095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 95262793728.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 952627953664.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.11498724669218063
		 entropy bonus: 0.2130708247423172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19440317153930664
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0057707056403160095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 95262793728.0 - Differentiable computation graph = True!
PPO iteration: 273/1000:
	 start solving instance: 103...
	 start solving instance: 36...
	 start solving instance: 116...
	 start solving instance: 146...
	 start solving instance: 141...
	 start solving instance: 113...
	 start solving instance: 63...
	 start solving instance: 95...
	 start solving instance: 38...
	 start solving instance: 121...
	 start solving instance: 96...
	 start solving instance: 14...
	 start solving instance: 122...
	 start solving instance: 89...
	 start solving instance: 48...
	 start solving instance: 115...
	 start solving instance: 114...
	 start solving instance: 80...
	 start solving instance: 74...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 8234559602688.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025227336212992668
		 entropy bonus: 0.20823541283607483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13560593128204346
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20079511404037476
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 823455973376.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8234559602688.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.056711770594120026
		 entropy bonus: 0.20823541283607483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13560593128204346
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20079511404037476
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 823455973376.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8234559602688.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.056711770594120026
		 entropy bonus: 0.20823541283607483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13560593128204346
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20079511404037476
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 823455973376.0 - Differentiable computation graph = True!
PPO iteration: 274/1000:
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 63...
	 start solving instance: 14...
	 start solving instance: 48...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 74...
	 start solving instance: 95...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 115...
	 start solving instance: 96...
	 start solving instance: 103...
	 start solving instance: 80...
	 start solving instance: 146...
	 start solving instance: 113...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 118543085469696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007007503416389227
		 entropy bonus: 0.21098096668720245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.026757240295410156
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06551603227853775
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11854308966400.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 118543085469696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0280324574559927
		 entropy bonus: 0.20751523971557617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05012587457895279
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06721539050340652
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11854308966400.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 118543085469696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.040688406676054
		 entropy bonus: 0.21018119156360626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.057721491903066635
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06721539050340652
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11854308966400.0 - Differentiable computation graph = True!
PPO iteration: 275/1000:
	 start solving instance: 96...
	 start solving instance: 48...
	 start solving instance: 63...
	 start solving instance: 114...
	 start solving instance: 74...
	 start solving instance: 36...
	 start solving instance: 115...
	 start solving instance: 14...
	 start solving instance: 113...
	 start solving instance: 95...
	 start solving instance: 89...
	 start solving instance: 38...
	 start solving instance: 121...
	 start solving instance: 116...
	 start solving instance: 146...
	 start solving instance: 122...
	 start solving instance: 80...
	 start solving instance: 141...
	 start solving instance: 107...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 594410387537920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0009275674819946289
		 entropy bonus: 0.2146337330341339
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0029757798183709383
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11479043960571289
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59441038753792.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 594410387537920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0009275674819946289
		 entropy bonus: 0.2146337330341339
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.009571355767548084
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11479043960571289
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59441038753792.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 594410387537920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01003875769674778
		 entropy bonus: 0.2146337330341339
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.01581084169447422
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11479043960571289
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 59441038753792.0 - Differentiable computation graph = True!
PPO iteration: 276/1000:
	 start solving instance: 121...
	 start solving instance: 95...
	 start solving instance: 103...
	 start solving instance: 89...
	 start solving instance: 122...
	 start solving instance: 38...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 115...
	 start solving instance: 114...
	 start solving instance: 116...
	 start solving instance: 96...
	 start solving instance: 146...
	 start solving instance: 63...
	 start solving instance: 107...
	 start solving instance: 14...
	 start solving instance: 113...
	 start solving instance: 80...
	 start solving instance: 74...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 396936045658112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16081920266151428
		 entropy bonus: 0.20559866726398468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1619979739189148
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04188122972846031
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 39693605404672.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 396936045658112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16081920266151428
		 entropy bonus: 0.20559866726398468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16627627611160278
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04188122972846031
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 39693605404672.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 396936045658112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16081920266151428
		 entropy bonus: 0.20559866726398468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16627627611160278
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04188122972846031
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 39693605404672.0 - Differentiable computation graph = True!
PPO iteration: 277/1000:
	 start solving instance: 146...
	 start solving instance: 95...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 89...
	 start solving instance: 80...
	 start solving instance: 121...
	 start solving instance: 114...
	 start solving instance: 116...
	 start solving instance: 96...
	 start solving instance: 113...
	 start solving instance: 36...
	 start solving instance: 14...
	 start solving instance: 48...
	 start solving instance: 74...
	 start solving instance: 122...
	 start solving instance: 141...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 171920158883840.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03822390362620354
		 entropy bonus: 0.2080526351928711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09735700488090515
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18240372836589813
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 17192015888384.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 171920158883840.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03822390362620354
		 entropy bonus: 0.2080526351928711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09692006558179855
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18240372836589813
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 17192015888384.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 171920158883840.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03822390362620354
		 entropy bonus: 0.2080526351928711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10483957827091217
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18240372836589813
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 17192015888384.0 - Differentiable computation graph = True!
PPO iteration: 278/1000:
	 start solving instance: 113...
	 start solving instance: 80...
	 start solving instance: 103...
	 start solving instance: 141...
	 start solving instance: 63...
	 start solving instance: 95...
	 start solving instance: 121...
	 start solving instance: 122...
	 start solving instance: 115...
	 start solving instance: 146...
	 start solving instance: 114...
	 start solving instance: 107...
	 start solving instance: 48...
	 start solving instance: 96...
	 start solving instance: 36...
	 start solving instance: 14...
	 start solving instance: 116...
	 start solving instance: 74...
	 start solving instance: 38...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 80175488303104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.018359839916229248
		 entropy bonus: 0.20770683884620667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09246640652418137
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013089694082736969
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8017548935168.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 80175488303104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.018359839916229248
		 entropy bonus: 0.20770683884620667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09246640652418137
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013089694082736969
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8017548935168.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 80175488303104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.018359839916229248
		 entropy bonus: 0.20770683884620667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09246640652418137
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013089694082736969
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8017548935168.0 - Differentiable computation graph = True!
PPO iteration: 279/1000:
	 start solving instance: 107...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 74...
	 start solving instance: 103...
	 start solving instance: 122...
	 start solving instance: 115...
	 start solving instance: 48...
	 start solving instance: 121...
	 start solving instance: 113...
	 start solving instance: 89...
	 start solving instance: 80...
	 start solving instance: 38...
	 start solving instance: 95...
	 start solving instance: 116...
	 start solving instance: 63...
	 start solving instance: 146...
	 start solving instance: 141...
	 start solving instance: 36...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 68192223363072.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.032081689685583115
		 entropy bonus: 0.21189837157726288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14691416919231415
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1750902384519577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6819222650880.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 68192223363072.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.032081689685583115
		 entropy bonus: 0.21189837157726288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14691416919231415
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1750902384519577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6819222650880.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 68192223363072.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.032081689685583115
		 entropy bonus: 0.21189837157726288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14691416919231415
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1750902384519577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6819222650880.0 - Differentiable computation graph = True!
PPO iteration: 280/1000:
	 start solving instance: 14...
	 start solving instance: 146...
	 start solving instance: 95...
	 start solving instance: 63...
	 start solving instance: 114...
	 start solving instance: 116...
	 start solving instance: 141...
	 start solving instance: 74...
	 start solving instance: 80...
	 start solving instance: 107...
	 start solving instance: 113...
	 start solving instance: 96...
	 start solving instance: 48...
	 start solving instance: 38...
	 start solving instance: 36...
	 start solving instance: 89...
	 start solving instance: 115...
	 start solving instance: 103...
	 start solving instance: 121...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 70475254333440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08508380502462387
		 entropy bonus: 0.20674148201942444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16256208717823029
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01907479017972946
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7047525433344.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 70475254333440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08508380502462387
		 entropy bonus: 0.20674148201942444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16256208717823029
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01907479017972946
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7047525433344.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 70475254333440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08508380502462387
		 entropy bonus: 0.20674148201942444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16256208717823029
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01907479017972946
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7047525433344.0 - Differentiable computation graph = True!
PPO iteration: 281/1000:
	 New training batch of size 20...
	 start solving instance: 145...
	 start solving instance: 12...
	 start solving instance: 7...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 69...
	 start solving instance: 119...
	 start solving instance: 148...
	 start solving instance: 44...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 110...
	 start solving instance: 16...
	 start solving instance: 36...
	 start solving instance: 84...
	 start solving instance: 134...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 77345935327232.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.001833921647630632
		 entropy bonus: 0.23796868324279785
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1792105883359909
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2229977697134018
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7734593847296.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 77345935327232.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.001833921647630632
		 entropy bonus: 0.23796868324279785
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1792105883359909
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2229977697134018
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7734593847296.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 77345935327232.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.001833921647630632
		 entropy bonus: 0.23796868324279785
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1792105883359909
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2229977697134018
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7734593847296.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 74878535335936.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.052782028913497925
		 entropy bonus: 0.21186374127864838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09700393676757812
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18574683368206024
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7487853428736.0000
PPO iteration: 282/1000:
	 start solving instance: 35...
	 start solving instance: 110...
	 start solving instance: 90...
	 start solving instance: 7...
	 start solving instance: 44...
	 start solving instance: 84...
	 start solving instance: 148...
	 start solving instance: 36...
	 start solving instance: 16...
	 start solving instance: 128...
	 start solving instance: 132...
	 start solving instance: 10...
	 start solving instance: 75...
	 start solving instance: 5...
	 start solving instance: 69...
	 start solving instance: 12...
	 start solving instance: 80...
	 start solving instance: 145...
	 start solving instance: 134...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 80871340113920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0324774794280529
		 entropy bonus: 0.23831653594970703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1803365796804428
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011996660381555557
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8087134011392.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 80871340113920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0324774794280529
		 entropy bonus: 0.23831653594970703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1803365796804428
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011996660381555557
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8087134011392.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 80871340113920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0324774794280529
		 entropy bonus: 0.23831653594970703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1803365796804428
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011996660381555557
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8087134011392.0 - Differentiable computation graph = True!
PPO iteration: 283/1000:
	 start solving instance: 75...
	 start solving instance: 5...
	 start solving instance: 36...
	 start solving instance: 148...
	 start solving instance: 132...
	 start solving instance: 10...
	 start solving instance: 35...
	 start solving instance: 145...
	 start solving instance: 44...
	 start solving instance: 84...
	 start solving instance: 7...
	 start solving instance: 110...
	 start solving instance: 69...
	 start solving instance: 90...
	 start solving instance: 16...
	 start solving instance: 80...
	 start solving instance: 119...
	 start solving instance: 12...
	 start solving instance: 128...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 106053052137472.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04990427568554878
		 entropy bonus: 0.23575861752033234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2199808657169342
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09778264909982681
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10605305004032.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 106053052137472.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04990427568554878
		 entropy bonus: 0.23575861752033234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2199808657169342
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09778264909982681
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10605305004032.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 106053052137472.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04990427568554878
		 entropy bonus: 0.23575861752033234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2199808657169342
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09778264909982681
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10605305004032.0 - Differentiable computation graph = True!
PPO iteration: 284/1000:
	 start solving instance: 90...
	 start solving instance: 12...
	 start solving instance: 5...
	 start solving instance: 16...
	 start solving instance: 84...
	 start solving instance: 75...
	 start solving instance: 110...
	 start solving instance: 36...
	 start solving instance: 10...
	 start solving instance: 145...
	 start solving instance: 7...
	 start solving instance: 148...
	 start solving instance: 80...
	 start solving instance: 119...
	 start solving instance: 69...
	 start solving instance: 128...
	 start solving instance: 132...
	 start solving instance: 134...
	 start solving instance: 35...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 105741557956608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06590069085359573
		 entropy bonus: 0.24092347919940948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1832829862833023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02371765486896038
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10574156005376.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 105741557956608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06590069085359573
		 entropy bonus: 0.24092347919940948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1832829862833023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02371765486896038
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10574156005376.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 105741557956608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06590069085359573
		 entropy bonus: 0.24092347919940948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1832829862833023
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02371765486896038
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10574156005376.0 - Differentiable computation graph = True!
PPO iteration: 285/1000:
	 start solving instance: 36...
	 start solving instance: 90...
	 start solving instance: 16...
	 start solving instance: 134...
	 start solving instance: 80...
	 start solving instance: 84...
	 start solving instance: 132...
	 start solving instance: 119...
	 start solving instance: 145...
	 start solving instance: 75...
	 start solving instance: 128...
	 start solving instance: 12...
	 start solving instance: 110...
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 10...
	 start solving instance: 5...
	 start solving instance: 69...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 110390046359552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024944741278886795
		 entropy bonus: 0.23986628651618958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2103874683380127
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13011811673641205
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11039004426240.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 110390046359552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024944741278886795
		 entropy bonus: 0.23986628651618958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2103874683380127
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13011811673641205
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11039004426240.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 110390046359552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024944741278886795
		 entropy bonus: 0.23986628651618958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2103874683380127
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13011811673641205
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11039004426240.0 - Differentiable computation graph = True!
PPO iteration: 286/1000:
	 start solving instance: 7...
	 start solving instance: 110...
	 start solving instance: 145...
	 start solving instance: 119...
	 start solving instance: 132...
	 start solving instance: 36...
	 start solving instance: 84...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 35...
	 start solving instance: 75...
	 start solving instance: 148...
	 start solving instance: 10...
	 start solving instance: 12...
	 start solving instance: 80...
	 start solving instance: 128...
	 start solving instance: 16...
	 start solving instance: 44...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 122111356043264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0749409943819046
		 entropy bonus: 0.2229769229888916
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11422111839056015
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.014007141813635826
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12211136233472.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 122111356043264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0749409943819046
		 entropy bonus: 0.2229769229888916
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11422111839056015
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.014007141813635826
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12211136233472.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 122111356043264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0749409943819046
		 entropy bonus: 0.2229769229888916
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11422111839056015
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.014007141813635826
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12211136233472.0 - Differentiable computation graph = True!
PPO iteration: 287/1000:
	 start solving instance: 75...
	 start solving instance: 84...
	 start solving instance: 145...
	 start solving instance: 132...
	 start solving instance: 7...
	 start solving instance: 16...
	 start solving instance: 80...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 110...
	 start solving instance: 69...
	 start solving instance: 148...
	 start solving instance: 10...
	 start solving instance: 5...
	 start solving instance: 119...
	 start solving instance: 36...
	 start solving instance: 44...
	 start solving instance: 35...
	 start solving instance: 134...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 166985644113920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0705903097987175
		 entropy bonus: 0.2527761161327362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18195442855358124
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10336082428693771
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16698564411392.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 166985644113920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0705903097987175
		 entropy bonus: 0.2527761161327362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18195442855358124
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10336082428693771
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16698564411392.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 166985644113920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0705903097987175
		 entropy bonus: 0.2527761161327362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18195442855358124
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10336082428693771
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16698564411392.0 - Differentiable computation graph = True!
PPO iteration: 288/1000:
	 start solving instance: 80...
	 start solving instance: 145...
	 start solving instance: 36...
	 start solving instance: 16...
	 start solving instance: 69...
	 start solving instance: 10...
	 start solving instance: 110...
	 start solving instance: 90...
	 start solving instance: 134...
	 start solving instance: 119...
	 start solving instance: 35...
	 start solving instance: 12...
	 start solving instance: 44...
	 start solving instance: 75...
	 start solving instance: 7...
	 start solving instance: 84...
	 start solving instance: 148...
	 start solving instance: 5...
	 start solving instance: 128...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 188604479438848.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02782229147851467
		 entropy bonus: 0.24473431706428528
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17775161564350128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.31327834725379944
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18860449202176.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 188604479438848.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02800934389233589
		 entropy bonus: 0.2426956444978714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17775161564350128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.31327834725379944
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18860449202176.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 188604479438848.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02800934389233589
		 entropy bonus: 0.2426956444978714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17775161564350128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.31327834725379944
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 18860449202176.0 - Differentiable computation graph = True!
PPO iteration: 289/1000:
	 start solving instance: 36...
	 start solving instance: 132...
	 start solving instance: 148...
	 start solving instance: 134...
	 start solving instance: 84...
	 start solving instance: 35...
	 start solving instance: 128...
	 start solving instance: 44...
	 start solving instance: 10...
	 start solving instance: 16...
	 start solving instance: 110...
	 start solving instance: 119...
	 start solving instance: 145...
	 start solving instance: 90...
	 start solving instance: 75...
	 start solving instance: 5...
	 start solving instance: 7...
	 start solving instance: 69...
	 start solving instance: 12...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 207928208392192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04109708219766617
		 entropy bonus: 0.2420179396867752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27241238951683044
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11181167513132095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20792821678080.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 207928208392192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04109708219766617
		 entropy bonus: 0.2420179396867752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27241238951683044
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11181167513132095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20792821678080.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 207928208392192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04109708219766617
		 entropy bonus: 0.2420179396867752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27241238951683044
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11181167513132095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20792821678080.0 - Differentiable computation graph = True!
PPO iteration: 290/1000:
	 start solving instance: 69...
	 start solving instance: 44...
	 start solving instance: 128...
	 start solving instance: 119...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 132...
	 start solving instance: 7...
	 start solving instance: 148...
	 start solving instance: 36...
	 start solving instance: 134...
	 start solving instance: 145...
	 start solving instance: 10...
	 start solving instance: 84...
	 start solving instance: 80...
	 start solving instance: 90...
	 start solving instance: 110...
	 start solving instance: 16...
	 start solving instance: 12...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 193637577129984.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0888000950217247
		 entropy bonus: 0.2324957400560379
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06000104174017906
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02574106678366661
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19363757293568.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 193637577129984.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0888000950217247
		 entropy bonus: 0.2324957400560379
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06000104174017906
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02574106678366661
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19363757293568.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 193637577129984.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0888000950217247
		 entropy bonus: 0.2324957400560379
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06000104174017906
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02574106678366661
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 19363757293568.0 - Differentiable computation graph = True!
PPO iteration: 291/1000:
	 New training batch of size 20...
	 start solving instance: 54...
	 start solving instance: 53...
	 start solving instance: 106...
	 start solving instance: 33...
	 start solving instance: 65...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 133...
	 start solving instance: 72...
	 start solving instance: 46...
	 start solving instance: 52...
	 start solving instance: 42...
	 start solving instance: 48...
	 start solving instance: 97...
	 start solving instance: 90...
	 start solving instance: 138...
	 start solving instance: 39...
	 start solving instance: 6...
	 start solving instance: 44...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 363032513347584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05690775066614151
		 entropy bonus: 0.2140151709318161
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06080298498272896
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05280511826276779
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 36303253012480.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 363032513347584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05772702768445015
		 entropy bonus: 0.21170468628406525
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06080298498272896
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05280511826276779
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 36303253012480.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 363032513347584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05690775066614151
		 entropy bonus: 0.2140151709318161
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06080298498272896
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05280511826276779
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 36303253012480.0 - Differentiable computation graph = True!
PPO iteration: 292/1000:
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 149...
	 start solving instance: 90...
	 start solving instance: 33...
	 start solving instance: 6...
	 start solving instance: 44...
	 start solving instance: 48...
	 start solving instance: 119...
	 start solving instance: 138...
	 start solving instance: 46...
	 start solving instance: 133...
	 start solving instance: 54...
	 start solving instance: 72...
	 start solving instance: 97...
	 start solving instance: 106...
	 start solving instance: 1...
	 start solving instance: 52...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 828728770822144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08445620536804199
		 entropy bonus: 0.2177390158176422
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09670007228851318
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20254620909690857
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 82872878759936.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 828728770822144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08445620536804199
		 entropy bonus: 0.2177390158176422
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09670007228851318
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20254620909690857
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 82872878759936.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 828728770822144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08526512235403061
		 entropy bonus: 0.22004953026771545
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09670007228851318
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20254620909690857
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 82872878759936.0 - Differentiable computation graph = True!
PPO iteration: 293/1000:
	 start solving instance: 54...
	 start solving instance: 33...
	 start solving instance: 6...
	 start solving instance: 46...
	 start solving instance: 138...
	 start solving instance: 52...
	 start solving instance: 39...
	 start solving instance: 106...
	 start solving instance: 44...
	 start solving instance: 53...
	 start solving instance: 119...
	 start solving instance: 97...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 65...
	 start solving instance: 90...
	 start solving instance: 72...
	 start solving instance: 42...
	 start solving instance: 133...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 1026371153297408.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07327443361282349
		 entropy bonus: 0.21842984855175018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.054149139672517776
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18921463191509247
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 102637118685184.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1026371153297408.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07327443361282349
		 entropy bonus: 0.21842984855175018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05505882576107979
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18921463191509247
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 102637118685184.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1026371153297408.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07327443361282349
		 entropy bonus: 0.21842984855175018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05505882576107979
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18921463191509247
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 102637118685184.0 - Differentiable computation graph = True!
PPO iteration: 294/1000:
	 start solving instance: 119...
	 start solving instance: 106...
	 start solving instance: 72...
	 start solving instance: 46...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 53...
	 start solving instance: 1...
	 start solving instance: 149...
	 start solving instance: 54...
	 start solving instance: 39...
	 start solving instance: 133...
	 start solving instance: 33...
	 start solving instance: 48...
	 start solving instance: 6...
	 start solving instance: 44...
	 start solving instance: 138...
	 start solving instance: 90...
	 start solving instance: 52...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 588380521889792.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047418463975191116
		 entropy bonus: 0.22128383815288544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07429753243923187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.008134681731462479
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 58838053027840.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 588380521889792.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047418463975191116
		 entropy bonus: 0.22128383815288544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07429753243923187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.008134681731462479
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 58838053027840.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 588380521889792.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047418463975191116
		 entropy bonus: 0.22128383815288544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07429753243923187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.008134681731462479
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 58838053027840.0 - Differentiable computation graph = True!
PPO iteration: 295/1000:
	 start solving instance: 72...
	 start solving instance: 106...
	 start solving instance: 149...
	 start solving instance: 6...
	 start solving instance: 1...
	 start solving instance: 133...
	 start solving instance: 48...
	 start solving instance: 90...
	 start solving instance: 65...
	 start solving instance: 119...
	 start solving instance: 52...
	 start solving instance: 42...
	 start solving instance: 46...
	 start solving instance: 53...
	 start solving instance: 138...
	 start solving instance: 33...
	 start solving instance: 54...
	 start solving instance: 44...
	 start solving instance: 97...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 866502337101824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.022154975682497025
		 entropy bonus: 0.2205737680196762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14139792323112488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05671682208776474
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 86650235387904.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 866502337101824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.022154975682497025
		 entropy bonus: 0.2205737680196762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14139792323112488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05671682208776474
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 86650235387904.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 866502337101824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.022154975682497025
		 entropy bonus: 0.2205737680196762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14139792323112488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05671682208776474
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 86650235387904.0 - Differentiable computation graph = True!
PPO iteration: 296/1000:
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 53...
	 start solving instance: 97...
	 start solving instance: 46...
	 start solving instance: 119...
	 start solving instance: 52...
	 start solving instance: 65...
	 start solving instance: 133...
	 start solving instance: 106...
	 start solving instance: 72...
	 start solving instance: 54...
	 start solving instance: 39...
	 start solving instance: 42...
	 start solving instance: 6...
	 start solving instance: 33...
	 start solving instance: 48...
	 start solving instance: 90...
	 start solving instance: 138...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 1384329162784768.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0012012108927592635
		 entropy bonus: 0.22631530463695526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2930719554424286
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.031096698716282845
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 138432919633920.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1384329162784768.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007812963798642159
		 entropy bonus: 0.22400479018688202
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2930719554424286
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.031096698716282845
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 138432919633920.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1384329162784768.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0012012108927592635
		 entropy bonus: 0.22631530463695526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2930719554424286
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.031096698716282845
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 138432919633920.0 - Differentiable computation graph = True!
PPO iteration: 297/1000:
	 start solving instance: 119...
	 start solving instance: 39...
	 start solving instance: 52...
	 start solving instance: 53...
	 start solving instance: 106...
	 start solving instance: 54...
	 start solving instance: 6...
	 start solving instance: 33...
	 start solving instance: 42...
	 start solving instance: 138...
	 start solving instance: 97...
	 start solving instance: 65...
	 start solving instance: 149...
	 start solving instance: 72...
	 start solving instance: 1...
	 start solving instance: 133...
	 start solving instance: 90...
	 start solving instance: 44...
	 start solving instance: 48...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 518108414476288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.12317023426294327
		 entropy bonus: 0.23797860741615295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14899273216724396
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07862038910388947
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 51810840608768.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 518108414476288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.12317023426294327
		 entropy bonus: 0.23797860741615295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14899273216724396
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07862038910388947
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 51810840608768.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 518108414476288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.12317023426294327
		 entropy bonus: 0.23797860741615295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14899273216724396
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07862038910388947
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 51810840608768.0 - Differentiable computation graph = True!
PPO iteration: 298/1000:
	 start solving instance: 42...
	 start solving instance: 46...
	 start solving instance: 149...
	 start solving instance: 53...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 54...
	 start solving instance: 52...
	 start solving instance: 133...
	 start solving instance: 138...
	 start solving instance: 48...
	 start solving instance: 106...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 33...
	 start solving instance: 119...
	 start solving instance: 6...
	 start solving instance: 44...
	 start solving instance: 72...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 268543820038144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.000584098685067147
		 entropy bonus: 0.22281567752361298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13892202079296112
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.050104618072509766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26854381584384.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 268543820038144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0004964798572473228
		 entropy bonus: 0.22485435009002686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13892202079296112
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.050104618072509766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26854381584384.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 268543820038144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.000584098685067147
		 entropy bonus: 0.22281567752361298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13892202079296112
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.050104618072509766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26854381584384.0 - Differentiable computation graph = True!
PPO iteration: 299/1000:
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 72...
	 start solving instance: 44...
	 start solving instance: 53...
	 start solving instance: 149...
	 start solving instance: 97...
	 start solving instance: 133...
	 start solving instance: 48...
	 start solving instance: 90...
	 start solving instance: 119...
	 start solving instance: 6...
	 start solving instance: 46...
	 start solving instance: 106...
	 start solving instance: 1...
	 start solving instance: 52...
	 start solving instance: 138...
	 start solving instance: 33...
	 start solving instance: 54...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 295813221711872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0042153000831604
		 entropy bonus: 0.22592411935329437
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14904533326625824
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.27575552463531494
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 29581323010048.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 295813221711872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0042153000831604
		 entropy bonus: 0.22592411935329437
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14904533326625824
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.27575552463531494
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 29581323010048.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 295813221711872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0042153000831604
		 entropy bonus: 0.22592411935329437
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14904533326625824
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.27575552463531494
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 29581323010048.0 - Differentiable computation graph = True!
PPO iteration: 300/1000:
	 start solving instance: 46...
	 start solving instance: 72...
	 start solving instance: 54...
	 start solving instance: 6...
	 start solving instance: 138...
	 start solving instance: 48...
	 start solving instance: 1...
	 start solving instance: 53...
	 start solving instance: 97...
	 start solving instance: 119...
	 start solving instance: 90...
	 start solving instance: 44...
	 start solving instance: 149...
	 start solving instance: 133...
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 33...
	 start solving instance: 106...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 505514429513728.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03602557256817818
		 entropy bonus: 0.23920921981334686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.133440762758255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2122821807861328
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 50551442112512.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 505514429513728.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03602557256817818
		 entropy bonus: 0.23920921981334686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13370655477046967
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2122821807861328
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 50551442112512.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 505514429513728.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03602557256817818
		 entropy bonus: 0.23920921981334686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13376851379871368
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2122821807861328
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 50551442112512.0 - Differentiable computation graph = True!
PPO iteration: 301/1000:
	 New training batch of size 20...
	 start solving instance: 42...
	 start solving instance: 48...
	 start solving instance: 112...
	 start solving instance: 41...
	 start solving instance: 143...
	 start solving instance: 122...
	 start solving instance: 13...
	 start solving instance: 91...
	 start solving instance: 130...
	 start solving instance: 135...
	 start solving instance: 40...
	 start solving instance: 77...
	 start solving instance: 72...
	 start solving instance: 110...
	 start solving instance: 134...
	 start solving instance: 24...
	 start solving instance: 10...
	 start solving instance: 50...
	 start solving instance: 21...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 1615268346331136.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11320061981678009
		 entropy bonus: 0.21536961197853088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11062289774417877
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.00016242265701293945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 161526841344000.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1615268346331136.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11591537296772003
		 entropy bonus: 0.2156102955341339
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11307710409164429
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.00016242265701293945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 161526841344000.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1615268346331136.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11340327560901642
		 entropy bonus: 0.21344421803951263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11307710409164429
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.00016242265701293945
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 161526841344000.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 1.239214565883904e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04380747675895691
		 entropy bonus: 0.2132960855960846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.053632255643606186
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.01743939518928528
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1239214565883904.0000
PPO iteration: 302/1000:
	 start solving instance: 42...
	 start solving instance: 143...
	 start solving instance: 24...
	 start solving instance: 48...
	 start solving instance: 110...
	 start solving instance: 10...
	 start solving instance: 91...
	 start solving instance: 130...
	 start solving instance: 50...
	 start solving instance: 13...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 122...
	 start solving instance: 52...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 21...
	 start solving instance: 41...
	 start solving instance: 77...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.1634511280340992e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028315246105194092
		 entropy bonus: 0.21174989640712738
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04497003182768822
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.008342752233147621
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1163451208564736.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.1634511280340992e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010927832685410976
		 entropy bonus: 0.20679883658885956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04716810584068298
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.008342752233147621
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1163451208564736.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.1634511280340992e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02493000589311123
		 entropy bonus: 0.19910970330238342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04919807240366936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.008342752233147621
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1163451208564736.0 - Differentiable computation graph = True!
PPO iteration: 303/1000:
	 start solving instance: 143...
	 start solving instance: 40...
	 start solving instance: 135...
	 start solving instance: 72...
	 start solving instance: 112...
	 start solving instance: 52...
	 start solving instance: 42...
	 start solving instance: 134...
	 start solving instance: 10...
	 start solving instance: 122...
	 start solving instance: 77...
	 start solving instance: 21...
	 start solving instance: 50...
	 start solving instance: 130...
	 start solving instance: 41...
	 start solving instance: 24...
	 start solving instance: 13...
	 start solving instance: 48...
	 start solving instance: 110...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.2034027478043853e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06576662510633469
		 entropy bonus: 0.22463011741638184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13214211165905
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031828589737415314
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.203402833703731e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.2034027478043853e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06576662510633469
		 entropy bonus: 0.22463011741638184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.136406809091568
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031828589737415314
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.203402833703731e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.2034027478043853e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06576662510633469
		 entropy bonus: 0.22463011741638184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.136406809091568
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031828589737415314
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.203402833703731e+16 - Differentiable computation graph = True!
PPO iteration: 304/1000:
	 start solving instance: 13...
	 start solving instance: 143...
	 start solving instance: 50...
	 start solving instance: 134...
	 start solving instance: 41...
	 start solving instance: 10...
	 start solving instance: 72...
	 start solving instance: 24...
	 start solving instance: 21...
	 start solving instance: 112...
	 start solving instance: 130...
	 start solving instance: 52...
	 start solving instance: 40...
	 start solving instance: 110...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 122...
	 start solving instance: 91...
	 start solving instance: 48...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.577339222117581e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05214017629623413
		 entropy bonus: 0.2228095531463623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09092681854963303
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06461886316537857
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2577339275804672.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.577339222117581e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015601003542542458
		 entropy bonus: 0.2219630479812622
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09486035257577896
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06461886316537857
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2577339275804672.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.577339222117581e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.012304151430726051
		 entropy bonus: 0.22369590401649475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09683603048324585
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06461886316537857
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2577339275804672.0 - Differentiable computation graph = True!
PPO iteration: 305/1000:
	 start solving instance: 24...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 21...
	 start solving instance: 48...
	 start solving instance: 112...
	 start solving instance: 40...
	 start solving instance: 110...
	 start solving instance: 10...
	 start solving instance: 50...
	 start solving instance: 77...
	 start solving instance: 135...
	 start solving instance: 91...
	 start solving instance: 42...
	 start solving instance: 41...
	 start solving instance: 72...
	 start solving instance: 52...
	 start solving instance: 143...
	 start solving instance: 13...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 9816539670773760.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13445784151554108
		 entropy bonus: 0.22530384361743927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12878024578094482
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0032886331900954247
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 981653967077376.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9816539670773760.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13445784151554108
		 entropy bonus: 0.22530384361743927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12878024578094482
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0032886331900954247
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 981653967077376.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9816539670773760.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13445784151554108
		 entropy bonus: 0.22530384361743927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12878024578094482
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0032886331900954247
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 981653967077376.0 - Differentiable computation graph = True!
PPO iteration: 306/1000:
	 start solving instance: 72...
	 start solving instance: 48...
	 start solving instance: 77...
	 start solving instance: 42...
	 start solving instance: 130...
	 start solving instance: 134...
	 start solving instance: 50...
	 start solving instance: 10...
	 start solving instance: 112...
	 start solving instance: 21...
	 start solving instance: 52...
	 start solving instance: 122...
	 start solving instance: 41...
	 start solving instance: 24...
	 start solving instance: 135...
	 start solving instance: 40...
	 start solving instance: 13...
	 start solving instance: 110...
	 start solving instance: 143...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 7068470881550336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04143903777003288
		 entropy bonus: 0.22003693878650665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09042090177536011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.021413389593362808
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 706847128420352.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7068470881550336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04143903777003288
		 entropy bonus: 0.22003693878650665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09042090177536011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.021413389593362808
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 706847128420352.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7068470881550336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04143903777003288
		 entropy bonus: 0.22003693878650665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09042090177536011
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.021413389593362808
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 706847128420352.0 - Differentiable computation graph = True!
PPO iteration: 307/1000:
	 start solving instance: 21...
	 start solving instance: 13...
	 start solving instance: 10...
	 start solving instance: 72...
	 start solving instance: 40...
	 start solving instance: 52...
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 41...
	 start solving instance: 112...
	 start solving instance: 42...
	 start solving instance: 91...
	 start solving instance: 77...
	 start solving instance: 50...
	 start solving instance: 110...
	 start solving instance: 24...
	 start solving instance: 143...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 5906233940770816.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05127173662185669
		 entropy bonus: 0.21845713257789612
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10905952751636505
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06429020315408707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 590623434342400.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5906233940770816.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05127173662185669
		 entropy bonus: 0.21845713257789612
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10905952751636505
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06429020315408707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 590623434342400.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5906233940770816.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05434531718492508
		 entropy bonus: 0.215981587767601
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10905952751636505
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06429020315408707
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 590623434342400.0 - Differentiable computation graph = True!
PPO iteration: 308/1000:
	 start solving instance: 77...
	 start solving instance: 122...
	 start solving instance: 41...
	 start solving instance: 134...
	 start solving instance: 52...
	 start solving instance: 42...
	 start solving instance: 110...
	 start solving instance: 13...
	 start solving instance: 10...
	 start solving instance: 24...
	 start solving instance: 135...
	 start solving instance: 21...
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 40...
	 start solving instance: 91...
	 start solving instance: 143...
	 start solving instance: 72...
	 start solving instance: 112...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 5319803401142272.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1476714164018631
		 entropy bonus: 0.20590506494045258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07002066820859909
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.019419647753238678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 531980353536000.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5319803401142272.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1476714164018631
		 entropy bonus: 0.20590506494045258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07002066820859909
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.019419647753238678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 531980353536000.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5319803401142272.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1476714164018631
		 entropy bonus: 0.20590506494045258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07002066820859909
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.019419647753238678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 531980353536000.0 - Differentiable computation graph = True!
PPO iteration: 309/1000:
	 start solving instance: 110...
	 start solving instance: 10...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 122...
	 start solving instance: 91...
	 start solving instance: 130...
	 start solving instance: 24...
	 start solving instance: 40...
	 start solving instance: 52...
	 start solving instance: 50...
	 start solving instance: 41...
	 start solving instance: 42...
	 start solving instance: 13...
	 start solving instance: 21...
	 start solving instance: 77...
	 start solving instance: 72...
	 start solving instance: 48...
	 start solving instance: 134...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 5359542049177600.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13561145961284637
		 entropy bonus: 0.22282211482524872
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10828349739313126
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09904831647872925
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535954204917760.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5359542049177600.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13617096841335297
		 entropy bonus: 0.22521041333675385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10828349739313126
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09904831647872925
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535954204917760.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5359542049177600.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.13617096841335297
		 entropy bonus: 0.22521041333675385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10828349739313126
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09904831647872925
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535954204917760.0 - Differentiable computation graph = True!
PPO iteration: 310/1000:
	 start solving instance: 72...
	 start solving instance: 41...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 10...
	 start solving instance: 122...
	 start solving instance: 77...
	 start solving instance: 91...
	 start solving instance: 40...
	 start solving instance: 13...
	 start solving instance: 143...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 50...
	 start solving instance: 48...
	 start solving instance: 112...
	 start solving instance: 42...
	 start solving instance: 52...
	 start solving instance: 21...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 5222492327116800.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007936174049973488
		 entropy bonus: 0.2234574407339096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21809135377407074
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.015922904014587402
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 522249232711680.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5222492327116800.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.00459103612229228
		 entropy bonus: 0.2259329855442047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21809135377407074
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.015922904014587402
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 522249232711680.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5222492327116800.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.00459103612229228
		 entropy bonus: 0.2259329855442047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21809135377407074
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.015922904014587402
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 522249232711680.0 - Differentiable computation graph = True!
PPO iteration: 311/1000:
	 New training batch of size 20...
	 start solving instance: 108...
	 start solving instance: 9...
	 start solving instance: 121...
	 start solving instance: 7...
	 start solving instance: 51...
	 start solving instance: 95...
	 start solving instance: 15...
	 start solving instance: 77...
	 start solving instance: 30...
	 start solving instance: 110...
	 start solving instance: 61...
	 start solving instance: 58...
	 start solving instance: 148...
	 start solving instance: 50...
	 start solving instance: 139...
	 start solving instance: 107...
	 start solving instance: 146...
	 start solving instance: 18...
	 start solving instance: 68...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 5409802830217216.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.031111940741539
		 entropy bonus: 0.22545795142650604
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16770215332508087
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15145590901374817
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 540980289732608.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5409802830217216.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.031111940741539
		 entropy bonus: 0.22545795142650604
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16770215332508087
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15145590901374817
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 540980289732608.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5409802830217216.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.031111940741539
		 entropy bonus: 0.22545795142650604
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16770215332508087
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15145590901374817
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 540980289732608.0 - Differentiable computation graph = True!
PPO iteration: 312/1000:
	 start solving instance: 148...
	 start solving instance: 18...
	 start solving instance: 139...
	 start solving instance: 119...
	 start solving instance: 9...
	 start solving instance: 51...
	 start solving instance: 121...
	 start solving instance: 77...
	 start solving instance: 108...
	 start solving instance: 110...
	 start solving instance: 30...
	 start solving instance: 7...
	 start solving instance: 95...
	 start solving instance: 50...
	 start solving instance: 61...
	 start solving instance: 107...
	 start solving instance: 68...
	 start solving instance: 146...
	 start solving instance: 58...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 5532185775833088.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16316059231758118
		 entropy bonus: 0.22312140464782715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05253317579627037
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13210955262184143
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 553218597715968.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5532185775833088.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16456177830696106
		 entropy bonus: 0.22550968825817108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05253317579627037
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13210955262184143
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 553218597715968.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5532185775833088.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16316059231758118
		 entropy bonus: 0.22312140464782715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05253317579627037
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13210955262184143
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 553218597715968.0 - Differentiable computation graph = True!
PPO iteration: 313/1000:
	 start solving instance: 30...
	 start solving instance: 148...
	 start solving instance: 58...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 108...
	 start solving instance: 146...
	 start solving instance: 7...
	 start solving instance: 119...
	 start solving instance: 110...
	 start solving instance: 139...
	 start solving instance: 68...
	 start solving instance: 9...
	 start solving instance: 77...
	 start solving instance: 15...
	 start solving instance: 95...
	 start solving instance: 50...
	 start solving instance: 61...
	 start solving instance: 107...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 5435396540334080.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03617636859416962
		 entropy bonus: 0.22091613709926605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11416180431842804
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.044122498482465744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 543539654033408.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5435396540334080.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03801536187529564
		 entropy bonus: 0.21844057738780975
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11416180431842804
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.044122498482465744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 543539654033408.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5435396540334080.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03617636859416962
		 entropy bonus: 0.22091613709926605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11416180431842804
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.044122498482465744
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 543539654033408.0 - Differentiable computation graph = True!
PPO iteration: 314/1000:
	 start solving instance: 148...
	 start solving instance: 18...
	 start solving instance: 77...
	 start solving instance: 68...
	 start solving instance: 30...
	 start solving instance: 108...
	 start solving instance: 107...
	 start solving instance: 15...
	 start solving instance: 121...
	 start solving instance: 95...
	 start solving instance: 7...
	 start solving instance: 61...
	 start solving instance: 119...
	 start solving instance: 139...
	 start solving instance: 146...
	 start solving instance: 50...
	 start solving instance: 58...
	 start solving instance: 110...
	 start solving instance: 51...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 5301509524815872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0872136577963829
		 entropy bonus: 0.24285249412059784
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1904820203781128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08434860408306122
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 530150965903360.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5301509524815872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0872136577963829
		 entropy bonus: 0.24285249412059784
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1904820203781128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08434860408306122
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 530150965903360.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5301509524815872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0872136577963829
		 entropy bonus: 0.24285249412059784
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1904820203781128
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08434860408306122
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 530150965903360.0 - Differentiable computation graph = True!
PPO iteration: 315/1000:
	 start solving instance: 148...
	 start solving instance: 7...
	 start solving instance: 58...
	 start solving instance: 77...
	 start solving instance: 107...
	 start solving instance: 61...
	 start solving instance: 139...
	 start solving instance: 110...
	 start solving instance: 146...
	 start solving instance: 119...
	 start solving instance: 18...
	 start solving instance: 121...
	 start solving instance: 30...
	 start solving instance: 108...
	 start solving instance: 15...
	 start solving instance: 9...
	 start solving instance: 51...
	 start solving instance: 68...
	 start solving instance: 50...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 5360183609917440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03253072500228882
		 entropy bonus: 0.2260773628950119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07117209583520889
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22346530854701996
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 536018360991744.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5360183609917440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03253072500228882
		 entropy bonus: 0.2260773628950119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07117209583520889
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22346530854701996
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 536018360991744.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5360183609917440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03253072500228882
		 entropy bonus: 0.2260773628950119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07117209583520889
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22346530854701996
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 536018360991744.0 - Differentiable computation graph = True!
PPO iteration: 316/1000:
	 start solving instance: 95...
	 start solving instance: 148...
	 start solving instance: 108...
	 start solving instance: 110...
	 start solving instance: 30...
	 start solving instance: 107...
	 start solving instance: 146...
	 start solving instance: 9...
	 start solving instance: 139...
	 start solving instance: 119...
	 start solving instance: 61...
	 start solving instance: 68...
	 start solving instance: 121...
	 start solving instance: 7...
	 start solving instance: 77...
	 start solving instance: 51...
	 start solving instance: 18...
	 start solving instance: 50...
	 start solving instance: 15...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 5295844462952448.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015564954839646816
		 entropy bonus: 0.2339463084936142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05760864168405533
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18226122856140137
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 529584466427904.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5295844462952448.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015564954839646816
		 entropy bonus: 0.2339463084936142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05760864168405533
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18226122856140137
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 529584466427904.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5295844462952448.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.015564954839646816
		 entropy bonus: 0.2339463084936142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05760864168405533
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18226122856140137
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 529584466427904.0 - Differentiable computation graph = True!
PPO iteration: 317/1000:
	 start solving instance: 108...
	 start solving instance: 148...
	 start solving instance: 146...
	 start solving instance: 9...
	 start solving instance: 61...
	 start solving instance: 15...
	 start solving instance: 50...
	 start solving instance: 30...
	 start solving instance: 18...
	 start solving instance: 119...
	 start solving instance: 110...
	 start solving instance: 95...
	 start solving instance: 139...
	 start solving instance: 107...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 68...
	 start solving instance: 77...
	 start solving instance: 7...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 5318350091583488.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05460094287991524
		 entropy bonus: 0.23601765930652618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15019412338733673
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08963858336210251
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 531835029291008.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5318350091583488.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05460094287991524
		 entropy bonus: 0.23601765930652618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15019412338733673
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08963858336210251
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 531835029291008.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5318350091583488.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05460094287991524
		 entropy bonus: 0.23601765930652618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15019412338733673
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08963858336210251
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 531835029291008.0 - Differentiable computation graph = True!
PPO iteration: 318/1000:
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 95...
	 start solving instance: 77...
	 start solving instance: 119...
	 start solving instance: 51...
	 start solving instance: 18...
	 start solving instance: 146...
	 start solving instance: 148...
	 start solving instance: 107...
	 start solving instance: 7...
	 start solving instance: 108...
	 start solving instance: 15...
	 start solving instance: 50...
	 start solving instance: 30...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 9...
	 start solving instance: 58...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 5281591077109760.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04842832311987877
		 entropy bonus: 0.2355394810438156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1453392058610916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16290313005447388
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 528159107710976.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5281591077109760.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05205655097961426
		 entropy bonus: 0.23337340354919434
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1453392058610916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16290313005447388
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 528159107710976.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5281591077109760.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04842832311987877
		 entropy bonus: 0.2355394810438156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1453392058610916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16290313005447388
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 528159107710976.0 - Differentiable computation graph = True!
PPO iteration: 319/1000:
	 start solving instance: 107...
	 start solving instance: 61...
	 start solving instance: 51...
	 start solving instance: 15...
	 start solving instance: 121...
	 start solving instance: 110...
	 start solving instance: 108...
	 start solving instance: 95...
	 start solving instance: 30...
	 start solving instance: 18...
	 start solving instance: 139...
	 start solving instance: 77...
	 start solving instance: 50...
	 start solving instance: 7...
	 start solving instance: 58...
	 start solving instance: 68...
	 start solving instance: 9...
	 start solving instance: 146...
	 start solving instance: 148...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 5426607426633728.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009741238318383694
		 entropy bonus: 0.23474936187267303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19966188073158264
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0623655840754509
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 542660762796032.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5426607426633728.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009741238318383694
		 entropy bonus: 0.23474936187267303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19966188073158264
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0623655840754509
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 542660762796032.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5426607426633728.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009741238318383694
		 entropy bonus: 0.23474936187267303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19966188073158264
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0623655840754509
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 542660762796032.0 - Differentiable computation graph = True!
PPO iteration: 320/1000:
	 start solving instance: 139...
	 start solving instance: 61...
	 start solving instance: 110...
	 start solving instance: 18...
	 start solving instance: 68...
	 start solving instance: 15...
	 start solving instance: 9...
	 start solving instance: 95...
	 start solving instance: 50...
	 start solving instance: 58...
	 start solving instance: 51...
	 start solving instance: 121...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 107...
	 start solving instance: 7...
	 start solving instance: 108...
	 start solving instance: 119...
	 start solving instance: 148...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 5573646168883200.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09106885641813278
		 entropy bonus: 0.24671220779418945
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12891936302185059
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.007886436767876148
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 557364616888320.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5573646168883200.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09343700110912323
		 entropy bonus: 0.2491004914045334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12891936302185059
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.007886436767876148
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 557364616888320.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5573646168883200.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09106885641813278
		 entropy bonus: 0.24671220779418945
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12891936302185059
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.007886436767876148
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 557364616888320.0 - Differentiable computation graph = True!
PPO iteration: 321/1000:
	 New training batch of size 20...
	 start solving instance: 8...
	 start solving instance: 103...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 54...
	 start solving instance: 58...
	 start solving instance: 53...
	 start solving instance: 68...
	 start solving instance: 46...
	 start solving instance: 92...
	 start solving instance: 143...
	 start solving instance: 39...
	 start solving instance: 102...
	 start solving instance: 78...
	 start solving instance: 29...
	 start solving instance: 128...
	 start solving instance: 52...
	 start solving instance: 97...
	 start solving instance: 104...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 5130104896225280.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03457985073328018
		 entropy bonus: 0.22395840287208557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1016397476196289
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10980138927698135
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 513010489622528.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5130104896225280.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03457985073328018
		 entropy bonus: 0.22395840287208557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1016397476196289
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10980138927698135
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 513010489622528.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5130104896225280.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0302105899900198
		 entropy bonus: 0.22515347599983215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1016397476196289
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10980138927698135
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 513010489622528.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 5381675626266624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021302834153175354
		 entropy bonus: 0.21565261483192444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17941975593566895
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18547779321670532
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 538167555915776.0000
PPO iteration: 322/1000:
	 start solving instance: 148...
	 start solving instance: 46...
	 start solving instance: 40...
	 start solving instance: 143...
	 start solving instance: 58...
	 start solving instance: 92...
	 start solving instance: 97...
	 start solving instance: 68...
	 start solving instance: 128...
	 start solving instance: 39...
	 start solving instance: 104...
	 start solving instance: 8...
	 start solving instance: 20...
	 start solving instance: 103...
	 start solving instance: 53...
	 start solving instance: 78...
	 start solving instance: 52...
	 start solving instance: 29...
	 start solving instance: 102...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 5255437410631680.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03509470820426941
		 entropy bonus: 0.22448065876960754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17706404626369476
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09997335076332092
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 525543741063168.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5255437410631680.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03509470820426941
		 entropy bonus: 0.22448065876960754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17706404626369476
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09997335076332092
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 525543741063168.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5255437410631680.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03509470820426941
		 entropy bonus: 0.22448065876960754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17706404626369476
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09997335076332092
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 525543741063168.0 - Differentiable computation graph = True!
PPO iteration: 323/1000:
	 start solving instance: 53...
	 start solving instance: 8...
	 start solving instance: 40...
	 start solving instance: 29...
	 start solving instance: 54...
	 start solving instance: 102...
	 start solving instance: 97...
	 start solving instance: 52...
	 start solving instance: 104...
	 start solving instance: 46...
	 start solving instance: 128...
	 start solving instance: 143...
	 start solving instance: 78...
	 start solving instance: 20...
	 start solving instance: 148...
	 start solving instance: 68...
	 start solving instance: 39...
	 start solving instance: 58...
	 start solving instance: 103...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 5287164334047232.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03692878410220146
		 entropy bonus: 0.23217640817165375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.187550887465477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10515293478965759
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 528716446826496.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5287164334047232.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03692878410220146
		 entropy bonus: 0.23217640817165375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.187550887465477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10515293478965759
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 528716446826496.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5287164334047232.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03692878410220146
		 entropy bonus: 0.23217640817165375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.187550887465477
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10515293478965759
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 528716446826496.0 - Differentiable computation graph = True!
PPO iteration: 324/1000:
	 start solving instance: 104...
	 start solving instance: 143...
	 start solving instance: 97...
	 start solving instance: 92...
	 start solving instance: 148...
	 start solving instance: 102...
	 start solving instance: 58...
	 start solving instance: 40...
	 start solving instance: 53...
	 start solving instance: 103...
	 start solving instance: 52...
	 start solving instance: 128...
	 start solving instance: 54...
	 start solving instance: 46...
	 start solving instance: 20...
	 start solving instance: 68...
	 start solving instance: 39...
	 start solving instance: 78...
	 start solving instance: 8...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 5087696389144576.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06487889587879181
		 entropy bonus: 0.2358817607164383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2508038282394409
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19566567242145538
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508769645625344.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5087696389144576.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06487889587879181
		 entropy bonus: 0.2358817607164383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2508038282394409
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19566567242145538
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508769645625344.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5087696389144576.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07530521601438522
		 entropy bonus: 0.23468665778636932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2508038282394409
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19566567242145538
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508769645625344.0 - Differentiable computation graph = True!
PPO iteration: 325/1000:
	 start solving instance: 92...
	 start solving instance: 78...
	 start solving instance: 97...
	 start solving instance: 40...
	 start solving instance: 54...
	 start solving instance: 102...
	 start solving instance: 58...
	 start solving instance: 39...
	 start solving instance: 46...
	 start solving instance: 128...
	 start solving instance: 8...
	 start solving instance: 53...
	 start solving instance: 104...
	 start solving instance: 52...
	 start solving instance: 68...
	 start solving instance: 29...
	 start solving instance: 103...
	 start solving instance: 143...
	 start solving instance: 20...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 4766737241210880.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011987075209617615
		 entropy bonus: 0.22537489235401154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14682386815547943
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08983322978019714
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 476673724121088.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4766737241210880.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011987075209617615
		 entropy bonus: 0.22537489235401154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14682386815547943
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08983322978019714
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 476673724121088.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4766737241210880.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007578679826110601
		 entropy bonus: 0.2265699952840805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14682386815547943
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08983322978019714
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 476673724121088.0 - Differentiable computation graph = True!
PPO iteration: 326/1000:
	 start solving instance: 68...
	 start solving instance: 148...
	 start solving instance: 29...
	 start solving instance: 58...
	 start solving instance: 143...
	 start solving instance: 20...
	 start solving instance: 78...
	 start solving instance: 104...
	 start solving instance: 40...
	 start solving instance: 8...
	 start solving instance: 92...
	 start solving instance: 54...
	 start solving instance: 103...
	 start solving instance: 53...
	 start solving instance: 39...
	 start solving instance: 102...
	 start solving instance: 128...
	 start solving instance: 97...
	 start solving instance: 46...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 5090572406620160.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.043927550315856934
		 entropy bonus: 0.22395868599414825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10355792194604874
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.066276915371418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 509057240662016.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5090572406620160.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.043927550315856934
		 entropy bonus: 0.22395868599414825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10355792194604874
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.066276915371418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 509057240662016.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5090572406620160.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.043927550315856934
		 entropy bonus: 0.22395868599414825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10355792194604874
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.066276915371418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 509057240662016.0 - Differentiable computation graph = True!
PPO iteration: 327/1000:
	 start solving instance: 53...
	 start solving instance: 92...
	 start solving instance: 58...
	 start solving instance: 97...
	 start solving instance: 128...
	 start solving instance: 103...
	 start solving instance: 39...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 40...
	 start solving instance: 78...
	 start solving instance: 8...
	 start solving instance: 143...
	 start solving instance: 148...
	 start solving instance: 68...
	 start solving instance: 102...
	 start solving instance: 54...
	 start solving instance: 104...
	 start solving instance: 29...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 5159478177562624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07231513410806656
		 entropy bonus: 0.23159468173980713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12684445083141327
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.003503672545775771
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 515947811045376.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5159478177562624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06669143587350845
		 entropy bonus: 0.2327897548675537
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12684445083141327
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.003503672545775771
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 515947811045376.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5159478177562624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07231513410806656
		 entropy bonus: 0.23159468173980713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12684445083141327
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.003503672545775771
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 515947811045376.0 - Differentiable computation graph = True!
PPO iteration: 328/1000:
	 start solving instance: 97...
	 start solving instance: 78...
	 start solving instance: 103...
	 start solving instance: 143...
	 start solving instance: 92...
	 start solving instance: 8...
	 start solving instance: 58...
	 start solving instance: 128...
	 start solving instance: 102...
	 start solving instance: 148...
	 start solving instance: 53...
	 start solving instance: 46...
	 start solving instance: 39...
	 start solving instance: 40...
	 start solving instance: 54...
	 start solving instance: 29...
	 start solving instance: 52...
	 start solving instance: 104...
	 start solving instance: 68...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 5200587993907200.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005817890167236328
		 entropy bonus: 0.21773464977741241
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13080134987831116
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.018651200458407402
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520058799390720.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5200587993907200.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005817890167236328
		 entropy bonus: 0.21773464977741241
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13080134987831116
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.018651200458407402
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520058799390720.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5200587993907200.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005817890167236328
		 entropy bonus: 0.21773464977741241
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13080134987831116
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.018651200458407402
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520058799390720.0 - Differentiable computation graph = True!
PPO iteration: 329/1000:
	 start solving instance: 97...
	 start solving instance: 39...
	 start solving instance: 8...
	 start solving instance: 102...
	 start solving instance: 58...
	 start solving instance: 143...
	 start solving instance: 103...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 68...
	 start solving instance: 148...
	 start solving instance: 53...
	 start solving instance: 54...
	 start solving instance: 104...
	 start solving instance: 92...
	 start solving instance: 29...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 40...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 5044878786428928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.032088231295347214
		 entropy bonus: 0.23076041042804718
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10274715721607208
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031017180532217026
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 504487898775552.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5044878786428928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02259688451886177
		 entropy bonus: 0.2295653373003006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10274715721607208
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031017180532217026
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 504487898775552.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5044878786428928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02259688451886177
		 entropy bonus: 0.2295653373003006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10274715721607208
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.031017180532217026
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 504487898775552.0 - Differentiable computation graph = True!
PPO iteration: 330/1000:
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 68...
	 start solving instance: 143...
	 start solving instance: 104...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 52...
	 start solving instance: 128...
	 start solving instance: 40...
	 start solving instance: 29...
	 start solving instance: 92...
	 start solving instance: 54...
	 start solving instance: 102...
	 start solving instance: 39...
	 start solving instance: 8...
	 start solving instance: 53...
	 start solving instance: 78...
	 start solving instance: 148...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4840005625184256.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.040479183197021484
		 entropy bonus: 0.21988323330879211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2458762228488922
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12070941179990768
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 484000569229312.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4840005625184256.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04520414024591446
		 entropy bonus: 0.2210783213376999
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2458762228488922
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12070941179990768
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 484000569229312.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4840005625184256.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.040479183197021484
		 entropy bonus: 0.21988323330879211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2458762228488922
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12070941179990768
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 484000569229312.0 - Differentiable computation graph = True!
PPO iteration: 331/1000:
	 New training batch of size 20...
	 start solving instance: 146...
	 start solving instance: 92...
	 start solving instance: 67...
	 start solving instance: 71...
	 start solving instance: 40...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 97...
	 start solving instance: 74...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 134...
	 start solving instance: 118...
	 start solving instance: 125...
	 start solving instance: 148...
	 start solving instance: 3...
	 start solving instance: 30...
	 start solving instance: 138...
	 start solving instance: 45...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4891065270140928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037288617342710495
		 entropy bonus: 0.22752058506011963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20046289265155792
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13579155504703522
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 489106547146752.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4891065270140928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037288617342710495
		 entropy bonus: 0.22752058506011963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20046289265155792
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13579155504703522
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 489106547146752.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4891065270140928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037288617342710495
		 entropy bonus: 0.22752058506011963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20046289265155792
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13579155504703522
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 489106547146752.0 - Differentiable computation graph = True!
PPO iteration: 332/1000:
	 start solving instance: 54...
	 start solving instance: 3...
	 start solving instance: 30...
	 start solving instance: 92...
	 start solving instance: 67...
	 start solving instance: 125...
	 start solving instance: 43...
	 start solving instance: 118...
	 start solving instance: 40...
	 start solving instance: 138...
	 start solving instance: 71...
	 start solving instance: 57...
	 start solving instance: 45...
	 start solving instance: 148...
	 start solving instance: 129...
	 start solving instance: 74...
	 start solving instance: 97...
	 start solving instance: 101...
	 start solving instance: 134...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 5199165822861312.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05723748728632927
		 entropy bonus: 0.22153201699256897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.034325625747442245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03610358387231827
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 519916595707904.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5199165822861312.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05723748728632927
		 entropy bonus: 0.22153201699256897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.034325625747442245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03610358387231827
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 519916595707904.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5199165822861312.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05723748728632927
		 entropy bonus: 0.22153201699256897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.034325625747442245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03610358387231827
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 519916595707904.0 - Differentiable computation graph = True!
PPO iteration: 333/1000:
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 71...
	 start solving instance: 92...
	 start solving instance: 134...
	 start solving instance: 43...
	 start solving instance: 57...
	 start solving instance: 45...
	 start solving instance: 129...
	 start solving instance: 3...
	 start solving instance: 74...
	 start solving instance: 40...
	 start solving instance: 30...
	 start solving instance: 148...
	 start solving instance: 125...
	 start solving instance: 138...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 146...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 4636021522169856.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1111786887049675
		 entropy bonus: 0.21162422001361847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07381211221218109
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08813009411096573
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 463602158927872.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4636021522169856.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1111786887049675
		 entropy bonus: 0.21162422001361847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07381211221218109
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08813009411096573
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 463602158927872.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4636021522169856.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1111786887049675
		 entropy bonus: 0.21162422001361847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07381211221218109
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08813009411096573
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 463602158927872.0 - Differentiable computation graph = True!
PPO iteration: 334/1000:
	 start solving instance: 92...
	 start solving instance: 125...
	 start solving instance: 54...
	 start solving instance: 3...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 138...
	 start solving instance: 43...
	 start solving instance: 67...
	 start solving instance: 129...
	 start solving instance: 71...
	 start solving instance: 30...
	 start solving instance: 101...
	 start solving instance: 45...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 74...
	 start solving instance: 57...
	 start solving instance: 146...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 4696416278544384.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08095235377550125
		 entropy bonus: 0.22209282219409943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17853522300720215
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.027921080589294434
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469641621143552.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4696416278544384.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08095235377550125
		 entropy bonus: 0.22209282219409943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17853522300720215
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.027921080589294434
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469641621143552.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4696416278544384.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08095235377550125
		 entropy bonus: 0.22209282219409943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17853522300720215
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.027921080589294434
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469641621143552.0 - Differentiable computation graph = True!
PPO iteration: 335/1000:
	 start solving instance: 54...
	 start solving instance: 129...
	 start solving instance: 101...
	 start solving instance: 118...
	 start solving instance: 134...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 67...
	 start solving instance: 30...
	 start solving instance: 97...
	 start solving instance: 57...
	 start solving instance: 74...
	 start solving instance: 3...
	 start solving instance: 92...
	 start solving instance: 146...
	 start solving instance: 71...
	 start solving instance: 148...
	 start solving instance: 45...
	 start solving instance: 125...
	 start solving instance: 43...
	 Optimization epoch: 1/3
		 value loss (over batch): 4689679085469696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1897389143705368
		 entropy bonus: 0.22654402256011963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27367448806762695
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09278343617916107
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468967915257856.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4689679085469696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1897389143705368
		 entropy bonus: 0.22654402256011963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27367448806762695
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09278343617916107
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468967915257856.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4689679085469696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1897389143705368
		 entropy bonus: 0.22654402256011963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27367448806762695
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09278343617916107
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468967915257856.0 - Differentiable computation graph = True!
PPO iteration: 336/1000:
	 start solving instance: 45...
	 start solving instance: 134...
	 start solving instance: 129...
	 start solving instance: 3...
	 start solving instance: 146...
	 start solving instance: 57...
	 start solving instance: 97...
	 start solving instance: 148...
	 start solving instance: 138...
	 start solving instance: 74...
	 start solving instance: 40...
	 start solving instance: 118...
	 start solving instance: 30...
	 start solving instance: 92...
	 start solving instance: 54...
	 start solving instance: 125...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 71...
	 Optimization epoch: 1/3
		 value loss (over batch): 4562478797160448.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.014993679709732533
		 entropy bonus: 0.21567068994045258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12172215431928635
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0669902041554451
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 456247899848704.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4562478797160448.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.014993679709732533
		 entropy bonus: 0.21567068994045258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12172215431928635
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0669902041554451
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 456247899848704.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4562478797160448.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.014993679709732533
		 entropy bonus: 0.21567068994045258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12172215431928635
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0669902041554451
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 456247899848704.0 - Differentiable computation graph = True!
PPO iteration: 337/1000:
	 start solving instance: 74...
	 start solving instance: 129...
	 start solving instance: 40...
	 start solving instance: 118...
	 start solving instance: 101...
	 start solving instance: 138...
	 start solving instance: 146...
	 start solving instance: 3...
	 start solving instance: 67...
	 start solving instance: 125...
	 start solving instance: 43...
	 start solving instance: 134...
	 start solving instance: 148...
	 start solving instance: 45...
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 92...
	 start solving instance: 71...
	 start solving instance: 30...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4594174582063104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006962031126022339
		 entropy bonus: 0.20721207559108734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.020238852128386497
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07126574218273163
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 459417451495424.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4594174582063104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006962031126022339
		 entropy bonus: 0.20721207559108734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.020238852128386497
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07126574218273163
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 459417451495424.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4594174582063104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.006962031126022339
		 entropy bonus: 0.20721207559108734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.020238852128386497
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.07126574218273163
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 459417451495424.0 - Differentiable computation graph = True!
PPO iteration: 338/1000:
	 start solving instance: 101...
	 start solving instance: 97...
	 start solving instance: 71...
	 start solving instance: 45...
	 start solving instance: 3...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 118...
	 start solving instance: 134...
	 start solving instance: 74...
	 start solving instance: 129...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 30...
	 start solving instance: 146...
	 start solving instance: 148...
	 start solving instance: 67...
	 start solving instance: 125...
	 start solving instance: 54...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 4603779202678784.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.027534056454896927
		 entropy bonus: 0.2135646641254425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02642177604138851
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08084121346473694
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 460377913556992.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4603779202678784.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.027534056454896927
		 entropy bonus: 0.2135646641254425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02642177604138851
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08084121346473694
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 460377913556992.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4603779202678784.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.027534056454896927
		 entropy bonus: 0.2135646641254425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.02642177604138851
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08084121346473694
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 460377913556992.0 - Differentiable computation graph = True!
PPO iteration: 339/1000:
	 start solving instance: 71...
	 start solving instance: 54...
	 start solving instance: 67...
	 start solving instance: 92...
	 start solving instance: 43...
	 start solving instance: 45...
	 start solving instance: 40...
	 start solving instance: 74...
	 start solving instance: 129...
	 start solving instance: 138...
	 start solving instance: 3...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 101...
	 start solving instance: 57...
	 start solving instance: 134...
	 start solving instance: 148...
	 start solving instance: 146...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4709670010748928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07283610105514526
		 entropy bonus: 0.21837382018566132
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1038389727473259
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06797485053539276
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 470967021207552.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4709670010748928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07283610105514526
		 entropy bonus: 0.21837382018566132
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1038389727473259
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06797485053539276
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 470967021207552.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4709670010748928.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07283610105514526
		 entropy bonus: 0.21837382018566132
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1038389727473259
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06797485053539276
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 470967021207552.0 - Differentiable computation graph = True!
PPO iteration: 340/1000:
	 start solving instance: 71...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 45...
	 start solving instance: 74...
	 start solving instance: 3...
	 start solving instance: 43...
	 start solving instance: 30...
	 start solving instance: 146...
	 start solving instance: 129...
	 start solving instance: 101...
	 start solving instance: 40...
	 start solving instance: 67...
	 start solving instance: 125...
	 start solving instance: 92...
	 start solving instance: 148...
	 start solving instance: 134...
	 start solving instance: 138...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4684342051733504.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04616890475153923
		 entropy bonus: 0.21581895649433136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10255370289087296
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03695529326796532
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468434198462464.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4684342051733504.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04616890475153923
		 entropy bonus: 0.21581895649433136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10255370289087296
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03695529326796532
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468434198462464.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4684342051733504.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04616890475153923
		 entropy bonus: 0.21581895649433136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10255370289087296
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03695529326796532
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468434198462464.0 - Differentiable computation graph = True!
PPO iteration: 341/1000:
	 New training batch of size 20...
	 start solving instance: 135...
	 start solving instance: 12...
	 start solving instance: 134...
	 start solving instance: 133...
	 start solving instance: 22...
	 start solving instance: 72...
	 start solving instance: 98...
	 start solving instance: 108...
	 start solving instance: 47...
	 start solving instance: 2...
	 start solving instance: 17...
	 start solving instance: 101...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 48...
	 start solving instance: 114...
	 start solving instance: 128...
	 start solving instance: 10...
	 start solving instance: 145...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4690383996977152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0234688650816679
		 entropy bonus: 0.22637148201465607
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11615852266550064
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06303676217794418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469038413119488.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4690383996977152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030104851350188255
		 entropy bonus: 0.22389595210552216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11615852266550064
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06303676217794418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469038413119488.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4690383996977152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030104851350188255
		 entropy bonus: 0.22389595210552216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11615852266550064
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06303676217794418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469038413119488.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4780835471360000.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0027173073031008244
		 entropy bonus: 0.20945696532726288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1489817202091217
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.19143837690353394
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 478083547136000.0000
PPO iteration: 342/1000:
	 start solving instance: 133...
	 start solving instance: 10...
	 start solving instance: 72...
	 start solving instance: 48...
	 start solving instance: 108...
	 start solving instance: 51...
	 start solving instance: 145...
	 start solving instance: 134...
	 start solving instance: 22...
	 start solving instance: 121...
	 start solving instance: 135...
	 start solving instance: 2...
	 start solving instance: 101...
	 start solving instance: 114...
	 start solving instance: 98...
	 start solving instance: 128...
	 start solving instance: 17...
	 start solving instance: 47...
	 start solving instance: 12...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4770295084744704.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.027752498164772987
		 entropy bonus: 0.21652939915657043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06888499110937119
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.002233797451481223
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 477029501763584.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4770295084744704.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.027752498164772987
		 entropy bonus: 0.21652939915657043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06888499110937119
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.002233797451481223
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 477029501763584.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4770295084744704.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.027752498164772987
		 entropy bonus: 0.21652939915657043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06888499110937119
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.002233797451481223
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 477029501763584.0 - Differentiable computation graph = True!
PPO iteration: 343/1000:
	 start solving instance: 101...
	 start solving instance: 98...
	 start solving instance: 72...
	 start solving instance: 133...
	 start solving instance: 145...
	 start solving instance: 89...
	 start solving instance: 2...
	 start solving instance: 114...
	 start solving instance: 128...
	 start solving instance: 22...
	 start solving instance: 134...
	 start solving instance: 135...
	 start solving instance: 51...
	 start solving instance: 12...
	 start solving instance: 48...
	 start solving instance: 47...
	 start solving instance: 17...
	 start solving instance: 121...
	 start solving instance: 10...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4725058341699584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07211970537900925
		 entropy bonus: 0.21414755284786224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08707859367132187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1325574666261673
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 472505827459072.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4725058341699584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07211970537900925
		 entropy bonus: 0.21414755284786224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08707859367132187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1325574666261673
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 472505827459072.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4725058341699584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07211970537900925
		 entropy bonus: 0.21414755284786224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08707859367132187
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1325574666261673
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 472505827459072.0 - Differentiable computation graph = True!
PPO iteration: 344/1000:
	 start solving instance: 114...
	 start solving instance: 51...
	 start solving instance: 12...
	 start solving instance: 128...
	 start solving instance: 2...
	 start solving instance: 48...
	 start solving instance: 10...
	 start solving instance: 72...
	 start solving instance: 101...
	 start solving instance: 89...
	 start solving instance: 108...
	 start solving instance: 133...
	 start solving instance: 47...
	 start solving instance: 17...
	 start solving instance: 22...
	 start solving instance: 134...
	 start solving instance: 135...
	 start solving instance: 98...
	 start solving instance: 145...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4661107352403968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.001001235912553966
		 entropy bonus: 0.22469738125801086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12477102130651474
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01677393913269043
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 466110755373056.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4661107352403968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.004619821906089783
		 entropy bonus: 0.22686345875263214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12477102130651474
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01677393913269043
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 466110755373056.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4661107352403968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.004619821906089783
		 entropy bonus: 0.22686345875263214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12477102130651474
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.01677393913269043
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 466110755373056.0 - Differentiable computation graph = True!
PPO iteration: 345/1000:
	 start solving instance: 72...
	 start solving instance: 98...
	 start solving instance: 114...
	 start solving instance: 10...
	 start solving instance: 101...
	 start solving instance: 48...
	 start solving instance: 145...
	 start solving instance: 51...
	 start solving instance: 89...
	 start solving instance: 12...
	 start solving instance: 108...
	 start solving instance: 47...
	 start solving instance: 2...
	 start solving instance: 121...
	 start solving instance: 135...
	 start solving instance: 133...
	 start solving instance: 134...
	 start solving instance: 128...
	 start solving instance: 17...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4962849742913536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.059937216341495514
		 entropy bonus: 0.22697873413562775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06727533787488937
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21320591866970062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 496284981002240.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4962849742913536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.059937216341495514
		 entropy bonus: 0.22697873413562775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06727533787488937
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21320591866970062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 496284981002240.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4962849742913536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06102827936410904
		 entropy bonus: 0.22914481163024902
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06727533787488937
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21320591866970062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 496284981002240.0 - Differentiable computation graph = True!
PPO iteration: 346/1000:
	 start solving instance: 98...
	 start solving instance: 2...
	 start solving instance: 12...
	 start solving instance: 108...
	 start solving instance: 114...
	 start solving instance: 47...
	 start solving instance: 133...
	 start solving instance: 51...
	 start solving instance: 101...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 22...
	 start solving instance: 135...
	 start solving instance: 10...
	 start solving instance: 134...
	 start solving instance: 48...
	 start solving instance: 17...
	 start solving instance: 145...
	 start solving instance: 89...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4857103353118720.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.017072761431336403
		 entropy bonus: 0.22767646610736847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0922369584441185
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13344834744930267
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 485710335311872.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4857103353118720.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.017580687999725342
		 entropy bonus: 0.22520093619823456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0922369584441185
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13344834744930267
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 485710335311872.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4857103353118720.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.017072761431336403
		 entropy bonus: 0.22767646610736847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0922369584441185
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13344834744930267
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 485710335311872.0 - Differentiable computation graph = True!
PPO iteration: 347/1000:
	 start solving instance: 72...
	 start solving instance: 114...
	 start solving instance: 2...
	 start solving instance: 128...
	 start solving instance: 89...
	 start solving instance: 135...
	 start solving instance: 98...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 17...
	 start solving instance: 10...
	 start solving instance: 51...
	 start solving instance: 133...
	 start solving instance: 22...
	 start solving instance: 108...
	 start solving instance: 48...
	 start solving instance: 12...
	 start solving instance: 134...
	 start solving instance: 47...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 5030861086916608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0247417613863945
		 entropy bonus: 0.2241905927658081
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04551078379154205
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19985441863536835
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 503086128824320.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5030861086916608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02093018777668476
		 entropy bonus: 0.2217150777578354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04551078379154205
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19985441863536835
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 503086128824320.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5030861086916608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02093018777668476
		 entropy bonus: 0.2217150777578354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04551078379154205
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19985441863536835
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 503086128824320.0 - Differentiable computation graph = True!
PPO iteration: 348/1000:
	 start solving instance: 145...
	 start solving instance: 89...
	 start solving instance: 101...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 2...
	 start solving instance: 12...
	 start solving instance: 17...
	 start solving instance: 133...
	 start solving instance: 22...
	 start solving instance: 98...
	 start solving instance: 48...
	 start solving instance: 47...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 108...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 114...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4911809962180608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010892549529671669
		 entropy bonus: 0.23090147972106934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09144420921802521
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.023596325889229774
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 491181016350720.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4911809962180608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010892549529671669
		 entropy bonus: 0.23090147972106934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09144420921802521
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.023596325889229774
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 491181016350720.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4911809962180608.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01340879499912262
		 entropy bonus: 0.2284259796142578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09144420921802521
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.023596325889229774
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 491181016350720.0 - Differentiable computation graph = True!
PPO iteration: 349/1000:
	 start solving instance: 135...
	 start solving instance: 145...
	 start solving instance: 72...
	 start solving instance: 48...
	 start solving instance: 133...
	 start solving instance: 121...
	 start solving instance: 98...
	 start solving instance: 22...
	 start solving instance: 128...
	 start solving instance: 12...
	 start solving instance: 2...
	 start solving instance: 134...
	 start solving instance: 51...
	 start solving instance: 89...
	 start solving instance: 10...
	 start solving instance: 101...
	 start solving instance: 47...
	 start solving instance: 108...
	 start solving instance: 17...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 4842728634449920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0014988065231591463
		 entropy bonus: 0.2213691771030426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.130133256316185
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21591871976852417
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 484272863444992.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4842728634449920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0014988065231591463
		 entropy bonus: 0.2213691771030426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.130133256316185
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21591871976852417
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 484272863444992.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4842728634449920.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0014283061027526855
		 entropy bonus: 0.22353525459766388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.130133256316185
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21591871976852417
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 484272863444992.0 - Differentiable computation graph = True!
PPO iteration: 350/1000:
	 start solving instance: 98...
	 start solving instance: 10...
	 start solving instance: 128...
	 start solving instance: 114...
	 start solving instance: 72...
	 start solving instance: 2...
	 start solving instance: 101...
	 start solving instance: 133...
	 start solving instance: 47...
	 start solving instance: 12...
	 start solving instance: 51...
	 start solving instance: 145...
	 start solving instance: 89...
	 start solving instance: 135...
	 start solving instance: 17...
	 start solving instance: 22...
	 start solving instance: 48...
	 start solving instance: 134...
	 start solving instance: 121...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4671740617687040.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025037435814738274
		 entropy bonus: 0.2115067094564438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09870245307683945
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07600647956132889
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 467174061768704.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4671740617687040.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025037435814738274
		 entropy bonus: 0.2115067094564438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09870245307683945
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07600647956132889
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 467174061768704.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4671740617687040.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025037435814738274
		 entropy bonus: 0.2115067094564438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.09870245307683945
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07600647956132889
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 467174061768704.0 - Differentiable computation graph = True!
PPO iteration: 351/1000:
	 New training batch of size 20...
	 start solving instance: 84...
	 start solving instance: 129...
	 start solving instance: 78...
	 start solving instance: 42...
	 start solving instance: 28...
	 start solving instance: 92...
	 start solving instance: 16...
	 start solving instance: 72...
	 start solving instance: 142...
	 start solving instance: 127...
	 start solving instance: 30...
	 start solving instance: 121...
	 start solving instance: 132...
	 start solving instance: 8...
	 start solving instance: 26...
	 start solving instance: 86...
	 start solving instance: 90...
	 start solving instance: 124...
	 start solving instance: 112...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 5084788159414272.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0874013900756836
		 entropy bonus: 0.24084067344665527
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1636180728673935
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07129290699958801
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508478829363200.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5084788159414272.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0874013900756836
		 entropy bonus: 0.24084067344665527
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1636180728673935
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07129290699958801
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508478829363200.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5084788159414272.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0874013900756836
		 entropy bonus: 0.24084067344665527
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1636180728673935
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07129290699958801
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508478829363200.0 - Differentiable computation graph = True!
PPO iteration: 352/1000:
	 start solving instance: 90...
	 start solving instance: 121...
	 start solving instance: 16...
	 start solving instance: 8...
	 start solving instance: 127...
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 112...
	 start solving instance: 124...
	 start solving instance: 72...
	 start solving instance: 132...
	 start solving instance: 30...
	 start solving instance: 28...
	 start solving instance: 86...
	 start solving instance: 84...
	 start solving instance: 26...
	 start solving instance: 142...
	 start solving instance: 113...
	 start solving instance: 129...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 5203453273964544.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.048329778015613556
		 entropy bonus: 0.24779701232910156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2777688205242157
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.028848759829998016
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520345320685568.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5203453273964544.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.048329778015613556
		 entropy bonus: 0.24779701232910156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2777688205242157
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.028848759829998016
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520345320685568.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5203453273964544.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.048329778015613556
		 entropy bonus: 0.24779701232910156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2777688205242157
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.028848759829998016
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520345320685568.0 - Differentiable computation graph = True!
PPO iteration: 353/1000:
	 start solving instance: 90...
	 start solving instance: 16...
	 start solving instance: 78...
	 start solving instance: 30...
	 start solving instance: 132...
	 start solving instance: 86...
	 start solving instance: 112...
	 start solving instance: 72...
	 start solving instance: 142...
	 start solving instance: 129...
	 start solving instance: 92...
	 start solving instance: 42...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 121...
	 start solving instance: 84...
	 start solving instance: 8...
	 start solving instance: 113...
	 start solving instance: 124...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 5168296282292224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009115739725530148
		 entropy bonus: 0.24840806424617767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3038662075996399
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08678393810987473
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 516829621518336.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5168296282292224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009115739725530148
		 entropy bonus: 0.24840806424617767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3038662075996399
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08678393810987473
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 516829621518336.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5168296282292224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009115739725530148
		 entropy bonus: 0.24840806424617767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3038662075996399
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08678393810987473
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 516829621518336.0 - Differentiable computation graph = True!
PPO iteration: 354/1000:
	 start solving instance: 86...
	 start solving instance: 127...
	 start solving instance: 16...
	 start solving instance: 26...
	 start solving instance: 121...
	 start solving instance: 129...
	 start solving instance: 8...
	 start solving instance: 42...
	 start solving instance: 30...
	 start solving instance: 28...
	 start solving instance: 132...
	 start solving instance: 92...
	 start solving instance: 113...
	 start solving instance: 142...
	 start solving instance: 78...
	 start solving instance: 84...
	 start solving instance: 90...
	 start solving instance: 112...
	 start solving instance: 124...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 4994108514893824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1412949413061142
		 entropy bonus: 0.2423717975616455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3212265968322754
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011895387433469296
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 499410844778496.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4994108514893824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1412949413061142
		 entropy bonus: 0.2423717975616455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3212265968322754
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011895387433469296
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 499410844778496.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4994108514893824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1412949413061142
		 entropy bonus: 0.2423717975616455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3212265968322754
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.011895387433469296
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 499410844778496.0 - Differentiable computation graph = True!
PPO iteration: 355/1000:
	 start solving instance: 72...
	 start solving instance: 92...
	 start solving instance: 86...
	 start solving instance: 121...
	 start solving instance: 113...
	 start solving instance: 124...
	 start solving instance: 28...
	 start solving instance: 84...
	 start solving instance: 42...
	 start solving instance: 132...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 16...
	 start solving instance: 78...
	 start solving instance: 127...
	 start solving instance: 142...
	 start solving instance: 90...
	 start solving instance: 26...
	 start solving instance: 8...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 5083531881480192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06912237405776978
		 entropy bonus: 0.2293391227722168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18552269041538239
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16907398402690887
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508353201569792.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5083531881480192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06912237405776978
		 entropy bonus: 0.2293391227722168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18552269041538239
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16907398402690887
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508353201569792.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5083531881480192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06912237405776978
		 entropy bonus: 0.2293391227722168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18552269041538239
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16907398402690887
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 508353201569792.0 - Differentiable computation graph = True!
PPO iteration: 356/1000:
	 start solving instance: 92...
	 start solving instance: 8...
	 start solving instance: 124...
	 start solving instance: 113...
	 start solving instance: 16...
	 start solving instance: 129...
	 start solving instance: 127...
	 start solving instance: 26...
	 start solving instance: 112...
	 start solving instance: 142...
	 start solving instance: 72...
	 start solving instance: 42...
	 start solving instance: 121...
	 start solving instance: 28...
	 start solving instance: 84...
	 start solving instance: 30...
	 start solving instance: 78...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 4700493276250112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007651356048882008
		 entropy bonus: 0.2343151569366455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29374274611473083
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.014953295700252056
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 470049341046784.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4700493276250112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007651356048882008
		 entropy bonus: 0.2343151569366455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29374274611473083
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.014953295700252056
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 470049341046784.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4700493276250112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007651356048882008
		 entropy bonus: 0.2343151569366455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29374274611473083
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.014953295700252056
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 470049341046784.0 - Differentiable computation graph = True!
PPO iteration: 357/1000:
	 start solving instance: 42...
	 start solving instance: 30...
	 start solving instance: 78...
	 start solving instance: 90...
	 start solving instance: 84...
	 start solving instance: 142...
	 start solving instance: 72...
	 start solving instance: 129...
	 start solving instance: 28...
	 start solving instance: 124...
	 start solving instance: 16...
	 start solving instance: 127...
	 start solving instance: 112...
	 start solving instance: 113...
	 start solving instance: 92...
	 start solving instance: 86...
	 start solving instance: 26...
	 start solving instance: 132...
	 start solving instance: 8...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4865108098416640.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02082800306379795
		 entropy bonus: 0.2395755797624588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26096972823143005
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08512665331363678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 486510809841664.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4865108098416640.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02082800306379795
		 entropy bonus: 0.2395755797624588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26096972823143005
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08512665331363678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 486510809841664.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4865108098416640.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02082800306379795
		 entropy bonus: 0.2395755797624588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26096972823143005
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08512665331363678
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 486510809841664.0 - Differentiable computation graph = True!
PPO iteration: 358/1000:
	 start solving instance: 8...
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 127...
	 start solving instance: 78...
	 start solving instance: 16...
	 start solving instance: 112...
	 start solving instance: 90...
	 start solving instance: 113...
	 start solving instance: 142...
	 start solving instance: 132...
	 start solving instance: 86...
	 start solving instance: 26...
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 72...
	 start solving instance: 121...
	 start solving instance: 28...
	 start solving instance: 84...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 4975489294794752.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.023873556405305862
		 entropy bonus: 0.22886410355567932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12648554146289825
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04107743129134178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 497548942901248.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4975489294794752.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.023873556405305862
		 entropy bonus: 0.22886410355567932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12648554146289825
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04107743129134178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 497548942901248.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4975489294794752.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.023873556405305862
		 entropy bonus: 0.22886410355567932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12648554146289825
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04107743129134178
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 497548942901248.0 - Differentiable computation graph = True!
PPO iteration: 359/1000:
	 start solving instance: 127...
	 start solving instance: 92...
	 start solving instance: 8...
	 start solving instance: 84...
	 start solving instance: 16...
	 start solving instance: 28...
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 129...
	 start solving instance: 78...
	 start solving instance: 42...
	 start solving instance: 113...
	 start solving instance: 26...
	 start solving instance: 30...
	 start solving instance: 124...
	 start solving instance: 86...
	 start solving instance: 112...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 5351661857931264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06077907234430313
		 entropy bonus: 0.24528768658638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1906663328409195
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.23655442893505096
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535166179082240.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5351661857931264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06077907234430313
		 entropy bonus: 0.24528768658638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1906663328409195
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.23655442893505096
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535166179082240.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5351661857931264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06077907234430313
		 entropy bonus: 0.24528768658638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1906663328409195
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.23655442893505096
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535166179082240.0 - Differentiable computation graph = True!
PPO iteration: 360/1000:
	 start solving instance: 28...
	 start solving instance: 112...
	 start solving instance: 90...
	 start solving instance: 129...
	 start solving instance: 124...
	 start solving instance: 113...
	 start solving instance: 92...
	 start solving instance: 86...
	 start solving instance: 16...
	 start solving instance: 78...
	 start solving instance: 42...
	 start solving instance: 84...
	 start solving instance: 142...
	 start solving instance: 121...
	 start solving instance: 132...
	 start solving instance: 8...
	 start solving instance: 127...
	 start solving instance: 30...
	 start solving instance: 26...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 5492183524179968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08079323917627335
		 entropy bonus: 0.24589037895202637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29400500655174255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15086470544338226
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 549218372550656.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5492183524179968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08079323917627335
		 entropy bonus: 0.24589037895202637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29400500655174255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15086470544338226
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 549218372550656.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5492183524179968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08079323917627335
		 entropy bonus: 0.24589037895202637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.29400500655174255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.15086470544338226
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 549218372550656.0 - Differentiable computation graph = True!
PPO iteration: 361/1000:
	 New training batch of size 20...
	 start solving instance: 38...
	 start solving instance: 104...
	 start solving instance: 45...
	 start solving instance: 61...
	 start solving instance: 12...
	 start solving instance: 123...
	 start solving instance: 118...
	 start solving instance: 36...
	 start solving instance: 53...
	 start solving instance: 95...
	 start solving instance: 51...
	 start solving instance: 135...
	 start solving instance: 46...
	 start solving instance: 80...
	 start solving instance: 14...
	 start solving instance: 142...
	 start solving instance: 85...
	 start solving instance: 129...
	 start solving instance: 75...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 5365600637419520.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09567393362522125
		 entropy bonus: 0.2161649912595749
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16168580949306488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04229823127388954
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 536560063741952.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5365600637419520.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09477382898330688
		 entropy bonus: 0.2139989137649536
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16168580949306488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04229823127388954
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 536560063741952.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5365600637419520.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09477382898330688
		 entropy bonus: 0.2139989137649536
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.16168580949306488
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04229823127388954
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 536560063741952.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 5111411587940352.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10274036973714828
		 entropy bonus: 0.21919028460979462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1135852262377739
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14151696860790253
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 511141172215808.0000
PPO iteration: 362/1000:
	 start solving instance: 36...
	 start solving instance: 51...
	 start solving instance: 45...
	 start solving instance: 95...
	 start solving instance: 61...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 118...
	 start solving instance: 80...
	 start solving instance: 63...
	 start solving instance: 75...
	 start solving instance: 129...
	 start solving instance: 38...
	 start solving instance: 123...
	 start solving instance: 12...
	 start solving instance: 46...
	 start solving instance: 85...
	 start solving instance: 14...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 5701165358514176.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07300161570310593
		 entropy bonus: 0.21854467689990997
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06778834015130997
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04083207994699478
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 570116576116736.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5701165358514176.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07300161570310593
		 entropy bonus: 0.21854467689990997
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06778834015130997
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04083207994699478
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 570116576116736.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5701165358514176.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07300161570310593
		 entropy bonus: 0.21854467689990997
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06778834015130997
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04083207994699478
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 570116576116736.0 - Differentiable computation graph = True!
PPO iteration: 363/1000:
	 start solving instance: 123...
	 start solving instance: 142...
	 start solving instance: 61...
	 start solving instance: 12...
	 start solving instance: 63...
	 start solving instance: 104...
	 start solving instance: 135...
	 start solving instance: 38...
	 start solving instance: 36...
	 start solving instance: 45...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 85...
	 start solving instance: 53...
	 start solving instance: 46...
	 start solving instance: 80...
	 start solving instance: 75...
	 start solving instance: 14...
	 start solving instance: 51...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 5380812337840128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05761784315109253
		 entropy bonus: 0.2192448228597641
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1596733182668686
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13024146854877472
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 538081253916672.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5380812337840128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05761784315109253
		 entropy bonus: 0.2192448228597641
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1596733182668686
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13024146854877472
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 538081253916672.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5380812337840128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.05612671375274658
		 entropy bonus: 0.22172032296657562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1596733182668686
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13024146854877472
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 538081253916672.0 - Differentiable computation graph = True!
PPO iteration: 364/1000:
	 start solving instance: 12...
	 start solving instance: 63...
	 start solving instance: 38...
	 start solving instance: 46...
	 start solving instance: 61...
	 start solving instance: 80...
	 start solving instance: 14...
	 start solving instance: 53...
	 start solving instance: 51...
	 start solving instance: 123...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 85...
	 start solving instance: 135...
	 start solving instance: 45...
	 start solving instance: 36...
	 start solving instance: 118...
	 start solving instance: 142...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 5469996796870656.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.012990075163543224
		 entropy bonus: 0.2250383347272873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14868547022342682
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13469825685024261
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 546999686397952.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5469996796870656.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.017328089103102684
		 entropy bonus: 0.22720442712306976
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14868547022342682
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13469825685024261
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 546999686397952.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5469996796870656.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.012990075163543224
		 entropy bonus: 0.2250383347272873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14868547022342682
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13469825685024261
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 546999686397952.0 - Differentiable computation graph = True!
PPO iteration: 365/1000:
	 start solving instance: 142...
	 start solving instance: 12...
	 start solving instance: 135...
	 start solving instance: 51...
	 start solving instance: 63...
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 129...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 118...
	 start solving instance: 38...
	 start solving instance: 104...
	 start solving instance: 36...
	 start solving instance: 80...
	 start solving instance: 123...
	 start solving instance: 14...
	 start solving instance: 61...
	 start solving instance: 53...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 5434151536689152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04726674407720566
		 entropy bonus: 0.21400175988674164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12087851017713547
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07034456729888916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 543415167090688.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5434151536689152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.046163205057382584
		 entropy bonus: 0.21152622997760773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12087851017713547
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07034456729888916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 543415167090688.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5434151536689152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04726674407720566
		 entropy bonus: 0.21400175988674164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12087851017713547
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07034456729888916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 543415167090688.0 - Differentiable computation graph = True!
PPO iteration: 366/1000:
	 start solving instance: 46...
	 start solving instance: 61...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 14...
	 start solving instance: 118...
	 start solving instance: 75...
	 start solving instance: 45...
	 start solving instance: 135...
	 start solving instance: 80...
	 start solving instance: 38...
	 start solving instance: 12...
	 start solving instance: 142...
	 start solving instance: 53...
	 start solving instance: 104...
	 start solving instance: 51...
	 start solving instance: 123...
	 start solving instance: 63...
	 start solving instance: 36...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 5564827527282688.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.038743503391742706
		 entropy bonus: 0.22266323864459991
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0708424523472786
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.023980824276804924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 556482772860928.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5564827527282688.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04087681323289871
		 entropy bonus: 0.22049716114997864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0708424523472786
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.023980824276804924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 556482772860928.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5564827527282688.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04087681323289871
		 entropy bonus: 0.22049716114997864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0708424523472786
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.023980824276804924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 556482772860928.0 - Differentiable computation graph = True!
PPO iteration: 367/1000:
	 start solving instance: 129...
	 start solving instance: 104...
	 start solving instance: 53...
	 start solving instance: 123...
	 start solving instance: 12...
	 start solving instance: 95...
	 start solving instance: 46...
	 start solving instance: 36...
	 start solving instance: 118...
	 start solving instance: 38...
	 start solving instance: 51...
	 start solving instance: 135...
	 start solving instance: 75...
	 start solving instance: 14...
	 start solving instance: 85...
	 start solving instance: 80...
	 start solving instance: 63...
	 start solving instance: 142...
	 start solving instance: 61...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 5672669324247040.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07083308696746826
		 entropy bonus: 0.21660397946834564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1623474806547165
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10835909843444824
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 567266932424704.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5672669324247040.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07083308696746826
		 entropy bonus: 0.21660397946834564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1623474806547165
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10835909843444824
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 567266932424704.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5672669324247040.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07001512497663498
		 entropy bonus: 0.21907949447631836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1623474806547165
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10835909843444824
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 567266932424704.0 - Differentiable computation graph = True!
PPO iteration: 368/1000:
	 start solving instance: 142...
	 start solving instance: 95...
	 start solving instance: 80...
	 start solving instance: 14...
	 start solving instance: 129...
	 start solving instance: 46...
	 start solving instance: 61...
	 start solving instance: 53...
	 start solving instance: 38...
	 start solving instance: 12...
	 start solving instance: 123...
	 start solving instance: 118...
	 start solving instance: 36...
	 start solving instance: 51...
	 start solving instance: 63...
	 start solving instance: 85...
	 start solving instance: 104...
	 start solving instance: 45...
	 start solving instance: 75...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 6040651921620992.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1061113104224205
		 entropy bonus: 0.21928496658802032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08589320629835129
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08433327823877335
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 604065205583872.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6040651921620992.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1061113104224205
		 entropy bonus: 0.21928496658802032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08589320629835129
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08433327823877335
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 604065205583872.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6040651921620992.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1061113104224205
		 entropy bonus: 0.21928496658802032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08589320629835129
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08433327823877335
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 604065205583872.0 - Differentiable computation graph = True!
PPO iteration: 369/1000:
	 start solving instance: 38...
	 start solving instance: 61...
	 start solving instance: 45...
	 start solving instance: 142...
	 start solving instance: 75...
	 start solving instance: 53...
	 start solving instance: 135...
	 start solving instance: 104...
	 start solving instance: 36...
	 start solving instance: 129...
	 start solving instance: 123...
	 start solving instance: 46...
	 start solving instance: 12...
	 start solving instance: 63...
	 start solving instance: 14...
	 start solving instance: 95...
	 start solving instance: 118...
	 start solving instance: 80...
	 start solving instance: 85...
	 start solving instance: 51...
	 Optimization epoch: 1/3
		 value loss (over batch): 5875315544948736.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02198079228401184
		 entropy bonus: 0.21158447861671448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10921665281057358
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0516892671585083
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 587531594760192.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5875315544948736.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02198079228401184
		 entropy bonus: 0.21158447861671448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10921665281057358
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0516892671585083
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 587531594760192.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5875315544948736.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02198079228401184
		 entropy bonus: 0.21158447861671448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10921665281057358
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0516892671585083
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 587531594760192.0 - Differentiable computation graph = True!
PPO iteration: 370/1000:
	 start solving instance: 14...
	 start solving instance: 38...
	 start solving instance: 135...
	 start solving instance: 75...
	 start solving instance: 80...
	 start solving instance: 85...
	 start solving instance: 123...
	 start solving instance: 118...
	 start solving instance: 51...
	 start solving instance: 129...
	 start solving instance: 36...
	 start solving instance: 63...
	 start solving instance: 53...
	 start solving instance: 142...
	 start solving instance: 46...
	 start solving instance: 104...
	 start solving instance: 61...
	 start solving instance: 12...
	 start solving instance: 95...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 6235617667055616.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009039587341248989
		 entropy bonus: 0.22982962429523468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1326034814119339
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13489216566085815
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 623561806970880.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6235617667055616.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009039587341248989
		 entropy bonus: 0.22982962429523468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1326034814119339
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13489216566085815
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 623561806970880.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6235617667055616.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.009039587341248989
		 entropy bonus: 0.22982962429523468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1326034814119339
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.13489216566085815
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 623561806970880.0 - Differentiable computation graph = True!
PPO iteration: 371/1000:
	 New training batch of size 20...
	 start solving instance: 141...
	 start solving instance: 99...
	 start solving instance: 58...
	 start solving instance: 61...
	 start solving instance: 59...
	 start solving instance: 46...
	 start solving instance: 149...
	 start solving instance: 16...
	 start solving instance: 109...
	 start solving instance: 148...
	 start solving instance: 23...
	 start solving instance: 40...
	 start solving instance: 74...
	 start solving instance: 147...
	 start solving instance: 15...
	 start solving instance: 85...
	 start solving instance: 92...
	 start solving instance: 103...
	 start solving instance: 105...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 value loss (over batch): 5998666468818944.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03145388886332512
		 entropy bonus: 0.22176499664783478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2222442626953125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.015516970306634903
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 599866673725440.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5998666468818944.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03145388886332512
		 entropy bonus: 0.22176499664783478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2222442626953125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.015516970306634903
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 599866673725440.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5998666468818944.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03145388886332512
		 entropy bonus: 0.22176499664783478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2222442626953125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.015516970306634903
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 599866673725440.0 - Differentiable computation graph = True!
PPO iteration: 372/1000:
	 start solving instance: 92...
	 start solving instance: 61...
	 start solving instance: 15...
	 start solving instance: 74...
	 start solving instance: 8...
	 start solving instance: 40...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 85...
	 start solving instance: 103...
	 start solving instance: 141...
	 start solving instance: 58...
	 start solving instance: 99...
	 start solving instance: 147...
	 start solving instance: 148...
	 start solving instance: 46...
	 start solving instance: 109...
	 start solving instance: 149...
	 start solving instance: 23...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 6102496766328832.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.046409666538238525
		 entropy bonus: 0.20963235199451447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1940593272447586
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11204291880130768
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 610249690054656.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6102496766328832.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.046409666538238525
		 entropy bonus: 0.20963235199451447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1940593272447586
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11204291880130768
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 610249690054656.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6102496766328832.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.050526637583971024
		 entropy bonus: 0.21082739531993866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1940593272447586
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11204291880130768
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 610249690054656.0 - Differentiable computation graph = True!
PPO iteration: 373/1000:
	 start solving instance: 74...
	 start solving instance: 85...
	 start solving instance: 148...
	 start solving instance: 141...
	 start solving instance: 8...
	 start solving instance: 46...
	 start solving instance: 61...
	 start solving instance: 103...
	 start solving instance: 15...
	 start solving instance: 99...
	 start solving instance: 16...
	 start solving instance: 92...
	 start solving instance: 105...
	 start solving instance: 109...
	 start solving instance: 149...
	 start solving instance: 59...
	 start solving instance: 23...
	 start solving instance: 147...
	 start solving instance: 40...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 6080197296128000.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04689741134643555
		 entropy bonus: 0.22164414823055267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1981644481420517
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09621363878250122
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 608019729612800.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6080197296128000.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0450035035610199
		 entropy bonus: 0.2204490751028061
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1981644481420517
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09621363878250122
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 608019729612800.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6080197296128000.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0450035035610199
		 entropy bonus: 0.2204490751028061
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1981644481420517
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09621363878250122
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 608019729612800.0 - Differentiable computation graph = True!
PPO iteration: 374/1000:
	 start solving instance: 23...
	 start solving instance: 8...
	 start solving instance: 61...
	 start solving instance: 99...
	 start solving instance: 103...
	 start solving instance: 59...
	 start solving instance: 40...
	 start solving instance: 85...
	 start solving instance: 16...
	 start solving instance: 58...
	 start solving instance: 74...
	 start solving instance: 149...
	 start solving instance: 105...
	 start solving instance: 141...
	 start solving instance: 15...
	 start solving instance: 148...
	 start solving instance: 92...
	 start solving instance: 109...
	 start solving instance: 46...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 5896397928792064.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01580604538321495
		 entropy bonus: 0.216134175658226
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04891675338149071
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15797753632068634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 589639819722752.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5896397928792064.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01130504161119461
		 entropy bonus: 0.2173292636871338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04891675338149071
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15797753632068634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 589639819722752.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5896397928792064.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.01580604538321495
		 entropy bonus: 0.216134175658226
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04891675338149071
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15797753632068634
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 589639819722752.0 - Differentiable computation graph = True!
PPO iteration: 375/1000:
	 start solving instance: 149...
	 start solving instance: 59...
	 start solving instance: 46...
	 start solving instance: 99...
	 start solving instance: 23...
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 109...
	 start solving instance: 85...
	 start solving instance: 40...
	 start solving instance: 148...
	 start solving instance: 105...
	 start solving instance: 8...
	 start solving instance: 141...
	 start solving instance: 15...
	 start solving instance: 74...
	 start solving instance: 61...
	 start solving instance: 16...
	 start solving instance: 147...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 6033034797121536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03145498037338257
		 entropy bonus: 0.2047414779663086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08918316662311554
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20508095622062683
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 603303519977472.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6033034797121536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03359454870223999
		 entropy bonus: 0.20354638993740082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08918316662311554
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20508095622062683
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 603303519977472.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6033034797121536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.03359454870223999
		 entropy bonus: 0.20354638993740082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08918316662311554
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20508095622062683
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 603303519977472.0 - Differentiable computation graph = True!
PPO iteration: 376/1000:
	 start solving instance: 92...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 61...
	 start solving instance: 58...
	 start solving instance: 149...
	 start solving instance: 109...
	 start solving instance: 103...
	 start solving instance: 8...
	 start solving instance: 46...
	 start solving instance: 23...
	 start solving instance: 85...
	 start solving instance: 74...
	 start solving instance: 99...
	 start solving instance: 147...
	 start solving instance: 16...
	 start solving instance: 15...
	 start solving instance: 105...
	 start solving instance: 141...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 6197416617312256.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0044494508765637875
		 entropy bonus: 0.21625006198883057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14238297939300537
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10515753924846649
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 619741701996544.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6197416617312256.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0044494508765637875
		 entropy bonus: 0.21625006198883057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14238297939300537
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10515753924846649
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 619741701996544.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6197416617312256.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0044494508765637875
		 entropy bonus: 0.21625006198883057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14238297939300537
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10515753924846649
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 619741701996544.0 - Differentiable computation graph = True!
PPO iteration: 377/1000:
	 start solving instance: 61...
	 start solving instance: 149...
	 start solving instance: 23...
	 start solving instance: 59...
	 start solving instance: 58...
	 start solving instance: 92...
	 start solving instance: 15...
	 start solving instance: 16...
	 start solving instance: 109...
	 start solving instance: 8...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 85...
	 start solving instance: 74...
	 start solving instance: 40...
	 start solving instance: 46...
	 start solving instance: 147...
	 start solving instance: 103...
	 start solving instance: 141...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 6207034122829824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037834834307432175
		 entropy bonus: 0.2161027193069458
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11835761368274689
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0877356007695198
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 620703439126528.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6207034122829824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037834834307432175
		 entropy bonus: 0.2161027193069458
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11835761368274689
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0877356007695198
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 620703439126528.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6207034122829824.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.037834834307432175
		 entropy bonus: 0.2161027193069458
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11835761368274689
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0877356007695198
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 620703439126528.0 - Differentiable computation graph = True!
PPO iteration: 378/1000:
	 start solving instance: 147...
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 105...
	 start solving instance: 59...
	 start solving instance: 40...
	 start solving instance: 92...
	 start solving instance: 85...
	 start solving instance: 109...
	 start solving instance: 99...
	 start solving instance: 8...
	 start solving instance: 15...
	 start solving instance: 61...
	 start solving instance: 148...
	 start solving instance: 74...
	 start solving instance: 16...
	 start solving instance: 149...
	 start solving instance: 23...
	 start solving instance: 141...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 6235108176560128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.054462868720293045
		 entropy bonus: 0.20778465270996094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15446218848228455
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004993544891476631
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 623510804234240.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6235108176560128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.054462868720293045
		 entropy bonus: 0.20778465270996094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15446218848228455
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004993544891476631
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 623510804234240.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6235108176560128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.054462868720293045
		 entropy bonus: 0.20778465270996094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15446218848228455
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004993544891476631
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 623510804234240.0 - Differentiable computation graph = True!
PPO iteration: 379/1000:
	 start solving instance: 8...
	 start solving instance: 15...
	 start solving instance: 46...
	 start solving instance: 141...
	 start solving instance: 149...
	 start solving instance: 99...
	 start solving instance: 92...
	 start solving instance: 59...
	 start solving instance: 23...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 105...
	 start solving instance: 109...
	 start solving instance: 147...
	 start solving instance: 16...
	 start solving instance: 74...
	 start solving instance: 85...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 6154903957274624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07155479490756989
		 entropy bonus: 0.2081226110458374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20406483113765717
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03443601354956627
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 615490422571008.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6154903957274624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07155479490756989
		 entropy bonus: 0.2081226110458374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20406483113765717
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03443601354956627
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 615490422571008.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6154903957274624.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07155479490756989
		 entropy bonus: 0.2081226110458374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.20406483113765717
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.03443601354956627
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 615490422571008.0 - Differentiable computation graph = True!
PPO iteration: 380/1000:
	 start solving instance: 58...
	 start solving instance: 16...
	 start solving instance: 61...
	 start solving instance: 23...
	 start solving instance: 103...
	 start solving instance: 148...
	 start solving instance: 109...
	 start solving instance: 105...
	 start solving instance: 74...
	 start solving instance: 141...
	 start solving instance: 149...
	 start solving instance: 15...
	 start solving instance: 59...
	 start solving instance: 40...
	 start solving instance: 92...
	 start solving instance: 99...
	 start solving instance: 85...
	 start solving instance: 147...
	 start solving instance: 46...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 value loss (over batch): 6149506793996288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.035020459443330765
		 entropy bonus: 0.19958873093128204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0570768378674984
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15259671211242676
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 614950665977856.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6149506793996288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.035020459443330765
		 entropy bonus: 0.19958873093128204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0570768378674984
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15259671211242676
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 614950665977856.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6149506793996288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.035020459443330765
		 entropy bonus: 0.19958873093128204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0570768378674984
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15259671211242676
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 614950665977856.0 - Differentiable computation graph = True!
PPO iteration: 381/1000:
	 New training batch of size 20...
	 start solving instance: 90...
	 start solving instance: 24...
	 start solving instance: 137...
	 start solving instance: 147...
	 start solving instance: 31...
	 start solving instance: 124...
	 start solving instance: 133...
	 start solving instance: 3...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 97...
	 start solving instance: 114...
	 start solving instance: 28...
	 start solving instance: 38...
	 start solving instance: 139...
	 start solving instance: 143...
	 start solving instance: 102...
	 start solving instance: 100...
	 start solving instance: 84...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 6560574892670976.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03163900598883629
		 entropy bonus: 0.22023628652095795
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22529689967632294
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12754440307617188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 656057529532416.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6560574892670976.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03163900598883629
		 entropy bonus: 0.22023628652095795
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22529689967632294
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12754440307617188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 656057529532416.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6560574892670976.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03163900598883629
		 entropy bonus: 0.22023628652095795
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.22529689967632294
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.12754440307617188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 656057529532416.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 6468953039699968.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008993971161544323
		 entropy bonus: 0.21261537075042725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.15484081208705902
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09058402478694916
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 646895290548224.0000
PPO iteration: 382/1000:
	 start solving instance: 124...
	 start solving instance: 3...
	 start solving instance: 90...
	 start solving instance: 17...
	 start solving instance: 31...
	 start solving instance: 28...
	 start solving instance: 102...
	 start solving instance: 137...
	 start solving instance: 143...
	 start solving instance: 24...
	 start solving instance: 147...
	 start solving instance: 38...
	 start solving instance: 84...
	 start solving instance: 42...
	 start solving instance: 97...
	 start solving instance: 100...
	 start solving instance: 133...
	 start solving instance: 65...
	 start solving instance: 114...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 6522622414159872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.011738389730453491
		 entropy bonus: 0.22120168805122375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3041805624961853
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05982416123151779
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652262254837760.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6522622414159872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.011738389730453491
		 entropy bonus: 0.22120168805122375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3041805624961853
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05982416123151779
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652262254837760.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6522622414159872.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.011738389730453491
		 entropy bonus: 0.22120168805122375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3041805624961853
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05982416123151779
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652262254837760.0 - Differentiable computation graph = True!
PPO iteration: 383/1000:
	 start solving instance: 42...
	 start solving instance: 143...
	 start solving instance: 133...
	 start solving instance: 24...
	 start solving instance: 102...
	 start solving instance: 84...
	 start solving instance: 100...
	 start solving instance: 114...
	 start solving instance: 90...
	 start solving instance: 65...
	 start solving instance: 124...
	 start solving instance: 31...
	 start solving instance: 139...
	 start solving instance: 38...
	 start solving instance: 28...
	 start solving instance: 97...
	 start solving instance: 17...
	 start solving instance: 137...
	 start solving instance: 3...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 6756900532125696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009364592842757702
		 entropy bonus: 0.22034402191638947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2661423683166504
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05653858557343483
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 675690093477888.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6756900532125696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009364592842757702
		 entropy bonus: 0.22034402191638947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2661423683166504
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05653858557343483
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 675690093477888.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6756900532125696.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.009364592842757702
		 entropy bonus: 0.22034402191638947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2661423683166504
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05653858557343483
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 675690093477888.0 - Differentiable computation graph = True!
PPO iteration: 384/1000:
	 start solving instance: 139...
	 start solving instance: 24...
	 start solving instance: 133...
	 start solving instance: 147...
	 start solving instance: 100...
	 start solving instance: 17...
	 start solving instance: 102...
	 start solving instance: 28...
	 start solving instance: 3...
	 start solving instance: 31...
	 start solving instance: 97...
	 start solving instance: 38...
	 start solving instance: 137...
	 start solving instance: 65...
	 start solving instance: 114...
	 start solving instance: 84...
	 start solving instance: 42...
	 start solving instance: 90...
	 start solving instance: 143...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 6887066495352832.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005784586071968079
		 entropy bonus: 0.20822162926197052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1350768804550171
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05241699889302254
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 688706662957056.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6887066495352832.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005784586071968079
		 entropy bonus: 0.20822162926197052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1350768804550171
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05241699889302254
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 688706662957056.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6887066495352832.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.005784586071968079
		 entropy bonus: 0.20822162926197052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1350768804550171
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05241699889302254
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 688706662957056.0 - Differentiable computation graph = True!
PPO iteration: 385/1000:
	 start solving instance: 31...
	 start solving instance: 65...
	 start solving instance: 90...
	 start solving instance: 100...
	 start solving instance: 139...
	 start solving instance: 97...
	 start solving instance: 114...
	 start solving instance: 3...
	 start solving instance: 84...
	 start solving instance: 102...
	 start solving instance: 147...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 42...
	 start solving instance: 24...
	 start solving instance: 17...
	 start solving instance: 137...
	 start solving instance: 124...
	 start solving instance: 38...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 7051655010844672.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021600140258669853
		 entropy bonus: 0.2222922295331955
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26570257544517517
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.028289534151554108
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 705165514506240.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7051655010844672.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021600140258669853
		 entropy bonus: 0.2222922295331955
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26570257544517517
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.028289534151554108
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 705165514506240.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7051655010844672.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021600140258669853
		 entropy bonus: 0.2222922295331955
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.26570257544517517
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.028289534151554108
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 705165514506240.0 - Differentiable computation graph = True!
PPO iteration: 386/1000:
	 start solving instance: 114...
	 start solving instance: 137...
	 start solving instance: 42...
	 start solving instance: 28...
	 start solving instance: 100...
	 start solving instance: 97...
	 start solving instance: 31...
	 start solving instance: 133...
	 start solving instance: 84...
	 start solving instance: 102...
	 start solving instance: 139...
	 start solving instance: 24...
	 start solving instance: 38...
	 start solving instance: 143...
	 start solving instance: 147...
	 start solving instance: 65...
	 start solving instance: 3...
	 start solving instance: 90...
	 start solving instance: 17...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 7228024621629440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07212797552347183
		 entropy bonus: 0.21502934396266937
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14053121209144592
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.010311820544302464
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 722802462162944.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7228024621629440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07212797552347183
		 entropy bonus: 0.21502934396266937
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14053121209144592
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.010311820544302464
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 722802462162944.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7228024621629440.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07212797552347183
		 entropy bonus: 0.21502934396266937
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.14053121209144592
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.010311820544302464
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 722802462162944.0 - Differentiable computation graph = True!
PPO iteration: 387/1000:
	 start solving instance: 100...
	 start solving instance: 114...
	 start solving instance: 42...
	 start solving instance: 137...
	 start solving instance: 24...
	 start solving instance: 97...
	 start solving instance: 147...
	 start solving instance: 102...
	 start solving instance: 124...
	 start solving instance: 133...
	 start solving instance: 31...
	 start solving instance: 90...
	 start solving instance: 28...
	 start solving instance: 17...
	 start solving instance: 3...
	 start solving instance: 139...
	 start solving instance: 143...
	 start solving instance: 38...
	 start solving instance: 84...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 7256202828316672.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030086183920502663
		 entropy bonus: 0.2090536653995514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25239577889442444
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.14350144565105438
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 725620296253440.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7256202828316672.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030086183920502663
		 entropy bonus: 0.2090536653995514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25239577889442444
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.14350144565105438
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 725620296253440.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7256202828316672.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.030086183920502663
		 entropy bonus: 0.2090536653995514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.25239577889442444
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.14350144565105438
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 725620296253440.0 - Differentiable computation graph = True!
PPO iteration: 388/1000:
	 start solving instance: 137...
	 start solving instance: 97...
	 start solving instance: 100...
	 start solving instance: 90...
	 start solving instance: 147...
	 start solving instance: 38...
	 start solving instance: 28...
	 start solving instance: 24...
	 start solving instance: 102...
	 start solving instance: 133...
	 start solving instance: 17...
	 start solving instance: 114...
	 start solving instance: 65...
	 start solving instance: 31...
	 start solving instance: 42...
	 start solving instance: 84...
	 start solving instance: 124...
	 start solving instance: 3...
	 start solving instance: 139...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 7442904519802880.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08224503695964813
		 entropy bonus: 0.22131569683551788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18394647538661957
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03310008347034454
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 744290451980288.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7442904519802880.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08224503695964813
		 entropy bonus: 0.22131569683551788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18394647538661957
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03310008347034454
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 744290451980288.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7442904519802880.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08224503695964813
		 entropy bonus: 0.22131569683551788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18394647538661957
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.03310008347034454
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 744290451980288.0 - Differentiable computation graph = True!
PPO iteration: 389/1000:
	 start solving instance: 139...
	 start solving instance: 133...
	 start solving instance: 102...
	 start solving instance: 42...
	 start solving instance: 97...
	 start solving instance: 65...
	 start solving instance: 124...
	 start solving instance: 137...
	 start solving instance: 3...
	 start solving instance: 84...
	 start solving instance: 100...
	 start solving instance: 17...
	 start solving instance: 38...
	 start solving instance: 143...
	 start solving instance: 147...
	 start solving instance: 114...
	 start solving instance: 90...
	 start solving instance: 28...
	 start solving instance: 24...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 8221002806853632.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07548560202121735
		 entropy bonus: 0.22182857990264893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2119895964860916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10625025629997253
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 822100294107136.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8221002806853632.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07548560202121735
		 entropy bonus: 0.22182857990264893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2119895964860916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10625025629997253
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 822100294107136.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8221002806853632.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07548560202121735
		 entropy bonus: 0.22182857990264893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2119895964860916
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10625025629997253
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 822100294107136.0 - Differentiable computation graph = True!
PPO iteration: 390/1000:
	 start solving instance: 84...
	 start solving instance: 137...
	 start solving instance: 139...
	 start solving instance: 3...
	 start solving instance: 17...
	 start solving instance: 133...
	 start solving instance: 124...
	 start solving instance: 97...
	 start solving instance: 147...
	 start solving instance: 114...
	 start solving instance: 31...
	 start solving instance: 42...
	 start solving instance: 143...
	 start solving instance: 100...
	 start solving instance: 28...
	 start solving instance: 90...
	 start solving instance: 65...
	 start solving instance: 24...
	 start solving instance: 38...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 8672990669570048.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047781914472579956
		 entropy bonus: 0.22849856317043304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.286705881357193
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.050123438239097595
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 867299053535232.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8672990669570048.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047781914472579956
		 entropy bonus: 0.22849856317043304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.286705881357193
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.050123438239097595
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 867299053535232.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8672990669570048.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.047781914472579956
		 entropy bonus: 0.22849856317043304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.286705881357193
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.050123438239097595
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 867299053535232.0 - Differentiable computation graph = True!
PPO iteration: 391/1000:
	 New training batch of size 20...
	 start solving instance: 53...
	 start solving instance: 142...
	 start solving instance: 80...
	 start solving instance: 32...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 16...
	 start solving instance: 61...
	 start solving instance: 74...
	 start solving instance: 23...
	 start solving instance: 123...
	 start solving instance: 98...
	 start solving instance: 94...
	 start solving instance: 85...
	 start solving instance: 20...
	 start solving instance: 36...
	 start solving instance: 135...
	 start solving instance: 43...
	 start solving instance: 68...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 8987859017007104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04288630560040474
		 entropy bonus: 0.23304963111877441
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2521936893463135
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02978103794157505
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 898785928544256.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8987859017007104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04288630560040474
		 entropy bonus: 0.23304963111877441
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2521936893463135
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02978103794157505
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 898785928544256.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8987859017007104.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04288630560040474
		 entropy bonus: 0.23304963111877441
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.2521936893463135
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.02978103794157505
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 898785928544256.0 - Differentiable computation graph = True!
PPO iteration: 392/1000:
	 start solving instance: 66...
	 start solving instance: 43...
	 start solving instance: 16...
	 start solving instance: 33...
	 start solving instance: 94...
	 start solving instance: 78...
	 start solving instance: 135...
	 start solving instance: 68...
	 start solving instance: 61...
	 start solving instance: 32...
	 start solving instance: 36...
	 start solving instance: 23...
	 start solving instance: 53...
	 start solving instance: 80...
	 start solving instance: 85...
	 start solving instance: 74...
	 start solving instance: 142...
	 start solving instance: 98...
	 start solving instance: 20...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 9145244872343552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1394263356924057
		 entropy bonus: 0.23385806381702423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17721961438655853
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12216774374246597
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 914524500656128.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9145244872343552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1394263356924057
		 entropy bonus: 0.23385806381702423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17721961438655853
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12216774374246597
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 914524500656128.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9145244872343552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1394263356924057
		 entropy bonus: 0.23385806381702423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17721961438655853
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12216774374246597
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 914524500656128.0 - Differentiable computation graph = True!
PPO iteration: 393/1000:
	 start solving instance: 123...
	 start solving instance: 36...
	 start solving instance: 142...
	 start solving instance: 53...
	 start solving instance: 80...
	 start solving instance: 20...
	 start solving instance: 74...
	 start solving instance: 94...
	 start solving instance: 16...
	 start solving instance: 85...
	 start solving instance: 78...
	 start solving instance: 61...
	 start solving instance: 68...
	 start solving instance: 23...
	 start solving instance: 66...
	 start solving instance: 33...
	 start solving instance: 43...
	 start solving instance: 32...
	 start solving instance: 98...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 8946127504146432.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04917105287313461
		 entropy bonus: 0.22226738929748535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12162160873413086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14745217561721802
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 894612763836416.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8946127504146432.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04917105287313461
		 entropy bonus: 0.22226738929748535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12162160873413086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14745217561721802
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 894612763836416.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8946127504146432.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04917105287313461
		 entropy bonus: 0.22226738929748535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12162160873413086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14745217561721802
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 894612763836416.0 - Differentiable computation graph = True!
PPO iteration: 394/1000:
	 start solving instance: 74...
	 start solving instance: 142...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 43...
	 start solving instance: 66...
	 start solving instance: 33...
	 start solving instance: 80...
	 start solving instance: 135...
	 start solving instance: 61...
	 start solving instance: 32...
	 start solving instance: 85...
	 start solving instance: 94...
	 start solving instance: 16...
	 start solving instance: 53...
	 start solving instance: 20...
	 start solving instance: 78...
	 start solving instance: 36...
	 start solving instance: 123...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 9541025034928128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05210163816809654
		 entropy bonus: 0.21845009922981262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10501857101917267
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1546894609928131
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 954102490071040.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9541025034928128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05210163816809654
		 entropy bonus: 0.21845009922981262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10501857101917267
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1546894609928131
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 954102490071040.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9541025034928128.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05210163816809654
		 entropy bonus: 0.21845009922981262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10501857101917267
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1546894609928131
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 954102490071040.0 - Differentiable computation graph = True!
PPO iteration: 395/1000:
	 start solving instance: 61...
	 start solving instance: 123...
	 start solving instance: 80...
	 start solving instance: 23...
	 start solving instance: 33...
	 start solving instance: 85...
	 start solving instance: 74...
	 start solving instance: 16...
	 start solving instance: 53...
	 start solving instance: 98...
	 start solving instance: 68...
	 start solving instance: 78...
	 start solving instance: 32...
	 start solving instance: 142...
	 start solving instance: 66...
	 start solving instance: 20...
	 start solving instance: 36...
	 start solving instance: 135...
	 start solving instance: 43...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.068224401637376e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11403480917215347
		 entropy bonus: 0.2277088463306427
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1987808495759964
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.009122089482843876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1068224401637376.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.068224401637376e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11403480917215347
		 entropy bonus: 0.2277088463306427
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1987808495759964
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.009122089482843876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1068224401637376.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.068224401637376e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.11403480917215347
		 entropy bonus: 0.2277088463306427
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1987808495759964
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.009122089482843876
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1068224401637376.0 - Differentiable computation graph = True!
PPO iteration: 396/1000:
	 start solving instance: 16...
	 start solving instance: 43...
	 start solving instance: 78...
	 start solving instance: 23...
	 start solving instance: 33...
	 start solving instance: 68...
	 start solving instance: 36...
	 start solving instance: 94...
	 start solving instance: 135...
	 start solving instance: 85...
	 start solving instance: 32...
	 start solving instance: 53...
	 start solving instance: 20...
	 start solving instance: 80...
	 start solving instance: 142...
	 start solving instance: 123...
	 start solving instance: 98...
	 start solving instance: 66...
	 start solving instance: 61...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.1370284892291072e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0634947344660759
		 entropy bonus: 0.22116795182228088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1272604614496231
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17031224071979523
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1137028569759744.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.1370284892291072e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0634947344660759
		 entropy bonus: 0.22116795182228088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1272604614496231
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17031224071979523
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1137028569759744.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.1370284892291072e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0634947344660759
		 entropy bonus: 0.22116795182228088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1272604614496231
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.17031224071979523
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1137028569759744.0 - Differentiable computation graph = True!
PPO iteration: 397/1000:
	 start solving instance: 74...
	 start solving instance: 80...
	 start solving instance: 36...
	 start solving instance: 43...
	 start solving instance: 142...
	 start solving instance: 61...
	 start solving instance: 20...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 78...
	 start solving instance: 32...
	 start solving instance: 98...
	 start solving instance: 23...
	 start solving instance: 94...
	 start solving instance: 135...
	 start solving instance: 68...
	 start solving instance: 85...
	 start solving instance: 123...
	 start solving instance: 53...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.205396530266112e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0667664185166359
		 entropy bonus: 0.2220098078250885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10383453220129013
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16433022916316986
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1205396530266112.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.205396530266112e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0667664185166359
		 entropy bonus: 0.2220098078250885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10383453220129013
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16433022916316986
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1205396530266112.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.205396530266112e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0667664185166359
		 entropy bonus: 0.2220098078250885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10383453220129013
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16433022916316986
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1205396530266112.0 - Differentiable computation graph = True!
PPO iteration: 398/1000:
	 start solving instance: 20...
	 start solving instance: 123...
	 start solving instance: 135...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 85...
	 start solving instance: 78...
	 start solving instance: 53...
	 start solving instance: 36...
	 start solving instance: 68...
	 start solving instance: 74...
	 start solving instance: 142...
	 start solving instance: 16...
	 start solving instance: 43...
	 start solving instance: 94...
	 start solving instance: 33...
	 start solving instance: 80...
	 start solving instance: 61...
	 start solving instance: 32...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2497494764158976e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05918222293257713
		 entropy bonus: 0.21265411376953125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011759850196540356
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2587584853172302
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1249749449572352.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2497494764158976e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05918222293257713
		 entropy bonus: 0.21265411376953125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011759850196540356
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2587584853172302
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1249749449572352.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2497494764158976e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05918222293257713
		 entropy bonus: 0.21265411376953125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.011759850196540356
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2587584853172302
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1249749449572352.0 - Differentiable computation graph = True!
PPO iteration: 399/1000:
	 start solving instance: 135...
	 start solving instance: 94...
	 start solving instance: 78...
	 start solving instance: 66...
	 start solving instance: 16...
	 start solving instance: 43...
	 start solving instance: 53...
	 start solving instance: 20...
	 start solving instance: 142...
	 start solving instance: 23...
	 start solving instance: 61...
	 start solving instance: 33...
	 start solving instance: 32...
	 start solving instance: 85...
	 start solving instance: 80...
	 start solving instance: 98...
	 start solving instance: 123...
	 start solving instance: 68...
	 start solving instance: 74...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2617049473810432e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02852696180343628
		 entropy bonus: 0.22546334564685822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27274560928344727
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07425151765346527
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1261705027911680.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2617049473810432e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02852696180343628
		 entropy bonus: 0.22546334564685822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27274560928344727
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07425151765346527
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1261705027911680.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2617049473810432e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02852696180343628
		 entropy bonus: 0.22546334564685822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.27274560928344727
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07425151765346527
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1261705027911680.0 - Differentiable computation graph = True!
PPO iteration: 400/1000:
	 start solving instance: 68...
	 start solving instance: 43...
	 start solving instance: 36...
	 start solving instance: 80...
	 start solving instance: 98...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 53...
	 start solving instance: 123...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 16...
	 start solving instance: 20...
	 start solving instance: 85...
	 start solving instance: 74...
	 start solving instance: 23...
	 start solving instance: 78...
	 start solving instance: 94...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.3051352271814656e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028234899044036865
		 entropy bonus: 0.2331017255783081
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.169845849275589
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09646763652563095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1305135200337920.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.3051352271814656e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028234899044036865
		 entropy bonus: 0.2331017255783081
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.169845849275589
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09646763652563095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1305135200337920.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.3051352271814656e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.028234899044036865
		 entropy bonus: 0.2331017255783081
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.169845849275589
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09646763652563095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1305135200337920.0 - Differentiable computation graph = True!
PPO iteration: 401/1000:
	 New training batch of size 20...
	 start solving instance: 118...
	 start solving instance: 127...
	 start solving instance: 17...
	 start solving instance: 113...
	 start solving instance: 79...
	 start solving instance: 106...
	 start solving instance: 14...
	 start solving instance: 146...
	 start solving instance: 86...
	 start solving instance: 72...
	 start solving instance: 32...
	 start solving instance: 100...
	 start solving instance: 129...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 16...
	 start solving instance: 99...
	 start solving instance: 91...
	 start solving instance: 1...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2659682392932352e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06261416524648666
		 entropy bonus: 0.2137204259634018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.057420577853918076
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.35001763701438904
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1265968319823872.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2659682392932352e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06261416524648666
		 entropy bonus: 0.2137204259634018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.057420577853918076
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.35001763701438904
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1265968319823872.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2659682392932352e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06261416524648666
		 entropy bonus: 0.2137204259634018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.057420577853918076
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.35001763701438904
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1265968319823872.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 1.2189577821290496e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07556996494531631
		 entropy bonus: 0.20218487083911896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05563109740614891
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06946966052055359
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1218957755285504.0000
PPO iteration: 402/1000:
	 start solving instance: 127...
	 start solving instance: 79...
	 start solving instance: 100...
	 start solving instance: 86...
	 start solving instance: 130...
	 start solving instance: 146...
	 start solving instance: 106...
	 start solving instance: 129...
	 start solving instance: 17...
	 start solving instance: 16...
	 start solving instance: 67...
	 start solving instance: 118...
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 56...
	 start solving instance: 99...
	 start solving instance: 14...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.1946727485472768e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12252636253833771
		 entropy bonus: 0.20803260803222656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10004373639822006
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16056036949157715
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1194672802234368.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.1946727485472768e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12252636253833771
		 entropy bonus: 0.20803260803222656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10004373639822006
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16056036949157715
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1194672802234368.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.1946727485472768e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.12252636253833771
		 entropy bonus: 0.20803260803222656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10004373639822006
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16056036949157715
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1194672802234368.0 - Differentiable computation graph = True!
PPO iteration: 403/1000:
	 start solving instance: 127...
	 start solving instance: 113...
	 start solving instance: 106...
	 start solving instance: 118...
	 start solving instance: 56...
	 start solving instance: 16...
	 start solving instance: 72...
	 start solving instance: 100...
	 start solving instance: 99...
	 start solving instance: 1...
	 start solving instance: 17...
	 start solving instance: 67...
	 start solving instance: 91...
	 start solving instance: 146...
	 start solving instance: 79...
	 start solving instance: 32...
	 start solving instance: 86...
	 start solving instance: 14...
	 start solving instance: 130...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.363515751268352e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008395877666771412
		 entropy bonus: 0.20451000332832336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05470842123031616
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3851541578769684
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1363515751268352.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.363515751268352e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008395877666771412
		 entropy bonus: 0.20451000332832336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05470842123031616
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3851541578769684
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1363515751268352.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.363515751268352e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.008395877666771412
		 entropy bonus: 0.20451000332832336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05470842123031616
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3851541578769684
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1363515751268352.0 - Differentiable computation graph = True!
PPO iteration: 404/1000:
	 start solving instance: 17...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 32...
	 start solving instance: 118...
	 start solving instance: 16...
	 start solving instance: 79...
	 start solving instance: 91...
	 start solving instance: 67...
	 start solving instance: 100...
	 start solving instance: 1...
	 start solving instance: 127...
	 start solving instance: 86...
	 start solving instance: 106...
	 start solving instance: 129...
	 start solving instance: 14...
	 start solving instance: 72...
	 start solving instance: 146...
	 start solving instance: 113...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.4542105355485184e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.019815659150481224
		 entropy bonus: 0.2081528753042221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.023373926058411598
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1646585464477539
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1454210562392064.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.4542105355485184e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.019815659150481224
		 entropy bonus: 0.2081528753042221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.023373926058411598
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1646585464477539
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1454210562392064.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.4542105355485184e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.019815659150481224
		 entropy bonus: 0.2081528753042221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.023373926058411598
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1646585464477539
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1454210562392064.0 - Differentiable computation graph = True!
PPO iteration: 405/1000:
	 start solving instance: 16...
	 start solving instance: 32...
	 start solving instance: 17...
	 start solving instance: 72...
	 start solving instance: 86...
	 start solving instance: 91...
	 start solving instance: 130...
	 start solving instance: 79...
	 start solving instance: 118...
	 start solving instance: 56...
	 start solving instance: 99...
	 start solving instance: 67...
	 start solving instance: 146...
	 start solving instance: 14...
	 start solving instance: 106...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 127...
	 start solving instance: 113...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.486450063310848e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04970281198620796
		 entropy bonus: 0.21639929711818695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1896878480911255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2809113562107086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1486450063310848.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.486450063310848e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04970281198620796
		 entropy bonus: 0.21639929711818695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1896878480911255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2809113562107086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1486450063310848.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.486450063310848e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04970281198620796
		 entropy bonus: 0.21639929711818695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1896878480911255
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2809113562107086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1486450063310848.0 - Differentiable computation graph = True!
PPO iteration: 406/1000:
	 start solving instance: 17...
	 start solving instance: 118...
	 start solving instance: 16...
	 start solving instance: 146...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 106...
	 start solving instance: 1...
	 start solving instance: 129...
	 start solving instance: 100...
	 start solving instance: 79...
	 start solving instance: 130...
	 start solving instance: 72...
	 start solving instance: 127...
	 start solving instance: 91...
	 start solving instance: 99...
	 start solving instance: 67...
	 start solving instance: 14...
	 start solving instance: 86...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.6598619448672256e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.032042331993579865
		 entropy bonus: 0.21947447955608368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.004338456783443689
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1505151242017746
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1659861918023680.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.6598619448672256e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.032042331993579865
		 entropy bonus: 0.21947447955608368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.004338456783443689
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1505151242017746
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1659861918023680.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.6598619448672256e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.032042331993579865
		 entropy bonus: 0.21947447955608368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.004338456783443689
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1505151242017746
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1659861918023680.0 - Differentiable computation graph = True!
PPO iteration: 407/1000:
	 start solving instance: 14...
	 start solving instance: 100...
	 start solving instance: 79...
	 start solving instance: 72...
	 start solving instance: 16...
	 start solving instance: 113...
	 start solving instance: 17...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 67...
	 start solving instance: 106...
	 start solving instance: 32...
	 start solving instance: 127...
	 start solving instance: 130...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 99...
	 start solving instance: 91...
	 start solving instance: 86...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.6063455786172416e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10841212421655655
		 entropy bonus: 0.202532097697258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05987009406089783
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.31071656942367554
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1606345551773696.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.6063455786172416e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10841212421655655
		 entropy bonus: 0.202532097697258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05987009406089783
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.31071656942367554
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1606345551773696.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.6063455786172416e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10841212421655655
		 entropy bonus: 0.202532097697258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05987009406089783
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.31071656942367554
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1606345551773696.0 - Differentiable computation graph = True!
PPO iteration: 408/1000:
	 start solving instance: 99...
	 start solving instance: 129...
	 start solving instance: 130...
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 14...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 32...
	 start solving instance: 106...
	 start solving instance: 127...
	 start solving instance: 118...
	 start solving instance: 56...
	 start solving instance: 17...
	 start solving instance: 67...
	 start solving instance: 113...
	 start solving instance: 100...
	 start solving instance: 79...
	 start solving instance: 16...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.4336075774296064e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07987364381551743
		 entropy bonus: 0.20613935589790344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.00022993088350631297
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16118872165679932
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1433607604273152.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.4336075774296064e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07987364381551743
		 entropy bonus: 0.20613935589790344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.00022993088350631297
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16118872165679932
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1433607604273152.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.4336075774296064e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07987364381551743
		 entropy bonus: 0.20613935589790344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.00022993088350631297
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16118872165679932
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1433607604273152.0 - Differentiable computation graph = True!
PPO iteration: 409/1000:
	 start solving instance: 99...
	 start solving instance: 56...
	 start solving instance: 106...
	 start solving instance: 14...
	 start solving instance: 100...
	 start solving instance: 16...
	 start solving instance: 127...
	 start solving instance: 1...
	 start solving instance: 72...
	 start solving instance: 146...
	 start solving instance: 113...
	 start solving instance: 17...
	 start solving instance: 86...
	 start solving instance: 79...
	 start solving instance: 118...
	 start solving instance: 91...
	 start solving instance: 129...
	 start solving instance: 67...
	 start solving instance: 32...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.5883118699347968e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07564087212085724
		 entropy bonus: 0.2139810174703598
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013766470365226269
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15097537636756897
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1588311923621888.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.5883118699347968e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07564087212085724
		 entropy bonus: 0.2139810174703598
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013766470365226269
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15097537636756897
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1588311923621888.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.5883118699347968e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07564087212085724
		 entropy bonus: 0.2139810174703598
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.013766470365226269
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15097537636756897
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1588311923621888.0 - Differentiable computation graph = True!
PPO iteration: 410/1000:
	 start solving instance: 79...
	 start solving instance: 99...
	 start solving instance: 72...
	 start solving instance: 17...
	 start solving instance: 91...
	 start solving instance: 86...
	 start solving instance: 14...
	 start solving instance: 32...
	 start solving instance: 16...
	 start solving instance: 100...
	 start solving instance: 146...
	 start solving instance: 127...
	 start solving instance: 106...
	 start solving instance: 67...
	 start solving instance: 118...
	 start solving instance: 130...
	 start solving instance: 56...
	 start solving instance: 1...
	 start solving instance: 129...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.624258920841216e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02409259043633938
		 entropy bonus: 0.2112904042005539
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04300794377923012
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.4225999116897583
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1624258920841216.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.624258920841216e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02409259043633938
		 entropy bonus: 0.2112904042005539
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04300794377923012
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.4225999116897583
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1624258920841216.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.624258920841216e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02409259043633938
		 entropy bonus: 0.2112904042005539
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04300794377923012
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.4225999116897583
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1624258920841216.0 - Differentiable computation graph = True!
PPO iteration: 411/1000:
	 New training batch of size 20...
	 start solving instance: 68...
	 start solving instance: 107...
	 start solving instance: 129...
	 start solving instance: 63...
	 start solving instance: 108...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 147...
	 start solving instance: 50...
	 start solving instance: 137...
	 start solving instance: 121...
	 start solving instance: 86...
	 start solving instance: 71...
	 start solving instance: 125...
	 start solving instance: 145...
	 start solving instance: 46...
	 start solving instance: 122...
	 start solving instance: 126...
	 start solving instance: 13...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.5527293543776256e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09988653659820557
		 entropy bonus: 0.21454934775829315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11866191774606705
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.044314466416835785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1552729327534080.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.5527293543776256e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09988653659820557
		 entropy bonus: 0.21454934775829315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11866191774606705
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.044314466416835785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1552729327534080.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.5527293543776256e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09988653659820557
		 entropy bonus: 0.21454934775829315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11866191774606705
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.044314466416835785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1552729327534080.0 - Differentiable computation graph = True!
PPO iteration: 412/1000:
	 start solving instance: 137...
	 start solving instance: 106...
	 start solving instance: 108...
	 start solving instance: 122...
	 start solving instance: 13...
	 start solving instance: 71...
	 start solving instance: 11...
	 start solving instance: 68...
	 start solving instance: 121...
	 start solving instance: 107...
	 start solving instance: 50...
	 start solving instance: 126...
	 start solving instance: 2...
	 start solving instance: 46...
	 start solving instance: 63...
	 start solving instance: 86...
	 start solving instance: 129...
	 start solving instance: 125...
	 start solving instance: 145...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.5925893352390656e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.057840295135974884
		 entropy bonus: 0.21672968566417694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1744374930858612
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16690273582935333
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1592589308395520.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.5925893352390656e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.057840295135974884
		 entropy bonus: 0.21672968566417694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1744374930858612
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16690273582935333
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1592589308395520.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.5925893352390656e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.057840295135974884
		 entropy bonus: 0.21672968566417694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1744374930858612
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.16690273582935333
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1592589308395520.0 - Differentiable computation graph = True!
PPO iteration: 413/1000:
	 start solving instance: 106...
	 start solving instance: 129...
	 start solving instance: 147...
	 start solving instance: 122...
	 start solving instance: 108...
	 start solving instance: 46...
	 start solving instance: 137...
	 start solving instance: 71...
	 start solving instance: 121...
	 start solving instance: 125...
	 start solving instance: 2...
	 start solving instance: 68...
	 start solving instance: 11...
	 start solving instance: 126...
	 start solving instance: 107...
	 start solving instance: 13...
	 start solving instance: 145...
	 start solving instance: 86...
	 start solving instance: 63...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.7592919410081792e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011555743403732777
		 entropy bonus: 0.23134422302246094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24155132472515106
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11005407571792603
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1759292021538816.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.7592919410081792e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011555743403732777
		 entropy bonus: 0.23134422302246094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24155132472515106
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11005407571792603
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1759292021538816.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.7592919410081792e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011555743403732777
		 entropy bonus: 0.23134422302246094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.24155132472515106
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.11005407571792603
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1759292021538816.0 - Differentiable computation graph = True!
PPO iteration: 414/1000:
	 start solving instance: 86...
	 start solving instance: 46...
	 start solving instance: 147...
	 start solving instance: 106...
	 start solving instance: 71...
	 start solving instance: 129...
	 start solving instance: 145...
	 start solving instance: 125...
	 start solving instance: 68...
	 start solving instance: 107...
	 start solving instance: 126...
	 start solving instance: 137...
	 start solving instance: 121...
	 start solving instance: 63...
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 2...
	 start solving instance: 11...
	 start solving instance: 50...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.0586289350836224e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14172843098640442
		 entropy bonus: 0.22633306682109833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13184089958667755
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.26185110211372375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2058628961927168.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.0586289350836224e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14172843098640442
		 entropy bonus: 0.22633306682109833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13184089958667755
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.26185110211372375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2058628961927168.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.0586289350836224e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14172843098640442
		 entropy bonus: 0.22633306682109833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13184089958667755
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.26185110211372375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2058628961927168.0 - Differentiable computation graph = True!
PPO iteration: 415/1000:
	 start solving instance: 147...
	 start solving instance: 71...
	 start solving instance: 145...
	 start solving instance: 126...
	 start solving instance: 68...
	 start solving instance: 129...
	 start solving instance: 107...
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 125...
	 start solving instance: 86...
	 start solving instance: 122...
	 start solving instance: 137...
	 start solving instance: 50...
	 start solving instance: 46...
	 start solving instance: 63...
	 start solving instance: 11...
	 start solving instance: 106...
	 start solving instance: 121...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.991494945524941e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024018419906497
		 entropy bonus: 0.22437043488025665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19749899208545685
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08455638587474823
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1991494999212032.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.991494945524941e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024018419906497
		 entropy bonus: 0.22437043488025665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19749899208545685
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08455638587474823
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1991494999212032.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.991494945524941e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.024018419906497
		 entropy bonus: 0.22437043488025665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.19749899208545685
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08455638587474823
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1991494999212032.0 - Differentiable computation graph = True!
PPO iteration: 416/1000:
	 start solving instance: 50...
	 start solving instance: 106...
	 start solving instance: 13...
	 start solving instance: 86...
	 start solving instance: 121...
	 start solving instance: 11...
	 start solving instance: 147...
	 start solving instance: 71...
	 start solving instance: 107...
	 start solving instance: 137...
	 start solving instance: 68...
	 start solving instance: 2...
	 start solving instance: 129...
	 start solving instance: 122...
	 start solving instance: 145...
	 start solving instance: 125...
	 start solving instance: 126...
	 start solving instance: 108...
	 start solving instance: 46...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.6647017287647232e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08482062071561813
		 entropy bonus: 0.21831761300563812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0815088152885437
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.29906606674194336
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1664701809295360.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.6647017287647232e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08482062071561813
		 entropy bonus: 0.21831761300563812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0815088152885437
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.29906606674194336
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1664701809295360.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.6647017287647232e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08482062071561813
		 entropy bonus: 0.21831761300563812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0815088152885437
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.29906606674194336
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1664701809295360.0 - Differentiable computation graph = True!
PPO iteration: 417/1000:
	 start solving instance: 129...
	 start solving instance: 147...
	 start solving instance: 86...
	 start solving instance: 145...
	 start solving instance: 63...
	 start solving instance: 121...
	 start solving instance: 2...
	 start solving instance: 11...
	 start solving instance: 137...
	 start solving instance: 126...
	 start solving instance: 50...
	 start solving instance: 122...
	 start solving instance: 125...
	 start solving instance: 107...
	 start solving instance: 108...
	 start solving instance: 68...
	 start solving instance: 13...
	 start solving instance: 71...
	 start solving instance: 46...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.408618276585472e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0970098003745079
		 entropy bonus: 0.21425025165081024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10971476882696152
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04886632785201073
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1408618276585472.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.408618276585472e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0970098003745079
		 entropy bonus: 0.21425025165081024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10971476882696152
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04886632785201073
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1408618276585472.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.408618276585472e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0970098003745079
		 entropy bonus: 0.21425025165081024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10971476882696152
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04886632785201073
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1408618276585472.0 - Differentiable computation graph = True!
PPO iteration: 418/1000:
	 start solving instance: 129...
	 start solving instance: 63...
	 start solving instance: 145...
	 start solving instance: 46...
	 start solving instance: 125...
	 start solving instance: 106...
	 start solving instance: 147...
	 start solving instance: 2...
	 start solving instance: 50...
	 start solving instance: 13...
	 start solving instance: 108...
	 start solving instance: 86...
	 start solving instance: 121...
	 start solving instance: 122...
	 start solving instance: 137...
	 start solving instance: 126...
	 start solving instance: 11...
	 start solving instance: 107...
	 start solving instance: 68...
	 start solving instance: 71...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.4709203205619712e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1544501632452011
		 entropy bonus: 0.23042385280132294
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12780408561229706
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002725585363805294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1470920401092608.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.4709203205619712e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1544501632452011
		 entropy bonus: 0.23042385280132294
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12780408561229706
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002725585363805294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1470920401092608.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.4709203205619712e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1544501632452011
		 entropy bonus: 0.23042385280132294
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12780408561229706
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002725585363805294
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1470920401092608.0 - Differentiable computation graph = True!
PPO iteration: 419/1000:
	 start solving instance: 13...
	 start solving instance: 86...
	 start solving instance: 11...
	 start solving instance: 63...
	 start solving instance: 147...
	 start solving instance: 107...
	 start solving instance: 126...
	 start solving instance: 108...
	 start solving instance: 2...
	 start solving instance: 50...
	 start solving instance: 145...
	 start solving instance: 68...
	 start solving instance: 129...
	 start solving instance: 121...
	 start solving instance: 106...
	 start solving instance: 137...
	 start solving instance: 46...
	 start solving instance: 122...
	 start solving instance: 71...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.4563563012096e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007529342081397772
		 entropy bonus: 0.24330322444438934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3059605062007904
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10875552147626877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1456356301209600.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.4563563012096e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010230314917862415
		 entropy bonus: 0.2409149408340454
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3059605062007904
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10875552147626877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1456356301209600.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.4563563012096e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.010230314917862415
		 entropy bonus: 0.2409149408340454
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.3059605062007904
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.10875552147626877
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1456356301209600.0 - Differentiable computation graph = True!
PPO iteration: 420/1000:
	 start solving instance: 86...
	 start solving instance: 145...
	 start solving instance: 122...
	 start solving instance: 121...
	 start solving instance: 71...
	 start solving instance: 126...
	 start solving instance: 107...
	 start solving instance: 46...
	 start solving instance: 106...
	 start solving instance: 125...
	 start solving instance: 147...
	 start solving instance: 68...
	 start solving instance: 50...
	 start solving instance: 129...
	 start solving instance: 63...
	 start solving instance: 2...
	 start solving instance: 13...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.4869145640239104e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.05668297037482262
		 entropy bonus: 0.22540007531642914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12028639763593674
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05609701946377754
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1486914590867456.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.4869145640239104e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0582365058362484
		 entropy bonus: 0.22778835892677307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12028639763593674
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05609701946377754
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1486914590867456.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.4869145640239104e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0582365058362484
		 entropy bonus: 0.22778835892677307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12028639763593674
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05609701946377754
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1486914590867456.0 - Differentiable computation graph = True!
PPO iteration: 421/1000:
	 New training batch of size 20...
	 start solving instance: 54...
	 start solving instance: 142...
	 start solving instance: 11...
	 start solving instance: 7...
	 start solving instance: 68...
	 start solving instance: 29...
	 start solving instance: 38...
	 start solving instance: 59...
	 start solving instance: 112...
	 start solving instance: 100...
	 start solving instance: 97...
	 start solving instance: 127...
	 start solving instance: 58...
	 start solving instance: 110...
	 start solving instance: 47...
	 start solving instance: 141...
	 start solving instance: 121...
	 start solving instance: 103...
	 start solving instance: 34...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.814049015935795e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14586679637432098
		 entropy bonus: 0.23468156158924103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08473280817270279
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0731009840965271
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1814049096466432.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.814049015935795e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14586679637432098
		 entropy bonus: 0.23468156158924103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08473280817270279
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0731009840965271
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1814049096466432.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.814049015935795e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.14586679637432098
		 entropy bonus: 0.23468156158924103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08473280817270279
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0731009840965271
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1814049096466432.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 1.79479435542528e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08759484440088272
		 entropy bonus: 0.21285395324230194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.17101149260997772
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22532756626605988
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1794794355425280.0000
PPO iteration: 422/1000:
	 start solving instance: 121...
	 start solving instance: 110...
	 start solving instance: 127...
	 start solving instance: 141...
	 start solving instance: 137...
	 start solving instance: 142...
	 start solving instance: 100...
	 start solving instance: 38...
	 start solving instance: 34...
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 59...
	 start solving instance: 58...
	 start solving instance: 68...
	 start solving instance: 11...
	 start solving instance: 112...
	 start solving instance: 29...
	 start solving instance: 7...
	 start solving instance: 103...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.915708100103373e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07200702279806137
		 entropy bonus: 0.22409287095069885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0726415142416954
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004427054431289434
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1915708153790464.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.915708100103373e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07200702279806137
		 entropy bonus: 0.22409287095069885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0726415142416954
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004427054431289434
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1915708153790464.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.915708100103373e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07200702279806137
		 entropy bonus: 0.22409287095069885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0726415142416954
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.004427054431289434
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1915708153790464.0 - Differentiable computation graph = True!
PPO iteration: 423/1000:
	 start solving instance: 34...
	 start solving instance: 7...
	 start solving instance: 97...
	 start solving instance: 11...
	 start solving instance: 29...
	 start solving instance: 121...
	 start solving instance: 112...
	 start solving instance: 142...
	 start solving instance: 127...
	 start solving instance: 110...
	 start solving instance: 59...
	 start solving instance: 54...
	 start solving instance: 68...
	 start solving instance: 47...
	 start solving instance: 58...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.2454449800740864e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07453683763742447
		 entropy bonus: 0.22873397171497345
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07642104476690292
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07222429662942886
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2245445006917632.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.2454449800740864e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07453683763742447
		 entropy bonus: 0.22873397171497345
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07642104476690292
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07222429662942886
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2245445006917632.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.2454449800740864e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07453683763742447
		 entropy bonus: 0.22873397171497345
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07642104476690292
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07222429662942886
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2245445006917632.0 - Differentiable computation graph = True!
PPO iteration: 424/1000:
	 start solving instance: 121...
	 start solving instance: 97...
	 start solving instance: 7...
	 start solving instance: 54...
	 start solving instance: 38...
	 start solving instance: 68...
	 start solving instance: 47...
	 start solving instance: 11...
	 start solving instance: 112...
	 start solving instance: 58...
	 start solving instance: 142...
	 start solving instance: 141...
	 start solving instance: 59...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 100...
	 start solving instance: 127...
	 start solving instance: 34...
	 start solving instance: 110...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.6908685221494784e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09864473342895508
		 entropy bonus: 0.22520771622657776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0022137060295790434
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05052671208977699
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2690868683210752.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.6908685221494784e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09864473342895508
		 entropy bonus: 0.22520771622657776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0022137060295790434
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05052671208977699
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2690868683210752.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.6908685221494784e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09864473342895508
		 entropy bonus: 0.22520771622657776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0022137060295790434
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.05052671208977699
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2690868683210752.0 - Differentiable computation graph = True!
PPO iteration: 425/1000:
	 start solving instance: 110...
	 start solving instance: 127...
	 start solving instance: 97...
	 start solving instance: 68...
	 start solving instance: 58...
	 start solving instance: 112...
	 start solving instance: 137...
	 start solving instance: 141...
	 start solving instance: 29...
	 start solving instance: 103...
	 start solving instance: 38...
	 start solving instance: 47...
	 start solving instance: 54...
	 start solving instance: 7...
	 start solving instance: 100...
	 start solving instance: 11...
	 start solving instance: 59...
	 start solving instance: 142...
	 start solving instance: 121...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.577727487161139e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09234809130430222
		 entropy bonus: 0.22052240371704102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21440573036670685
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06150589883327484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2577727433474048.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.577727487161139e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09234809130430222
		 entropy bonus: 0.22052240371704102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21440573036670685
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06150589883327484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2577727433474048.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.577727487161139e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09234809130430222
		 entropy bonus: 0.22052240371704102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.21440573036670685
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.06150589883327484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2577727433474048.0 - Differentiable computation graph = True!
PPO iteration: 426/1000:
	 start solving instance: 54...
	 start solving instance: 97...
	 start solving instance: 34...
	 start solving instance: 110...
	 start solving instance: 11...
	 start solving instance: 59...
	 start solving instance: 7...
	 start solving instance: 127...
	 start solving instance: 58...
	 start solving instance: 100...
	 start solving instance: 68...
	 start solving instance: 103...
	 start solving instance: 112...
	 start solving instance: 38...
	 start solving instance: 142...
	 start solving instance: 137...
	 start solving instance: 121...
	 start solving instance: 47...
	 start solving instance: 29...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.7675034088636416e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09165026992559433
		 entropy bonus: 0.20977111160755157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0390942208468914
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.005872310139238834
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2767503516237824.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.7675034088636416e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09165026992559433
		 entropy bonus: 0.20977111160755157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0390942208468914
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.005872310139238834
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2767503516237824.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.7675034088636416e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09165026992559433
		 entropy bonus: 0.20977111160755157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0390942208468914
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.005872310139238834
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2767503516237824.0 - Differentiable computation graph = True!
PPO iteration: 427/1000:
	 start solving instance: 127...
	 start solving instance: 38...
	 start solving instance: 68...
	 start solving instance: 29...
	 start solving instance: 34...
	 start solving instance: 142...
	 start solving instance: 58...
	 start solving instance: 47...
	 start solving instance: 59...
	 start solving instance: 54...
	 start solving instance: 112...
	 start solving instance: 110...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 121...
	 start solving instance: 11...
	 start solving instance: 97...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.369269988216013e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07140177488327026
		 entropy bonus: 0.22810077667236328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039192233234643936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.32259467244148254
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3369270041903104.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.369269988216013e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07140177488327026
		 entropy bonus: 0.22810077667236328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039192233234643936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.32259467244148254
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3369270041903104.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.369269988216013e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06589476019144058
		 entropy bonus: 0.22929587960243225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039192233234643936
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.32259467244148254
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3369270041903104.0 - Differentiable computation graph = True!
PPO iteration: 428/1000:
	 start solving instance: 141...
	 start solving instance: 38...
	 start solving instance: 137...
	 start solving instance: 58...
	 start solving instance: 127...
	 start solving instance: 54...
	 start solving instance: 112...
	 start solving instance: 47...
	 start solving instance: 7...
	 start solving instance: 11...
	 start solving instance: 29...
	 start solving instance: 34...
	 start solving instance: 103...
	 start solving instance: 110...
	 start solving instance: 100...
	 start solving instance: 59...
	 start solving instance: 121...
	 start solving instance: 68...
	 start solving instance: 142...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.821426965269709e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06937580555677414
		 entropy bonus: 0.22791054844856262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07424622029066086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12024454772472382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3821427018956800.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.821426965269709e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07202970236539841
		 entropy bonus: 0.22671547532081604
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07424622029066086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12024454772472382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3821427018956800.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.821426965269709e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07202970236539841
		 entropy bonus: 0.22671547532081604
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07424622029066086
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12024454772472382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3821427018956800.0 - Differentiable computation graph = True!
PPO iteration: 429/1000:
	 start solving instance: 97...
	 start solving instance: 58...
	 start solving instance: 47...
	 start solving instance: 29...
	 start solving instance: 141...
	 start solving instance: 121...
	 start solving instance: 68...
	 start solving instance: 59...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 142...
	 start solving instance: 11...
	 start solving instance: 38...
	 start solving instance: 54...
	 start solving instance: 112...
	 start solving instance: 7...
	 start solving instance: 34...
	 start solving instance: 127...
	 start solving instance: 100...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.526513707391386e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.024042850360274315
		 entropy bonus: 0.22947216033935547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1668330878019333
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09755711257457733
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4526513814765568.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.526513707391386e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.024042850360274315
		 entropy bonus: 0.22947216033935547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1668330878019333
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09755711257457733
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4526513814765568.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.526513707391386e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.024042850360274315
		 entropy bonus: 0.22947216033935547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.1668330878019333
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.09755711257457733
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4526513814765568.0 - Differentiable computation graph = True!
PPO iteration: 430/1000:
	 start solving instance: 59...
	 start solving instance: 97...
	 start solving instance: 141...
	 start solving instance: 100...
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 121...
	 start solving instance: 11...
	 start solving instance: 142...
	 start solving instance: 54...
	 start solving instance: 7...
	 start solving instance: 110...
	 start solving instance: 34...
	 start solving instance: 47...
	 start solving instance: 137...
	 start solving instance: 68...
	 start solving instance: 127...
	 start solving instance: 29...
	 start solving instance: 112...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.065680279411098e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07834132015705109
		 entropy bonus: 0.23181596398353577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18503589928150177
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08522388339042664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5065680386785280.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.065680279411098e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07834132015705109
		 entropy bonus: 0.23181596398353577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18503589928150177
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08522388339042664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5065680386785280.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.065680279411098e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07155980914831161
		 entropy bonus: 0.23301105201244354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.18503589928150177
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08522388339042664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5065680386785280.0 - Differentiable computation graph = True!
PPO iteration: 431/1000:
	 New training batch of size 20...
	 start solving instance: 91...
	 start solving instance: 137...
	 start solving instance: 105...
	 start solving instance: 32...
	 start solving instance: 39...
	 start solving instance: 1...
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 21...
	 start solving instance: 100...
	 start solving instance: 97...
	 start solving instance: 79...
	 start solving instance: 130...
	 start solving instance: 3...
	 start solving instance: 10...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 126...
	 start solving instance: 107...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.852578042596557e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06721381098031998
		 entropy bonus: 0.22228781878948212
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05977065488696098
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1112045869231224
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7852578364719104.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.852578042596557e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06721381098031998
		 entropy bonus: 0.22228781878948212
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05977065488696098
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1112045869231224
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7852578364719104.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.852578042596557e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06721381098031998
		 entropy bonus: 0.22228781878948212
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05977065488696098
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.1112045869231224
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7852578364719104.0 - Differentiable computation graph = True!
PPO iteration: 432/1000:
	 start solving instance: 130...
	 start solving instance: 46...
	 start solving instance: 39...
	 start solving instance: 32...
	 start solving instance: 137...
	 start solving instance: 107...
	 start solving instance: 43...
	 start solving instance: 75...
	 start solving instance: 91...
	 start solving instance: 3...
	 start solving instance: 1...
	 start solving instance: 142...
	 start solving instance: 100...
	 start solving instance: 79...
	 start solving instance: 10...
	 start solving instance: 132...
	 start solving instance: 126...
	 start solving instance: 105...
	 start solving instance: 97...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.677862208969114e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.15253986418247223
		 entropy bonus: 0.23121407628059387
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.003100717207416892
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19742393493652344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7677862316343296.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.677862208969114e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.15253986418247223
		 entropy bonus: 0.23121407628059387
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.003100717207416892
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19742393493652344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7677862316343296.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.677862208969114e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.15253986418247223
		 entropy bonus: 0.23121407628059387
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.003100717207416892
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.19742393493652344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7677862316343296.0 - Differentiable computation graph = True!
PPO iteration: 433/1000:
	 start solving instance: 79...
	 start solving instance: 100...
	 start solving instance: 137...
	 start solving instance: 130...
	 start solving instance: 105...
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 91...
	 start solving instance: 1...
	 start solving instance: 3...
	 start solving instance: 97...
	 start solving instance: 21...
	 start solving instance: 10...
	 start solving instance: 107...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 75...
	 start solving instance: 39...
	 start solving instance: 126...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.082301052878848e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011785924434661865
		 entropy bonus: 0.2360268086194992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12487160414457321
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3782227337360382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9082301052878848.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.082301052878848e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011785924434661865
		 entropy bonus: 0.2360268086194992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12487160414457321
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3782227337360382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9082301052878848.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.082301052878848e+16
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.011785924434661865
		 entropy bonus: 0.2360268086194992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.12487160414457321
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3782227337360382
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9082301052878848.0 - Differentiable computation graph = True!
PPO iteration: 434/1000:
	 start solving instance: 21...
	 start solving instance: 132...
	 start solving instance: 97...
	 start solving instance: 32...
	 start solving instance: 79...
	 start solving instance: 10...
	 start solving instance: 46...
	 start solving instance: 3...
	 start solving instance: 130...
	 start solving instance: 75...
	 start solving instance: 43...
	 start solving instance: 142...
	 start solving instance: 91...
	 start solving instance: 105...
	 start solving instance: 126...
	 start solving instance: 107...
	 start solving instance: 100...
	 start solving instance: 137...
	 start solving instance: 39...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.4440513272807424e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.026493443176150322
		 entropy bonus: 0.21893210709095
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07581397145986557
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.026410335674881935
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.4440513272807424e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.4440513272807424e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.023811280727386475
		 entropy bonus: 0.2205074578523636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07581397145986557
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.026410335674881935
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.4440513272807424e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.4440513272807424e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.026493443176150322
		 entropy bonus: 0.21893210709095
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0825987383723259
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.026410335674881935
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.4440513272807424e+16 - Differentiable computation graph = True!
PPO iteration: 435/1000:
	 start solving instance: 132...
	 start solving instance: 107...
	 start solving instance: 105...
	 start solving instance: 79...
	 start solving instance: 46...
	 start solving instance: 21...
	 start solving instance: 32...
	 start solving instance: 97...
	 start solving instance: 130...
	 start solving instance: 137...
	 start solving instance: 3...
	 start solving instance: 75...
	 start solving instance: 39...
	 start solving instance: 43...
	 start solving instance: 126...
	 start solving instance: 1...
	 start solving instance: 100...
	 start solving instance: 142...
	 start solving instance: 91...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.26642534853247e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08407536894083023
		 entropy bonus: 0.2210187017917633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.01566765271127224
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21965563297271729
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.266425520331162e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.26642534853247e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08407536894083023
		 entropy bonus: 0.2210187017917633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.024130305275321007
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21965563297271729
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.266425520331162e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.26642534853247e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08407536894083023
		 entropy bonus: 0.2210187017917633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02709655463695526
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21965563297271729
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.266425520331162e+16 - Differentiable computation graph = True!
PPO iteration: 436/1000:
	 start solving instance: 137...
	 start solving instance: 32...
	 start solving instance: 132...
	 start solving instance: 97...
	 start solving instance: 100...
	 start solving instance: 1...
	 start solving instance: 21...
	 start solving instance: 107...
	 start solving instance: 3...
	 start solving instance: 43...
	 start solving instance: 75...
	 start solving instance: 46...
	 start solving instance: 39...
	 start solving instance: 105...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 126...
	 start solving instance: 91...
	 start solving instance: 10...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.3249865531386757e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10637116432189941
		 entropy bonus: 0.22204194962978363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0005437255022116005
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16682423651218414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.324986587498414e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.3249865531386757e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.08082965761423111
		 entropy bonus: 0.21770977973937988
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.003969615790992975
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16682423651218414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.324986587498414e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.3249865531386757e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07373598963022232
		 entropy bonus: 0.21874122321605682
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.007917028851807117
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.16682423651218414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.324986587498414e+17 - Differentiable computation graph = True!
PPO iteration: 437/1000:
	 start solving instance: 21...
	 start solving instance: 39...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 79...
	 start solving instance: 32...
	 start solving instance: 130...
	 start solving instance: 75...
	 start solving instance: 132...
	 start solving instance: 97...
	 start solving instance: 3...
	 start solving instance: 10...
	 start solving instance: 91...
	 start solving instance: 105...
	 start solving instance: 107...
	 start solving instance: 142...
	 start solving instance: 1...
	 start solving instance: 137...
	 start solving instance: 126...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.1825890771033129e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07359358668327332
		 entropy bonus: 0.2412872314453125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.182589077103313e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.1825890771033129e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07359358668327332
		 entropy bonus: 0.2412872314453125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.182589077103313e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.1825890771033129e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08902494609355927
		 entropy bonus: 0.24417829513549805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.182589077103313e+18 - Differentiable computation graph = True!
PPO iteration: 438/1000:
	 start solving instance: 79...
	 start solving instance: 100...
	 start solving instance: 32...
	 start solving instance: 97...
	 start solving instance: 132...
	 start solving instance: 107...
	 start solving instance: 43...
	 start solving instance: 10...
	 start solving instance: 3...
	 start solving instance: 130...
	 start solving instance: 91...
	 start solving instance: 142...
	 start solving instance: 1...
	 start solving instance: 21...
	 start solving instance: 39...
	 start solving instance: 126...
	 start solving instance: 75...
	 start solving instance: 105...
	 start solving instance: 46...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0579703134119526e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00333977653644979
		 entropy bonus: 0.24955730140209198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.044468726962804794
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0579703134119526e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0579703134119526e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00333977653644979
		 entropy bonus: 0.24955730140209198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.044468726962804794
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0579703134119526e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0579703134119526e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.00333977653644979
		 entropy bonus: 0.24955730140209198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.044468726962804794
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0579703134119526e+17 - Differentiable computation graph = True!
PPO iteration: 439/1000:
	 start solving instance: 3...
	 start solving instance: 126...
	 start solving instance: 46...
	 start solving instance: 32...
	 start solving instance: 137...
	 start solving instance: 142...
	 start solving instance: 39...
	 start solving instance: 1...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 21...
	 start solving instance: 10...
	 start solving instance: 79...
	 start solving instance: 100...
	 start solving instance: 107...
	 start solving instance: 132...
	 start solving instance: 43...
	 start solving instance: 130...
	 start solving instance: 91...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.5669893372900803e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.014094317331910133
		 entropy bonus: 0.2301177978515625
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07051266729831696
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11283144354820251
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5669894403692954e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.5669893372900803e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0132890734821558
		 entropy bonus: 0.22854244709014893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07051266729831696
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11283144354820251
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5669894403692954e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.5669893372900803e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0132890734821558
		 entropy bonus: 0.22854244709014893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.07051266729831696
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11283144354820251
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.5669894403692954e+17 - Differentiable computation graph = True!
PPO iteration: 440/1000:
	 start solving instance: 137...
	 start solving instance: 46...
	 start solving instance: 79...
	 start solving instance: 91...
	 start solving instance: 132...
	 start solving instance: 105...
	 start solving instance: 126...
	 start solving instance: 75...
	 start solving instance: 1...
	 start solving instance: 43...
	 start solving instance: 3...
	 start solving instance: 32...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 39...
	 start solving instance: 100...
	 start solving instance: 10...
	 start solving instance: 97...
	 start solving instance: 21...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.1876314374282936e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09101712703704834
		 entropy bonus: 0.23637227714061737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.000699335359968245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2087869942188263
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.187631471788032e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.1876314374282936e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09101712703704834
		 entropy bonus: 0.23637227714061737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.000699335359968245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2087869942188263
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.187631471788032e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.1876314374282936e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09101712703704834
		 entropy bonus: 0.23637227714061737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.000699335359968245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2087869942188263
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.187631471788032e+17 - Differentiable computation graph = True!
PPO iteration: 441/1000:
	 New training batch of size 20...
	 start solving instance: 138...
	 start solving instance: 92...
	 start solving instance: 117...
	 start solving instance: 130...
	 start solving instance: 78...
	 start solving instance: 126...
	 start solving instance: 102...
	 start solving instance: 95...
	 start solving instance: 108...
	 start solving instance: 89...
	 start solving instance: 129...
	 start solving instance: 77...
	 start solving instance: 135...
	 start solving instance: 72...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 85...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.535425975148872e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.012949878349900246
		 entropy bonus: 0.2106342315673828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03397748991847038
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0064666480757296085
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.535426490544947e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.535425975148872e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.012949878349900246
		 entropy bonus: 0.2106342315673828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03397748991847038
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0064666480757296085
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.535426490544947e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.535425975148872e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.002898693084716797
		 entropy bonus: 0.21485964953899384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.03397748991847038
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0064666480757296085
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.535426490544947e+16 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 6.202259192938496e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.0813649520277977
		 entropy bonus: 0.2089756280183792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02419658936560154
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1552729606628418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 62022591929384960.0000
PPO iteration: 442/1000:
	 start solving instance: 92...
	 start solving instance: 95...
	 start solving instance: 72...
	 start solving instance: 78...
	 start solving instance: 138...
	 start solving instance: 108...
	 start solving instance: 130...
	 start solving instance: 102...
	 start solving instance: 89...
	 start solving instance: 77...
	 start solving instance: 39...
	 start solving instance: 129...
	 start solving instance: 114...
	 start solving instance: 126...
	 start solving instance: 117...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 135...
	 start solving instance: 122...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.325988610801664e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01585989259183407
		 entropy bonus: 0.18560567498207092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04031018540263176
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12677396833896637
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.325988610801664e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.325988610801664e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01585989259183407
		 entropy bonus: 0.18560567498207092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04031018540263176
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12677396833896637
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.325988610801664e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.325988610801664e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01585989259183407
		 entropy bonus: 0.18560567498207092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04031018540263176
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12677396833896637
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.325988610801664e+16 - Differentiable computation graph = True!
PPO iteration: 443/1000:
	 start solving instance: 72...
	 start solving instance: 39...
	 start solving instance: 126...
	 start solving instance: 135...
	 start solving instance: 130...
	 start solving instance: 117...
	 start solving instance: 122...
	 start solving instance: 95...
	 start solving instance: 129...
	 start solving instance: 102...
	 start solving instance: 92...
	 start solving instance: 108...
	 start solving instance: 78...
	 start solving instance: 89...
	 start solving instance: 77...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 138...
	 start solving instance: 85...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.739922440505262e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.029286295175552368
		 entropy bonus: 0.19451569020748138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10801352560520172
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002044782042503357
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.739922526404608e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.739922440505262e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.029286295175552368
		 entropy bonus: 0.19451569020748138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10801352560520172
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002044782042503357
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.739922526404608e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.739922440505262e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.029286295175552368
		 entropy bonus: 0.19451569020748138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10801352560520172
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.002044782042503357
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.739922526404608e+16 - Differentiable computation graph = True!
PPO iteration: 444/1000:
	 start solving instance: 129...
	 start solving instance: 115...
	 start solving instance: 122...
	 start solving instance: 108...
	 start solving instance: 39...
	 start solving instance: 95...
	 start solving instance: 135...
	 start solving instance: 130...
	 start solving instance: 114...
	 start solving instance: 138...
	 start solving instance: 92...
	 start solving instance: 78...
	 start solving instance: 72...
	 start solving instance: 102...
	 start solving instance: 85...
	 start solving instance: 63...
	 start solving instance: 117...
	 start solving instance: 89...
	 start solving instance: 77...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.142812363102618e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16153143346309662
		 entropy bonus: 0.18592719733715057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09478259831666946
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1420101821422577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.142812363102618e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.142812363102618e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16153143346309662
		 entropy bonus: 0.18592719733715057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09478259831666946
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1420101821422577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.142812363102618e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.142812363102618e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.16153143346309662
		 entropy bonus: 0.18592719733715057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.09478259831666946
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1420101821422577
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.142812363102618e+16 - Differentiable computation graph = True!
PPO iteration: 445/1000:
	 start solving instance: 108...
	 start solving instance: 89...
	 start solving instance: 72...
	 start solving instance: 130...
	 start solving instance: 135...
	 start solving instance: 114...
	 start solving instance: 129...
	 start solving instance: 115...
	 start solving instance: 138...
	 start solving instance: 117...
	 start solving instance: 102...
	 start solving instance: 126...
	 start solving instance: 95...
	 start solving instance: 78...
	 start solving instance: 122...
	 start solving instance: 92...
	 start solving instance: 39...
	 start solving instance: 63...
	 start solving instance: 77...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.864282015970099e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07283423095941544
		 entropy bonus: 0.19925424456596375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05587770417332649
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15387049317359924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.864282015970099e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.864282015970099e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06993406265974045
		 entropy bonus: 0.19677871465682983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05861510708928108
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15387049317359924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.864282015970099e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.864282015970099e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.06993406265974045
		 entropy bonus: 0.19677871465682983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05861510708928108
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.15387049317359924
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.864282015970099e+16 - Differentiable computation graph = True!
PPO iteration: 446/1000:
	 start solving instance: 117...
	 start solving instance: 63...
	 start solving instance: 129...
	 start solving instance: 114...
	 start solving instance: 115...
	 start solving instance: 85...
	 start solving instance: 122...
	 start solving instance: 138...
	 start solving instance: 92...
	 start solving instance: 108...
	 start solving instance: 78...
	 start solving instance: 135...
	 start solving instance: 95...
	 start solving instance: 72...
	 start solving instance: 102...
	 start solving instance: 126...
	 start solving instance: 77...
	 start solving instance: 130...
	 start solving instance: 89...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.459350078428283e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04080794379115105
		 entropy bonus: 0.2049061805009842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.007668136153370142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10744089633226395
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.459350593824358e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.459350078428283e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04080794379115105
		 entropy bonus: 0.2049061805009842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.007668136153370142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10744089633226395
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.459350593824358e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.459350078428283e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.04080794379115105
		 entropy bonus: 0.2049061805009842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.007668136153370142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.10744089633226395
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.459350593824358e+16 - Differentiable computation graph = True!
PPO iteration: 447/1000:
	 start solving instance: 63...
	 start solving instance: 72...
	 start solving instance: 126...
	 start solving instance: 89...
	 start solving instance: 129...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 95...
	 start solving instance: 77...
	 start solving instance: 102...
	 start solving instance: 135...
	 start solving instance: 114...
	 start solving instance: 39...
	 start solving instance: 92...
	 start solving instance: 85...
	 start solving instance: 130...
	 start solving instance: 122...
	 start solving instance: 138...
	 start solving instance: 115...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.704679984765338e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06730552762746811
		 entropy bonus: 0.19959349930286407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06213175132870674
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1270453929901123
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.704679984765338e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.704679984765338e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06730552762746811
		 entropy bonus: 0.19959349930286407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06213175132870674
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1270453929901123
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.704679984765338e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.704679984765338e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06730552762746811
		 entropy bonus: 0.19959349930286407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.06213175132870674
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1270453929901123
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.704679984765338e+16 - Differentiable computation graph = True!
PPO iteration: 448/1000:
	 start solving instance: 126...
	 start solving instance: 72...
	 start solving instance: 89...
	 start solving instance: 39...
	 start solving instance: 63...
	 start solving instance: 108...
	 start solving instance: 138...
	 start solving instance: 130...
	 start solving instance: 95...
	 start solving instance: 85...
	 start solving instance: 135...
	 start solving instance: 115...
	 start solving instance: 92...
	 start solving instance: 77...
	 start solving instance: 102...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 129...
	 start solving instance: 78...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.944154991684485e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07697891443967819
		 entropy bonus: 0.19512340426445007
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039698727428913116
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08336479961872101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.944155335281869e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.944154991684485e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07475981116294861
		 entropy bonus: 0.1975989192724228
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039698727428913116
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08336479961872101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.944155335281869e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.944154991684485e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07697891443967819
		 entropy bonus: 0.19512340426445007
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.039698727428913116
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.08336479961872101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.944155335281869e+16 - Differentiable computation graph = True!
PPO iteration: 449/1000:
	 start solving instance: 108...
	 start solving instance: 115...
	 start solving instance: 117...
	 start solving instance: 77...
	 start solving instance: 114...
	 start solving instance: 95...
	 start solving instance: 126...
	 start solving instance: 78...
	 start solving instance: 89...
	 start solving instance: 135...
	 start solving instance: 102...
	 start solving instance: 92...
	 start solving instance: 130...
	 start solving instance: 85...
	 start solving instance: 72...
	 start solving instance: 138...
	 start solving instance: 129...
	 start solving instance: 39...
	 start solving instance: 122...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 8.231229918554358e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0010241568088531494
		 entropy bonus: 0.20004959404468536
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04538998007774353
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12901578843593597
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.23123009035305e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8.231229918554358e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.005495655816048384
		 entropy bonus: 0.1978835016489029
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04538998007774353
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12901578843593597
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.23123009035305e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8.231229918554358e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.005495655816048384
		 entropy bonus: 0.1978835016489029
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04538998007774353
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12901578843593597
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.23123009035305e+16 - Differentiable computation graph = True!
PPO iteration: 450/1000:
	 start solving instance: 102...
	 start solving instance: 92...
	 start solving instance: 85...
	 start solving instance: 77...
	 start solving instance: 130...
	 start solving instance: 72...
	 start solving instance: 126...
	 start solving instance: 129...
	 start solving instance: 115...
	 start solving instance: 89...
	 start solving instance: 138...
	 start solving instance: 95...
	 start solving instance: 122...
	 start solving instance: 114...
	 start solving instance: 39...
	 start solving instance: 117...
	 start solving instance: 63...
	 start solving instance: 135...
	 start solving instance: 108...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 8.677596592498278e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16360321640968323
		 entropy bonus: 0.20112602412700653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08824179321527481
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05775825306773186
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.677596592498278e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8.677596592498278e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16360321640968323
		 entropy bonus: 0.20112602412700653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08824179321527481
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05775825306773186
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.677596592498278e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8.677596592498278e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.16055598855018616
		 entropy bonus: 0.20360155403614044
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08824179321527481
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.05775825306773186
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.677596592498278e+16 - Differentiable computation graph = True!
PPO iteration: 451/1000:
	 New training batch of size 20...
	 start solving instance: 67...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 23...
	 start solving instance: 14...
	 start solving instance: 21...
	 start solving instance: 116...
	 start solving instance: 30...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 105...
	 start solving instance: 88...
	 start solving instance: 28...
	 start solving instance: 95...
	 start solving instance: 120...
	 start solving instance: 143...
	 start solving instance: 39...
	 start solving instance: 92...
	 start solving instance: 3...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.260014117870633e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15961341559886932
		 entropy bonus: 0.21484792232513428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11666449159383774
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.056667618453502655
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.260014289669325e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.260014117870633e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15961341559886932
		 entropy bonus: 0.21484792232513428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11666449159383774
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.056667618453502655
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.260014289669325e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.260014117870633e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.15961341559886932
		 entropy bonus: 0.21484792232513428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11666449159383774
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.056667618453502655
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.260014289669325e+16 - Differentiable computation graph = True!
PPO iteration: 452/1000:
	 start solving instance: 21...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 14...
	 start solving instance: 143...
	 start solving instance: 88...
	 start solving instance: 5...
	 start solving instance: 120...
	 start solving instance: 92...
	 start solving instance: 28...
	 start solving instance: 67...
	 start solving instance: 23...
	 start solving instance: 95...
	 start solving instance: 34...
	 start solving instance: 96...
	 start solving instance: 30...
	 start solving instance: 3...
	 start solving instance: 74...
	 start solving instance: 105...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.160917165056983e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14375363290309906
		 entropy bonus: 0.20087061822414398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10941758006811142
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14942194521427155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.160916993258291e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.160917165056983e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14375363290309906
		 entropy bonus: 0.20087061822414398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11722507327795029
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14942194521427155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.160916993258291e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.160917165056983e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.14375363290309906
		 entropy bonus: 0.20087061822414398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.11722507327795029
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14942194521427155
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.160916993258291e+16 - Differentiable computation graph = True!
PPO iteration: 453/1000:
	 start solving instance: 105...
	 start solving instance: 120...
	 start solving instance: 5...
	 start solving instance: 116...
	 start solving instance: 95...
	 start solving instance: 96...
	 start solving instance: 3...
	 start solving instance: 67...
	 start solving instance: 143...
	 start solving instance: 21...
	 start solving instance: 28...
	 start solving instance: 23...
	 start solving instance: 88...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 92...
	 start solving instance: 39...
	 start solving instance: 14...
	 start solving instance: 30...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.7054353059741696e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.026294350624084473
		 entropy bonus: 0.20079796016216278
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.026622414588928223
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07415032386779785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7054353059741696e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.7054353059741696e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02611028030514717
		 entropy bonus: 0.19914761185646057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.026622414588928223
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07415032386779785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7054353059741696e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.7054353059741696e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02611028030514717
		 entropy bonus: 0.19914761185646057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.026622414588928223
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07415032386779785
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7054353059741696e+17 - Differentiable computation graph = True!
PPO iteration: 454/1000:
	 start solving instance: 92...
	 start solving instance: 96...
	 start solving instance: 74...
	 start solving instance: 143...
	 start solving instance: 5...
	 start solving instance: 60...
	 start solving instance: 30...
	 start solving instance: 95...
	 start solving instance: 105...
	 start solving instance: 3...
	 start solving instance: 28...
	 start solving instance: 120...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 23...
	 start solving instance: 21...
	 start solving instance: 88...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.043868970733273e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10003992170095444
		 entropy bonus: 0.21073591709136963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05386079102754593
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13149872422218323
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.0438689363735347e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.043868970733273e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10003992170095444
		 entropy bonus: 0.21073591709136963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05386079102754593
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13149872422218323
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.0438689363735347e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.043868970733273e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10003992170095444
		 entropy bonus: 0.21073591709136963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05386079102754593
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13149872422218323
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.0438689363735347e+17 - Differentiable computation graph = True!
PPO iteration: 455/1000:
	 start solving instance: 39...
	 start solving instance: 120...
	 start solving instance: 60...
	 start solving instance: 3...
	 start solving instance: 105...
	 start solving instance: 21...
	 start solving instance: 88...
	 start solving instance: 143...
	 start solving instance: 116...
	 start solving instance: 67...
	 start solving instance: 34...
	 start solving instance: 96...
	 start solving instance: 74...
	 start solving instance: 92...
	 start solving instance: 5...
	 start solving instance: 28...
	 start solving instance: 95...
	 start solving instance: 30...
	 start solving instance: 23...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.734402405151015e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07162664085626602
		 entropy bonus: 0.19691519439220428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06476864963769913
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11546435952186584
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.7344024395107533e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.734402405151015e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07162664085626602
		 entropy bonus: 0.19691519439220428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06476864963769913
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11546435952186584
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.7344024395107533e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.734402405151015e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07162664085626602
		 entropy bonus: 0.19691519439220428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.06476864963769913
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11546435952186584
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.7344024395107533e+17 - Differentiable computation graph = True!
PPO iteration: 456/1000:
	 start solving instance: 5...
	 start solving instance: 92...
	 start solving instance: 28...
	 start solving instance: 39...
	 start solving instance: 3...
	 start solving instance: 67...
	 start solving instance: 96...
	 start solving instance: 60...
	 start solving instance: 34...
	 start solving instance: 30...
	 start solving instance: 21...
	 start solving instance: 23...
	 start solving instance: 14...
	 start solving instance: 74...
	 start solving instance: 120...
	 start solving instance: 95...
	 start solving instance: 116...
	 start solving instance: 143...
	 start solving instance: 105...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.246381198531887e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07318492978811264
		 entropy bonus: 0.21030278503894806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07682903856039047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.246381267251364e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.246381198531887e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07318492978811264
		 entropy bonus: 0.21030278503894806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07682903856039047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.246381267251364e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.246381198531887e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.08279278129339218
		 entropy bonus: 0.21529646217823029
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07682903856039047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.246381267251364e+17 - Differentiable computation graph = True!
PPO iteration: 457/1000:
	 start solving instance: 21...
	 start solving instance: 23...
	 start solving instance: 96...
	 start solving instance: 30...
	 start solving instance: 67...
	 start solving instance: 92...
	 start solving instance: 95...
	 start solving instance: 116...
	 start solving instance: 60...
	 start solving instance: 143...
	 start solving instance: 3...
	 start solving instance: 14...
	 start solving instance: 105...
	 start solving instance: 34...
	 start solving instance: 39...
	 start solving instance: 120...
	 start solving instance: 28...
	 start solving instance: 74...
	 start solving instance: 5...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.614603466479239e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.016074199229478836
		 entropy bonus: 0.19945620000362396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21371746063232422
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.6146034321195008e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.614603466479239e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02478225901722908
		 entropy bonus: 0.19741754233837128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21371746063232422
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.6146034321195008e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.614603466479239e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.02478225901722908
		 entropy bonus: 0.19741754233837128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.21371746063232422
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.6146034321195008e+17 - Differentiable computation graph = True!
PPO iteration: 458/1000:
	 start solving instance: 116...
	 start solving instance: 5...
	 start solving instance: 39...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 23...
	 start solving instance: 92...
	 start solving instance: 95...
	 start solving instance: 21...
	 start solving instance: 105...
	 start solving instance: 3...
	 start solving instance: 67...
	 start solving instance: 143...
	 start solving instance: 28...
	 start solving instance: 88...
	 start solving instance: 14...
	 start solving instance: 120...
	 start solving instance: 74...
	 start solving instance: 30...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.2921270139740488e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04882492497563362
		 entropy bonus: 0.19650708138942719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01826336607336998
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.167942076921463
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.2921269796143104e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.2921270139740488e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04882492497563362
		 entropy bonus: 0.19650708138942719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01826336607336998
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.167942076921463
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.2921269796143104e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.2921270139740488e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04882492497563362
		 entropy bonus: 0.19650708138942719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01826336607336998
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.167942076921463
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.2921269796143104e+17 - Differentiable computation graph = True!
PPO iteration: 459/1000:
	 start solving instance: 92...
	 start solving instance: 96...
	 start solving instance: 116...
	 start solving instance: 21...
	 start solving instance: 14...
	 start solving instance: 60...
	 start solving instance: 95...
	 start solving instance: 67...
	 start solving instance: 3...
	 start solving instance: 88...
	 start solving instance: 23...
	 start solving instance: 120...
	 start solving instance: 74...
	 start solving instance: 5...
	 start solving instance: 143...
	 start solving instance: 30...
	 start solving instance: 105...
	 start solving instance: 39...
	 start solving instance: 34...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.3772054370249605e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04703430086374283
		 entropy bonus: 0.20362897217273712
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13305135071277618
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.377205471384699e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.3772054370249605e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04703430086374283
		 entropy bonus: 0.20362897217273712
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13305135071277618
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.377205471384699e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.3772054370249605e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.04703430086374283
		 entropy bonus: 0.20362897217273712
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.13305135071277618
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.377205471384699e+17 - Differentiable computation graph = True!
PPO iteration: 460/1000:
	 start solving instance: 96...
	 start solving instance: 74...
	 start solving instance: 120...
	 start solving instance: 88...
	 start solving instance: 39...
	 start solving instance: 30...
	 start solving instance: 92...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 67...
	 start solving instance: 21...
	 start solving instance: 3...
	 start solving instance: 14...
	 start solving instance: 23...
	 start solving instance: 95...
	 start solving instance: 116...
	 start solving instance: 5...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.1446401734916178e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09675713628530502
		 entropy bonus: 0.1951463669538498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02761567197740078
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06961741298437119
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.144640207851356e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.1446401734916178e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09675713628530502
		 entropy bonus: 0.1951463669538498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02761567197740078
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06961741298437119
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.144640207851356e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.1446401734916178e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09675713628530502
		 entropy bonus: 0.1951463669538498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.02761567197740078
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.06961741298437119
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.144640207851356e+17 - Differentiable computation graph = True!
PPO iteration: 461/1000:
	 New training batch of size 20...
	 start solving instance: 18...
	 start solving instance: 109...
	 start solving instance: 54...
	 start solving instance: 100...
	 start solving instance: 73...
	 start solving instance: 147...
	 start solving instance: 65...
	 start solving instance: 25...
	 start solving instance: 142...
	 start solving instance: 86...
	 start solving instance: 69...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 57...
	 start solving instance: 7...
	 start solving instance: 9...
	 start solving instance: 134...
	 start solving instance: 130...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.788681530336346e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07232940942049026
		 entropy bonus: 0.21955934166908264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.059936221688985825
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.36570271849632263
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7886815646960845e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.788681530336346e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07232940942049026
		 entropy bonus: 0.21955934166908264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.059936221688985825
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.36570271849632263
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7886815646960845e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.788681530336346e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.07232940942049026
		 entropy bonus: 0.21955934166908264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.059936221688985825
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.36570271849632263
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7886815646960845e+17 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 1.1399745490313544e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.09506656229496002
		 entropy bonus: 0.20792244374752045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08767598122358322
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3773996829986572
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 113997460057096192.0000
PPO iteration: 462/1000:
	 start solving instance: 100...
	 start solving instance: 109...
	 start solving instance: 69...
	 start solving instance: 67...
	 start solving instance: 9...
	 start solving instance: 147...
	 start solving instance: 73...
	 start solving instance: 25...
	 start solving instance: 130...
	 start solving instance: 86...
	 start solving instance: 65...
	 start solving instance: 57...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 142...
	 start solving instance: 18...
	 start solving instance: 80...
	 start solving instance: 134...
	 start solving instance: 1...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2522735127316398e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07889022678136826
		 entropy bonus: 0.2207334041595459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.016536343842744827
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25148630142211914
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2522735642712474e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2522735127316398e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07889022678136826
		 entropy bonus: 0.2207334041595459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.016536343842744827
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25148630142211914
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2522735642712474e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2522735127316398e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07889022678136826
		 entropy bonus: 0.2207334041595459
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.016536343842744827
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25148630142211914
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2522735642712474e+17 - Differentiable computation graph = True!
PPO iteration: 463/1000:
	 start solving instance: 1...
	 start solving instance: 65...
	 start solving instance: 86...
	 start solving instance: 54...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 80...
	 start solving instance: 73...
	 start solving instance: 147...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 57...
	 start solving instance: 18...
	 start solving instance: 9...
	 start solving instance: 67...
	 start solving instance: 101...
	 start solving instance: 69...
	 start solving instance: 25...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2504072291824435e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10609734058380127
		 entropy bonus: 0.2292395830154419
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10341798514127731
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09962436556816101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2504072291824435e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2504072291824435e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10609734058380127
		 entropy bonus: 0.2292395830154419
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10341798514127731
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09962436556816101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2504072291824435e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2504072291824435e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10609734058380127
		 entropy bonus: 0.2292395830154419
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10341798514127731
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.09962436556816101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2504072291824435e+17 - Differentiable computation graph = True!
PPO iteration: 464/1000:
	 start solving instance: 109...
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 73...
	 start solving instance: 100...
	 start solving instance: 86...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 147...
	 start solving instance: 1...
	 start solving instance: 101...
	 start solving instance: 65...
	 start solving instance: 130...
	 start solving instance: 134...
	 start solving instance: 67...
	 start solving instance: 142...
	 start solving instance: 69...
	 start solving instance: 57...
	 start solving instance: 80...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.0923588923204567e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.083199642598629
		 entropy bonus: 0.22915492951869965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.059195030480623245
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.26826632022857666
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.0923588751405875e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.0923588923204567e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0749392956495285
		 entropy bonus: 0.22915492951869965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05528334900736809
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.26826632022857666
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.0923588751405875e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.0923588923204567e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0749392956495285
		 entropy bonus: 0.22915492951869965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.05528334900736809
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.26826632022857666
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.0923588751405875e+17 - Differentiable computation graph = True!
PPO iteration: 465/1000:
	 start solving instance: 73...
	 start solving instance: 65...
	 start solving instance: 54...
	 start solving instance: 86...
	 start solving instance: 134...
	 start solving instance: 142...
	 start solving instance: 80...
	 start solving instance: 130...
	 start solving instance: 57...
	 start solving instance: 9...
	 start solving instance: 101...
	 start solving instance: 1...
	 start solving instance: 25...
	 start solving instance: 109...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 147...
	 start solving instance: 100...
	 start solving instance: 69...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 8.776256458053386e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.041428741067647934
		 entropy bonus: 0.2292138785123825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05209367349743843
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.035512737929821014
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.776256286254694e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8.776256458053386e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.041428741067647934
		 entropy bonus: 0.2292138785123825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05209367349743843
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.035512737929821014
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.776256286254694e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8.776256458053386e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.041428741067647934
		 entropy bonus: 0.2292138785123825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05664048343896866
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.035512737929821014
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8.776256286254694e+16 - Differentiable computation graph = True!
PPO iteration: 466/1000:
	 start solving instance: 25...
	 start solving instance: 142...
	 start solving instance: 109...
	 start solving instance: 65...
	 start solving instance: 73...
	 start solving instance: 54...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 18...
	 start solving instance: 57...
	 start solving instance: 130...
	 start solving instance: 147...
	 start solving instance: 100...
	 start solving instance: 86...
	 start solving instance: 67...
	 start solving instance: 1...
	 start solving instance: 80...
	 start solving instance: 101...
	 start solving instance: 9...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.455272264678769e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.038008544594049454
		 entropy bonus: 0.2246936410665512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.017148340120911598
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07639811933040619
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.455272092880077e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.455272264678769e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.038008544594049454
		 entropy bonus: 0.2246936410665512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.017148340120911598
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07639811933040619
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.455272092880077e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.455272264678769e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.038008544594049454
		 entropy bonus: 0.2246936410665512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.017148340120911598
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.07639811933040619
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.455272092880077e+16 - Differentiable computation graph = True!
PPO iteration: 467/1000:
	 start solving instance: 147...
	 start solving instance: 18...
	 start solving instance: 57...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 69...
	 start solving instance: 142...
	 start solving instance: 25...
	 start solving instance: 7...
	 start solving instance: 54...
	 start solving instance: 134...
	 start solving instance: 65...
	 start solving instance: 67...
	 start solving instance: 86...
	 start solving instance: 101...
	 start solving instance: 80...
	 start solving instance: 9...
	 start solving instance: 109...
	 start solving instance: 100...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.379032128408781e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1132783442735672
		 entropy bonus: 0.22554977238178253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08795250952243805
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11195739358663559
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.37903212840878e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.379032128408781e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1132783442735672
		 entropy bonus: 0.22554977238178253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08795250952243805
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11195739358663559
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.37903212840878e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.379032128408781e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.1132783442735672
		 entropy bonus: 0.22554977238178253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.08795250952243805
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11195739358663559
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.37903212840878e+16 - Differentiable computation graph = True!
PPO iteration: 468/1000:
	 start solving instance: 80...
	 start solving instance: 18...
	 start solving instance: 86...
	 start solving instance: 101...
	 start solving instance: 1...
	 start solving instance: 25...
	 start solving instance: 109...
	 start solving instance: 142...
	 start solving instance: 100...
	 start solving instance: 54...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 67...
	 start solving instance: 147...
	 start solving instance: 65...
	 start solving instance: 9...
	 start solving instance: 73...
	 start solving instance: 7...
	 start solving instance: 57...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.43516632017535e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02423018217086792
		 entropy bonus: 0.23429684340953827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04668688401579857
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.44762060046195984
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.435166491974042e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.43516632017535e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02423018217086792
		 entropy bonus: 0.23429684340953827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04668688401579857
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.44762060046195984
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.435166491974042e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.43516632017535e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.02423018217086792
		 entropy bonus: 0.23429684340953827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.04668688401579857
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.44762060046195984
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.435166491974042e+16 - Differentiable computation graph = True!
PPO iteration: 469/1000:
	 start solving instance: 57...
	 start solving instance: 86...
	 start solving instance: 100...
	 start solving instance: 109...
	 start solving instance: 101...
	 start solving instance: 7...
	 start solving instance: 130...
	 start solving instance: 147...
	 start solving instance: 25...
	 start solving instance: 142...
	 start solving instance: 80...
	 start solving instance: 73...
	 start solving instance: 1...
	 start solving instance: 9...
	 start solving instance: 18...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 65...
	 start solving instance: 54...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.005784711392133e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1790369749069214
		 entropy bonus: 0.21946847438812256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08958026021718979
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.39134499430656433
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.005784625492787e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.005784711392133e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1790369749069214
		 entropy bonus: 0.21946847438812256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08958026021718979
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.39134499430656433
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.005784625492787e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.005784711392133e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.1790369749069214
		 entropy bonus: 0.21946847438812256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.08958026021718979
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.39134499430656433
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.005784625492787e+16 - Differentiable computation graph = True!
PPO iteration: 470/1000:
	 start solving instance: 101...
	 start solving instance: 18...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 73...
	 start solving instance: 54...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 142...
	 start solving instance: 86...
	 start solving instance: 57...
	 start solving instance: 67...
	 start solving instance: 100...
	 start solving instance: 9...
	 start solving instance: 25...
	 start solving instance: 80...
	 start solving instance: 130...
	 start solving instance: 147...
	 start solving instance: 69...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.4047088486803046e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06339140236377716
		 entropy bonus: 0.23543277382850647
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.025639032945036888
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3945631682872772
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.404709106378342e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.4047088486803046e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06339140236377716
		 entropy bonus: 0.23543277382850647
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.025639032945036888
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3945631682872772
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.404709106378342e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.4047088486803046e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.06339140236377716
		 entropy bonus: 0.23543277382850647
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.025639032945036888
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3945631682872772
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.404709106378342e+16 - Differentiable computation graph = True!
PPO iteration: 471/1000:
	 New training batch of size 20...
	 start solving instance: 135...
	 start solving instance: 119...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 142...
	 start solving instance: 63...
	 start solving instance: 97...
	 start solving instance: 129...
	 start solving instance: 54...
	 start solving instance: 138...
	 start solving instance: 10...
	 start solving instance: 22...
	 start solving instance: 133...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 67...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 66...
	 start solving instance: 27...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.964987332443505e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10273297131061554
		 entropy bonus: 0.2367023527622223
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014710485935211182
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.006870746612548828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.964987590141542e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.964987332443505e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10273297131061554
		 entropy bonus: 0.2367023527622223
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014710485935211182
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.006870746612548828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.964987590141542e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.964987332443505e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10273297131061554
		 entropy bonus: 0.2367023527622223
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.014710485935211182
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.006870746612548828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.964987590141542e+16 - Differentiable computation graph = True!
PPO iteration: 472/1000:
	 start solving instance: 54...
	 start solving instance: 135...
	 start solving instance: 27...
	 start solving instance: 133...
	 start solving instance: 67...
	 start solving instance: 63...
	 start solving instance: 22...
	 start solving instance: 10...
	 start solving instance: 97...
	 start solving instance: 119...
	 start solving instance: 129...
	 start solving instance: 130...
	 start solving instance: 138...
	 start solving instance: 75...
	 start solving instance: 105...
	 start solving instance: 145...
	 start solving instance: 66...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 6.515316266767483e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07452218979597092
		 entropy bonus: 0.23840999603271484
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.027543583884835243
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14750513434410095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.515316352666829e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6.515316266767483e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07452218979597092
		 entropy bonus: 0.23840999603271484
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.027543583884835243
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14750513434410095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.515316352666829e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6.515316266767483e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.07452218979597092
		 entropy bonus: 0.23840999603271484
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.027543583884835243
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14750513434410095
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6.515316352666829e+16 - Differentiable computation graph = True!
PPO iteration: 473/1000:
	 start solving instance: 10...
	 start solving instance: 22...
	 start solving instance: 142...
	 start solving instance: 97...
	 start solving instance: 67...
	 start solving instance: 27...
	 start solving instance: 105...
	 start solving instance: 135...
	 start solving instance: 119...
	 start solving instance: 66...
	 start solving instance: 75...
	 start solving instance: 54...
	 start solving instance: 138...
	 start solving instance: 129...
	 start solving instance: 63...
	 start solving instance: 145...
	 start solving instance: 130...
	 start solving instance: 5...
	 start solving instance: 133...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.410660267576525e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10817205160856247
		 entropy bonus: 0.23108641803264618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.054847002029418945
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0667697861790657
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.410660267576525e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.410660267576525e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10817205160856247
		 entropy bonus: 0.23108641803264618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.054847002029418945
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0667697861790657
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.410660267576525e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.410660267576525e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.10817205160856247
		 entropy bonus: 0.23108641803264618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.054847002029418945
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.0667697861790657
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.410660267576525e+16 - Differentiable computation graph = True!
PPO iteration: 474/1000:
	 start solving instance: 119...
	 start solving instance: 138...
	 start solving instance: 129...
	 start solving instance: 66...
	 start solving instance: 54...
	 start solving instance: 27...
	 start solving instance: 145...
	 start solving instance: 130...
	 start solving instance: 22...
	 start solving instance: 105...
	 start solving instance: 96...
	 start solving instance: 97...
	 start solving instance: 135...
	 start solving instance: 133...
	 start solving instance: 63...
	 start solving instance: 67...
	 start solving instance: 142...
	 start solving instance: 5...
	 start solving instance: 75...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.242149115503575e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.23807020485401154
		 entropy bonus: 0.23651538789272308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.032757923007011414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11141283065080643
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.242148943704883e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.242149115503575e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.23807020485401154
		 entropy bonus: 0.23651538789272308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.032757923007011414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11141283065080643
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.242148943704883e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.242149115503575e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.23807020485401154
		 entropy bonus: 0.23651538789272308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.032757923007011414
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11141283065080643
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.242148943704883e+16 - Differentiable computation graph = True!
PPO iteration: 475/1000:
	 start solving instance: 63...
	 start solving instance: 66...
	 start solving instance: 75...
	 start solving instance: 130...
	 start solving instance: 10...
	 start solving instance: 145...
	 start solving instance: 105...
	 start solving instance: 27...
	 start solving instance: 54...
	 start solving instance: 135...
	 start solving instance: 133...
	 start solving instance: 129...
	 start solving instance: 97...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 5...
	 start solving instance: 142...
	 start solving instance: 96...
	 start solving instance: 22...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.028389623973806e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.18752887845039368
		 entropy bonus: 0.23026572167873383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03365596756339073
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25961774587631226
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.028389709873152e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.028389623973806e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.18752887845039368
		 entropy bonus: 0.23026572167873383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03365596756339073
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25961774587631226
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.028389709873152e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.028389623973806e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.18752887845039368
		 entropy bonus: 0.23026572167873383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03365596756339073
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.25961774587631226
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.028389709873152e+16 - Differentiable computation graph = True!
PPO iteration: 476/1000:
	 start solving instance: 96...
	 start solving instance: 130...
	 start solving instance: 10...
	 start solving instance: 75...
	 start solving instance: 129...
	 start solving instance: 133...
	 start solving instance: 63...
	 start solving instance: 142...
	 start solving instance: 22...
	 start solving instance: 5...
	 start solving instance: 67...
	 start solving instance: 135...
	 start solving instance: 145...
	 start solving instance: 66...
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 105...
	 start solving instance: 27...
	 start solving instance: 119...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.38134385160618e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10213577002286911
		 entropy bonus: 0.2400030642747879
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13977335393428802
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08642970025539398
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.381343679807488e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.38134385160618e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10213577002286911
		 entropy bonus: 0.2400030642747879
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13977335393428802
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08642970025539398
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.381343679807488e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.38134385160618e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.10213577002286911
		 entropy bonus: 0.2400030642747879
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.13977335393428802
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08642970025539398
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.381343679807488e+16 - Differentiable computation graph = True!
PPO iteration: 477/1000:
	 start solving instance: 129...
	 start solving instance: 135...
	 start solving instance: 133...
	 start solving instance: 105...
	 start solving instance: 27...
	 start solving instance: 97...
	 start solving instance: 138...
	 start solving instance: 130...
	 start solving instance: 67...
	 start solving instance: 63...
	 start solving instance: 66...
	 start solving instance: 142...
	 start solving instance: 54...
	 start solving instance: 119...
	 start solving instance: 5...
	 start solving instance: 10...
	 start solving instance: 22...
	 start solving instance: 75...
	 start solving instance: 96...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 7.815173344214385e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.016774190589785576
		 entropy bonus: 0.24109800159931183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05709127336740494
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08337562531232834
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.815173172415693e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7.815173344214385e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.016774190589785576
		 entropy bonus: 0.24109800159931183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05709127336740494
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08337562531232834
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.815173172415693e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7.815173344214385e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.016774190589785576
		 entropy bonus: 0.24109800159931183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05709127336740494
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.08337562531232834
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7.815173172415693e+16 - Differentiable computation graph = True!
PPO iteration: 478/1000:
	 start solving instance: 22...
	 start solving instance: 66...
	 start solving instance: 145...
	 start solving instance: 63...
	 start solving instance: 67...
	 start solving instance: 97...
	 start solving instance: 27...
	 start solving instance: 133...
	 start solving instance: 10...
	 start solving instance: 142...
	 start solving instance: 54...
	 start solving instance: 129...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 119...
	 start solving instance: 135...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 105...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.003300798825759e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09842900931835175
		 entropy bonus: 0.22880101203918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03708888590335846
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013038098812103271
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.003301142423142e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.003300798825759e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09842900931835175
		 entropy bonus: 0.22880101203918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03708888590335846
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013038098812103271
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.003301142423142e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.003300798825759e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.09842900931835175
		 entropy bonus: 0.22880101203918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.03708888590335846
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.013038098812103271
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.003301142423142e+16 - Differentiable computation graph = True!
PPO iteration: 479/1000:
	 start solving instance: 119...
	 start solving instance: 27...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 133...
	 start solving instance: 63...
	 start solving instance: 130...
	 start solving instance: 66...
	 start solving instance: 67...
	 start solving instance: 10...
	 start solving instance: 97...
	 start solving instance: 22...
	 start solving instance: 75...
	 start solving instance: 135...
	 start solving instance: 105...
	 start solving instance: 142...
	 start solving instance: 145...
	 start solving instance: 129...
	 start solving instance: 54...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 9.977525825395753e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007837692275643349
		 entropy bonus: 0.231998011469841
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01404203474521637
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04502667486667633
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.977525997194445e+16 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9.977525825395753e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007837692275643349
		 entropy bonus: 0.231998011469841
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01404203474521637
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04502667486667633
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.977525997194445e+16 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9.977525825395753e+17
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.007837692275643349
		 entropy bonus: 0.231998011469841
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.01404203474521637
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -0.04502667486667633
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9.977525997194445e+16 - Differentiable computation graph = True!
PPO iteration: 480/1000:
	 start solving instance: 66...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 10...
	 start solving instance: 27...
	 start solving instance: 5...
	 start solving instance: 142...
	 start solving instance: 129...
	 start solving instance: 135...
	 start solving instance: 67...
	 start solving instance: 119...
	 start solving instance: 133...
	 start solving instance: 54...
	 start solving instance: 97...
	 start solving instance: 145...
	 start solving instance: 105...
	 start solving instance: 130...
	 start solving instance: 22...
	 start solving instance: 63...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2157231348842496e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021122664213180542
		 entropy bonus: 0.2346719354391098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05982253700494766
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.016928264871239662
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2157231348842496e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2157231348842496e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021122664213180542
		 entropy bonus: 0.2346719354391098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05982253700494766
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.016928264871239662
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2157231348842496e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2157231348842496e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.021122664213180542
		 entropy bonus: 0.2346719354391098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05982253700494766
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.016928264871239662
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2157231348842496e+17 - Differentiable computation graph = True!
PPO iteration: 481/1000:
	 New training batch of size 20...
	 start solving instance: 99...
	 start solving instance: 13...
	 start solving instance: 57...
	 start solving instance: 121...
	 start solving instance: 120...
	 start solving instance: 47...
	 start solving instance: 42...
	 start solving instance: 91...
	 start solving instance: 128...
	 start solving instance: 108...
	 start solving instance: 79...
	 start solving instance: 6...
	 start solving instance: 111...
	 start solving instance: 113...
	 start solving instance: 7...
	 start solving instance: 41...
	 start solving instance: 9...
	 start solving instance: 71...
	 start solving instance: 50...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.2226998110403953e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.021268511191010475
		 entropy bonus: 0.2157745659351349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04285157471895218
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12047367542982101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.222699793860526e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.2226998110403953e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.021268511191010475
		 entropy bonus: 0.2157745659351349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04285157471895218
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12047367542982101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.222699793860526e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.2226998110403953e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.021268511191010475
		 entropy bonus: 0.2157745659351349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.04285157471895218
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.12047367542982101
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.222699793860526e+17 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 1.4679479412001341e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.116063192486763
		 entropy bonus: 0.20814429223537445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.10632424801588058
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.2304241955280304
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 146794800991961088.0000
PPO iteration: 482/1000:
	 start solving instance: 47...
	 start solving instance: 41...
	 start solving instance: 128...
	 start solving instance: 7...
	 start solving instance: 6...
	 start solving instance: 111...
	 start solving instance: 35...
	 start solving instance: 91...
	 start solving instance: 71...
	 start solving instance: 121...
	 start solving instance: 13...
	 start solving instance: 9...
	 start solving instance: 79...
	 start solving instance: 99...
	 start solving instance: 120...
	 start solving instance: 113...
	 start solving instance: 108...
	 start solving instance: 42...
	 start solving instance: 50...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.3896734335408538e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007010925095528364
		 entropy bonus: 0.21478402614593506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012071400880813599
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11058888584375381
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.3896734335408538e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.3896734335408538e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007010925095528364
		 entropy bonus: 0.21478402614593506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012071400880813599
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11058888584375381
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.3896734335408538e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.3896734335408538e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.007010925095528364
		 entropy bonus: 0.21478402614593506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.012071400880813599
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.11058888584375381
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.3896734335408538e+17 - Differentiable computation graph = True!
PPO iteration: 483/1000:
	 start solving instance: 7...
	 start solving instance: 13...
	 start solving instance: 50...
	 start solving instance: 121...
	 start solving instance: 71...
	 start solving instance: 6...
	 start solving instance: 57...
	 start solving instance: 120...
	 start solving instance: 113...
	 start solving instance: 99...
	 start solving instance: 91...
	 start solving instance: 47...
	 start solving instance: 79...
	 start solving instance: 42...
	 start solving instance: 35...
	 start solving instance: 41...
	 start solving instance: 9...
	 start solving instance: 128...
	 start solving instance: 111...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.7110024082235064e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03874843940138817
		 entropy bonus: 0.21430335938930511
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0021720172371715307
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22270719707012177
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7110024425832448e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.7110024082235064e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03874843940138817
		 entropy bonus: 0.21430335938930511
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0021720172371715307
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22270719707012177
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7110024425832448e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.7110024082235064e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03874843940138817
		 entropy bonus: 0.21430335938930511
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0021720172371715307
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.22270719707012177
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.7110024425832448e+17 - Differentiable computation graph = True!
PPO iteration: 484/1000:
	 start solving instance: 35...
	 start solving instance: 7...
	 start solving instance: 120...
	 start solving instance: 41...
	 start solving instance: 57...
	 start solving instance: 13...
	 start solving instance: 9...
	 start solving instance: 42...
	 start solving instance: 6...
	 start solving instance: 121...
	 start solving instance: 71...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 111...
	 start solving instance: 79...
	 start solving instance: 108...
	 start solving instance: 128...
	 start solving instance: 50...
	 start solving instance: 47...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.6408791300167434e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03147603198885918
		 entropy bonus: 0.2170194834470749
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05155602842569351
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18652325868606567
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.64087919873622e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.6408791300167434e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03147603198885918
		 entropy bonus: 0.2170194834470749
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05155602842569351
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18652325868606567
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.64087919873622e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.6408791300167434e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.03147603198885918
		 entropy bonus: 0.2170194834470749
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.05155602842569351
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.18652325868606567
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.64087919873622e+17 - Differentiable computation graph = True!
PPO iteration: 485/1000:
	 start solving instance: 7...
	 start solving instance: 9...
	 start solving instance: 42...
	 start solving instance: 13...
	 start solving instance: 121...
	 start solving instance: 57...
	 start solving instance: 47...
	 start solving instance: 35...
	 start solving instance: 111...
	 start solving instance: 6...
	 start solving instance: 120...
	 start solving instance: 113...
	 start solving instance: 71...
	 start solving instance: 91...
	 start solving instance: 128...
	 start solving instance: 108...
	 start solving instance: 99...
	 start solving instance: 41...
	 start solving instance: 79...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.222786535020036e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025246715173125267
		 entropy bonus: 0.21735525131225586
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0033240169286727905
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20080207288265228
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2227865521999053e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.222786535020036e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025246715173125267
		 entropy bonus: 0.21735525131225586
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0033240169286727905
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20080207288265228
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2227865521999053e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.222786535020036e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.025246715173125267
		 entropy bonus: 0.21735525131225586
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.0033240169286727905
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.20080207288265228
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.2227865521999053e+17 - Differentiable computation graph = True!
PPO iteration: 486/1000:
	 start solving instance: 50...
	 start solving instance: 57...
	 start solving instance: 7...
	 start solving instance: 79...
	 start solving instance: 120...
	 start solving instance: 13...
	 start solving instance: 35...
	 start solving instance: 41...
	 start solving instance: 121...
	 start solving instance: 9...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 71...
	 start solving instance: 111...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 108...
	 start solving instance: 42...
	 start solving instance: 6...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.204129471964119e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.023441234603524208
		 entropy bonus: 0.20665322244167328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021497711539268494
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.23581816256046295
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.204129471964119e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.204129471964119e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.023441234603524208
		 entropy bonus: 0.20665322244167328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021497711539268494
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.23581816256046295
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.204129471964119e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.204129471964119e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.023441234603524208
		 entropy bonus: 0.20665322244167328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.021497711539268494
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.23581816256046295
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.204129471964119e+17 - Differentiable computation graph = True!
PPO iteration: 487/1000:
	 start solving instance: 111...
	 start solving instance: 113...
	 start solving instance: 120...
	 start solving instance: 42...
	 start solving instance: 71...
	 start solving instance: 91...
	 start solving instance: 35...
	 start solving instance: 128...
	 start solving instance: 79...
	 start solving instance: 47...
	 start solving instance: 6...
	 start solving instance: 50...
	 start solving instance: 121...
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 7...
	 start solving instance: 9...
	 start solving instance: 57...
	 start solving instance: 41...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.6310819316574454e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01996704377233982
		 entropy bonus: 0.20747585594654083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.025934824720025063
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3314494788646698
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.6310820347366605e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.6310819316574454e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01996704377233982
		 entropy bonus: 0.20747585594654083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.025934824720025063
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3314494788646698
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.6310820347366605e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.6310819316574454e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.01996704377233982
		 entropy bonus: 0.20747585594654083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.025934824720025063
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.3314494788646698
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.6310820347366605e+17 - Differentiable computation graph = True!
PPO iteration: 488/1000:
	 start solving instance: 47...
	 start solving instance: 71...
	 start solving instance: 79...
	 start solving instance: 120...
	 start solving instance: 7...
	 start solving instance: 128...
	 start solving instance: 6...
	 start solving instance: 35...
	 start solving instance: 13...
	 start solving instance: 57...
	 start solving instance: 91...
	 start solving instance: 111...
	 start solving instance: 121...
	 start solving instance: 50...
	 start solving instance: 42...
	 start solving instance: 108...
	 start solving instance: 113...
	 start solving instance: 99...
	 start solving instance: 9...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.8844319506854052e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.033024679869413376
		 entropy bonus: 0.20244918763637543
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.018924398347735405
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1352509707212448
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.884432019404882e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.8844319506854052e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.033024679869413376
		 entropy bonus: 0.20244918763637543
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.018924398347735405
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1352509707212448
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.884432019404882e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.8844319506854052e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.033024679869413376
		 entropy bonus: 0.20244918763637543
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -0.018924398347735405
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.1352509707212448
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.884432019404882e+17 - Differentiable computation graph = True!
PPO iteration: 489/1000:
	 start solving instance: 6...
	 start solving instance: 35...
	 start solving instance: 41...
	 start solving instance: 99...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 113...
	 start solving instance: 47...
	 start solving instance: 13...
	 start solving instance: 128...
	 start solving instance: 108...
	 start solving instance: 91...
	 start solving instance: 71...
	 start solving instance: 111...
	 start solving instance: 120...
	 start solving instance: 42...
	 start solving instance: 9...
	 start solving instance: 121...
	 start solving instance: 7...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.099842243125051e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.061411794275045395
		 entropy bonus: 0.2164788693189621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14830143749713898
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0998424492834816e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.099842243125051e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.061411794275045395
		 entropy bonus: 0.2164788693189621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14830143749713898
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0998424492834816e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.099842243125051e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -0.061411794275045395
		 entropy bonus: 0.2164788693189621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.14830143749713898
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0998424492834816e+17 - Differentiable computation graph = True!
PPO iteration: 490/1000:
	 start solving instance: 42...
	 start solving instance: 7...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 128...
	 start solving instance: 111...
	 start solving instance: 9...
	 start solving instance: 47...
	 start solving instance: 71...
	 start solving instance: 6...
	 start solving instance: 13...
	 start solving instance: 120...
	 start solving instance: 99...
	 start solving instance: 35...
	 start solving instance: 108...
	 start solving instance: 121...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 57...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.061732400448196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20976011455059052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.061732620350521e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.061732400448196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20976011455059052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.061732620350521e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.061732400448196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20976011455059052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.061732620350521e+18 - Differentiable computation graph = True!
PPO iteration: 491/1000:
	 New training batch of size 20...
	 start solving instance: 107...
	 start solving instance: 34...
	 start solving instance: 40...
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 79...
	 start solving instance: 130...
	 start solving instance: 134...
	 start solving instance: 44...
	 start solving instance: 15...
	 start solving instance: 56...
	 start solving instance: 141...
	 start solving instance: 100...
	 start solving instance: 94...
	 start solving instance: 132...
	 start solving instance: 80...
	 start solving instance: 3...
	 start solving instance: 25...
	 start solving instance: 51...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.2147304388617568e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2194732427597046
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.214730438861757e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.2147304388617568e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2194732427597046
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.214730438861757e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.2147304388617568e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22213919460773468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.214730438861757e+19 - Differentiable computation graph = True!
PPO iteration: 492/1000:
	 start solving instance: 25...
	 start solving instance: 54...
	 start solving instance: 80...
	 start solving instance: 132...
	 start solving instance: 15...
	 start solving instance: 100...
	 start solving instance: 3...
	 start solving instance: 91...
	 start solving instance: 44...
	 start solving instance: 97...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 51...
	 start solving instance: 56...
	 start solving instance: 141...
	 start solving instance: 34...
	 start solving instance: 107...
	 start solving instance: 94...
	 start solving instance: 40...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.689268946217269e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2278260737657547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6892689901977338e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.689268946217269e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2278260737657547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6892689901977338e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.689268946217269e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2278260737657547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6892689901977338e+19 - Differentiable computation graph = True!
PPO iteration: 493/1000:
	 start solving instance: 94...
	 start solving instance: 100...
	 start solving instance: 15...
	 start solving instance: 80...
	 start solving instance: 51...
	 start solving instance: 44...
	 start solving instance: 97...
	 start solving instance: 56...
	 start solving instance: 54...
	 start solving instance: 91...
	 start solving instance: 34...
	 start solving instance: 40...
	 start solving instance: 3...
	 start solving instance: 132...
	 start solving instance: 141...
	 start solving instance: 79...
	 start solving instance: 130...
	 start solving instance: 134...
	 start solving instance: 107...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.622399659728437e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21114717423915863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.622399659728437e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.622399659728437e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20949681103229523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.622399659728437e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.622399659728437e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2110036462545395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.622399659728437e+19 - Differentiable computation graph = True!
PPO iteration: 494/1000:
	 start solving instance: 54...
	 start solving instance: 130...
	 start solving instance: 56...
	 start solving instance: 34...
	 start solving instance: 44...
	 start solving instance: 134...
	 start solving instance: 80...
	 start solving instance: 107...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 51...
	 start solving instance: 3...
	 start solving instance: 100...
	 start solving instance: 94...
	 start solving instance: 132...
	 start solving instance: 15...
	 start solving instance: 97...
	 start solving instance: 40...
	 start solving instance: 25...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.833295137872617e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22527599334716797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.833295225833547e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.833295137872617e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22794194519519806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.833295225833547e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.833295137872617e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22692635655403137
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.833295225833547e+19 - Differentiable computation graph = True!
PPO iteration: 495/1000:
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 107...
	 start solving instance: 40...
	 start solving instance: 34...
	 start solving instance: 97...
	 start solving instance: 100...
	 start solving instance: 80...
	 start solving instance: 132...
	 start solving instance: 91...
	 start solving instance: 51...
	 start solving instance: 141...
	 start solving instance: 15...
	 start solving instance: 94...
	 start solving instance: 130...
	 start solving instance: 56...
	 start solving instance: 3...
	 start solving instance: 134...
	 start solving instance: 54...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.153003564357323e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22844675183296204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.153003740279184e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.153003564357323e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22693991661071777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.153003740279184e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.153003564357323e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22528956830501556
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.153003740279184e+19 - Differentiable computation graph = True!
PPO iteration: 496/1000:
	 start solving instance: 91...
	 start solving instance: 34...
	 start solving instance: 44...
	 start solving instance: 56...
	 start solving instance: 40...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 25...
	 start solving instance: 132...
	 start solving instance: 141...
	 start solving instance: 134...
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 80...
	 start solving instance: 97...
	 start solving instance: 79...
	 start solving instance: 15...
	 start solving instance: 3...
	 start solving instance: 94...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.975166970384089e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21915876865386963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.975166970384089e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.975166970384089e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21915876865386963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.975166970384089e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.975166970384089e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21915876865386963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.975166970384089e+19 - Differentiable computation graph = True!
PPO iteration: 497/1000:
	 start solving instance: 80...
	 start solving instance: 132...
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 56...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 91...
	 start solving instance: 3...
	 start solving instance: 130...
	 start solving instance: 141...
	 start solving instance: 15...
	 start solving instance: 94...
	 start solving instance: 51...
	 start solving instance: 100...
	 start solving instance: 40...
	 start solving instance: 107...
	 start solving instance: 134...
	 start solving instance: 97...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.2206187795753153e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21345172822475433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.2206188675362456e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.2206187795753153e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21345172822475433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.2206188675362456e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.2206187795753153e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21345172822475433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.2206188675362456e+19 - Differentiable computation graph = True!
PPO iteration: 498/1000:
	 start solving instance: 3...
	 start solving instance: 91...
	 start solving instance: 141...
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 51...
	 start solving instance: 15...
	 start solving instance: 34...
	 start solving instance: 79...
	 start solving instance: 134...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 40...
	 start solving instance: 25...
	 start solving instance: 132...
	 start solving instance: 107...
	 start solving instance: 94...
	 start solving instance: 80...
	 start solving instance: 44...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0813080175081895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2264820635318756
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.08130810546912e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0813080175081895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2264820635318756
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.08130810546912e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0813080175081895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2264820635318756
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.08130810546912e+19 - Differentiable computation graph = True!
PPO iteration: 499/1000:
	 start solving instance: 97...
	 start solving instance: 54...
	 start solving instance: 134...
	 start solving instance: 3...
	 start solving instance: 100...
	 start solving instance: 130...
	 start solving instance: 15...
	 start solving instance: 56...
	 start solving instance: 79...
	 start solving instance: 132...
	 start solving instance: 107...
	 start solving instance: 34...
	 start solving instance: 80...
	 start solving instance: 94...
	 start solving instance: 44...
	 start solving instance: 51...
	 start solving instance: 91...
	 start solving instance: 40...
	 start solving instance: 25...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.1881970843828984e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23440098762512207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.188197348265689e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.1881970843828984e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23173503577709198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.188197348265689e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.1881970843828984e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23173503577709198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.188197348265689e+19 - Differentiable computation graph = True!
PPO iteration: 500/1000:
	 start solving instance: 25...
	 start solving instance: 100...
	 start solving instance: 134...
	 start solving instance: 130...
	 start solving instance: 107...
	 start solving instance: 79...
	 start solving instance: 141...
	 start solving instance: 34...
	 start solving instance: 3...
	 start solving instance: 40...
	 start solving instance: 54...
	 start solving instance: 56...
	 start solving instance: 97...
	 start solving instance: 94...
	 start solving instance: 132...
	 start solving instance: 15...
	 start solving instance: 51...
	 start solving instance: 44...
	 start solving instance: 91...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.933077665272824e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2161543369293213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.933077665272824e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.933077665272824e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2161543369293213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.933077665272824e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.933077665272824e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21930502355098724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.933077665272824e+19 - Differentiable computation graph = True!
PPO iteration: 501/1000:
	 New training batch of size 20...
	 start solving instance: 59...
	 start solving instance: 50...
	 start solving instance: 111...
	 start solving instance: 101...
	 start solving instance: 138...
	 start solving instance: 92...
	 start solving instance: 2...
	 start solving instance: 49...
	 start solving instance: 132...
	 start solving instance: 1...
	 start solving instance: 98...
	 start solving instance: 110...
	 start solving instance: 5...
	 start solving instance: 149...
	 start solving instance: 129...
	 start solving instance: 128...
	 start solving instance: 57...
	 start solving instance: 48...
	 start solving instance: 134...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.143534042453335e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22567692399024963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.143534306336126e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.143534042453335e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22567692399024963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.143534306336126e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.143534042453335e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22347645461559296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.143534306336126e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.6676713912951374e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21330778300762177
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46676713912951373824.0000
PPO iteration: 502/1000:
	 start solving instance: 2...
	 start solving instance: 110...
	 start solving instance: 92...
	 start solving instance: 149...
	 start solving instance: 129...
	 start solving instance: 57...
	 start solving instance: 50...
	 start solving instance: 111...
	 start solving instance: 90...
	 start solving instance: 49...
	 start solving instance: 138...
	 start solving instance: 128...
	 start solving instance: 134...
	 start solving instance: 1...
	 start solving instance: 48...
	 start solving instance: 101...
	 start solving instance: 59...
	 start solving instance: 98...
	 start solving instance: 132...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.308104720774196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2125595062971115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.308104808735126e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.308104720774196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2125595062971115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.308104808735126e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.308104720774196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2152254581451416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.308104808735126e+19 - Differentiable computation graph = True!
PPO iteration: 503/1000:
	 start solving instance: 138...
	 start solving instance: 50...
	 start solving instance: 128...
	 start solving instance: 48...
	 start solving instance: 149...
	 start solving instance: 49...
	 start solving instance: 92...
	 start solving instance: 101...
	 start solving instance: 98...
	 start solving instance: 1...
	 start solving instance: 111...
	 start solving instance: 57...
	 start solving instance: 5...
	 start solving instance: 110...
	 start solving instance: 59...
	 start solving instance: 129...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 2...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.4233697792683724e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21848396956920624
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.423369691307442e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.4233697792683724e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22079448401927948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.423369691307442e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.4233697792683724e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2159871608018875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.423369691307442e+19 - Differentiable computation graph = True!
PPO iteration: 504/1000:
	 start solving instance: 59...
	 start solving instance: 138...
	 start solving instance: 49...
	 start solving instance: 50...
	 start solving instance: 110...
	 start solving instance: 2...
	 start solving instance: 129...
	 start solving instance: 149...
	 start solving instance: 57...
	 start solving instance: 101...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 111...
	 start solving instance: 134...
	 start solving instance: 132...
	 start solving instance: 5...
	 start solving instance: 1...
	 start solving instance: 90...
	 start solving instance: 92...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.265369078747659e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23545995354652405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.265368990786729e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.265369078747659e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23545995354652405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.265368990786729e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.265369078747659e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23160913586616516
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.265368990786729e+19 - Differentiable computation graph = True!
PPO iteration: 505/1000:
	 start solving instance: 90...
	 start solving instance: 49...
	 start solving instance: 111...
	 start solving instance: 50...
	 start solving instance: 59...
	 start solving instance: 138...
	 start solving instance: 149...
	 start solving instance: 134...
	 start solving instance: 92...
	 start solving instance: 48...
	 start solving instance: 132...
	 start solving instance: 101...
	 start solving instance: 5...
	 start solving instance: 128...
	 start solving instance: 57...
	 start solving instance: 2...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 110...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.7343827400350446e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2250024825334549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.734382827995975e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.7343827400350446e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22185181081295013
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.734382827995975e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.7343827400350446e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2250024825334549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.734382827995975e+19 - Differentiable computation graph = True!
PPO iteration: 506/1000:
	 start solving instance: 138...
	 start solving instance: 49...
	 start solving instance: 92...
	 start solving instance: 101...
	 start solving instance: 2...
	 start solving instance: 149...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 57...
	 start solving instance: 110...
	 start solving instance: 111...
	 start solving instance: 132...
	 start solving instance: 5...
	 start solving instance: 59...
	 start solving instance: 50...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 90...
	 start solving instance: 48...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.037492567102246e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21431055665016174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.037492567102246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.037492567102246e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21697650849819183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.037492567102246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.037492567102246e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21697650849819183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.037492567102246e+19 - Differentiable computation graph = True!
PPO iteration: 507/1000:
	 start solving instance: 92...
	 start solving instance: 111...
	 start solving instance: 50...
	 start solving instance: 49...
	 start solving instance: 57...
	 start solving instance: 59...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 138...
	 start solving instance: 98...
	 start solving instance: 2...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 101...
	 start solving instance: 110...
	 start solving instance: 132...
	 start solving instance: 149...
	 start solving instance: 48...
	 start solving instance: 1...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.20288831894859e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2212756872177124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.202888582831381e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.20288831894859e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22192950546741486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.202888582831381e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.20288831894859e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22442637383937836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.202888582831381e+19 - Differentiable computation graph = True!
PPO iteration: 508/1000:
	 start solving instance: 132...
	 start solving instance: 48...
	 start solving instance: 49...
	 start solving instance: 101...
	 start solving instance: 149...
	 start solving instance: 129...
	 start solving instance: 2...
	 start solving instance: 1...
	 start solving instance: 50...
	 start solving instance: 110...
	 start solving instance: 98...
	 start solving instance: 134...
	 start solving instance: 128...
	 start solving instance: 59...
	 start solving instance: 90...
	 start solving instance: 111...
	 start solving instance: 57...
	 start solving instance: 5...
	 start solving instance: 92...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.148048901079774e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22027340531349182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.148048901079774e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.148048901079774e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22027340531349182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.148048901079774e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.148048901079774e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22412419319152832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.148048901079774e+19 - Differentiable computation graph = True!
PPO iteration: 509/1000:
	 start solving instance: 57...
	 start solving instance: 132...
	 start solving instance: 48...
	 start solving instance: 50...
	 start solving instance: 98...
	 start solving instance: 90...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 5...
	 start solving instance: 128...
	 start solving instance: 149...
	 start solving instance: 129...
	 start solving instance: 2...
	 start solving instance: 49...
	 start solving instance: 1...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 101...
	 start solving instance: 110...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.213089323948305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2290606051683426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.2130894119092355e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.213089323948305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2290606051683426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.2130894119092355e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.213089323948305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22656376659870148
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.2130894119092355e+19 - Differentiable computation graph = True!
PPO iteration: 510/1000:
	 start solving instance: 129...
	 start solving instance: 138...
	 start solving instance: 48...
	 start solving instance: 110...
	 start solving instance: 98...
	 start solving instance: 132...
	 start solving instance: 59...
	 start solving instance: 101...
	 start solving instance: 1...
	 start solving instance: 50...
	 start solving instance: 90...
	 start solving instance: 92...
	 start solving instance: 134...
	 start solving instance: 57...
	 start solving instance: 149...
	 start solving instance: 128...
	 start solving instance: 49...
	 start solving instance: 5...
	 start solving instance: 2...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.921379565240729e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21918316185474396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.921379741162589e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.921379565240729e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21651721000671387
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.921379741162589e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.921379565240729e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21918316185474396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.921379741162589e+19 - Differentiable computation graph = True!
PPO iteration: 511/1000:
	 New training batch of size 20...
	 start solving instance: 97...
	 start solving instance: 66...
	 start solving instance: 58...
	 start solving instance: 14...
	 start solving instance: 119...
	 start solving instance: 21...
	 start solving instance: 144...
	 start solving instance: 63...
	 start solving instance: 91...
	 start solving instance: 123...
	 start solving instance: 27...
	 start solving instance: 145...
	 start solving instance: 16...
	 start solving instance: 99...
	 start solving instance: 104...
	 start solving instance: 72...
	 start solving instance: 59...
	 start solving instance: 111...
	 start solving instance: 150...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3707744006105045e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22456255555152893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370774664493295e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3707744006105045e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22456255555152893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370774664493295e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3707744006105045e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22456255555152893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370774664493295e+19 - Differentiable computation graph = True!
PPO iteration: 512/1000:
	 start solving instance: 72...
	 start solving instance: 58...
	 start solving instance: 91...
	 start solving instance: 16...
	 start solving instance: 99...
	 start solving instance: 39...
	 start solving instance: 123...
	 start solving instance: 66...
	 start solving instance: 59...
	 start solving instance: 63...
	 start solving instance: 119...
	 start solving instance: 21...
	 start solving instance: 150...
	 start solving instance: 27...
	 start solving instance: 145...
	 start solving instance: 14...
	 start solving instance: 97...
	 start solving instance: 111...
	 start solving instance: 144...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.266329240221086e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20242170989513397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.266329416142946e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.266329240221086e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20242170989513397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.266329416142946e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.266329240221086e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20242170989513397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.266329416142946e+19 - Differentiable computation graph = True!
PPO iteration: 513/1000:
	 start solving instance: 63...
	 start solving instance: 111...
	 start solving instance: 59...
	 start solving instance: 91...
	 start solving instance: 144...
	 start solving instance: 97...
	 start solving instance: 72...
	 start solving instance: 58...
	 start solving instance: 14...
	 start solving instance: 145...
	 start solving instance: 150...
	 start solving instance: 99...
	 start solving instance: 119...
	 start solving instance: 66...
	 start solving instance: 123...
	 start solving instance: 27...
	 start solving instance: 16...
	 start solving instance: 39...
	 start solving instance: 104...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.376694874901892e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20864228904247284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376694874901892e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.376694874901892e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20864228904247284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376694874901892e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.376694874901892e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20647621154785156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376694874901892e+19 - Differentiable computation graph = True!
PPO iteration: 514/1000:
	 start solving instance: 145...
	 start solving instance: 21...
	 start solving instance: 111...
	 start solving instance: 16...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 39...
	 start solving instance: 63...
	 start solving instance: 123...
	 start solving instance: 97...
	 start solving instance: 58...
	 start solving instance: 66...
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 144...
	 start solving instance: 119...
	 start solving instance: 99...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2467058603759816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21633079648017883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246705772415051e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2467058603759816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21825622022151947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246705772415051e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2467058603759816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21633079648017883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246705772415051e+19 - Differentiable computation graph = True!
PPO iteration: 515/1000:
	 start solving instance: 63...
	 start solving instance: 72...
	 start solving instance: 119...
	 start solving instance: 91...
	 start solving instance: 59...
	 start solving instance: 104...
	 start solving instance: 145...
	 start solving instance: 97...
	 start solving instance: 16...
	 start solving instance: 144...
	 start solving instance: 99...
	 start solving instance: 27...
	 start solving instance: 123...
	 start solving instance: 66...
	 start solving instance: 21...
	 start solving instance: 14...
	 start solving instance: 111...
	 start solving instance: 39...
	 start solving instance: 150...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.497670708829807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20651821792125702
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497670620868877e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.497670708829807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20651821792125702
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497670620868877e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.497670708829807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20651821792125702
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497670620868877e+19 - Differentiable computation graph = True!
PPO iteration: 516/1000:
	 start solving instance: 97...
	 start solving instance: 104...
	 start solving instance: 16...
	 start solving instance: 72...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 27...
	 start solving instance: 66...
	 start solving instance: 21...
	 start solving instance: 63...
	 start solving instance: 91...
	 start solving instance: 99...
	 start solving instance: 14...
	 start solving instance: 145...
	 start solving instance: 58...
	 start solving instance: 111...
	 start solving instance: 39...
	 start solving instance: 144...
	 start solving instance: 119...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.487542535480316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20927970111370087
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.487542799363106e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.487542535480316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2112051099538803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.487542799363106e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.487542535480316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20927970111370087
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.487542799363106e+19 - Differentiable computation graph = True!
PPO iteration: 517/1000:
	 start solving instance: 14...
	 start solving instance: 111...
	 start solving instance: 58...
	 start solving instance: 59...
	 start solving instance: 66...
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 39...
	 start solving instance: 123...
	 start solving instance: 145...
	 start solving instance: 144...
	 start solving instance: 21...
	 start solving instance: 150...
	 start solving instance: 63...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 16...
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.314524793108368e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21566224098205566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.314524969030228e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.314524793108368e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2168547660112381
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.314524969030228e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.314524793108368e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21566224098205566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.314524969030228e+19 - Differentiable computation graph = True!
PPO iteration: 518/1000:
	 start solving instance: 63...
	 start solving instance: 145...
	 start solving instance: 91...
	 start solving instance: 111...
	 start solving instance: 39...
	 start solving instance: 104...
	 start solving instance: 97...
	 start solving instance: 123...
	 start solving instance: 27...
	 start solving instance: 72...
	 start solving instance: 59...
	 start solving instance: 119...
	 start solving instance: 99...
	 start solving instance: 14...
	 start solving instance: 144...
	 start solving instance: 21...
	 start solving instance: 66...
	 start solving instance: 58...
	 start solving instance: 150...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.495921693693271e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2147386074066162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495921957576062e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.495921693693271e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2169046849012375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495921957576062e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.495921693693271e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2147386074066162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495921957576062e+19 - Differentiable computation graph = True!
PPO iteration: 519/1000:
	 start solving instance: 63...
	 start solving instance: 144...
	 start solving instance: 58...
	 start solving instance: 39...
	 start solving instance: 21...
	 start solving instance: 14...
	 start solving instance: 150...
	 start solving instance: 145...
	 start solving instance: 59...
	 start solving instance: 111...
	 start solving instance: 72...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 16...
	 start solving instance: 91...
	 start solving instance: 99...
	 start solving instance: 66...
	 start solving instance: 119...
	 start solving instance: 123...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.37449972192727e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2118285745382309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3744998098882e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.37449972192727e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20990315079689026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3744998098882e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.37449972192727e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2118285745382309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3744998098882e+19 - Differentiable computation graph = True!
PPO iteration: 520/1000:
	 start solving instance: 59...
	 start solving instance: 27...
	 start solving instance: 97...
	 start solving instance: 144...
	 start solving instance: 99...
	 start solving instance: 145...
	 start solving instance: 16...
	 start solving instance: 111...
	 start solving instance: 21...
	 start solving instance: 58...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 63...
	 start solving instance: 72...
	 start solving instance: 123...
	 start solving instance: 150...
	 start solving instance: 39...
	 start solving instance: 119...
	 start solving instance: 66...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.480003228229121e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21745304763317108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480003228229121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.480003228229121e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21745304763317108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480003228229121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.480003228229121e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21852007508277893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480003228229121e+19 - Differentiable computation graph = True!
PPO iteration: 521/1000:
	 New training batch of size 20...
	 start solving instance: 149...
	 start solving instance: 16...
	 start solving instance: 24...
	 start solving instance: 38...
	 start solving instance: 23...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 96...
	 start solving instance: 70...
	 start solving instance: 108...
	 start solving instance: 106...
	 start solving instance: 114...
	 start solving instance: 93...
	 start solving instance: 30...
	 start solving instance: 58...
	 start solving instance: 2...
	 start solving instance: 118...
	 start solving instance: 34...
	 start solving instance: 61...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.819947242633277e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21269527077674866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.819947154672347e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.819947242633277e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21269527077674866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.819947154672347e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.819947242633277e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21269527077674866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.819947154672347e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.679269215866779e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2058875560760498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46792694797495697408.0000
PPO iteration: 522/1000:
	 start solving instance: 58...
	 start solving instance: 114...
	 start solving instance: 16...
	 start solving instance: 34...
	 start solving instance: 61...
	 start solving instance: 42...
	 start solving instance: 2...
	 start solving instance: 108...
	 start solving instance: 96...
	 start solving instance: 149...
	 start solving instance: 38...
	 start solving instance: 70...
	 start solving instance: 30...
	 start solving instance: 105...
	 start solving instance: 118...
	 start solving instance: 24...
	 start solving instance: 23...
	 start solving instance: 106...
	 start solving instance: 93...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.98519205352336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21849560737609863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.985192317406151e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.98519205352336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21849560737609863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.985192317406151e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.98519205352336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21849560737609863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.985192317406151e+19 - Differentiable computation graph = True!
PPO iteration: 523/1000:
	 start solving instance: 149...
	 start solving instance: 42...
	 start solving instance: 2...
	 start solving instance: 70...
	 start solving instance: 30...
	 start solving instance: 105...
	 start solving instance: 58...
	 start solving instance: 118...
	 start solving instance: 16...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 24...
	 start solving instance: 148...
	 start solving instance: 106...
	 start solving instance: 108...
	 start solving instance: 23...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 38...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.738284666858819e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22100701928138733
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738284666858819e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.738284666858819e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22100701928138733
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738284666858819e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.738284666858819e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22100701928138733
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738284666858819e+19 - Differentiable computation graph = True!
PPO iteration: 524/1000:
	 start solving instance: 61...
	 start solving instance: 38...
	 start solving instance: 34...
	 start solving instance: 96...
	 start solving instance: 149...
	 start solving instance: 30...
	 start solving instance: 2...
	 start solving instance: 148...
	 start solving instance: 58...
	 start solving instance: 24...
	 start solving instance: 114...
	 start solving instance: 118...
	 start solving instance: 108...
	 start solving instance: 23...
	 start solving instance: 16...
	 start solving instance: 42...
	 start solving instance: 106...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 70...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.73847536615554e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22847726941108704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738475542077401e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.73847536615554e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22847726941108704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738475542077401e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.73847536615554e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22847726941108704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738475542077401e+19 - Differentiable computation graph = True!
PPO iteration: 525/1000:
	 start solving instance: 23...
	 start solving instance: 58...
	 start solving instance: 96...
	 start solving instance: 118...
	 start solving instance: 42...
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 149...
	 start solving instance: 2...
	 start solving instance: 70...
	 start solving instance: 24...
	 start solving instance: 114...
	 start solving instance: 105...
	 start solving instance: 106...
	 start solving instance: 38...
	 start solving instance: 93...
	 start solving instance: 61...
	 start solving instance: 16...
	 start solving instance: 30...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9427885519693414e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22807292640209198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9427885519693414e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9427885519693414e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22807292640209198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9427885519693414e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9427885519693414e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22807292640209198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9427885519693414e+19 - Differentiable computation graph = True!
PPO iteration: 526/1000:
	 start solving instance: 93...
	 start solving instance: 16...
	 start solving instance: 70...
	 start solving instance: 149...
	 start solving instance: 38...
	 start solving instance: 2...
	 start solving instance: 24...
	 start solving instance: 58...
	 start solving instance: 42...
	 start solving instance: 106...
	 start solving instance: 148...
	 start solving instance: 96...
	 start solving instance: 30...
	 start solving instance: 114...
	 start solving instance: 105...
	 start solving instance: 61...
	 start solving instance: 23...
	 start solving instance: 34...
	 start solving instance: 118...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8536679448432135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22012631595134735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853667856882283e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8536679448432135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22012631595134735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853667856882283e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8536679448432135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22012631595134735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853667856882283e+19 - Differentiable computation graph = True!
PPO iteration: 527/1000:
	 start solving instance: 34...
	 start solving instance: 23...
	 start solving instance: 16...
	 start solving instance: 118...
	 start solving instance: 149...
	 start solving instance: 96...
	 start solving instance: 93...
	 start solving instance: 58...
	 start solving instance: 148...
	 start solving instance: 70...
	 start solving instance: 38...
	 start solving instance: 108...
	 start solving instance: 106...
	 start solving instance: 114...
	 start solving instance: 24...
	 start solving instance: 105...
	 start solving instance: 30...
	 start solving instance: 2...
	 start solving instance: 42...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.652566740357402e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22325554490089417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652566740357402e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.652566740357402e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22325554490089417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652566740357402e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.652566740357402e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22325554490089417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652566740357402e+19 - Differentiable computation graph = True!
PPO iteration: 528/1000:
	 start solving instance: 38...
	 start solving instance: 2...
	 start solving instance: 108...
	 start solving instance: 114...
	 start solving instance: 42...
	 start solving instance: 23...
	 start solving instance: 58...
	 start solving instance: 118...
	 start solving instance: 61...
	 start solving instance: 105...
	 start solving instance: 24...
	 start solving instance: 148...
	 start solving instance: 34...
	 start solving instance: 16...
	 start solving instance: 70...
	 start solving instance: 149...
	 start solving instance: 96...
	 start solving instance: 93...
	 start solving instance: 30...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8294600413149345e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2216600924730301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.829460129275865e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8294600413149345e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2216600924730301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.829460129275865e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8294600413149345e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2216600924730301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.829460129275865e+19 - Differentiable computation graph = True!
PPO iteration: 529/1000:
	 start solving instance: 23...
	 start solving instance: 114...
	 start solving instance: 16...
	 start solving instance: 105...
	 start solving instance: 96...
	 start solving instance: 58...
	 start solving instance: 34...
	 start solving instance: 108...
	 start solving instance: 149...
	 start solving instance: 42...
	 start solving instance: 106...
	 start solving instance: 61...
	 start solving instance: 2...
	 start solving instance: 38...
	 start solving instance: 118...
	 start solving instance: 93...
	 start solving instance: 148...
	 start solving instance: 30...
	 start solving instance: 70...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0137079315701957e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20791219174861908
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.013707931570196e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0137079315701957e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20791219174861908
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.013707931570196e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0137079315701957e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20791219174861908
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.013707931570196e+19 - Differentiable computation graph = True!
PPO iteration: 530/1000:
	 start solving instance: 148...
	 start solving instance: 30...
	 start solving instance: 106...
	 start solving instance: 61...
	 start solving instance: 34...
	 start solving instance: 114...
	 start solving instance: 38...
	 start solving instance: 108...
	 start solving instance: 70...
	 start solving instance: 105...
	 start solving instance: 16...
	 start solving instance: 96...
	 start solving instance: 2...
	 start solving instance: 149...
	 start solving instance: 24...
	 start solving instance: 42...
	 start solving instance: 118...
	 start solving instance: 23...
	 start solving instance: 58...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.841555372907912e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20871825516223907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.841555636790703e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.841555372907912e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20871825516223907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.841555636790703e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.841555372907912e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20871825516223907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.841555636790703e+19 - Differentiable computation graph = True!
PPO iteration: 531/1000:
	 New training batch of size 20...
	 start solving instance: 112...
	 start solving instance: 72...
	 start solving instance: 99...
	 start solving instance: 146...
	 start solving instance: 69...
	 start solving instance: 40...
	 start solving instance: 137...
	 start solving instance: 102...
	 start solving instance: 124...
	 start solving instance: 29...
	 start solving instance: 135...
	 start solving instance: 3...
	 start solving instance: 143...
	 start solving instance: 142...
	 start solving instance: 26...
	 start solving instance: 51...
	 start solving instance: 133...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3746622737263205e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19629697501659393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.374662537609111e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3746622737263205e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19629697501659393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.374662537609111e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3746622737263205e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19629697501659393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.374662537609111e+19 - Differentiable computation graph = True!
PPO iteration: 532/1000:
	 start solving instance: 99...
	 start solving instance: 142...
	 start solving instance: 51...
	 start solving instance: 72...
	 start solving instance: 3...
	 start solving instance: 146...
	 start solving instance: 112...
	 start solving instance: 137...
	 start solving instance: 45...
	 start solving instance: 135...
	 start solving instance: 40...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 29...
	 start solving instance: 69...
	 start solving instance: 133...
	 start solving instance: 26...
	 start solving instance: 124...
	 start solving instance: 143...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6466603398148496e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19834297895431519
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64666060369764e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6466603398148496e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19834297895431519
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64666060369764e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6466603398148496e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19834297895431519
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64666060369764e+19 - Differentiable computation graph = True!
PPO iteration: 533/1000:
	 start solving instance: 69...
	 start solving instance: 18...
	 start solving instance: 3...
	 start solving instance: 143...
	 start solving instance: 45...
	 start solving instance: 72...
	 start solving instance: 137...
	 start solving instance: 51...
	 start solving instance: 102...
	 start solving instance: 124...
	 start solving instance: 26...
	 start solving instance: 89...
	 start solving instance: 29...
	 start solving instance: 146...
	 start solving instance: 133...
	 start solving instance: 142...
	 start solving instance: 40...
	 start solving instance: 99...
	 start solving instance: 112...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5876867582255956e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20853853225708008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.587686758225596e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5876867582255956e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21120451390743256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.587686758225596e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5876867582255956e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20853853225708008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.587686758225596e+19 - Differentiable computation graph = True!
PPO iteration: 534/1000:
	 start solving instance: 143...
	 start solving instance: 99...
	 start solving instance: 40...
	 start solving instance: 45...
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 137...
	 start solving instance: 102...
	 start solving instance: 89...
	 start solving instance: 124...
	 start solving instance: 72...
	 start solving instance: 26...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 69...
	 start solving instance: 18...
	 start solving instance: 29...
	 start solving instance: 51...
	 start solving instance: 142...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6011613172044556e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2076447308063507
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601161493126316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6011613172044556e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2076447308063507
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601161493126316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6011613172044556e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20929506421089172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601161493126316e+19 - Differentiable computation graph = True!
PPO iteration: 535/1000:
	 start solving instance: 133...
	 start solving instance: 72...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 99...
	 start solving instance: 137...
	 start solving instance: 112...
	 start solving instance: 142...
	 start solving instance: 143...
	 start solving instance: 29...
	 start solving instance: 18...
	 start solving instance: 45...
	 start solving instance: 51...
	 start solving instance: 69...
	 start solving instance: 102...
	 start solving instance: 26...
	 start solving instance: 146...
	 start solving instance: 135...
	 start solving instance: 3...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5283289632931316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2034141570329666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5283289632931316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5283289632931316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20656482875347137
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5283289632931316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5283289632931316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2034141570329666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5283289632931316e+19 - Differentiable computation graph = True!
PPO iteration: 536/1000:
	 start solving instance: 142...
	 start solving instance: 3...
	 start solving instance: 112...
	 start solving instance: 26...
	 start solving instance: 133...
	 start solving instance: 124...
	 start solving instance: 99...
	 start solving instance: 29...
	 start solving instance: 102...
	 start solving instance: 146...
	 start solving instance: 143...
	 start solving instance: 45...
	 start solving instance: 89...
	 start solving instance: 18...
	 start solving instance: 135...
	 start solving instance: 51...
	 start solving instance: 69...
	 start solving instance: 137...
	 start solving instance: 72...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.70939126049947e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20097331702709198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.70939126049947e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.70939126049947e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20097331702709198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.70939126049947e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.70939126049947e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19830738008022308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.70939126049947e+19 - Differentiable computation graph = True!
PPO iteration: 537/1000:
	 start solving instance: 51...
	 start solving instance: 72...
	 start solving instance: 133...
	 start solving instance: 29...
	 start solving instance: 45...
	 start solving instance: 112...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 40...
	 start solving instance: 135...
	 start solving instance: 99...
	 start solving instance: 102...
	 start solving instance: 146...
	 start solving instance: 124...
	 start solving instance: 137...
	 start solving instance: 69...
	 start solving instance: 143...
	 start solving instance: 3...
	 start solving instance: 142...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.461178181786712e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2021687775850296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.461178269747642e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.461178181786712e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2021687775850296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.461178269747642e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.461178181786712e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20367561280727386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.461178269747642e+19 - Differentiable computation graph = True!
PPO iteration: 538/1000:
	 start solving instance: 112...
	 start solving instance: 3...
	 start solving instance: 29...
	 start solving instance: 69...
	 start solving instance: 40...
	 start solving instance: 124...
	 start solving instance: 18...
	 start solving instance: 26...
	 start solving instance: 133...
	 start solving instance: 51...
	 start solving instance: 72...
	 start solving instance: 143...
	 start solving instance: 102...
	 start solving instance: 146...
	 start solving instance: 45...
	 start solving instance: 137...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 135...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.344799889759645e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19249828159809113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.344799801798715e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.344799889759645e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19249828159809113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.344799801798715e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.344799889759645e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19249828159809113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.344799801798715e+19 - Differentiable computation graph = True!
PPO iteration: 539/1000:
	 start solving instance: 29...
	 start solving instance: 45...
	 start solving instance: 40...
	 start solving instance: 99...
	 start solving instance: 102...
	 start solving instance: 89...
	 start solving instance: 143...
	 start solving instance: 124...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 18...
	 start solving instance: 3...
	 start solving instance: 72...
	 start solving instance: 133...
	 start solving instance: 137...
	 start solving instance: 51...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 69...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.509820928043243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20450715720653534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.509821103965104e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.509820928043243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2060139924287796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.509821103965104e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.509820928043243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20717310905456543
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.509821103965104e+19 - Differentiable computation graph = True!
PPO iteration: 540/1000:
	 start solving instance: 29...
	 start solving instance: 146...
	 start solving instance: 137...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 143...
	 start solving instance: 3...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 89...
	 start solving instance: 99...
	 start solving instance: 72...
	 start solving instance: 18...
	 start solving instance: 69...
	 start solving instance: 51...
	 start solving instance: 45...
	 start solving instance: 133...
	 start solving instance: 142...
	 start solving instance: 112...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.61864583907028e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20362558960914612
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.61864592703121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.61864583907028e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20211875438690186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.61864592703121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.61864583907028e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20211875438690186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.61864592703121e+19 - Differentiable computation graph = True!
PPO iteration: 541/1000:
	 New training batch of size 20...
	 start solving instance: 123...
	 start solving instance: 94...
	 start solving instance: 28...
	 start solving instance: 36...
	 start solving instance: 116...
	 start solving instance: 113...
	 start solving instance: 26...
	 start solving instance: 143...
	 start solving instance: 101...
	 start solving instance: 34...
	 start solving instance: 40...
	 start solving instance: 80...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 89...
	 start solving instance: 58...
	 start solving instance: 53...
	 start solving instance: 65...
	 start solving instance: 60...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4486567674477386e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20031335949897766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.448657031330529e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4486567674477386e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20031335949897766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.448657031330529e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4486567674477386e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20213742554187775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.448657031330529e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.405970383542126e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396216213703156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 44059704715030560768.0000
PPO iteration: 542/1000:
	 start solving instance: 26...
	 start solving instance: 58...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 36...
	 start solving instance: 122...
	 start solving instance: 28...
	 start solving instance: 80...
	 start solving instance: 143...
	 start solving instance: 123...
	 start solving instance: 65...
	 start solving instance: 60...
	 start solving instance: 101...
	 start solving instance: 116...
	 start solving instance: 34...
	 start solving instance: 94...
	 start solving instance: 89...
	 start solving instance: 39...
	 start solving instance: 113...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2964168041691297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20282121002674103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.29641689213006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2964168041691297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20282121002674103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.29641689213006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2964168041691297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20282121002674103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.29641689213006e+19 - Differentiable computation graph = True!
PPO iteration: 543/1000:
	 start solving instance: 101...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 89...
	 start solving instance: 123...
	 start solving instance: 60...
	 start solving instance: 143...
	 start solving instance: 94...
	 start solving instance: 122...
	 start solving instance: 34...
	 start solving instance: 113...
	 start solving instance: 80...
	 start solving instance: 53...
	 start solving instance: 65...
	 start solving instance: 39...
	 start solving instance: 58...
	 start solving instance: 116...
	 start solving instance: 40...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.355716544887647e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20021842420101166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.355716632848577e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.355716544887647e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20021842420101166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.355716632848577e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.355716544887647e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19839434325695038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.355716632848577e+19 - Differentiable computation graph = True!
PPO iteration: 544/1000:
	 start solving instance: 101...
	 start solving instance: 58...
	 start solving instance: 123...
	 start solving instance: 39...
	 start solving instance: 40...
	 start solving instance: 122...
	 start solving instance: 94...
	 start solving instance: 143...
	 start solving instance: 90...
	 start solving instance: 26...
	 start solving instance: 116...
	 start solving instance: 60...
	 start solving instance: 89...
	 start solving instance: 113...
	 start solving instance: 65...
	 start solving instance: 80...
	 start solving instance: 28...
	 start solving instance: 34...
	 start solving instance: 53...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3226829934646054e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20677022635936737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.322682905503675e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3226829934646054e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20677022635936737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.322682905503675e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3226829934646054e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20677022635936737
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.322682905503675e+19 - Differentiable computation graph = True!
PPO iteration: 545/1000:
	 start solving instance: 123...
	 start solving instance: 101...
	 start solving instance: 58...
	 start solving instance: 65...
	 start solving instance: 90...
	 start solving instance: 94...
	 start solving instance: 53...
	 start solving instance: 113...
	 start solving instance: 34...
	 start solving instance: 122...
	 start solving instance: 26...
	 start solving instance: 80...
	 start solving instance: 39...
	 start solving instance: 60...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 89...
	 start solving instance: 116...
	 start solving instance: 40...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.288469358201704e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20302192866802216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.288469622084495e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.288469358201704e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20302192866802216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.288469622084495e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.288469358201704e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20302192866802216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.288469622084495e+19 - Differentiable computation graph = True!
PPO iteration: 546/1000:
	 start solving instance: 94...
	 start solving instance: 90...
	 start solving instance: 34...
	 start solving instance: 89...
	 start solving instance: 39...
	 start solving instance: 28...
	 start solving instance: 60...
	 start solving instance: 116...
	 start solving instance: 36...
	 start solving instance: 53...
	 start solving instance: 122...
	 start solving instance: 65...
	 start solving instance: 40...
	 start solving instance: 143...
	 start solving instance: 113...
	 start solving instance: 123...
	 start solving instance: 101...
	 start solving instance: 80...
	 start solving instance: 58...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.246541549358327e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19638514518737793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246541725280187e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.246541549358327e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19638514518737793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246541725280187e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.246541549358327e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19638514518737793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246541725280187e+19 - Differentiable computation graph = True!
PPO iteration: 547/1000:
	 start solving instance: 60...
	 start solving instance: 39...
	 start solving instance: 36...
	 start solving instance: 113...
	 start solving instance: 123...
	 start solving instance: 116...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 94...
	 start solving instance: 122...
	 start solving instance: 26...
	 start solving instance: 40...
	 start solving instance: 53...
	 start solving instance: 101...
	 start solving instance: 28...
	 start solving instance: 65...
	 start solving instance: 80...
	 start solving instance: 58...
	 start solving instance: 143...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.241182617645477e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396743714809418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.241182705606407e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.241182617645477e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396743714809418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.241182705606407e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.241182617645477e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396743714809418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.241182705606407e+19 - Differentiable computation graph = True!
PPO iteration: 548/1000:
	 start solving instance: 65...
	 start solving instance: 89...
	 start solving instance: 60...
	 start solving instance: 143...
	 start solving instance: 36...
	 start solving instance: 123...
	 start solving instance: 113...
	 start solving instance: 53...
	 start solving instance: 80...
	 start solving instance: 58...
	 start solving instance: 28...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 94...
	 start solving instance: 26...
	 start solving instance: 101...
	 start solving instance: 116...
	 start solving instance: 122...
	 start solving instance: 34...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.550836757962078e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2058345079421997
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5508368459230085e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.550836757962078e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2058345079421997
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5508368459230085e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.550836757962078e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2058345079421997
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5508368459230085e+19 - Differentiable computation graph = True!
PPO iteration: 549/1000:
	 start solving instance: 116...
	 start solving instance: 94...
	 start solving instance: 89...
	 start solving instance: 123...
	 start solving instance: 39...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 26...
	 start solving instance: 143...
	 start solving instance: 53...
	 start solving instance: 101...
	 start solving instance: 113...
	 start solving instance: 28...
	 start solving instance: 65...
	 start solving instance: 36...
	 start solving instance: 60...
	 start solving instance: 40...
	 start solving instance: 58...
	 start solving instance: 122...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2244798925274664e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20866601169109344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224479804566536e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2244798925274664e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20866601169109344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224479804566536e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2244798925274664e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20866601169109344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224479804566536e+19 - Differentiable computation graph = True!
PPO iteration: 550/1000:
	 start solving instance: 39...
	 start solving instance: 143...
	 start solving instance: 89...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 123...
	 start solving instance: 113...
	 start solving instance: 94...
	 start solving instance: 34...
	 start solving instance: 58...
	 start solving instance: 65...
	 start solving instance: 53...
	 start solving instance: 40...
	 start solving instance: 90...
	 start solving instance: 116...
	 start solving instance: 101...
	 start solving instance: 60...
	 start solving instance: 122...
	 start solving instance: 26...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.434001772785298e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20462198555469513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4340018607462285e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.434001772785298e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20462198555469513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4340018607462285e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.434001772785298e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20462198555469513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4340018607462285e+19 - Differentiable computation graph = True!
PPO iteration: 551/1000:
	 New training batch of size 20...
	 start solving instance: 17...
	 start solving instance: 5...
	 start solving instance: 15...
	 start solving instance: 12...
	 start solving instance: 79...
	 start solving instance: 40...
	 start solving instance: 116...
	 start solving instance: 90...
	 start solving instance: 88...
	 start solving instance: 134...
	 start solving instance: 3...
	 start solving instance: 45...
	 start solving instance: 10...
	 start solving instance: 11...
	 start solving instance: 117...
	 start solving instance: 43...
	 start solving instance: 56...
	 start solving instance: 76...
	 start solving instance: 34...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.713836102225452e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20696714520454407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713836366108243e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.713836102225452e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20696714520454407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713836366108243e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.713836102225452e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20696714520454407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713836366108243e+19 - Differentiable computation graph = True!
PPO iteration: 552/1000:
	 start solving instance: 79...
	 start solving instance: 11...
	 start solving instance: 10...
	 start solving instance: 88...
	 start solving instance: 76...
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 56...
	 start solving instance: 90...
	 start solving instance: 43...
	 start solving instance: 116...
	 start solving instance: 17...
	 start solving instance: 45...
	 start solving instance: 15...
	 start solving instance: 12...
	 start solving instance: 144...
	 start solving instance: 3...
	 start solving instance: 5...
	 start solving instance: 40...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.680473225079659e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21346531808376312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.680473225079659e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.680473225079659e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21346531808376312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.680473225079659e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.680473225079659e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21346531808376312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.680473225079659e+19 - Differentiable computation graph = True!
PPO iteration: 553/1000:
	 start solving instance: 144...
	 start solving instance: 117...
	 start solving instance: 90...
	 start solving instance: 40...
	 start solving instance: 17...
	 start solving instance: 79...
	 start solving instance: 134...
	 start solving instance: 5...
	 start solving instance: 3...
	 start solving instance: 43...
	 start solving instance: 11...
	 start solving instance: 10...
	 start solving instance: 116...
	 start solving instance: 56...
	 start solving instance: 15...
	 start solving instance: 12...
	 start solving instance: 34...
	 start solving instance: 45...
	 start solving instance: 76...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.401432655073829e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2000291645526886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.401432567112899e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.401432655073829e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2000291645526886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.401432567112899e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.401432655073829e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2000291645526886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.401432567112899e+19 - Differentiable computation graph = True!
PPO iteration: 554/1000:
	 start solving instance: 10...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 76...
	 start solving instance: 45...
	 start solving instance: 5...
	 start solving instance: 43...
	 start solving instance: 144...
	 start solving instance: 17...
	 start solving instance: 79...
	 start solving instance: 3...
	 start solving instance: 12...
	 start solving instance: 56...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 11...
	 start solving instance: 116...
	 start solving instance: 88...
	 start solving instance: 15...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.431306649883294e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20766091346740723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.431306737844224e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.431306649883294e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20766091346740723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.431306737844224e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.431306649883294e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20766091346740723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.431306737844224e+19 - Differentiable computation graph = True!
PPO iteration: 555/1000:
	 start solving instance: 3...
	 start solving instance: 12...
	 start solving instance: 43...
	 start solving instance: 40...
	 start solving instance: 134...
	 start solving instance: 11...
	 start solving instance: 144...
	 start solving instance: 56...
	 start solving instance: 5...
	 start solving instance: 88...
	 start solving instance: 34...
	 start solving instance: 76...
	 start solving instance: 117...
	 start solving instance: 116...
	 start solving instance: 45...
	 start solving instance: 79...
	 start solving instance: 17...
	 start solving instance: 90...
	 start solving instance: 10...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.474508484840008e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21857605874538422
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.474508748722799e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.474508484840008e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21857605874538422
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.474508748722799e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.474508484840008e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21857605874538422
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.474508748722799e+19 - Differentiable computation graph = True!
PPO iteration: 556/1000:
	 start solving instance: 76...
	 start solving instance: 45...
	 start solving instance: 10...
	 start solving instance: 79...
	 start solving instance: 40...
	 start solving instance: 15...
	 start solving instance: 144...
	 start solving instance: 56...
	 start solving instance: 34...
	 start solving instance: 11...
	 start solving instance: 134...
	 start solving instance: 90...
	 start solving instance: 3...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 17...
	 start solving instance: 116...
	 start solving instance: 88...
	 start solving instance: 117...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.616763827007248e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22535283863544464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6167640029291086e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.616763827007248e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22535283863544464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6167640029291086e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.616763827007248e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22535283863544464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6167640029291086e+19 - Differentiable computation graph = True!
PPO iteration: 557/1000:
	 start solving instance: 144...
	 start solving instance: 117...
	 start solving instance: 134...
	 start solving instance: 3...
	 start solving instance: 15...
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 79...
	 start solving instance: 56...
	 start solving instance: 12...
	 start solving instance: 90...
	 start solving instance: 116...
	 start solving instance: 88...
	 start solving instance: 17...
	 start solving instance: 34...
	 start solving instance: 10...
	 start solving instance: 5...
	 start solving instance: 11...
	 start solving instance: 40...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.606266569594545e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148299664258957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6062667455164056e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.606266569594545e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148299664258957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6062667455164056e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.606266569594545e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148299664258957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6062667455164056e+19 - Differentiable computation graph = True!
PPO iteration: 558/1000:
	 start solving instance: 88...
	 start solving instance: 43...
	 start solving instance: 134...
	 start solving instance: 144...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 76...
	 start solving instance: 10...
	 start solving instance: 15...
	 start solving instance: 45...
	 start solving instance: 12...
	 start solving instance: 56...
	 start solving instance: 5...
	 start solving instance: 3...
	 start solving instance: 40...
	 start solving instance: 116...
	 start solving instance: 117...
	 start solving instance: 17...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.605850690316455e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20847637951374054
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.605850690316455e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.605850690316455e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20847637951374054
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.605850690316455e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.605850690316455e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20847637951374054
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.605850690316455e+19 - Differentiable computation graph = True!
PPO iteration: 559/1000:
	 start solving instance: 116...
	 start solving instance: 43...
	 start solving instance: 15...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 17...
	 start solving instance: 40...
	 start solving instance: 56...
	 start solving instance: 11...
	 start solving instance: 45...
	 start solving instance: 76...
	 start solving instance: 144...
	 start solving instance: 5...
	 start solving instance: 34...
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 88...
	 start solving instance: 3...
	 start solving instance: 12...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.681286687762353e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2041953057050705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.681286863684213e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.681286687762353e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2041953057050705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.681286863684213e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.681286687762353e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2041953057050705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.681286863684213e+19 - Differentiable computation graph = True!
PPO iteration: 560/1000:
	 start solving instance: 56...
	 start solving instance: 34...
	 start solving instance: 5...
	 start solving instance: 40...
	 start solving instance: 144...
	 start solving instance: 90...
	 start solving instance: 134...
	 start solving instance: 45...
	 start solving instance: 11...
	 start solving instance: 10...
	 start solving instance: 117...
	 start solving instance: 88...
	 start solving instance: 15...
	 start solving instance: 116...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 17...
	 start solving instance: 3...
	 start solving instance: 76...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6264127892088894e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21134977042675018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.62641287716982e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6264127892088894e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21134977042675018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.62641287716982e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6264127892088894e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21134977042675018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.62641287716982e+19 - Differentiable computation graph = True!
PPO iteration: 561/1000:
	 New training batch of size 20...
	 start solving instance: 113...
	 start solving instance: 105...
	 start solving instance: 150...
	 start solving instance: 33...
	 start solving instance: 53...
	 start solving instance: 49...
	 start solving instance: 14...
	 start solving instance: 139...
	 start solving instance: 77...
	 start solving instance: 99...
	 start solving instance: 107...
	 start solving instance: 102...
	 start solving instance: 66...
	 start solving instance: 118...
	 start solving instance: 59...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 24...
	 start solving instance: 111...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.706587417887711e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21620361506938934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.706587505848641e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.706587417887711e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21620361506938934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.706587505848641e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.706587417887711e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21620361506938934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.706587505848641e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.801358635171305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20731309056282043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 48013588110931656704.0000
PPO iteration: 562/1000:
	 start solving instance: 112...
	 start solving instance: 59...
	 start solving instance: 14...
	 start solving instance: 105...
	 start solving instance: 99...
	 start solving instance: 150...
	 start solving instance: 102...
	 start solving instance: 53...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 77...
	 start solving instance: 107...
	 start solving instance: 111...
	 start solving instance: 24...
	 start solving instance: 146...
	 start solving instance: 113...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 118...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.871706972413158e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21215616166591644
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8717068844522275e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.871706972413158e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21215616166591644
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8717068844522275e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.871706972413158e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21215616166591644
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8717068844522275e+19 - Differentiable computation graph = True!
PPO iteration: 563/1000:
	 start solving instance: 33...
	 start solving instance: 53...
	 start solving instance: 107...
	 start solving instance: 105...
	 start solving instance: 24...
	 start solving instance: 113...
	 start solving instance: 66...
	 start solving instance: 14...
	 start solving instance: 102...
	 start solving instance: 118...
	 start solving instance: 99...
	 start solving instance: 77...
	 start solving instance: 49...
	 start solving instance: 111...
	 start solving instance: 139...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 150...
	 start solving instance: 89...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9181612507257635e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23071327805519104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9181612507257635e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9181612507257635e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23071327805519104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9181612507257635e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9181612507257635e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23071327805519104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9181612507257635e+19 - Differentiable computation graph = True!
PPO iteration: 564/1000:
	 start solving instance: 107...
	 start solving instance: 146...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 112...
	 start solving instance: 14...
	 start solving instance: 118...
	 start solving instance: 99...
	 start solving instance: 102...
	 start solving instance: 66...
	 start solving instance: 105...
	 start solving instance: 77...
	 start solving instance: 33...
	 start solving instance: 53...
	 start solving instance: 113...
	 start solving instance: 150...
	 start solving instance: 111...
	 start solving instance: 89...
	 start solving instance: 59...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.089073208428195e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22342737019062042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.089073296389125e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.089073208428195e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22342737019062042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.089073296389125e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.089073208428195e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22342737019062042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.089073296389125e+19 - Differentiable computation graph = True!
PPO iteration: 565/1000:
	 start solving instance: 139...
	 start solving instance: 14...
	 start solving instance: 77...
	 start solving instance: 112...
	 start solving instance: 49...
	 start solving instance: 150...
	 start solving instance: 53...
	 start solving instance: 146...
	 start solving instance: 107...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 59...
	 start solving instance: 99...
	 start solving instance: 118...
	 start solving instance: 111...
	 start solving instance: 113...
	 start solving instance: 102...
	 start solving instance: 89...
	 start solving instance: 24...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0012456269763314e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22385720908641815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.001245626976331e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0012456269763314e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22385720908641815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.001245626976331e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0012456269763314e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22385720908641815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.001245626976331e+19 - Differentiable computation graph = True!
PPO iteration: 566/1000:
	 start solving instance: 139...
	 start solving instance: 24...
	 start solving instance: 49...
	 start solving instance: 99...
	 start solving instance: 146...
	 start solving instance: 105...
	 start solving instance: 107...
	 start solving instance: 150...
	 start solving instance: 113...
	 start solving instance: 33...
	 start solving instance: 53...
	 start solving instance: 118...
	 start solving instance: 77...
	 start solving instance: 112...
	 start solving instance: 102...
	 start solving instance: 59...
	 start solving instance: 14...
	 start solving instance: 66...
	 start solving instance: 89...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.1731846165000356e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21910686790943146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1731846165000356e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.1731846165000356e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21910686790943146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1731846165000356e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.1731846165000356e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21910686790943146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1731846165000356e+19 - Differentiable computation graph = True!
PPO iteration: 567/1000:
	 start solving instance: 150...
	 start solving instance: 105...
	 start solving instance: 146...
	 start solving instance: 89...
	 start solving instance: 113...
	 start solving instance: 53...
	 start solving instance: 77...
	 start solving instance: 112...
	 start solving instance: 14...
	 start solving instance: 59...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 111...
	 start solving instance: 66...
	 start solving instance: 99...
	 start solving instance: 102...
	 start solving instance: 33...
	 start solving instance: 24...
	 start solving instance: 118...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7187837286285836e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2136424034833908
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.718783728628584e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7187837286285836e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2136424034833908
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.718783728628584e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7187837286285836e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2136424034833908
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.718783728628584e+19 - Differentiable computation graph = True!
PPO iteration: 568/1000:
	 start solving instance: 146...
	 start solving instance: 14...
	 start solving instance: 49...
	 start solving instance: 111...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 105...
	 start solving instance: 59...
	 start solving instance: 99...
	 start solving instance: 118...
	 start solving instance: 77...
	 start solving instance: 102...
	 start solving instance: 113...
	 start solving instance: 112...
	 start solving instance: 33...
	 start solving instance: 24...
	 start solving instance: 107...
	 start solving instance: 139...
	 start solving instance: 66...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8363347157773713e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22262249886989594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.836334715777371e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8363347157773713e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22262249886989594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.836334715777371e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8363347157773713e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22262249886989594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.836334715777371e+19 - Differentiable computation graph = True!
PPO iteration: 569/1000:
	 start solving instance: 49...
	 start solving instance: 24...
	 start solving instance: 139...
	 start solving instance: 33...
	 start solving instance: 107...
	 start solving instance: 113...
	 start solving instance: 112...
	 start solving instance: 150...
	 start solving instance: 111...
	 start solving instance: 146...
	 start solving instance: 118...
	 start solving instance: 99...
	 start solving instance: 53...
	 start solving instance: 105...
	 start solving instance: 59...
	 start solving instance: 66...
	 start solving instance: 77...
	 start solving instance: 89...
	 start solving instance: 14...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.963832676759393e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21033501625061035
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.963832764720323e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.963832676759393e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21033501625061035
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.963832764720323e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.963832676759393e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21033501625061035
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.963832764720323e+19 - Differentiable computation graph = True!
PPO iteration: 570/1000:
	 start solving instance: 146...
	 start solving instance: 105...
	 start solving instance: 102...
	 start solving instance: 112...
	 start solving instance: 139...
	 start solving instance: 89...
	 start solving instance: 24...
	 start solving instance: 113...
	 start solving instance: 118...
	 start solving instance: 53...
	 start solving instance: 150...
	 start solving instance: 33...
	 start solving instance: 107...
	 start solving instance: 111...
	 start solving instance: 77...
	 start solving instance: 49...
	 start solving instance: 59...
	 start solving instance: 14...
	 start solving instance: 66...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.754098986581586e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21154995262622833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7540991625034465e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.754098986581586e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21154995262622833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7540991625034465e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.754098986581586e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21154995262622833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7540991625034465e+19 - Differentiable computation graph = True!
PPO iteration: 571/1000:
	 New training batch of size 20...
	 start solving instance: 13...
	 start solving instance: 102...
	 start solving instance: 103...
	 start solving instance: 63...
	 start solving instance: 122...
	 start solving instance: 26...
	 start solving instance: 141...
	 start solving instance: 35...
	 start solving instance: 94...
	 start solving instance: 130...
	 start solving instance: 29...
	 start solving instance: 8...
	 start solving instance: 7...
	 start solving instance: 38...
	 start solving instance: 93...
	 start solving instance: 117...
	 start solving instance: 126...
	 start solving instance: 60...
	 start solving instance: 32...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.180498371885264e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19637127220630646
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.180498459846194e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.180498371885264e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19637127220630646
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.180498459846194e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.180498371885264e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19637127220630646
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.180498459846194e+19 - Differentiable computation graph = True!
PPO iteration: 572/1000:
	 start solving instance: 126...
	 start solving instance: 94...
	 start solving instance: 8...
	 start solving instance: 11...
	 start solving instance: 38...
	 start solving instance: 7...
	 start solving instance: 32...
	 start solving instance: 122...
	 start solving instance: 13...
	 start solving instance: 93...
	 start solving instance: 130...
	 start solving instance: 63...
	 start solving instance: 26...
	 start solving instance: 60...
	 start solving instance: 117...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 102...
	 start solving instance: 35...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4169598703203516e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20796345174312592
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416959870320352e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4169598703203516e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20796345174312592
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416959870320352e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4169598703203516e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20796345174312592
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416959870320352e+19 - Differentiable computation graph = True!
PPO iteration: 573/1000:
	 start solving instance: 8...
	 start solving instance: 102...
	 start solving instance: 32...
	 start solving instance: 103...
	 start solving instance: 126...
	 start solving instance: 141...
	 start solving instance: 94...
	 start solving instance: 11...
	 start solving instance: 117...
	 start solving instance: 26...
	 start solving instance: 63...
	 start solving instance: 13...
	 start solving instance: 35...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 130...
	 start solving instance: 29...
	 start solving instance: 38...
	 start solving instance: 7...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3461256368999524e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19399705529212952
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346125812821813e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3461256368999524e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19399705529212952
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346125812821813e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3461256368999524e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19399705529212952
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346125812821813e+19 - Differentiable computation graph = True!
PPO iteration: 574/1000:
	 start solving instance: 130...
	 start solving instance: 93...
	 start solving instance: 122...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 126...
	 start solving instance: 117...
	 start solving instance: 8...
	 start solving instance: 11...
	 start solving instance: 29...
	 start solving instance: 102...
	 start solving instance: 13...
	 start solving instance: 26...
	 start solving instance: 32...
	 start solving instance: 141...
	 start solving instance: 60...
	 start solving instance: 38...
	 start solving instance: 103...
	 start solving instance: 7...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.286815692713529e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1945934146642685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.28681595659632e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.286815692713529e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1945934146642685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.28681595659632e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.286815692713529e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1945934146642685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.28681595659632e+19 - Differentiable computation graph = True!
PPO iteration: 575/1000:
	 start solving instance: 26...
	 start solving instance: 130...
	 start solving instance: 126...
	 start solving instance: 122...
	 start solving instance: 7...
	 start solving instance: 63...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 13...
	 start solving instance: 8...
	 start solving instance: 11...
	 start solving instance: 35...
	 start solving instance: 102...
	 start solving instance: 60...
	 start solving instance: 94...
	 start solving instance: 32...
	 start solving instance: 29...
	 start solving instance: 38...
	 start solving instance: 93...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.175533153296088e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19862006604671478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1755330653351576e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.175533153296088e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19862006604671478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1755330653351576e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.175533153296088e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19862006604671478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1755330653351576e+19 - Differentiable computation graph = True!
PPO iteration: 576/1000:
	 start solving instance: 7...
	 start solving instance: 63...
	 start solving instance: 102...
	 start solving instance: 122...
	 start solving instance: 130...
	 start solving instance: 93...
	 start solving instance: 26...
	 start solving instance: 94...
	 start solving instance: 103...
	 start solving instance: 11...
	 start solving instance: 29...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 126...
	 start solving instance: 35...
	 start solving instance: 13...
	 start solving instance: 60...
	 start solving instance: 32...
	 start solving instance: 8...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5404362575726196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20114722847938538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.54043634553355e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5404362575726196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20114722847938538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.54043634553355e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5404362575726196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20114722847938538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.54043634553355e+19 - Differentiable computation graph = True!
PPO iteration: 577/1000:
	 start solving instance: 13...
	 start solving instance: 102...
	 start solving instance: 8...
	 start solving instance: 60...
	 start solving instance: 63...
	 start solving instance: 7...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 117...
	 start solving instance: 11...
	 start solving instance: 26...
	 start solving instance: 32...
	 start solving instance: 126...
	 start solving instance: 93...
	 start solving instance: 130...
	 start solving instance: 35...
	 start solving instance: 122...
	 start solving instance: 94...
	 start solving instance: 29...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.619799182787352e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2026156485080719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6197990948264215e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.619799182787352e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2026156485080719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6197990948264215e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.619799182787352e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2026156485080719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6197990948264215e+19 - Differentiable computation graph = True!
PPO iteration: 578/1000:
	 start solving instance: 102...
	 start solving instance: 26...
	 start solving instance: 11...
	 start solving instance: 94...
	 start solving instance: 93...
	 start solving instance: 38...
	 start solving instance: 13...
	 start solving instance: 126...
	 start solving instance: 32...
	 start solving instance: 122...
	 start solving instance: 130...
	 start solving instance: 103...
	 start solving instance: 8...
	 start solving instance: 29...
	 start solving instance: 63...
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 117...
	 start solving instance: 141...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4652384583257634e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2036781758069992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4652385462866936e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4652384583257634e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2036781758069992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4652385462866936e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4652384583257634e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2036781758069992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4652385462866936e+19 - Differentiable computation graph = True!
PPO iteration: 579/1000:
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 29...
	 start solving instance: 11...
	 start solving instance: 63...
	 start solving instance: 38...
	 start solving instance: 26...
	 start solving instance: 8...
	 start solving instance: 102...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 13...
	 start solving instance: 103...
	 start solving instance: 130...
	 start solving instance: 93...
	 start solving instance: 126...
	 start solving instance: 94...
	 start solving instance: 141...
	 start solving instance: 7...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.507946656542071e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19854851067066193
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.507946656542071e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.507946656542071e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19854851067066193
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.507946656542071e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.507946656542071e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19854851067066193
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.507946656542071e+19 - Differentiable computation graph = True!
PPO iteration: 580/1000:
	 start solving instance: 38...
	 start solving instance: 122...
	 start solving instance: 8...
	 start solving instance: 130...
	 start solving instance: 11...
	 start solving instance: 141...
	 start solving instance: 13...
	 start solving instance: 117...
	 start solving instance: 102...
	 start solving instance: 60...
	 start solving instance: 63...
	 start solving instance: 94...
	 start solving instance: 7...
	 start solving instance: 126...
	 start solving instance: 32...
	 start solving instance: 93...
	 start solving instance: 35...
	 start solving instance: 29...
	 start solving instance: 103...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.17836197681203e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19450591504573822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1783618888511e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.17836197681203e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19450591504573822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1783618888511e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.17836197681203e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19450591504573822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1783618888511e+19 - Differentiable computation graph = True!
PPO iteration: 581/1000:
	 New training batch of size 20...
	 start solving instance: 150...
	 start solving instance: 9...
	 start solving instance: 73...
	 start solving instance: 111...
	 start solving instance: 79...
	 start solving instance: 30...
	 start solving instance: 12...
	 start solving instance: 97...
	 start solving instance: 78...
	 start solving instance: 47...
	 start solving instance: 43...
	 start solving instance: 24...
	 start solving instance: 31...
	 start solving instance: 116...
	 start solving instance: 23...
	 start solving instance: 39...
	 start solving instance: 107...
	 start solving instance: 16...
	 start solving instance: 46...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.503520462533296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2277800589799881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.503520462533296e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.503520462533296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2277800589799881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.503520462533296e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.503520462533296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2277800589799881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.503520462533296e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.2309569835852995e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20799122750759125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 42309572474680901632.0000
PPO iteration: 582/1000:
	 start solving instance: 30...
	 start solving instance: 78...
	 start solving instance: 12...
	 start solving instance: 111...
	 start solving instance: 146...
	 start solving instance: 46...
	 start solving instance: 107...
	 start solving instance: 97...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 31...
	 start solving instance: 150...
	 start solving instance: 116...
	 start solving instance: 47...
	 start solving instance: 73...
	 start solving instance: 79...
	 start solving instance: 39...
	 start solving instance: 23...
	 start solving instance: 24...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.598318771783399e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22613821923732758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5983190356661895e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.598318771783399e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22613821923732758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5983190356661895e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.598318771783399e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22613821923732758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5983190356661895e+19 - Differentiable computation graph = True!
PPO iteration: 583/1000:
	 start solving instance: 79...
	 start solving instance: 107...
	 start solving instance: 150...
	 start solving instance: 43...
	 start solving instance: 146...
	 start solving instance: 39...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 46...
	 start solving instance: 47...
	 start solving instance: 12...
	 start solving instance: 97...
	 start solving instance: 116...
	 start solving instance: 9...
	 start solving instance: 30...
	 start solving instance: 23...
	 start solving instance: 24...
	 start solving instance: 31...
	 start solving instance: 16...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6777052705274305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21489153802394867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.677705534410221e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6777052705274305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21489153802394867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.677705534410221e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6777052705274305e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21489153802394867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.677705534410221e+19 - Differentiable computation graph = True!
PPO iteration: 584/1000:
	 start solving instance: 107...
	 start solving instance: 78...
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 16...
	 start solving instance: 24...
	 start solving instance: 43...
	 start solving instance: 46...
	 start solving instance: 79...
	 start solving instance: 12...
	 start solving instance: 31...
	 start solving instance: 116...
	 start solving instance: 111...
	 start solving instance: 73...
	 start solving instance: 9...
	 start solving instance: 150...
	 start solving instance: 47...
	 start solving instance: 39...
	 start solving instance: 146...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8017516446075375e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22551892697811127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.801751556646607e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8017516446075375e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22551892697811127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.801751556646607e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8017516446075375e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22551892697811127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.801751556646607e+19 - Differentiable computation graph = True!
PPO iteration: 585/1000:
	 start solving instance: 107...
	 start solving instance: 39...
	 start solving instance: 146...
	 start solving instance: 16...
	 start solving instance: 116...
	 start solving instance: 12...
	 start solving instance: 78...
	 start solving instance: 24...
	 start solving instance: 30...
	 start solving instance: 111...
	 start solving instance: 97...
	 start solving instance: 47...
	 start solving instance: 23...
	 start solving instance: 150...
	 start solving instance: 73...
	 start solving instance: 9...
	 start solving instance: 79...
	 start solving instance: 31...
	 start solving instance: 43...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6650149712024306e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22861699759960175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6650149712024306e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6650149712024306e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22861699759960175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6650149712024306e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6650149712024306e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22861699759960175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6650149712024306e+19 - Differentiable computation graph = True!
PPO iteration: 586/1000:
	 start solving instance: 97...
	 start solving instance: 146...
	 start solving instance: 39...
	 start solving instance: 23...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 31...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 150...
	 start solving instance: 73...
	 start solving instance: 111...
	 start solving instance: 24...
	 start solving instance: 12...
	 start solving instance: 78...
	 start solving instance: 46...
	 start solving instance: 30...
	 start solving instance: 16...
	 start solving instance: 79...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.832284642706226e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20817995071411133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.832284554745296e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.832284642706226e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20817995071411133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.832284554745296e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.832284642706226e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20817995071411133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.832284554745296e+19 - Differentiable computation graph = True!
PPO iteration: 587/1000:
	 start solving instance: 12...
	 start solving instance: 23...
	 start solving instance: 78...
	 start solving instance: 73...
	 start solving instance: 116...
	 start solving instance: 30...
	 start solving instance: 9...
	 start solving instance: 97...
	 start solving instance: 16...
	 start solving instance: 107...
	 start solving instance: 146...
	 start solving instance: 43...
	 start solving instance: 47...
	 start solving instance: 46...
	 start solving instance: 111...
	 start solving instance: 31...
	 start solving instance: 24...
	 start solving instance: 79...
	 start solving instance: 150...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.975753845710531e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21543268859386444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9757541095933215e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.975753845710531e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21543268859386444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9757541095933215e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.975753845710531e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21543268859386444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9757541095933215e+19 - Differentiable computation graph = True!
PPO iteration: 588/1000:
	 start solving instance: 46...
	 start solving instance: 78...
	 start solving instance: 47...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 39...
	 start solving instance: 73...
	 start solving instance: 16...
	 start solving instance: 116...
	 start solving instance: 9...
	 start solving instance: 97...
	 start solving instance: 79...
	 start solving instance: 31...
	 start solving instance: 12...
	 start solving instance: 43...
	 start solving instance: 107...
	 start solving instance: 24...
	 start solving instance: 30...
	 start solving instance: 146...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.79694827412997e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22017036378383636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7969484500518306e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.79694827412997e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22017036378383636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7969484500518306e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.79694827412997e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22017036378383636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7969484500518306e+19 - Differentiable computation graph = True!
PPO iteration: 589/1000:
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 150...
	 start solving instance: 39...
	 start solving instance: 9...
	 start solving instance: 31...
	 start solving instance: 146...
	 start solving instance: 16...
	 start solving instance: 78...
	 start solving instance: 79...
	 start solving instance: 47...
	 start solving instance: 23...
	 start solving instance: 97...
	 start solving instance: 116...
	 start solving instance: 111...
	 start solving instance: 107...
	 start solving instance: 12...
	 start solving instance: 73...
	 start solving instance: 24...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6247777714379214e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21591515839099884
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.624777683476991e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6247777714379214e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21591515839099884
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.624777683476991e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6247777714379214e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21591515839099884
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.624777683476991e+19 - Differentiable computation graph = True!
PPO iteration: 590/1000:
	 start solving instance: 146...
	 start solving instance: 47...
	 start solving instance: 97...
	 start solving instance: 111...
	 start solving instance: 24...
	 start solving instance: 78...
	 start solving instance: 12...
	 start solving instance: 107...
	 start solving instance: 16...
	 start solving instance: 43...
	 start solving instance: 79...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 23...
	 start solving instance: 150...
	 start solving instance: 46...
	 start solving instance: 9...
	 start solving instance: 30...
	 start solving instance: 73...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.689168690797693e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21458621323108673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689168602836763e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.689168690797693e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21458621323108673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689168602836763e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.689168690797693e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21458621323108673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689168602836763e+19 - Differentiable computation graph = True!
PPO iteration: 591/1000:
	 New training batch of size 20...
	 start solving instance: 27...
	 start solving instance: 144...
	 start solving instance: 52...
	 start solving instance: 85...
	 start solving instance: 33...
	 start solving instance: 106...
	 start solving instance: 143...
	 start solving instance: 42...
	 start solving instance: 135...
	 start solving instance: 94...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 110...
	 start solving instance: 29...
	 start solving instance: 95...
	 start solving instance: 26...
	 start solving instance: 60...
	 start solving instance: 128...
	 start solving instance: 57...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.036431758283768e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21470904350280762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.036431758283768e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.036431758283768e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21470904350280762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.036431758283768e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.036431758283768e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21470904350280762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.036431758283768e+19 - Differentiable computation graph = True!
PPO iteration: 592/1000:
	 start solving instance: 144...
	 start solving instance: 107...
	 start solving instance: 135...
	 start solving instance: 143...
	 start solving instance: 99...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 94...
	 start solving instance: 57...
	 start solving instance: 52...
	 start solving instance: 95...
	 start solving instance: 26...
	 start solving instance: 42...
	 start solving instance: 27...
	 start solving instance: 29...
	 start solving instance: 128...
	 start solving instance: 106...
	 start solving instance: 33...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6863722369040725e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21273289620876312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.686372324865003e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6863722369040725e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21273289620876312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.686372324865003e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6863722369040725e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21273289620876312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.686372324865003e+19 - Differentiable computation graph = True!
PPO iteration: 593/1000:
	 start solving instance: 85...
	 start solving instance: 128...
	 start solving instance: 99...
	 start solving instance: 94...
	 start solving instance: 27...
	 start solving instance: 135...
	 start solving instance: 42...
	 start solving instance: 29...
	 start solving instance: 143...
	 start solving instance: 26...
	 start solving instance: 60...
	 start solving instance: 107...
	 start solving instance: 110...
	 start solving instance: 106...
	 start solving instance: 33...
	 start solving instance: 144...
	 start solving instance: 57...
	 start solving instance: 95...
	 start solving instance: 34...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.656724477607139e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21069903671741486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6567246535289995e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.656724477607139e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21069903671741486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6567246535289995e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.656724477607139e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21069903671741486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6567246535289995e+19 - Differentiable computation graph = True!
PPO iteration: 594/1000:
	 start solving instance: 85...
	 start solving instance: 26...
	 start solving instance: 27...
	 start solving instance: 33...
	 start solving instance: 107...
	 start solving instance: 106...
	 start solving instance: 143...
	 start solving instance: 95...
	 start solving instance: 135...
	 start solving instance: 29...
	 start solving instance: 57...
	 start solving instance: 34...
	 start solving instance: 144...
	 start solving instance: 60...
	 start solving instance: 128...
	 start solving instance: 42...
	 start solving instance: 52...
	 start solving instance: 110...
	 start solving instance: 99...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.54004430366755e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21865025162696838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.54004447958941e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.54004430366755e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21865025162696838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.54004447958941e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.54004430366755e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21865025162696838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.54004447958941e+19 - Differentiable computation graph = True!
PPO iteration: 595/1000:
	 start solving instance: 106...
	 start solving instance: 110...
	 start solving instance: 33...
	 start solving instance: 95...
	 start solving instance: 27...
	 start solving instance: 107...
	 start solving instance: 52...
	 start solving instance: 85...
	 start solving instance: 57...
	 start solving instance: 128...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 99...
	 start solving instance: 42...
	 start solving instance: 29...
	 start solving instance: 143...
	 start solving instance: 135...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.827974908969065e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2165759652853012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.827974908969065e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.827974908969065e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2165759652853012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.827974908969065e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.827974908969065e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2165759652853012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.827974908969065e+19 - Differentiable computation graph = True!
PPO iteration: 596/1000:
	 start solving instance: 99...
	 start solving instance: 26...
	 start solving instance: 34...
	 start solving instance: 85...
	 start solving instance: 110...
	 start solving instance: 106...
	 start solving instance: 95...
	 start solving instance: 128...
	 start solving instance: 29...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 143...
	 start solving instance: 60...
	 start solving instance: 52...
	 start solving instance: 94...
	 start solving instance: 27...
	 start solving instance: 144...
	 start solving instance: 135...
	 start solving instance: 33...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.457732576228053e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21599820256233215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4577328401108435e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.457732576228053e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21599820256233215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4577328401108435e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.457732576228053e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21599820256233215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4577328401108435e+19 - Differentiable computation graph = True!
PPO iteration: 597/1000:
	 start solving instance: 106...
	 start solving instance: 33...
	 start solving instance: 135...
	 start solving instance: 57...
	 start solving instance: 110...
	 start solving instance: 85...
	 start solving instance: 144...
	 start solving instance: 143...
	 start solving instance: 29...
	 start solving instance: 60...
	 start solving instance: 128...
	 start solving instance: 52...
	 start solving instance: 94...
	 start solving instance: 34...
	 start solving instance: 26...
	 start solving instance: 42...
	 start solving instance: 95...
	 start solving instance: 99...
	 start solving instance: 107...
	 start solving instance: 27...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.823270406577067e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20847323536872864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.823270318616137e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.823270406577067e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20847323536872864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.823270318616137e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.823270406577067e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20847323536872864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.823270318616137e+19 - Differentiable computation graph = True!
PPO iteration: 598/1000:
	 start solving instance: 94...
	 start solving instance: 29...
	 start solving instance: 42...
	 start solving instance: 52...
	 start solving instance: 60...
	 start solving instance: 107...
	 start solving instance: 57...
	 start solving instance: 33...
	 start solving instance: 106...
	 start solving instance: 135...
	 start solving instance: 85...
	 start solving instance: 27...
	 start solving instance: 110...
	 start solving instance: 143...
	 start solving instance: 95...
	 start solving instance: 34...
	 start solving instance: 99...
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.497680208610271e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2120642215013504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497680296571201e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.497680208610271e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2120642215013504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497680296571201e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.497680208610271e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2120642215013504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497680296571201e+19 - Differentiable computation graph = True!
PPO iteration: 599/1000:
	 start solving instance: 26...
	 start solving instance: 99...
	 start solving instance: 42...
	 start solving instance: 95...
	 start solving instance: 29...
	 start solving instance: 94...
	 start solving instance: 60...
	 start solving instance: 57...
	 start solving instance: 33...
	 start solving instance: 52...
	 start solving instance: 27...
	 start solving instance: 110...
	 start solving instance: 106...
	 start solving instance: 135...
	 start solving instance: 144...
	 start solving instance: 85...
	 start solving instance: 107...
	 start solving instance: 143...
	 start solving instance: 128...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4688927072109095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20923347771167755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.46889288313277e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4688927072109095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20923347771167755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.46889288313277e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4688927072109095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20923347771167755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.46889288313277e+19 - Differentiable computation graph = True!
PPO iteration: 600/1000:
	 start solving instance: 52...
	 start solving instance: 106...
	 start solving instance: 94...
	 start solving instance: 60...
	 start solving instance: 34...
	 start solving instance: 110...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 135...
	 start solving instance: 85...
	 start solving instance: 42...
	 start solving instance: 128...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 144...
	 start solving instance: 33...
	 start solving instance: 29...
	 start solving instance: 143...
	 start solving instance: 95...
	 start solving instance: 27...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.597491939039311e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19911430776119232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.597492202922102e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.597491939039311e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19911430776119232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.597492202922102e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.597491939039311e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19911430776119232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.597492202922102e+19 - Differentiable computation graph = True!
PPO iteration: 601/1000:
	 New training batch of size 20...
	 start solving instance: 40...
	 start solving instance: 41...
	 start solving instance: 80...
	 start solving instance: 35...
	 start solving instance: 47...
	 start solving instance: 109...
	 start solving instance: 67...
	 start solving instance: 1...
	 start solving instance: 34...
	 start solving instance: 113...
	 start solving instance: 68...
	 start solving instance: 32...
	 start solving instance: 76...
	 start solving instance: 9...
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 100...
	 start solving instance: 94...
	 start solving instance: 28...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9405765104961166e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22498619556427002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.940576774378907e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9405765104961166e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22498619556427002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.940576774378907e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9405765104961166e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22498619556427002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.940576774378907e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.3067384915651094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21186374127864838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43067386674869698560.0000
PPO iteration: 602/1000:
	 start solving instance: 1...
	 start solving instance: 68...
	 start solving instance: 134...
	 start solving instance: 34...
	 start solving instance: 100...
	 start solving instance: 9...
	 start solving instance: 35...
	 start solving instance: 94...
	 start solving instance: 32...
	 start solving instance: 45...
	 start solving instance: 117...
	 start solving instance: 40...
	 start solving instance: 80...
	 start solving instance: 41...
	 start solving instance: 76...
	 start solving instance: 67...
	 start solving instance: 28...
	 start solving instance: 113...
	 start solving instance: 47...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.917385435321205e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21074259281158447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.917385435321205e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.917385435321205e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21074259281158447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.917385435321205e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.917385435321205e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21074259281158447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.917385435321205e+19 - Differentiable computation graph = True!
PPO iteration: 603/1000:
	 start solving instance: 35...
	 start solving instance: 68...
	 start solving instance: 1...
	 start solving instance: 117...
	 start solving instance: 45...
	 start solving instance: 9...
	 start solving instance: 113...
	 start solving instance: 109...
	 start solving instance: 41...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 40...
	 start solving instance: 32...
	 start solving instance: 47...
	 start solving instance: 100...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 94...
	 start solving instance: 76...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7375707759491364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22403016686439514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7375708639100666e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7375707759491364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22403016686439514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7375708639100666e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7375707759491364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22403016686439514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7375708639100666e+19 - Differentiable computation graph = True!
PPO iteration: 604/1000:
	 start solving instance: 76...
	 start solving instance: 28...
	 start solving instance: 9...
	 start solving instance: 109...
	 start solving instance: 134...
	 start solving instance: 1...
	 start solving instance: 41...
	 start solving instance: 113...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 117...
	 start solving instance: 100...
	 start solving instance: 40...
	 start solving instance: 45...
	 start solving instance: 47...
	 start solving instance: 94...
	 start solving instance: 67...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.934210250210363e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21006591618061066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.934210162249433e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.934210250210363e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21006591618061066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.934210162249433e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.934210250210363e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21006591618061066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.934210162249433e+19 - Differentiable computation graph = True!
PPO iteration: 605/1000:
	 start solving instance: 32...
	 start solving instance: 47...
	 start solving instance: 80...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 45...
	 start solving instance: 40...
	 start solving instance: 76...
	 start solving instance: 67...
	 start solving instance: 35...
	 start solving instance: 113...
	 start solving instance: 41...
	 start solving instance: 100...
	 start solving instance: 109...
	 start solving instance: 94...
	 start solving instance: 1...
	 start solving instance: 117...
	 start solving instance: 9...
	 start solving instance: 68...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.983627052652849e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2169172763824463
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.983627052652849e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.983627052652849e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2169172763824463
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.983627052652849e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.983627052652849e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2169172763824463
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.983627052652849e+19 - Differentiable computation graph = True!
PPO iteration: 606/1000:
	 start solving instance: 32...
	 start solving instance: 76...
	 start solving instance: 34...
	 start solving instance: 41...
	 start solving instance: 28...
	 start solving instance: 67...
	 start solving instance: 113...
	 start solving instance: 47...
	 start solving instance: 94...
	 start solving instance: 9...
	 start solving instance: 45...
	 start solving instance: 40...
	 start solving instance: 80...
	 start solving instance: 100...
	 start solving instance: 109...
	 start solving instance: 1...
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 35...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6219890581061606e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2197839766740799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.621989321988951e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6219890581061606e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2197839766740799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.621989321988951e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6219890581061606e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2197839766740799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.621989321988951e+19 - Differentiable computation graph = True!
PPO iteration: 607/1000:
	 start solving instance: 67...
	 start solving instance: 113...
	 start solving instance: 80...
	 start solving instance: 109...
	 start solving instance: 40...
	 start solving instance: 134...
	 start solving instance: 1...
	 start solving instance: 45...
	 start solving instance: 117...
	 start solving instance: 35...
	 start solving instance: 47...
	 start solving instance: 34...
	 start solving instance: 9...
	 start solving instance: 68...
	 start solving instance: 94...
	 start solving instance: 41...
	 start solving instance: 100...
	 start solving instance: 32...
	 start solving instance: 76...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0629727375252573e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21739254891872406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.062972649564327e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0629727375252573e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21739254891872406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.062972649564327e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0629727375252573e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21739254891872406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.062972649564327e+19 - Differentiable computation graph = True!
PPO iteration: 608/1000:
	 start solving instance: 34...
	 start solving instance: 94...
	 start solving instance: 80...
	 start solving instance: 109...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 134...
	 start solving instance: 45...
	 start solving instance: 35...
	 start solving instance: 100...
	 start solving instance: 47...
	 start solving instance: 117...
	 start solving instance: 67...
	 start solving instance: 28...
	 start solving instance: 76...
	 start solving instance: 40...
	 start solving instance: 9...
	 start solving instance: 41...
	 start solving instance: 68...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8439074481820507e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22092194855213165
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.843907712064841e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8439074481820507e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22092194855213165
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.843907712064841e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8439074481820507e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22092194855213165
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.843907712064841e+19 - Differentiable computation graph = True!
PPO iteration: 609/1000:
	 start solving instance: 80...
	 start solving instance: 76...
	 start solving instance: 45...
	 start solving instance: 94...
	 start solving instance: 32...
	 start solving instance: 117...
	 start solving instance: 1...
	 start solving instance: 40...
	 start solving instance: 109...
	 start solving instance: 100...
	 start solving instance: 113...
	 start solving instance: 47...
	 start solving instance: 134...
	 start solving instance: 41...
	 start solving instance: 28...
	 start solving instance: 67...
	 start solving instance: 68...
	 start solving instance: 34...
	 start solving instance: 9...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.837766719721387e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21623459458351135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.837766719721387e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.837766719721387e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21623459458351135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.837766719721387e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.837766719721387e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21623459458351135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.837766719721387e+19 - Differentiable computation graph = True!
PPO iteration: 610/1000:
	 start solving instance: 34...
	 start solving instance: 32...
	 start solving instance: 1...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 67...
	 start solving instance: 117...
	 start solving instance: 100...
	 start solving instance: 9...
	 start solving instance: 76...
	 start solving instance: 109...
	 start solving instance: 45...
	 start solving instance: 113...
	 start solving instance: 28...
	 start solving instance: 41...
	 start solving instance: 80...
	 start solving instance: 35...
	 start solving instance: 68...
	 start solving instance: 94...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.689962450232017e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21269193291664124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689962450232017e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.689962450232017e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21269193291664124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689962450232017e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.689962450232017e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21269193291664124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689962450232017e+19 - Differentiable computation graph = True!
PPO iteration: 611/1000:
	 New training batch of size 20...
	 start solving instance: 75...
	 start solving instance: 120...
	 start solving instance: 36...
	 start solving instance: 35...
	 start solving instance: 87...
	 start solving instance: 71...
	 start solving instance: 48...
	 start solving instance: 127...
	 start solving instance: 12...
	 start solving instance: 27...
	 start solving instance: 141...
	 start solving instance: 110...
	 start solving instance: 121...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 20...
	 start solving instance: 119...
	 start solving instance: 25...
	 start solving instance: 55...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.053730858508684e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22266583144664764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.053731034430544e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.053730858508684e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22266583144664764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.053731034430544e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.053730858508684e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22266583144664764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.053731034430544e+19 - Differentiable computation graph = True!
PPO iteration: 612/1000:
	 start solving instance: 55...
	 start solving instance: 98...
	 start solving instance: 42...
	 start solving instance: 25...
	 start solving instance: 27...
	 start solving instance: 120...
	 start solving instance: 141...
	 start solving instance: 20...
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 76...
	 start solving instance: 127...
	 start solving instance: 12...
	 start solving instance: 110...
	 start solving instance: 87...
	 start solving instance: 71...
	 start solving instance: 121...
	 start solving instance: 119...
	 start solving instance: 75...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.01281847064379e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23927998542785645
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0128186465656504e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.01281847064379e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23927998542785645
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0128186465656504e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.01281847064379e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23927998542785645
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0128186465656504e+19 - Differentiable computation graph = True!
PPO iteration: 613/1000:
	 start solving instance: 71...
	 start solving instance: 121...
	 start solving instance: 141...
	 start solving instance: 76...
	 start solving instance: 20...
	 start solving instance: 110...
	 start solving instance: 25...
	 start solving instance: 87...
	 start solving instance: 127...
	 start solving instance: 48...
	 start solving instance: 75...
	 start solving instance: 120...
	 start solving instance: 12...
	 start solving instance: 27...
	 start solving instance: 42...
	 start solving instance: 35...
	 start solving instance: 98...
	 start solving instance: 119...
	 start solving instance: 36...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.028962116089309e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22651325166225433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.028962116089309e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.028962116089309e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22651325166225433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.028962116089309e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.028962116089309e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22651325166225433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.028962116089309e+19 - Differentiable computation graph = True!
PPO iteration: 614/1000:
	 start solving instance: 76...
	 start solving instance: 121...
	 start solving instance: 119...
	 start solving instance: 42...
	 start solving instance: 98...
	 start solving instance: 12...
	 start solving instance: 36...
	 start solving instance: 20...
	 start solving instance: 120...
	 start solving instance: 48...
	 start solving instance: 75...
	 start solving instance: 71...
	 start solving instance: 55...
	 start solving instance: 25...
	 start solving instance: 27...
	 start solving instance: 141...
	 start solving instance: 110...
	 start solving instance: 35...
	 start solving instance: 127...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.1185672120191e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22809170186519623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1185674759018906e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.1185672120191e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22809170186519623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1185674759018906e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.1185672120191e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22809170186519623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1185674759018906e+19 - Differentiable computation graph = True!
PPO iteration: 615/1000:
	 start solving instance: 20...
	 start solving instance: 27...
	 start solving instance: 141...
	 start solving instance: 119...
	 start solving instance: 127...
	 start solving instance: 71...
	 start solving instance: 98...
	 start solving instance: 42...
	 start solving instance: 35...
	 start solving instance: 25...
	 start solving instance: 87...
	 start solving instance: 110...
	 start solving instance: 48...
	 start solving instance: 75...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 76...
	 start solving instance: 36...
	 start solving instance: 12...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.996876783494061e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23023107647895813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.996877047376852e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.996876783494061e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23023107647895813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.996877047376852e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.996876783494061e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23023107647895813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.996877047376852e+19 - Differentiable computation graph = True!
PPO iteration: 616/1000:
	 start solving instance: 27...
	 start solving instance: 76...
	 start solving instance: 121...
	 start solving instance: 127...
	 start solving instance: 87...
	 start solving instance: 35...
	 start solving instance: 141...
	 start solving instance: 55...
	 start solving instance: 25...
	 start solving instance: 42...
	 start solving instance: 48...
	 start solving instance: 119...
	 start solving instance: 12...
	 start solving instance: 75...
	 start solving instance: 98...
	 start solving instance: 20...
	 start solving instance: 120...
	 start solving instance: 110...
	 start solving instance: 71...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.011140176095153e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23367667198181152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.011140352017013e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.011140176095153e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23367667198181152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.011140352017013e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.011140176095153e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23367667198181152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.011140352017013e+19 - Differentiable computation graph = True!
PPO iteration: 617/1000:
	 start solving instance: 20...
	 start solving instance: 76...
	 start solving instance: 75...
	 start solving instance: 127...
	 start solving instance: 110...
	 start solving instance: 36...
	 start solving instance: 141...
	 start solving instance: 42...
	 start solving instance: 98...
	 start solving instance: 48...
	 start solving instance: 120...
	 start solving instance: 35...
	 start solving instance: 55...
	 start solving instance: 27...
	 start solving instance: 119...
	 start solving instance: 25...
	 start solving instance: 121...
	 start solving instance: 12...
	 start solving instance: 87...
	 start solving instance: 71...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.290090322264714e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23301231861114502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.290090410225644e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.290090322264714e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23301231861114502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.290090410225644e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.290090322264714e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23301231861114502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.290090410225644e+19 - Differentiable computation graph = True!
PPO iteration: 618/1000:
	 start solving instance: 25...
	 start solving instance: 42...
	 start solving instance: 12...
	 start solving instance: 87...
	 start solving instance: 119...
	 start solving instance: 75...
	 start solving instance: 127...
	 start solving instance: 110...
	 start solving instance: 55...
	 start solving instance: 20...
	 start solving instance: 76...
	 start solving instance: 121...
	 start solving instance: 27...
	 start solving instance: 98...
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 71...
	 start solving instance: 141...
	 start solving instance: 36...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0258634284394453e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22819510102272034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.025863692322236e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0258634284394453e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22819510102272034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.025863692322236e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0258634284394453e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22819510102272034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.025863692322236e+19 - Differentiable computation graph = True!
PPO iteration: 619/1000:
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 35...
	 start solving instance: 119...
	 start solving instance: 87...
	 start solving instance: 98...
	 start solving instance: 75...
	 start solving instance: 42...
	 start solving instance: 76...
	 start solving instance: 71...
	 start solving instance: 120...
	 start solving instance: 141...
	 start solving instance: 110...
	 start solving instance: 127...
	 start solving instance: 36...
	 start solving instance: 55...
	 start solving instance: 27...
	 start solving instance: 12...
	 start solving instance: 48...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.102122388348501e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23352114856243134
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1021223003875705e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.102122388348501e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23352114856243134
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1021223003875705e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.102122388348501e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23352114856243134
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1021223003875705e+19 - Differentiable computation graph = True!
PPO iteration: 620/1000:
	 start solving instance: 120...
	 start solving instance: 42...
	 start solving instance: 76...
	 start solving instance: 87...
	 start solving instance: 20...
	 start solving instance: 27...
	 start solving instance: 35...
	 start solving instance: 141...
	 start solving instance: 12...
	 start solving instance: 36...
	 start solving instance: 48...
	 start solving instance: 127...
	 start solving instance: 71...
	 start solving instance: 55...
	 start solving instance: 121...
	 start solving instance: 110...
	 start solving instance: 75...
	 start solving instance: 119...
	 start solving instance: 98...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0848676204324166e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2501594126224518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.084867884315207e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0848676204324166e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2501594126224518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.084867884315207e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0848676204324166e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2501594126224518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.084867884315207e+19 - Differentiable computation graph = True!
PPO iteration: 621/1000:
	 New training batch of size 20...
	 start solving instance: 57...
	 start solving instance: 2...
	 start solving instance: 9...
	 start solving instance: 98...
	 start solving instance: 143...
	 start solving instance: 44...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 145...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 51...
	 start solving instance: 102...
	 start solving instance: 53...
	 start solving instance: 24...
	 start solving instance: 90...
	 start solving instance: 149...
	 start solving instance: 105...
	 start solving instance: 73...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.006038090298551e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23718543350696564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.006038178259481e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.006038090298551e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23718543350696564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.006038178259481e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.006038090298551e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23718543350696564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.006038178259481e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.604865879741689e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21378913521766663
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 46048659677026189312.0000
PPO iteration: 622/1000:
	 start solving instance: 149...
	 start solving instance: 51...
	 start solving instance: 53...
	 start solving instance: 44...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 126...
	 start solving instance: 143...
	 start solving instance: 72...
	 start solving instance: 145...
	 start solving instance: 9...
	 start solving instance: 24...
	 start solving instance: 30...
	 start solving instance: 105...
	 start solving instance: 57...
	 start solving instance: 102...
	 start solving instance: 73...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.069183834730099e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22990940511226654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.069184010651959e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.069183834730099e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22990940511226654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.069184010651959e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.069183834730099e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22990940511226654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.069184010651959e+19 - Differentiable computation graph = True!
PPO iteration: 623/1000:
	 start solving instance: 63...
	 start solving instance: 105...
	 start solving instance: 51...
	 start solving instance: 9...
	 start solving instance: 72...
	 start solving instance: 73...
	 start solving instance: 53...
	 start solving instance: 30...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 102...
	 start solving instance: 2...
	 start solving instance: 145...
	 start solving instance: 24...
	 start solving instance: 57...
	 start solving instance: 90...
	 start solving instance: 143...
	 start solving instance: 44...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8550855231946726e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22934141755104065
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.855085787077463e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8550855231946726e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22934141755104065
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.855085787077463e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8550855231946726e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22934141755104065
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.855085787077463e+19 - Differentiable computation graph = True!
PPO iteration: 624/1000:
	 start solving instance: 63...
	 start solving instance: 105...
	 start solving instance: 24...
	 start solving instance: 51...
	 start solving instance: 126...
	 start solving instance: 98...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 90...
	 start solving instance: 57...
	 start solving instance: 53...
	 start solving instance: 9...
	 start solving instance: 73...
	 start solving instance: 145...
	 start solving instance: 143...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 44...
	 start solving instance: 102...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9125440657217815e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22954688966274261
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9125440657217815e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9125440657217815e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22954688966274261
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9125440657217815e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9125440657217815e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22954688966274261
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9125440657217815e+19 - Differentiable computation graph = True!
PPO iteration: 625/1000:
	 start solving instance: 44...
	 start solving instance: 90...
	 start solving instance: 63...
	 start solving instance: 149...
	 start solving instance: 126...
	 start solving instance: 102...
	 start solving instance: 24...
	 start solving instance: 72...
	 start solving instance: 104...
	 start solving instance: 30...
	 start solving instance: 9...
	 start solving instance: 2...
	 start solving instance: 98...
	 start solving instance: 105...
	 start solving instance: 73...
	 start solving instance: 145...
	 start solving instance: 57...
	 start solving instance: 51...
	 start solving instance: 143...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9577999643210416e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23060381412506104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.957799964321042e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9577999643210416e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23060381412506104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.957799964321042e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9577999643210416e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23060381412506104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.957799964321042e+19 - Differentiable computation graph = True!
PPO iteration: 626/1000:
	 start solving instance: 63...
	 start solving instance: 149...
	 start solving instance: 44...
	 start solving instance: 53...
	 start solving instance: 143...
	 start solving instance: 30...
	 start solving instance: 102...
	 start solving instance: 104...
	 start solving instance: 98...
	 start solving instance: 9...
	 start solving instance: 105...
	 start solving instance: 145...
	 start solving instance: 57...
	 start solving instance: 51...
	 start solving instance: 2...
	 start solving instance: 126...
	 start solving instance: 72...
	 start solving instance: 73...
	 start solving instance: 24...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7425827897531905e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23779010772705078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.742582877714121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7425827897531905e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23779010772705078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.742582877714121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7425827897531905e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23779010772705078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.742582877714121e+19 - Differentiable computation graph = True!
PPO iteration: 627/1000:
	 start solving instance: 149...
	 start solving instance: 73...
	 start solving instance: 143...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 105...
	 start solving instance: 30...
	 start solving instance: 98...
	 start solving instance: 51...
	 start solving instance: 53...
	 start solving instance: 44...
	 start solving instance: 72...
	 start solving instance: 2...
	 start solving instance: 57...
	 start solving instance: 126...
	 start solving instance: 24...
	 start solving instance: 145...
	 start solving instance: 9...
	 start solving instance: 102...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0827822426987115e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24078106880187988
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.082782330659642e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0827822426987115e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24078106880187988
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.082782330659642e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0827822426987115e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24078106880187988
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.082782330659642e+19 - Differentiable computation graph = True!
PPO iteration: 628/1000:
	 start solving instance: 98...
	 start solving instance: 9...
	 start solving instance: 30...
	 start solving instance: 51...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 2...
	 start solving instance: 105...
	 start solving instance: 143...
	 start solving instance: 72...
	 start solving instance: 145...
	 start solving instance: 126...
	 start solving instance: 57...
	 start solving instance: 53...
	 start solving instance: 63...
	 start solving instance: 24...
	 start solving instance: 44...
	 start solving instance: 73...
	 start solving instance: 149...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.13199427209564e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22424888610839844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.13199427209564e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.13199427209564e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22424888610839844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.13199427209564e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.13199427209564e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22424888610839844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.13199427209564e+19 - Differentiable computation graph = True!
PPO iteration: 629/1000:
	 start solving instance: 2...
	 start solving instance: 90...
	 start solving instance: 9...
	 start solving instance: 105...
	 start solving instance: 145...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 102...
	 start solving instance: 57...
	 start solving instance: 143...
	 start solving instance: 149...
	 start solving instance: 44...
	 start solving instance: 24...
	 start solving instance: 72...
	 start solving instance: 30...
	 start solving instance: 51...
	 start solving instance: 73...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.060051027267001e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22682705521583557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.060051027267001e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.060051027267001e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22682705521583557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.060051027267001e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.060051027267001e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22682705521583557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.060051027267001e+19 - Differentiable computation graph = True!
PPO iteration: 630/1000:
	 start solving instance: 149...
	 start solving instance: 9...
	 start solving instance: 98...
	 start solving instance: 72...
	 start solving instance: 102...
	 start solving instance: 90...
	 start solving instance: 44...
	 start solving instance: 126...
	 start solving instance: 30...
	 start solving instance: 57...
	 start solving instance: 73...
	 start solving instance: 2...
	 start solving instance: 104...
	 start solving instance: 105...
	 start solving instance: 63...
	 start solving instance: 51...
	 start solving instance: 53...
	 start solving instance: 24...
	 start solving instance: 143...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.110976535584655e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24606893956661224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.110976447623725e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.110976535584655e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24606893956661224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.110976447623725e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.110976535584655e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24606893956661224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.110976447623725e+19 - Differentiable computation graph = True!
PPO iteration: 631/1000:
	 New training batch of size 20...
	 start solving instance: 4...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 75...
	 start solving instance: 66...
	 start solving instance: 31...
	 start solving instance: 99...
	 start solving instance: 25...
	 start solving instance: 108...
	 start solving instance: 18...
	 start solving instance: 90...
	 start solving instance: 1...
	 start solving instance: 124...
	 start solving instance: 85...
	 start solving instance: 120...
	 start solving instance: 78...
	 start solving instance: 22...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.4914258546686375e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22210779786109924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.491425942629568e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.4914258546686375e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22210779786109924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.491425942629568e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.4914258546686375e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22210779786109924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.491425942629568e+19 - Differentiable computation graph = True!
PPO iteration: 632/1000:
	 start solving instance: 85...
	 start solving instance: 124...
	 start solving instance: 75...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 18...
	 start solving instance: 1...
	 start solving instance: 99...
	 start solving instance: 25...
	 start solving instance: 4...
	 start solving instance: 78...
	 start solving instance: 66...
	 start solving instance: 104...
	 start solving instance: 118...
	 start solving instance: 149...
	 start solving instance: 120...
	 start solving instance: 31...
	 start solving instance: 90...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.249241969957022e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21846571564674377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.249242233839813e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.249241969957022e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21846571564674377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.249242233839813e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.249241969957022e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21846571564674377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.249242233839813e+19 - Differentiable computation graph = True!
PPO iteration: 633/1000:
	 start solving instance: 108...
	 start solving instance: 66...
	 start solving instance: 124...
	 start solving instance: 118...
	 start solving instance: 85...
	 start solving instance: 25...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 31...
	 start solving instance: 104...
	 start solving instance: 101...
	 start solving instance: 18...
	 start solving instance: 22...
	 start solving instance: 75...
	 start solving instance: 90...
	 start solving instance: 99...
	 start solving instance: 117...
	 start solving instance: 4...
	 start solving instance: 78...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.084271245325511e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22320304811000824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0842715092083016e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.084271245325511e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22320304811000824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0842715092083016e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.084271245325511e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22320304811000824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0842715092083016e+19 - Differentiable computation graph = True!
PPO iteration: 634/1000:
	 start solving instance: 99...
	 start solving instance: 124...
	 start solving instance: 1...
	 start solving instance: 78...
	 start solving instance: 101...
	 start solving instance: 22...
	 start solving instance: 118...
	 start solving instance: 25...
	 start solving instance: 85...
	 start solving instance: 108...
	 start solving instance: 90...
	 start solving instance: 117...
	 start solving instance: 104...
	 start solving instance: 120...
	 start solving instance: 31...
	 start solving instance: 75...
	 start solving instance: 149...
	 start solving instance: 66...
	 start solving instance: 4...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.061474235117994e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21365690231323242
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.061474235117994e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.061474235117994e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21365690231323242
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.061474235117994e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.061474235117994e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21365690231323242
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.061474235117994e+19 - Differentiable computation graph = True!
PPO iteration: 635/1000:
	 start solving instance: 22...
	 start solving instance: 18...
	 start solving instance: 101...
	 start solving instance: 118...
	 start solving instance: 99...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 4...
	 start solving instance: 90...
	 start solving instance: 85...
	 start solving instance: 75...
	 start solving instance: 1...
	 start solving instance: 25...
	 start solving instance: 78...
	 start solving instance: 117...
	 start solving instance: 31...
	 start solving instance: 149...
	 start solving instance: 104...
	 start solving instance: 66...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.191500193234598e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2284669429063797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.191500281195528e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.191500193234598e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2284669429063797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.191500281195528e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.191500193234598e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2284669429063797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.191500281195528e+19 - Differentiable computation graph = True!
PPO iteration: 636/1000:
	 start solving instance: 118...
	 start solving instance: 1...
	 start solving instance: 22...
	 start solving instance: 31...
	 start solving instance: 120...
	 start solving instance: 78...
	 start solving instance: 108...
	 start solving instance: 124...
	 start solving instance: 149...
	 start solving instance: 117...
	 start solving instance: 66...
	 start solving instance: 25...
	 start solving instance: 75...
	 start solving instance: 101...
	 start solving instance: 85...
	 start solving instance: 4...
	 start solving instance: 99...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.259264238346526e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22882726788520813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.259264502229316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.259264238346526e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22882726788520813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.259264502229316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.259264238346526e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22882726788520813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.259264502229316e+19 - Differentiable computation graph = True!
PPO iteration: 637/1000:
	 start solving instance: 78...
	 start solving instance: 18...
	 start solving instance: 101...
	 start solving instance: 25...
	 start solving instance: 90...
	 start solving instance: 108...
	 start solving instance: 118...
	 start solving instance: 66...
	 start solving instance: 4...
	 start solving instance: 124...
	 start solving instance: 99...
	 start solving instance: 1...
	 start solving instance: 85...
	 start solving instance: 117...
	 start solving instance: 31...
	 start solving instance: 22...
	 start solving instance: 75...
	 start solving instance: 104...
	 start solving instance: 120...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.125805692888935e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23405461013317108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1258057808498655e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.125805692888935e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23405461013317108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1258057808498655e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.125805692888935e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23405461013317108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1258057808498655e+19 - Differentiable computation graph = True!
PPO iteration: 638/1000:
	 start solving instance: 99...
	 start solving instance: 25...
	 start solving instance: 108...
	 start solving instance: 104...
	 start solving instance: 75...
	 start solving instance: 22...
	 start solving instance: 4...
	 start solving instance: 1...
	 start solving instance: 120...
	 start solving instance: 31...
	 start solving instance: 101...
	 start solving instance: 78...
	 start solving instance: 149...
	 start solving instance: 66...
	 start solving instance: 117...
	 start solving instance: 118...
	 start solving instance: 18...
	 start solving instance: 124...
	 start solving instance: 85...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.411874341219509e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22796808183193207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.41187451714137e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.411874341219509e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22796808183193207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.41187451714137e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.411874341219509e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22796808183193207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.41187451714137e+19 - Differentiable computation graph = True!
PPO iteration: 639/1000:
	 start solving instance: 31...
	 start solving instance: 22...
	 start solving instance: 90...
	 start solving instance: 124...
	 start solving instance: 108...
	 start solving instance: 118...
	 start solving instance: 18...
	 start solving instance: 120...
	 start solving instance: 4...
	 start solving instance: 85...
	 start solving instance: 75...
	 start solving instance: 78...
	 start solving instance: 66...
	 start solving instance: 149...
	 start solving instance: 104...
	 start solving instance: 25...
	 start solving instance: 99...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.346943693591895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22419746220111847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.346943957474686e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.346943693591895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22419746220111847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.346943957474686e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.346943693591895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22419746220111847
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.346943957474686e+19 - Differentiable computation graph = True!
PPO iteration: 640/1000:
	 start solving instance: 124...
	 start solving instance: 66...
	 start solving instance: 18...
	 start solving instance: 31...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 85...
	 start solving instance: 118...
	 start solving instance: 90...
	 start solving instance: 22...
	 start solving instance: 104...
	 start solving instance: 101...
	 start solving instance: 149...
	 start solving instance: 4...
	 start solving instance: 99...
	 start solving instance: 78...
	 start solving instance: 1...
	 start solving instance: 120...
	 start solving instance: 75...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.1647484596042963e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21970131993293762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.164748723487087e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.1647484596042963e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21970131993293762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.164748723487087e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.1647484596042963e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21970131993293762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.164748723487087e+19 - Differentiable computation graph = True!
PPO iteration: 641/1000:
	 New training batch of size 20...
	 start solving instance: 13...
	 start solving instance: 129...
	 start solving instance: 77...
	 start solving instance: 114...
	 start solving instance: 59...
	 start solving instance: 89...
	 start solving instance: 56...
	 start solving instance: 41...
	 start solving instance: 94...
	 start solving instance: 8...
	 start solving instance: 67...
	 start solving instance: 145...
	 start solving instance: 68...
	 start solving instance: 7...
	 start solving instance: 72...
	 start solving instance: 61...
	 start solving instance: 80...
	 start solving instance: 107...
	 start solving instance: 53...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3908428627625325e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2214556783437729
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.390842950723463e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3908428627625325e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2214556783437729
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.390842950723463e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3908428627625325e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2214556783437729
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.390842950723463e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.413251085658468e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2154088020324707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 44132509976975376384.0000
PPO iteration: 642/1000:
	 start solving instance: 53...
	 start solving instance: 121...
	 start solving instance: 56...
	 start solving instance: 77...
	 start solving instance: 114...
	 start solving instance: 107...
	 start solving instance: 61...
	 start solving instance: 72...
	 start solving instance: 89...
	 start solving instance: 68...
	 start solving instance: 59...
	 start solving instance: 67...
	 start solving instance: 13...
	 start solving instance: 129...
	 start solving instance: 8...
	 start solving instance: 145...
	 start solving instance: 41...
	 start solving instance: 94...
	 start solving instance: 80...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6690193045898605e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22977276146411896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.669019392550791e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6690193045898605e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22977276146411896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.669019392550791e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6690193045898605e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22977276146411896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.669019392550791e+19 - Differentiable computation graph = True!
PPO iteration: 643/1000:
	 start solving instance: 67...
	 start solving instance: 107...
	 start solving instance: 41...
	 start solving instance: 53...
	 start solving instance: 56...
	 start solving instance: 13...
	 start solving instance: 145...
	 start solving instance: 8...
	 start solving instance: 72...
	 start solving instance: 77...
	 start solving instance: 7...
	 start solving instance: 114...
	 start solving instance: 129...
	 start solving instance: 80...
	 start solving instance: 89...
	 start solving instance: 59...
	 start solving instance: 68...
	 start solving instance: 61...
	 start solving instance: 94...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.510127735767858e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23151837289333344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.510127647806928e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.510127735767858e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23151837289333344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.510127647806928e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.510127735767858e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23151837289333344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.510127647806928e+19 - Differentiable computation graph = True!
PPO iteration: 644/1000:
	 start solving instance: 80...
	 start solving instance: 114...
	 start solving instance: 59...
	 start solving instance: 107...
	 start solving instance: 61...
	 start solving instance: 129...
	 start solving instance: 13...
	 start solving instance: 68...
	 start solving instance: 56...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 8...
	 start solving instance: 77...
	 start solving instance: 72...
	 start solving instance: 94...
	 start solving instance: 121...
	 start solving instance: 7...
	 start solving instance: 67...
	 start solving instance: 145...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.610089351621997e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23032040894031525
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.610089527543857e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.610089351621997e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23032040894031525
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.610089527543857e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.610089351621997e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23032040894031525
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.610089527543857e+19 - Differentiable computation graph = True!
PPO iteration: 645/1000:
	 start solving instance: 80...
	 start solving instance: 145...
	 start solving instance: 121...
	 start solving instance: 8...
	 start solving instance: 41...
	 start solving instance: 61...
	 start solving instance: 67...
	 start solving instance: 72...
	 start solving instance: 68...
	 start solving instance: 114...
	 start solving instance: 56...
	 start solving instance: 59...
	 start solving instance: 129...
	 start solving instance: 94...
	 start solving instance: 89...
	 start solving instance: 53...
	 start solving instance: 77...
	 start solving instance: 13...
	 start solving instance: 107...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.581349700968676e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24169249832630157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.581349613007746e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.581349700968676e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24169249832630157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.581349613007746e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.581349700968676e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24169249832630157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.581349613007746e+19 - Differentiable computation graph = True!
PPO iteration: 646/1000:
	 start solving instance: 80...
	 start solving instance: 77...
	 start solving instance: 7...
	 start solving instance: 107...
	 start solving instance: 56...
	 start solving instance: 121...
	 start solving instance: 59...
	 start solving instance: 61...
	 start solving instance: 41...
	 start solving instance: 114...
	 start solving instance: 53...
	 start solving instance: 72...
	 start solving instance: 13...
	 start solving instance: 129...
	 start solving instance: 89...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 8...
	 start solving instance: 94...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.703500341080637e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2421092987060547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.703500517002497e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.703500341080637e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2421092987060547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.703500517002497e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.703500341080637e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2421092987060547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.703500517002497e+19 - Differentiable computation graph = True!
PPO iteration: 647/1000:
	 start solving instance: 114...
	 start solving instance: 8...
	 start solving instance: 59...
	 start solving instance: 7...
	 start solving instance: 41...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 67...
	 start solving instance: 77...
	 start solving instance: 68...
	 start solving instance: 56...
	 start solving instance: 89...
	 start solving instance: 80...
	 start solving instance: 53...
	 start solving instance: 13...
	 start solving instance: 107...
	 start solving instance: 61...
	 start solving instance: 94...
	 start solving instance: 129...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4360832802380736e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2201867550611496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.436083456159934e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4360832802380736e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2201867550611496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.436083456159934e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4360832802380736e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2201867550611496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.436083456159934e+19 - Differentiable computation graph = True!
PPO iteration: 648/1000:
	 start solving instance: 89...
	 start solving instance: 107...
	 start solving instance: 53...
	 start solving instance: 67...
	 start solving instance: 61...
	 start solving instance: 77...
	 start solving instance: 129...
	 start solving instance: 7...
	 start solving instance: 121...
	 start solving instance: 80...
	 start solving instance: 13...
	 start solving instance: 114...
	 start solving instance: 68...
	 start solving instance: 145...
	 start solving instance: 41...
	 start solving instance: 72...
	 start solving instance: 56...
	 start solving instance: 94...
	 start solving instance: 8...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6571456345410424e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23108454048633575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.657145546580112e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6571456345410424e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23108454048633575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.657145546580112e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6571456345410424e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23108454048633575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.657145546580112e+19 - Differentiable computation graph = True!
PPO iteration: 649/1000:
	 start solving instance: 129...
	 start solving instance: 89...
	 start solving instance: 61...
	 start solving instance: 7...
	 start solving instance: 114...
	 start solving instance: 8...
	 start solving instance: 53...
	 start solving instance: 56...
	 start solving instance: 41...
	 start solving instance: 94...
	 start solving instance: 145...
	 start solving instance: 59...
	 start solving instance: 67...
	 start solving instance: 107...
	 start solving instance: 77...
	 start solving instance: 80...
	 start solving instance: 72...
	 start solving instance: 68...
	 start solving instance: 121...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.445952496608991e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2224959433078766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4459526725308514e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.445952496608991e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2224959433078766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4459526725308514e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.445952496608991e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2224959433078766
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4459526725308514e+19 - Differentiable computation graph = True!
PPO iteration: 650/1000:
	 start solving instance: 68...
	 start solving instance: 114...
	 start solving instance: 77...
	 start solving instance: 129...
	 start solving instance: 13...
	 start solving instance: 67...
	 start solving instance: 61...
	 start solving instance: 7...
	 start solving instance: 56...
	 start solving instance: 94...
	 start solving instance: 80...
	 start solving instance: 53...
	 start solving instance: 59...
	 start solving instance: 89...
	 start solving instance: 107...
	 start solving instance: 41...
	 start solving instance: 72...
	 start solving instance: 145...
	 start solving instance: 121...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6889143077874906e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2425464242696762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.688914395748421e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6889143077874906e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2425464242696762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.688914395748421e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6889143077874906e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2425464242696762
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.688914395748421e+19 - Differentiable computation graph = True!
PPO iteration: 651/1000:
	 New training batch of size 20...
	 start solving instance: 89...
	 start solving instance: 53...
	 start solving instance: 25...
	 start solving instance: 105...
	 start solving instance: 95...
	 start solving instance: 84...
	 start solving instance: 32...
	 start solving instance: 38...
	 start solving instance: 22...
	 start solving instance: 16...
	 start solving instance: 66...
	 start solving instance: 141...
	 start solving instance: 126...
	 start solving instance: 142...
	 start solving instance: 36...
	 start solving instance: 121...
	 start solving instance: 122...
	 start solving instance: 127...
	 start solving instance: 124...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.478325637367925e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20541155338287354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.478325813289786e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.478325637367925e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20541155338287354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.478325813289786e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.478325637367925e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20541155338287354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.478325813289786e+19 - Differentiable computation graph = True!
PPO iteration: 652/1000:
	 start solving instance: 127...
	 start solving instance: 121...
	 start solving instance: 60...
	 start solving instance: 126...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 141...
	 start solving instance: 142...
	 start solving instance: 105...
	 start solving instance: 38...
	 start solving instance: 124...
	 start solving instance: 36...
	 start solving instance: 84...
	 start solving instance: 32...
	 start solving instance: 66...
	 start solving instance: 16...
	 start solving instance: 122...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4847327115253016e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22195403277873993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.484732887447162e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4847327115253016e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22195403277873993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.484732887447162e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4847327115253016e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22195403277873993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.484732887447162e+19 - Differentiable computation graph = True!
PPO iteration: 653/1000:
	 start solving instance: 95...
	 start solving instance: 36...
	 start solving instance: 141...
	 start solving instance: 60...
	 start solving instance: 25...
	 start solving instance: 16...
	 start solving instance: 142...
	 start solving instance: 22...
	 start solving instance: 89...
	 start solving instance: 121...
	 start solving instance: 38...
	 start solving instance: 66...
	 start solving instance: 84...
	 start solving instance: 127...
	 start solving instance: 122...
	 start solving instance: 53...
	 start solving instance: 124...
	 start solving instance: 105...
	 start solving instance: 32...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.66076892117875e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21612797677516937
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.660769097100611e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.66076892117875e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21612797677516937
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.660769097100611e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.66076892117875e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21612797677516937
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.660769097100611e+19 - Differentiable computation graph = True!
PPO iteration: 654/1000:
	 start solving instance: 84...
	 start solving instance: 142...
	 start solving instance: 141...
	 start solving instance: 53...
	 start solving instance: 122...
	 start solving instance: 25...
	 start solving instance: 60...
	 start solving instance: 105...
	 start solving instance: 38...
	 start solving instance: 66...
	 start solving instance: 22...
	 start solving instance: 36...
	 start solving instance: 95...
	 start solving instance: 89...
	 start solving instance: 32...
	 start solving instance: 121...
	 start solving instance: 124...
	 start solving instance: 126...
	 start solving instance: 127...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5357891057071266e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2134631872177124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.535789369589917e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5357891057071266e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2134631872177124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.535789369589917e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5357891057071266e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2134631872177124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.535789369589917e+19 - Differentiable computation graph = True!
PPO iteration: 655/1000:
	 start solving instance: 32...
	 start solving instance: 105...
	 start solving instance: 53...
	 start solving instance: 126...
	 start solving instance: 22...
	 start solving instance: 95...
	 start solving instance: 121...
	 start solving instance: 127...
	 start solving instance: 38...
	 start solving instance: 36...
	 start solving instance: 25...
	 start solving instance: 60...
	 start solving instance: 122...
	 start solving instance: 124...
	 start solving instance: 89...
	 start solving instance: 141...
	 start solving instance: 142...
	 start solving instance: 66...
	 start solving instance: 84...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.52875610157029e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148226797580719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.52875601360936e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.52875610157029e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148226797580719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.52875601360936e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.52875610157029e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148226797580719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.52875601360936e+19 - Differentiable computation graph = True!
PPO iteration: 656/1000:
	 start solving instance: 16...
	 start solving instance: 95...
	 start solving instance: 38...
	 start solving instance: 53...
	 start solving instance: 22...
	 start solving instance: 126...
	 start solving instance: 36...
	 start solving instance: 25...
	 start solving instance: 122...
	 start solving instance: 141...
	 start solving instance: 121...
	 start solving instance: 105...
	 start solving instance: 142...
	 start solving instance: 66...
	 start solving instance: 127...
	 start solving instance: 124...
	 start solving instance: 89...
	 start solving instance: 32...
	 start solving instance: 84...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.64938959155778e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20300674438476562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64938959155778e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.64938959155778e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20300674438476562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64938959155778e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.64938959155778e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20300674438476562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64938959155778e+19 - Differentiable computation graph = True!
PPO iteration: 657/1000:
	 start solving instance: 124...
	 start solving instance: 122...
	 start solving instance: 142...
	 start solving instance: 60...
	 start solving instance: 84...
	 start solving instance: 22...
	 start solving instance: 126...
	 start solving instance: 16...
	 start solving instance: 127...
	 start solving instance: 38...
	 start solving instance: 32...
	 start solving instance: 66...
	 start solving instance: 89...
	 start solving instance: 121...
	 start solving instance: 105...
	 start solving instance: 36...
	 start solving instance: 53...
	 start solving instance: 95...
	 start solving instance: 141...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.745126619855213e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2253020852804184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.745126707816143e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.745126619855213e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2253020852804184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.745126707816143e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.745126619855213e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2253020852804184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.745126707816143e+19 - Differentiable computation graph = True!
PPO iteration: 658/1000:
	 start solving instance: 53...
	 start solving instance: 95...
	 start solving instance: 38...
	 start solving instance: 36...
	 start solving instance: 127...
	 start solving instance: 22...
	 start solving instance: 66...
	 start solving instance: 84...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 122...
	 start solving instance: 25...
	 start solving instance: 124...
	 start solving instance: 126...
	 start solving instance: 16...
	 start solving instance: 105...
	 start solving instance: 121...
	 start solving instance: 60...
	 start solving instance: 89...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.535764828490385e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21285009384155273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.535764740529455e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.535764828490385e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21285009384155273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.535764740529455e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.535764828490385e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21285009384155273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.535764740529455e+19 - Differentiable computation graph = True!
PPO iteration: 659/1000:
	 start solving instance: 141...
	 start solving instance: 105...
	 start solving instance: 38...
	 start solving instance: 66...
	 start solving instance: 16...
	 start solving instance: 142...
	 start solving instance: 122...
	 start solving instance: 89...
	 start solving instance: 95...
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 25...
	 start solving instance: 127...
	 start solving instance: 84...
	 start solving instance: 32...
	 start solving instance: 60...
	 start solving instance: 126...
	 start solving instance: 53...
	 start solving instance: 124...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.71101114899044e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21428032219409943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7110110610295095e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.71101114899044e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21428032219409943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7110110610295095e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.71101114899044e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21428032219409943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7110110610295095e+19 - Differentiable computation graph = True!
PPO iteration: 660/1000:
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 141...
	 start solving instance: 124...
	 start solving instance: 32...
	 start solving instance: 60...
	 start solving instance: 22...
	 start solving instance: 105...
	 start solving instance: 16...
	 start solving instance: 142...
	 start solving instance: 126...
	 start solving instance: 95...
	 start solving instance: 84...
	 start solving instance: 53...
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 38...
	 start solving instance: 122...
	 start solving instance: 66...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.596583126708257e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2096550017595291
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.596583126708257e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.596583126708257e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2096550017595291
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.596583126708257e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.596583126708257e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2096550017595291
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.596583126708257e+19 - Differentiable computation graph = True!
PPO iteration: 661/1000:
	 New training batch of size 20...
	 start solving instance: 134...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 57...
	 start solving instance: 102...
	 start solving instance: 150...
	 start solving instance: 38...
	 start solving instance: 29...
	 start solving instance: 41...
	 start solving instance: 77...
	 start solving instance: 28...
	 start solving instance: 144...
	 start solving instance: 35...
	 start solving instance: 69...
	 start solving instance: 93...
	 start solving instance: 63...
	 start solving instance: 119...
	 start solving instance: 46...
	 start solving instance: 120...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.570218773014653e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2123216837644577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.570219036897444e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.570218773014653e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2123216837644577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.570219036897444e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.570218773014653e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2123216837644577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.570219036897444e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.1985388068300915e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21713793277740479
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 41985388068300914688.0000
PPO iteration: 662/1000:
	 start solving instance: 120...
	 start solving instance: 93...
	 start solving instance: 41...
	 start solving instance: 134...
	 start solving instance: 29...
	 start solving instance: 77...
	 start solving instance: 63...
	 start solving instance: 57...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 144...
	 start solving instance: 35...
	 start solving instance: 28...
	 start solving instance: 46...
	 start solving instance: 102...
	 start solving instance: 47...
	 start solving instance: 119...
	 start solving instance: 150...
	 start solving instance: 38...
	 start solving instance: 69...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.099058181383284e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2180783748626709
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.099058181383284e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.099058181383284e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2180783748626709
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.099058181383284e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.099058181383284e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2180783748626709
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.099058181383284e+19 - Differentiable computation graph = True!
PPO iteration: 663/1000:
	 start solving instance: 57...
	 start solving instance: 28...
	 start solving instance: 69...
	 start solving instance: 150...
	 start solving instance: 119...
	 start solving instance: 134...
	 start solving instance: 35...
	 start solving instance: 120...
	 start solving instance: 24...
	 start solving instance: 93...
	 start solving instance: 38...
	 start solving instance: 41...
	 start solving instance: 77...
	 start solving instance: 61...
	 start solving instance: 63...
	 start solving instance: 144...
	 start solving instance: 46...
	 start solving instance: 47...
	 start solving instance: 29...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.959011010408339e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22114157676696777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9590111863302e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.959011010408339e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22114157676696777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9590111863302e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.959011010408339e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22114157676696777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9590111863302e+19 - Differentiable computation graph = True!
PPO iteration: 664/1000:
	 start solving instance: 63...
	 start solving instance: 77...
	 start solving instance: 119...
	 start solving instance: 46...
	 start solving instance: 150...
	 start solving instance: 28...
	 start solving instance: 120...
	 start solving instance: 29...
	 start solving instance: 134...
	 start solving instance: 144...
	 start solving instance: 38...
	 start solving instance: 35...
	 start solving instance: 93...
	 start solving instance: 57...
	 start solving instance: 69...
	 start solving instance: 41...
	 start solving instance: 47...
	 start solving instance: 102...
	 start solving instance: 24...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.896834243584118e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2362581342458725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.896834243584118e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.896834243584118e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2362581342458725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.896834243584118e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.896834243584118e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2362581342458725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.896834243584118e+19 - Differentiable computation graph = True!
PPO iteration: 665/1000:
	 start solving instance: 120...
	 start solving instance: 38...
	 start solving instance: 35...
	 start solving instance: 134...
	 start solving instance: 102...
	 start solving instance: 144...
	 start solving instance: 46...
	 start solving instance: 28...
	 start solving instance: 57...
	 start solving instance: 63...
	 start solving instance: 119...
	 start solving instance: 93...
	 start solving instance: 77...
	 start solving instance: 41...
	 start solving instance: 69...
	 start solving instance: 61...
	 start solving instance: 47...
	 start solving instance: 24...
	 start solving instance: 29...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6787294875989364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21037645637989044
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.678729399638006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6787294875989364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21037645637989044
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.678729399638006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6787294875989364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21037645637989044
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.678729399638006e+19 - Differentiable computation graph = True!
PPO iteration: 666/1000:
	 start solving instance: 102...
	 start solving instance: 144...
	 start solving instance: 24...
	 start solving instance: 57...
	 start solving instance: 150...
	 start solving instance: 47...
	 start solving instance: 35...
	 start solving instance: 134...
	 start solving instance: 61...
	 start solving instance: 46...
	 start solving instance: 29...
	 start solving instance: 120...
	 start solving instance: 69...
	 start solving instance: 41...
	 start solving instance: 38...
	 start solving instance: 77...
	 start solving instance: 28...
	 start solving instance: 63...
	 start solving instance: 119...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.008388054510364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22395431995391846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.008388054510364e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.008388054510364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22395431995391846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.008388054510364e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.008388054510364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22395431995391846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.008388054510364e+19 - Differentiable computation graph = True!
PPO iteration: 667/1000:
	 start solving instance: 38...
	 start solving instance: 150...
	 start solving instance: 57...
	 start solving instance: 35...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 47...
	 start solving instance: 24...
	 start solving instance: 63...
	 start solving instance: 69...
	 start solving instance: 77...
	 start solving instance: 102...
	 start solving instance: 46...
	 start solving instance: 144...
	 start solving instance: 61...
	 start solving instance: 119...
	 start solving instance: 120...
	 start solving instance: 41...
	 start solving instance: 29...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.884357513397697e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22915850579738617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.884357425436767e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.884357513397697e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22915850579738617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.884357425436767e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.884357513397697e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22915850579738617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.884357425436767e+19 - Differentiable computation graph = True!
PPO iteration: 668/1000:
	 start solving instance: 41...
	 start solving instance: 29...
	 start solving instance: 35...
	 start solving instance: 63...
	 start solving instance: 61...
	 start solving instance: 47...
	 start solving instance: 144...
	 start solving instance: 38...
	 start solving instance: 57...
	 start solving instance: 28...
	 start solving instance: 120...
	 start solving instance: 150...
	 start solving instance: 93...
	 start solving instance: 134...
	 start solving instance: 102...
	 start solving instance: 77...
	 start solving instance: 24...
	 start solving instance: 119...
	 start solving instance: 69...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.751900667013476e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20853964984416962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751900579052546e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.751900667013476e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20853964984416962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751900579052546e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.751900667013476e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20853964984416962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751900579052546e+19 - Differentiable computation graph = True!
PPO iteration: 669/1000:
	 start solving instance: 134...
	 start solving instance: 46...
	 start solving instance: 120...
	 start solving instance: 57...
	 start solving instance: 38...
	 start solving instance: 144...
	 start solving instance: 61...
	 start solving instance: 41...
	 start solving instance: 77...
	 start solving instance: 63...
	 start solving instance: 28...
	 start solving instance: 47...
	 start solving instance: 29...
	 start solving instance: 102...
	 start solving instance: 119...
	 start solving instance: 35...
	 start solving instance: 150...
	 start solving instance: 69...
	 start solving instance: 24...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8717931741247753e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2333538830280304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.871793086163845e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8717931741247753e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2333538830280304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.871793086163845e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8717931741247753e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2333538830280304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.871793086163845e+19 - Differentiable computation graph = True!
PPO iteration: 670/1000:
	 start solving instance: 61...
	 start solving instance: 41...
	 start solving instance: 150...
	 start solving instance: 144...
	 start solving instance: 38...
	 start solving instance: 63...
	 start solving instance: 29...
	 start solving instance: 102...
	 start solving instance: 47...
	 start solving instance: 28...
	 start solving instance: 93...
	 start solving instance: 35...
	 start solving instance: 120...
	 start solving instance: 46...
	 start solving instance: 24...
	 start solving instance: 77...
	 start solving instance: 119...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.764346786796179e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21176449954509735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.76434705067897e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.764346786796179e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21176449954509735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.76434705067897e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.764346786796179e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21176449954509735
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.76434705067897e+19 - Differentiable computation graph = True!
PPO iteration: 671/1000:
	 New training batch of size 20...
	 start solving instance: 44...
	 start solving instance: 35...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 124...
	 start solving instance: 63...
	 start solving instance: 41...
	 start solving instance: 115...
	 start solving instance: 130...
	 start solving instance: 84...
	 start solving instance: 5...
	 start solving instance: 144...
	 start solving instance: 66...
	 start solving instance: 106...
	 start solving instance: 146...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 32...
	 start solving instance: 135...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.400211757362347e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20947487652301788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4002116694014165e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.400211757362347e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20947487652301788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4002116694014165e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.400211757362347e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20947487652301788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4002116694014165e+19 - Differentiable computation graph = True!
PPO iteration: 672/1000:
	 start solving instance: 144...
	 start solving instance: 5...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 32...
	 start solving instance: 135...
	 start solving instance: 41...
	 start solving instance: 115...
	 start solving instance: 48...
	 start solving instance: 63...
	 start solving instance: 132...
	 start solving instance: 35...
	 start solving instance: 106...
	 start solving instance: 44...
	 start solving instance: 117...
	 start solving instance: 124...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 130...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.817918159894914e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2240736037492752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8179183358167745e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.817918159894914e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2240736037492752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8179183358167745e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.817918159894914e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2240736037492752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8179183358167745e+19 - Differentiable computation graph = True!
PPO iteration: 673/1000:
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 124...
	 start solving instance: 135...
	 start solving instance: 130...
	 start solving instance: 32...
	 start solving instance: 63...
	 start solving instance: 146...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 44...
	 start solving instance: 101...
	 start solving instance: 41...
	 start solving instance: 66...
	 start solving instance: 54...
	 start solving instance: 115...
	 start solving instance: 84...
	 start solving instance: 106...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.669179041639144e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20213933289051056
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.669179041639144e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.669179041639144e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20213933289051056
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.669179041639144e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.669179041639144e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20213933289051056
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.669179041639144e+19 - Differentiable computation graph = True!
PPO iteration: 674/1000:
	 start solving instance: 130...
	 start solving instance: 101...
	 start solving instance: 144...
	 start solving instance: 32...
	 start solving instance: 135...
	 start solving instance: 48...
	 start solving instance: 54...
	 start solving instance: 41...
	 start solving instance: 44...
	 start solving instance: 106...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 35...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 124...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 5...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7815917030880785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20386753976345062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.781591791049009e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7815917030880785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20386753976345062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.781591791049009e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7815917030880785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20386753976345062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.781591791049009e+19 - Differentiable computation graph = True!
PPO iteration: 675/1000:
	 start solving instance: 44...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 84...
	 start solving instance: 5...
	 start solving instance: 63...
	 start solving instance: 124...
	 start solving instance: 117...
	 start solving instance: 115...
	 start solving instance: 101...
	 start solving instance: 106...
	 start solving instance: 54...
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 41...
	 start solving instance: 132...
	 start solving instance: 130...
	 start solving instance: 144...
	 start solving instance: 66...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6270299230953275e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20995405316352844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6270299230953275e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6270299230953275e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20995405316352844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6270299230953275e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6270299230953275e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20995405316352844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6270299230953275e+19 - Differentiable computation graph = True!
PPO iteration: 676/1000:
	 start solving instance: 115...
	 start solving instance: 84...
	 start solving instance: 66...
	 start solving instance: 146...
	 start solving instance: 44...
	 start solving instance: 130...
	 start solving instance: 101...
	 start solving instance: 144...
	 start solving instance: 48...
	 start solving instance: 135...
	 start solving instance: 54...
	 start solving instance: 117...
	 start solving instance: 32...
	 start solving instance: 5...
	 start solving instance: 132...
	 start solving instance: 106...
	 start solving instance: 35...
	 start solving instance: 124...
	 start solving instance: 41...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8537910901455244e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.221703439950943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853791002184594e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8537910901455244e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.221703439950943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853791002184594e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8537910901455244e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.221703439950943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853791002184594e+19 - Differentiable computation graph = True!
PPO iteration: 677/1000:
	 start solving instance: 130...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 32...
	 start solving instance: 41...
	 start solving instance: 48...
	 start solving instance: 115...
	 start solving instance: 124...
	 start solving instance: 66...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 117...
	 start solving instance: 106...
	 start solving instance: 5...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 54...
	 start solving instance: 135...
	 start solving instance: 132...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.739303958118232e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22331510484218597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.739304134040093e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.739303958118232e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22331510484218597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.739304134040093e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.739303958118232e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22331510484218597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.739304134040093e+19 - Differentiable computation graph = True!
PPO iteration: 678/1000:
	 start solving instance: 106...
	 start solving instance: 132...
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 32...
	 start solving instance: 101...
	 start solving instance: 35...
	 start solving instance: 146...
	 start solving instance: 124...
	 start solving instance: 66...
	 start solving instance: 135...
	 start solving instance: 41...
	 start solving instance: 63...
	 start solving instance: 54...
	 start solving instance: 5...
	 start solving instance: 84...
	 start solving instance: 144...
	 start solving instance: 117...
	 start solving instance: 115...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.74761661786794e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21029292047023773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.74761688175073e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.74761661786794e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21029292047023773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.74761688175073e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.74761661786794e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21029292047023773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.74761688175073e+19 - Differentiable computation graph = True!
PPO iteration: 679/1000:
	 start solving instance: 101...
	 start solving instance: 66...
	 start solving instance: 106...
	 start solving instance: 132...
	 start solving instance: 146...
	 start solving instance: 115...
	 start solving instance: 117...
	 start solving instance: 32...
	 start solving instance: 124...
	 start solving instance: 44...
	 start solving instance: 5...
	 start solving instance: 54...
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 144...
	 start solving instance: 84...
	 start solving instance: 41...
	 start solving instance: 130...
	 start solving instance: 63...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.630727448758143e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21473275125026703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.630727360797213e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.630727448758143e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21473275125026703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.630727360797213e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.630727448758143e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21473275125026703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.630727360797213e+19 - Differentiable computation graph = True!
PPO iteration: 680/1000:
	 start solving instance: 32...
	 start solving instance: 5...
	 start solving instance: 41...
	 start solving instance: 117...
	 start solving instance: 48...
	 start solving instance: 101...
	 start solving instance: 63...
	 start solving instance: 106...
	 start solving instance: 130...
	 start solving instance: 144...
	 start solving instance: 84...
	 start solving instance: 44...
	 start solving instance: 146...
	 start solving instance: 66...
	 start solving instance: 124...
	 start solving instance: 132...
	 start solving instance: 54...
	 start solving instance: 115...
	 start solving instance: 35...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7728902560267895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2015639841556549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7728902560267895e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7728902560267895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2015639841556549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7728902560267895e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7728902560267895e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2015639841556549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7728902560267895e+19 - Differentiable computation graph = True!
PPO iteration: 681/1000:
	 New training batch of size 20...
	 start solving instance: 3...
	 start solving instance: 23...
	 start solving instance: 36...
	 start solving instance: 44...
	 start solving instance: 50...
	 start solving instance: 105...
	 start solving instance: 22...
	 start solving instance: 132...
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 124...
	 start solving instance: 98...
	 start solving instance: 94...
	 start solving instance: 145...
	 start solving instance: 120...
	 start solving instance: 88...
	 start solving instance: 30...
	 start solving instance: 128...
	 start solving instance: 15...
	 start solving instance: 6...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0078159566202e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23274675011634827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.00781586865927e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0078159566202e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23274675011634827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.00781586865927e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0078159566202e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23274675011634827
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.00781586865927e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.807177778471077e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20731468498706818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 48071778664320073728.0000
PPO iteration: 682/1000:
	 start solving instance: 94...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 44...
	 start solving instance: 132...
	 start solving instance: 50...
	 start solving instance: 15...
	 start solving instance: 6...
	 start solving instance: 88...
	 start solving instance: 128...
	 start solving instance: 22...
	 start solving instance: 65...
	 start solving instance: 36...
	 start solving instance: 105...
	 start solving instance: 145...
	 start solving instance: 120...
	 start solving instance: 3...
	 start solving instance: 124...
	 start solving instance: 39...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0240232857791994e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2298961877822876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.02402354966199e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0240232857791994e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2298961877822876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.02402354966199e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0240232857791994e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2298961877822876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.02402354966199e+19 - Differentiable computation graph = True!
PPO iteration: 683/1000:
	 start solving instance: 3...
	 start solving instance: 145...
	 start solving instance: 30...
	 start solving instance: 132...
	 start solving instance: 94...
	 start solving instance: 39...
	 start solving instance: 15...
	 start solving instance: 50...
	 start solving instance: 23...
	 start solving instance: 36...
	 start solving instance: 105...
	 start solving instance: 120...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 6...
	 start solving instance: 22...
	 start solving instance: 98...
	 start solving instance: 65...
	 start solving instance: 88...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.840209922519235e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22199860215187073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.840209834558305e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.840209922519235e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22199860215187073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.840209834558305e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.840209922519235e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22199860215187073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.840209834558305e+19 - Differentiable computation graph = True!
PPO iteration: 684/1000:
	 start solving instance: 23...
	 start solving instance: 6...
	 start solving instance: 65...
	 start solving instance: 124...
	 start solving instance: 145...
	 start solving instance: 44...
	 start solving instance: 94...
	 start solving instance: 22...
	 start solving instance: 50...
	 start solving instance: 120...
	 start solving instance: 105...
	 start solving instance: 128...
	 start solving instance: 3...
	 start solving instance: 30...
	 start solving instance: 98...
	 start solving instance: 36...
	 start solving instance: 39...
	 start solving instance: 88...
	 start solving instance: 132...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.965912073149843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2231416255235672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.965912161110773e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.965912073149843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2231416255235672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.965912161110773e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.965912073149843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2231416255235672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.965912161110773e+19 - Differentiable computation graph = True!
PPO iteration: 685/1000:
	 start solving instance: 6...
	 start solving instance: 36...
	 start solving instance: 39...
	 start solving instance: 23...
	 start solving instance: 50...
	 start solving instance: 128...
	 start solving instance: 22...
	 start solving instance: 124...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 94...
	 start solving instance: 65...
	 start solving instance: 120...
	 start solving instance: 98...
	 start solving instance: 132...
	 start solving instance: 105...
	 start solving instance: 3...
	 start solving instance: 88...
	 start solving instance: 30...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.879762786246617e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2206159085035324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.879762786246617e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.879762786246617e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2206159085035324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.879762786246617e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.879762786246617e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2206159085035324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.879762786246617e+19 - Differentiable computation graph = True!
PPO iteration: 686/1000:
	 start solving instance: 22...
	 start solving instance: 94...
	 start solving instance: 39...
	 start solving instance: 44...
	 start solving instance: 132...
	 start solving instance: 36...
	 start solving instance: 6...
	 start solving instance: 15...
	 start solving instance: 30...
	 start solving instance: 105...
	 start solving instance: 145...
	 start solving instance: 124...
	 start solving instance: 65...
	 start solving instance: 3...
	 start solving instance: 128...
	 start solving instance: 50...
	 start solving instance: 88...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8607350778209763e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2216806858778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.860735077820976e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8607350778209763e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2216806858778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.860735077820976e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8607350778209763e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2216806858778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.860735077820976e+19 - Differentiable computation graph = True!
PPO iteration: 687/1000:
	 start solving instance: 39...
	 start solving instance: 15...
	 start solving instance: 124...
	 start solving instance: 44...
	 start solving instance: 50...
	 start solving instance: 120...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 132...
	 start solving instance: 128...
	 start solving instance: 6...
	 start solving instance: 145...
	 start solving instance: 3...
	 start solving instance: 30...
	 start solving instance: 22...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 105...
	 start solving instance: 36...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.956251851949133e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21844542026519775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.956251851949133e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.956251851949133e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21844542026519775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.956251851949133e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.956251851949133e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21844542026519775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.956251851949133e+19 - Differentiable computation graph = True!
PPO iteration: 688/1000:
	 start solving instance: 88...
	 start solving instance: 98...
	 start solving instance: 6...
	 start solving instance: 124...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 22...
	 start solving instance: 65...
	 start solving instance: 132...
	 start solving instance: 36...
	 start solving instance: 30...
	 start solving instance: 128...
	 start solving instance: 50...
	 start solving instance: 39...
	 start solving instance: 94...
	 start solving instance: 105...
	 start solving instance: 3...
	 start solving instance: 120...
	 start solving instance: 23...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.753572980218858e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21808914840221405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7535731561407185e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.753572980218858e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21808914840221405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7535731561407185e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.753572980218858e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21808914840221405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7535731561407185e+19 - Differentiable computation graph = True!
PPO iteration: 689/1000:
	 start solving instance: 22...
	 start solving instance: 94...
	 start solving instance: 120...
	 start solving instance: 6...
	 start solving instance: 98...
	 start solving instance: 15...
	 start solving instance: 65...
	 start solving instance: 105...
	 start solving instance: 3...
	 start solving instance: 128...
	 start solving instance: 88...
	 start solving instance: 124...
	 start solving instance: 39...
	 start solving instance: 36...
	 start solving instance: 132...
	 start solving instance: 30...
	 start solving instance: 50...
	 start solving instance: 44...
	 start solving instance: 145...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.659565615653312e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2197495549917221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.659565791575173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.659565615653312e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21824268996715546
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.659565791575173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.659565615653312e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21824268996715546
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.659565791575173e+19 - Differentiable computation graph = True!
PPO iteration: 690/1000:
	 start solving instance: 3...
	 start solving instance: 124...
	 start solving instance: 6...
	 start solving instance: 44...
	 start solving instance: 94...
	 start solving instance: 15...
	 start solving instance: 98...
	 start solving instance: 120...
	 start solving instance: 23...
	 start solving instance: 132...
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 36...
	 start solving instance: 88...
	 start solving instance: 50...
	 start solving instance: 105...
	 start solving instance: 145...
	 start solving instance: 30...
	 start solving instance: 128...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.731867037389816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2143106907606125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.731867037389816e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.731867037389816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2143106907606125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.731867037389816e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.731867037389816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2143106907606125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.731867037389816e+19 - Differentiable computation graph = True!
PPO iteration: 691/1000:
	 New training batch of size 20...
	 start solving instance: 71...
	 start solving instance: 144...
	 start solving instance: 20...
	 start solving instance: 16...
	 start solving instance: 73...
	 start solving instance: 126...
	 start solving instance: 112...
	 start solving instance: 97...
	 start solving instance: 141...
	 start solving instance: 115...
	 start solving instance: 93...
	 start solving instance: 26...
	 start solving instance: 111...
	 start solving instance: 128...
	 start solving instance: 109...
	 start solving instance: 59...
	 start solving instance: 68...
	 start solving instance: 33...
	 start solving instance: 138...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5959005498897334e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2512679696083069
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5959005498897334e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5959005498897334e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2512679696083069
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5959005498897334e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5959005498897334e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2512679696083069
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5959005498897334e+19 - Differentiable computation graph = True!
PPO iteration: 692/1000:
	 start solving instance: 59...
	 start solving instance: 128...
	 start solving instance: 26...
	 start solving instance: 134...
	 start solving instance: 112...
	 start solving instance: 16...
	 start solving instance: 141...
	 start solving instance: 115...
	 start solving instance: 144...
	 start solving instance: 93...
	 start solving instance: 73...
	 start solving instance: 33...
	 start solving instance: 138...
	 start solving instance: 20...
	 start solving instance: 68...
	 start solving instance: 111...
	 start solving instance: 97...
	 start solving instance: 126...
	 start solving instance: 109...
	 start solving instance: 71...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.604657236415202e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.259470671415329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.604657500297993e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.604657236415202e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.259470671415329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.604657500297993e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.604657236415202e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.259470671415329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.604657500297993e+19 - Differentiable computation graph = True!
PPO iteration: 693/1000:
	 start solving instance: 93...
	 start solving instance: 73...
	 start solving instance: 20...
	 start solving instance: 115...
	 start solving instance: 71...
	 start solving instance: 68...
	 start solving instance: 33...
	 start solving instance: 144...
	 start solving instance: 138...
	 start solving instance: 97...
	 start solving instance: 109...
	 start solving instance: 128...
	 start solving instance: 126...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 16...
	 start solving instance: 141...
	 start solving instance: 26...
	 start solving instance: 111...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.70276885798491e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23419320583343506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.702769121867701e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.70276885798491e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23419320583343506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.702769121867701e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.70276885798491e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23419320583343506
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.702769121867701e+19 - Differentiable computation graph = True!
PPO iteration: 694/1000:
	 start solving instance: 126...
	 start solving instance: 111...
	 start solving instance: 144...
	 start solving instance: 68...
	 start solving instance: 134...
	 start solving instance: 33...
	 start solving instance: 128...
	 start solving instance: 115...
	 start solving instance: 112...
	 start solving instance: 71...
	 start solving instance: 138...
	 start solving instance: 109...
	 start solving instance: 93...
	 start solving instance: 16...
	 start solving instance: 20...
	 start solving instance: 73...
	 start solving instance: 26...
	 start solving instance: 97...
	 start solving instance: 59...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6804331148954776e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.25190678238868713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.680433202856408e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6804331148954776e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.25190678238868713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.680433202856408e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6804331148954776e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.25190678238868713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.680433202856408e+19 - Differentiable computation graph = True!
PPO iteration: 695/1000:
	 start solving instance: 115...
	 start solving instance: 26...
	 start solving instance: 112...
	 start solving instance: 33...
	 start solving instance: 111...
	 start solving instance: 138...
	 start solving instance: 59...
	 start solving instance: 68...
	 start solving instance: 73...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 71...
	 start solving instance: 16...
	 start solving instance: 144...
	 start solving instance: 97...
	 start solving instance: 20...
	 start solving instance: 141...
	 start solving instance: 93...
	 start solving instance: 109...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.844453509636869e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2489607185125351
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.844453509636869e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.844453509636869e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2489607185125351
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.844453509636869e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.844453509636869e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2489607185125351
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.844453509636869e+19 - Differentiable computation graph = True!
PPO iteration: 696/1000:
	 start solving instance: 73...
	 start solving instance: 141...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 126...
	 start solving instance: 93...
	 start solving instance: 115...
	 start solving instance: 109...
	 start solving instance: 59...
	 start solving instance: 111...
	 start solving instance: 71...
	 start solving instance: 134...
	 start solving instance: 68...
	 start solving instance: 138...
	 start solving instance: 16...
	 start solving instance: 112...
	 start solving instance: 20...
	 start solving instance: 97...
	 start solving instance: 128...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4262506556141286e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2359064370393753
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.426250743575059e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4262506556141286e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2359064370393753
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.426250743575059e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4262506556141286e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2359064370393753
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.426250743575059e+19 - Differentiable computation graph = True!
PPO iteration: 697/1000:
	 start solving instance: 109...
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 20...
	 start solving instance: 128...
	 start solving instance: 68...
	 start solving instance: 111...
	 start solving instance: 134...
	 start solving instance: 71...
	 start solving instance: 93...
	 start solving instance: 138...
	 start solving instance: 115...
	 start solving instance: 16...
	 start solving instance: 126...
	 start solving instance: 112...
	 start solving instance: 59...
	 start solving instance: 73...
	 start solving instance: 97...
	 start solving instance: 141...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.713382927512948e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24759338796138763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713382927512948e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.713382927512948e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24662797152996063
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713382927512948e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.713382927512948e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24662797152996063
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713382927512948e+19 - Differentiable computation graph = True!
PPO iteration: 698/1000:
	 start solving instance: 134...
	 start solving instance: 97...
	 start solving instance: 26...
	 start solving instance: 33...
	 start solving instance: 111...
	 start solving instance: 71...
	 start solving instance: 144...
	 start solving instance: 68...
	 start solving instance: 128...
	 start solving instance: 115...
	 start solving instance: 73...
	 start solving instance: 138...
	 start solving instance: 20...
	 start solving instance: 126...
	 start solving instance: 59...
	 start solving instance: 93...
	 start solving instance: 141...
	 start solving instance: 109...
	 start solving instance: 112...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6357130742831304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2509612739086151
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6357129863222e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6357130742831304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24994759261608124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6357129863222e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6357130742831304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24994759261608124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6357129863222e+19 - Differentiable computation graph = True!
PPO iteration: 699/1000:
	 start solving instance: 73...
	 start solving instance: 59...
	 start solving instance: 144...
	 start solving instance: 112...
	 start solving instance: 109...
	 start solving instance: 138...
	 start solving instance: 26...
	 start solving instance: 115...
	 start solving instance: 134...
	 start solving instance: 20...
	 start solving instance: 71...
	 start solving instance: 33...
	 start solving instance: 97...
	 start solving instance: 16...
	 start solving instance: 126...
	 start solving instance: 93...
	 start solving instance: 141...
	 start solving instance: 128...
	 start solving instance: 68...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4910746945943136e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24529699981212616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.491074870516174e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4910746945943136e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24529699981212616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.491074870516174e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4910746945943136e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24529699981212616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.491074870516174e+19 - Differentiable computation graph = True!
PPO iteration: 700/1000:
	 start solving instance: 33...
	 start solving instance: 16...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 59...
	 start solving instance: 20...
	 start solving instance: 126...
	 start solving instance: 71...
	 start solving instance: 141...
	 start solving instance: 109...
	 start solving instance: 144...
	 start solving instance: 115...
	 start solving instance: 134...
	 start solving instance: 73...
	 start solving instance: 26...
	 start solving instance: 93...
	 start solving instance: 111...
	 start solving instance: 68...
	 start solving instance: 138...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.72741269588337e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.25746798515319824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.72741269588337e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.72741269588337e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.25746798515319824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.72741269588337e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.72741269588337e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.25746798515319824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.72741269588337e+19 - Differentiable computation graph = True!
PPO iteration: 701/1000:
	 New training batch of size 20...
	 start solving instance: 130...
	 start solving instance: 11...
	 start solving instance: 29...
	 start solving instance: 30...
	 start solving instance: 88...
	 start solving instance: 27...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 44...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 111...
	 start solving instance: 147...
	 start solving instance: 36...
	 start solving instance: 146...
	 start solving instance: 112...
	 start solving instance: 120...
	 start solving instance: 25...
	 start solving instance: 71...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6220397236019685e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22396861016750336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.622039899523829e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6220397236019685e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22396861016750336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.622039899523829e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6220397236019685e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22396861016750336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.622039899523829e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.379761896616876e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21558403968811035
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43797620725387362304.0000
PPO iteration: 702/1000:
	 start solving instance: 29...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 111...
	 start solving instance: 141...
	 start solving instance: 71...
	 start solving instance: 117...
	 start solving instance: 85...
	 start solving instance: 21...
	 start solving instance: 36...
	 start solving instance: 147...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 34...
	 start solving instance: 11...
	 start solving instance: 44...
	 start solving instance: 120...
	 start solving instance: 27...
	 start solving instance: 112...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.711911517072193e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2368946075439453
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711911780954984e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.711911517072193e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2368946075439453
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711911780954984e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.711911517072193e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2368946075439453
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711911780954984e+19 - Differentiable computation graph = True!
PPO iteration: 703/1000:
	 start solving instance: 117...
	 start solving instance: 111...
	 start solving instance: 21...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 130...
	 start solving instance: 34...
	 start solving instance: 29...
	 start solving instance: 146...
	 start solving instance: 88...
	 start solving instance: 25...
	 start solving instance: 85...
	 start solving instance: 71...
	 start solving instance: 30...
	 start solving instance: 44...
	 start solving instance: 11...
	 start solving instance: 141...
	 start solving instance: 147...
	 start solving instance: 27...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.664327116728094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23225684463977814
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.664327116728094e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.664327116728094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23225684463977814
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.664327116728094e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.664327116728094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23225684463977814
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.664327116728094e+19 - Differentiable computation graph = True!
PPO iteration: 704/1000:
	 start solving instance: 36...
	 start solving instance: 112...
	 start solving instance: 141...
	 start solving instance: 85...
	 start solving instance: 146...
	 start solving instance: 25...
	 start solving instance: 71...
	 start solving instance: 29...
	 start solving instance: 117...
	 start solving instance: 147...
	 start solving instance: 21...
	 start solving instance: 44...
	 start solving instance: 27...
	 start solving instance: 111...
	 start solving instance: 34...
	 start solving instance: 120...
	 start solving instance: 11...
	 start solving instance: 130...
	 start solving instance: 30...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5038339552886076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22846053540706635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.503834043249538e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5038339552886076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22846053540706635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.503834043249538e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5038339552886076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22846053540706635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.503834043249538e+19 - Differentiable computation graph = True!
PPO iteration: 705/1000:
	 start solving instance: 130...
	 start solving instance: 88...
	 start solving instance: 141...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 11...
	 start solving instance: 111...
	 start solving instance: 36...
	 start solving instance: 30...
	 start solving instance: 112...
	 start solving instance: 147...
	 start solving instance: 117...
	 start solving instance: 21...
	 start solving instance: 146...
	 start solving instance: 85...
	 start solving instance: 71...
	 start solving instance: 34...
	 start solving instance: 120...
	 start solving instance: 27...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.439872988955762e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22207705676555634
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.439873252838552e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.439872988955762e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22207705676555634
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.439873252838552e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.439872988955762e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22207705676555634
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.439873252838552e+19 - Differentiable computation graph = True!
PPO iteration: 706/1000:
	 start solving instance: 71...
	 start solving instance: 112...
	 start solving instance: 25...
	 start solving instance: 111...
	 start solving instance: 85...
	 start solving instance: 30...
	 start solving instance: 27...
	 start solving instance: 88...
	 start solving instance: 147...
	 start solving instance: 146...
	 start solving instance: 11...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 120...
	 start solving instance: 36...
	 start solving instance: 29...
	 start solving instance: 130...
	 start solving instance: 44...
	 start solving instance: 34...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8934611178319616e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21728956699371338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.893461381714752e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8934611178319616e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21728956699371338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.893461381714752e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8934611178319616e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21728956699371338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.893461381714752e+19 - Differentiable computation graph = True!
PPO iteration: 707/1000:
	 start solving instance: 147...
	 start solving instance: 29...
	 start solving instance: 44...
	 start solving instance: 130...
	 start solving instance: 27...
	 start solving instance: 21...
	 start solving instance: 146...
	 start solving instance: 88...
	 start solving instance: 111...
	 start solving instance: 30...
	 start solving instance: 117...
	 start solving instance: 85...
	 start solving instance: 36...
	 start solving instance: 120...
	 start solving instance: 112...
	 start solving instance: 11...
	 start solving instance: 71...
	 start solving instance: 34...
	 start solving instance: 25...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.740928068733853e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23085735738277435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.740928332616643e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.740928068733853e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23085735738277435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.740928332616643e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.740928068733853e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23085735738277435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.740928332616643e+19 - Differentiable computation graph = True!
PPO iteration: 708/1000:
	 start solving instance: 25...
	 start solving instance: 34...
	 start solving instance: 120...
	 start solving instance: 29...
	 start solving instance: 27...
	 start solving instance: 21...
	 start solving instance: 36...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 147...
	 start solving instance: 71...
	 start solving instance: 130...
	 start solving instance: 88...
	 start solving instance: 11...
	 start solving instance: 146...
	 start solving instance: 85...
	 start solving instance: 44...
	 start solving instance: 117...
	 start solving instance: 111...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5778833366304843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22733521461486816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.577883512552345e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5778833366304843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22733521461486816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.577883512552345e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5778833366304843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22733521461486816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.577883512552345e+19 - Differentiable computation graph = True!
PPO iteration: 709/1000:
	 start solving instance: 11...
	 start solving instance: 36...
	 start solving instance: 147...
	 start solving instance: 146...
	 start solving instance: 44...
	 start solving instance: 27...
	 start solving instance: 111...
	 start solving instance: 25...
	 start solving instance: 112...
	 start solving instance: 34...
	 start solving instance: 130...
	 start solving instance: 29...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 120...
	 start solving instance: 30...
	 start solving instance: 141...
	 start solving instance: 71...
	 start solving instance: 85...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.768680445906361e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.231983944773674
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.768680445906361e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.768680445906361e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.231983944773674
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.768680445906361e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.768680445906361e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.231983944773674
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.768680445906361e+19 - Differentiable computation graph = True!
PPO iteration: 710/1000:
	 start solving instance: 11...
	 start solving instance: 44...
	 start solving instance: 147...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 117...
	 start solving instance: 111...
	 start solving instance: 112...
	 start solving instance: 120...
	 start solving instance: 27...
	 start solving instance: 85...
	 start solving instance: 88...
	 start solving instance: 29...
	 start solving instance: 34...
	 start solving instance: 71...
	 start solving instance: 141...
	 start solving instance: 36...
	 start solving instance: 25...
	 start solving instance: 130...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6044816663984787e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22053249180316925
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6044815784375484e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6044816663984787e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22053249180316925
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6044815784375484e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6044816663984787e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22053249180316925
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6044815784375484e+19 - Differentiable computation graph = True!
PPO iteration: 711/1000:
	 New training batch of size 20...
	 start solving instance: 5...
	 start solving instance: 16...
	 start solving instance: 6...
	 start solving instance: 123...
	 start solving instance: 56...
	 start solving instance: 146...
	 start solving instance: 61...
	 start solving instance: 89...
	 start solving instance: 111...
	 start solving instance: 87...
	 start solving instance: 90...
	 start solving instance: 59...
	 start solving instance: 135...
	 start solving instance: 75...
	 start solving instance: 96...
	 start solving instance: 147...
	 start solving instance: 9...
	 start solving instance: 106...
	 start solving instance: 18...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.552649808655816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2145708054304123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5526497206948856e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.552649808655816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2145708054304123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5526497206948856e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.552649808655816e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2145708054304123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5526497206948856e+19 - Differentiable computation graph = True!
PPO iteration: 712/1000:
	 start solving instance: 18...
	 start solving instance: 3...
	 start solving instance: 96...
	 start solving instance: 61...
	 start solving instance: 90...
	 start solving instance: 123...
	 start solving instance: 6...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 111...
	 start solving instance: 135...
	 start solving instance: 56...
	 start solving instance: 106...
	 start solving instance: 5...
	 start solving instance: 146...
	 start solving instance: 59...
	 start solving instance: 16...
	 start solving instance: 9...
	 start solving instance: 147...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1687098480169006e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21332144737243652
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.168709935977831e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1687098480169006e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21181459724903107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.168709935977831e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1687098480169006e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21181459724903107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.168709935977831e+19 - Differentiable computation graph = True!
PPO iteration: 713/1000:
	 start solving instance: 61...
	 start solving instance: 106...
	 start solving instance: 75...
	 start solving instance: 56...
	 start solving instance: 59...
	 start solving instance: 147...
	 start solving instance: 87...
	 start solving instance: 111...
	 start solving instance: 18...
	 start solving instance: 135...
	 start solving instance: 6...
	 start solving instance: 16...
	 start solving instance: 3...
	 start solving instance: 123...
	 start solving instance: 9...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 146...
	 start solving instance: 90...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.210926872398848e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22143720090389252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.210926784437918e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.210926872398848e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22143720090389252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.210926784437918e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.210926872398848e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22143720090389252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.210926784437918e+19 - Differentiable computation graph = True!
PPO iteration: 714/1000:
	 start solving instance: 16...
	 start solving instance: 111...
	 start solving instance: 90...
	 start solving instance: 89...
	 start solving instance: 6...
	 start solving instance: 18...
	 start solving instance: 61...
	 start solving instance: 106...
	 start solving instance: 87...
	 start solving instance: 59...
	 start solving instance: 146...
	 start solving instance: 147...
	 start solving instance: 9...
	 start solving instance: 3...
	 start solving instance: 5...
	 start solving instance: 123...
	 start solving instance: 135...
	 start solving instance: 56...
	 start solving instance: 75...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3864296869714303e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2139711230993271
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.386429950854221e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3864296869714303e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2139711230993271
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.386429950854221e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3864296869714303e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2139711230993271
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.386429950854221e+19 - Differentiable computation graph = True!
PPO iteration: 715/1000:
	 start solving instance: 89...
	 start solving instance: 75...
	 start solving instance: 135...
	 start solving instance: 18...
	 start solving instance: 61...
	 start solving instance: 96...
	 start solving instance: 106...
	 start solving instance: 56...
	 start solving instance: 90...
	 start solving instance: 59...
	 start solving instance: 87...
	 start solving instance: 5...
	 start solving instance: 16...
	 start solving instance: 123...
	 start solving instance: 6...
	 start solving instance: 3...
	 start solving instance: 146...
	 start solving instance: 111...
	 start solving instance: 9...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.208858383163746e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21672764420509338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.208858383163746e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.208858383163746e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21672764420509338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.208858383163746e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.208858383163746e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21672764420509338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.208858383163746e+19 - Differentiable computation graph = True!
PPO iteration: 716/1000:
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 61...
	 start solving instance: 123...
	 start solving instance: 87...
	 start solving instance: 75...
	 start solving instance: 106...
	 start solving instance: 3...
	 start solving instance: 16...
	 start solving instance: 18...
	 start solving instance: 6...
	 start solving instance: 56...
	 start solving instance: 89...
	 start solving instance: 147...
	 start solving instance: 9...
	 start solving instance: 90...
	 start solving instance: 111...
	 start solving instance: 59...
	 start solving instance: 146...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.363530290241135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21715418994426727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.363530202280205e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.363530290241135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21866105496883392
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.363530202280205e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.363530290241135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21715418994426727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.363530202280205e+19 - Differentiable computation graph = True!
PPO iteration: 717/1000:
	 start solving instance: 5...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 61...
	 start solving instance: 89...
	 start solving instance: 96...
	 start solving instance: 146...
	 start solving instance: 6...
	 start solving instance: 3...
	 start solving instance: 147...
	 start solving instance: 75...
	 start solving instance: 123...
	 start solving instance: 9...
	 start solving instance: 106...
	 start solving instance: 111...
	 start solving instance: 56...
	 start solving instance: 135...
	 start solving instance: 90...
	 start solving instance: 87...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3859152914514916e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22054588794708252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.385915379412422e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3859152914514916e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22054588794708252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.385915379412422e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3859152914514916e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22054588794708252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.385915379412422e+19 - Differentiable computation graph = True!
PPO iteration: 718/1000:
	 start solving instance: 123...
	 start solving instance: 9...
	 start solving instance: 75...
	 start solving instance: 59...
	 start solving instance: 135...
	 start solving instance: 147...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 96...
	 start solving instance: 5...
	 start solving instance: 61...
	 start solving instance: 90...
	 start solving instance: 89...
	 start solving instance: 87...
	 start solving instance: 18...
	 start solving instance: 3...
	 start solving instance: 111...
	 start solving instance: 146...
	 start solving instance: 16...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4278036937981297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20917458832263947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.42780369379813e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4278036937981297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21068143844604492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.42780369379813e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4278036937981297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21068143844604492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.42780369379813e+19 - Differentiable computation graph = True!
PPO iteration: 719/1000:
	 start solving instance: 147...
	 start solving instance: 56...
	 start solving instance: 96...
	 start solving instance: 123...
	 start solving instance: 61...
	 start solving instance: 111...
	 start solving instance: 106...
	 start solving instance: 90...
	 start solving instance: 5...
	 start solving instance: 6...
	 start solving instance: 89...
	 start solving instance: 146...
	 start solving instance: 3...
	 start solving instance: 75...
	 start solving instance: 9...
	 start solving instance: 135...
	 start solving instance: 59...
	 start solving instance: 18...
	 start solving instance: 16...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2352698839159485e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21826215088367462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.235269971876879e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2352698839159485e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21826215088367462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.235269971876879e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2352698839159485e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21826215088367462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.235269971876879e+19 - Differentiable computation graph = True!
PPO iteration: 720/1000:
	 start solving instance: 147...
	 start solving instance: 3...
	 start solving instance: 5...
	 start solving instance: 18...
	 start solving instance: 56...
	 start solving instance: 61...
	 start solving instance: 9...
	 start solving instance: 75...
	 start solving instance: 96...
	 start solving instance: 111...
	 start solving instance: 16...
	 start solving instance: 106...
	 start solving instance: 87...
	 start solving instance: 146...
	 start solving instance: 135...
	 start solving instance: 89...
	 start solving instance: 123...
	 start solving instance: 6...
	 start solving instance: 90...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.356897684258669e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20718760788440704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.35689794814146e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.356897684258669e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20718760788440704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.35689794814146e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.356897684258669e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20718760788440704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.35689794814146e+19 - Differentiable computation graph = True!
PPO iteration: 721/1000:
	 New training batch of size 20...
	 start solving instance: 54...
	 start solving instance: 27...
	 start solving instance: 20...
	 start solving instance: 49...
	 start solving instance: 53...
	 start solving instance: 39...
	 start solving instance: 29...
	 start solving instance: 63...
	 start solving instance: 10...
	 start solving instance: 43...
	 start solving instance: 124...
	 start solving instance: 1...
	 start solving instance: 95...
	 start solving instance: 17...
	 start solving instance: 2...
	 start solving instance: 117...
	 start solving instance: 61...
	 start solving instance: 40...
	 start solving instance: 84...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0814272925295706e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2229582518339157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.081427292529571e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0814272925295706e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2229582518339157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.081427292529571e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0814272925295706e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2229582518339157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.081427292529571e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.303135963706934e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2141435593366623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43031362275897245696.0000
PPO iteration: 722/1000:
	 start solving instance: 124...
	 start solving instance: 95...
	 start solving instance: 63...
	 start solving instance: 84...
	 start solving instance: 43...
	 start solving instance: 61...
	 start solving instance: 2...
	 start solving instance: 53...
	 start solving instance: 20...
	 start solving instance: 59...
	 start solving instance: 10...
	 start solving instance: 39...
	 start solving instance: 29...
	 start solving instance: 17...
	 start solving instance: 27...
	 start solving instance: 1...
	 start solving instance: 54...
	 start solving instance: 49...
	 start solving instance: 117...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.226731360538308e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2245776206254959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.226731272577378e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.226731360538308e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2245776206254959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.226731272577378e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.226731360538308e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2229272574186325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.226731272577378e+19 - Differentiable computation graph = True!
PPO iteration: 723/1000:
	 start solving instance: 10...
	 start solving instance: 124...
	 start solving instance: 54...
	 start solving instance: 53...
	 start solving instance: 49...
	 start solving instance: 1...
	 start solving instance: 39...
	 start solving instance: 17...
	 start solving instance: 27...
	 start solving instance: 2...
	 start solving instance: 95...
	 start solving instance: 63...
	 start solving instance: 40...
	 start solving instance: 59...
	 start solving instance: 20...
	 start solving instance: 61...
	 start solving instance: 117...
	 start solving instance: 43...
	 start solving instance: 29...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.087232362080507e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22712945938110352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.087232274119577e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.087232362080507e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22712945938110352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.087232274119577e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.087232362080507e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22712945938110352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.087232274119577e+19 - Differentiable computation graph = True!
PPO iteration: 724/1000:
	 start solving instance: 10...
	 start solving instance: 43...
	 start solving instance: 63...
	 start solving instance: 1...
	 start solving instance: 49...
	 start solving instance: 59...
	 start solving instance: 84...
	 start solving instance: 53...
	 start solving instance: 17...
	 start solving instance: 20...
	 start solving instance: 29...
	 start solving instance: 61...
	 start solving instance: 39...
	 start solving instance: 54...
	 start solving instance: 27...
	 start solving instance: 2...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 117...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.107838793281773e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23200586438179016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1078388812427035e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.107838793281773e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23200586438179016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1078388812427035e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.107838793281773e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23200586438179016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.1078388812427035e+19 - Differentiable computation graph = True!
PPO iteration: 725/1000:
	 start solving instance: 43...
	 start solving instance: 49...
	 start solving instance: 61...
	 start solving instance: 27...
	 start solving instance: 20...
	 start solving instance: 124...
	 start solving instance: 29...
	 start solving instance: 63...
	 start solving instance: 39...
	 start solving instance: 53...
	 start solving instance: 2...
	 start solving instance: 59...
	 start solving instance: 84...
	 start solving instance: 95...
	 start solving instance: 17...
	 start solving instance: 54...
	 start solving instance: 40...
	 start solving instance: 10...
	 start solving instance: 1...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.912058169543235e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21656464040279388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9120580815823045e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.912058169543235e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21656464040279388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9120580815823045e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.912058169543235e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21656464040279388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9120580815823045e+19 - Differentiable computation graph = True!
PPO iteration: 726/1000:
	 start solving instance: 2...
	 start solving instance: 29...
	 start solving instance: 61...
	 start solving instance: 40...
	 start solving instance: 95...
	 start solving instance: 117...
	 start solving instance: 53...
	 start solving instance: 10...
	 start solving instance: 43...
	 start solving instance: 17...
	 start solving instance: 84...
	 start solving instance: 54...
	 start solving instance: 49...
	 start solving instance: 20...
	 start solving instance: 39...
	 start solving instance: 59...
	 start solving instance: 1...
	 start solving instance: 63...
	 start solving instance: 27...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0293375333394966e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.216826394200325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.029337709261357e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0293375333394966e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.216826394200325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.029337709261357e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0293375333394966e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.216826394200325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.029337709261357e+19 - Differentiable computation graph = True!
PPO iteration: 727/1000:
	 start solving instance: 84...
	 start solving instance: 63...
	 start solving instance: 2...
	 start solving instance: 29...
	 start solving instance: 95...
	 start solving instance: 27...
	 start solving instance: 43...
	 start solving instance: 17...
	 start solving instance: 53...
	 start solving instance: 40...
	 start solving instance: 124...
	 start solving instance: 59...
	 start solving instance: 117...
	 start solving instance: 61...
	 start solving instance: 20...
	 start solving instance: 1...
	 start solving instance: 10...
	 start solving instance: 39...
	 start solving instance: 49...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.1337028252042736e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22204093635082245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.133702913165204e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.1337028252042736e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22204093635082245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.133702913165204e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.1337028252042736e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22204093635082245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.133702913165204e+19 - Differentiable computation graph = True!
PPO iteration: 728/1000:
	 start solving instance: 124...
	 start solving instance: 53...
	 start solving instance: 40...
	 start solving instance: 95...
	 start solving instance: 29...
	 start solving instance: 49...
	 start solving instance: 84...
	 start solving instance: 63...
	 start solving instance: 54...
	 start solving instance: 39...
	 start solving instance: 59...
	 start solving instance: 1...
	 start solving instance: 43...
	 start solving instance: 10...
	 start solving instance: 20...
	 start solving instance: 27...
	 start solving instance: 17...
	 start solving instance: 2...
	 start solving instance: 61...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.2434309190628304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21474190056324005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.243431094984691e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.2434309190628304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21474190056324005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.243431094984691e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.2434309190628304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21474190056324005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.243431094984691e+19 - Differentiable computation graph = True!
PPO iteration: 729/1000:
	 start solving instance: 59...
	 start solving instance: 53...
	 start solving instance: 63...
	 start solving instance: 40...
	 start solving instance: 54...
	 start solving instance: 124...
	 start solving instance: 1...
	 start solving instance: 49...
	 start solving instance: 84...
	 start solving instance: 95...
	 start solving instance: 61...
	 start solving instance: 17...
	 start solving instance: 117...
	 start solving instance: 29...
	 start solving instance: 10...
	 start solving instance: 43...
	 start solving instance: 20...
	 start solving instance: 27...
	 start solving instance: 2...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.050712743070904e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2237141877412796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.050712655109974e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.050712743070904e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2237141877412796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.050712655109974e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.050712743070904e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2237141877412796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.050712655109974e+19 - Differentiable computation graph = True!
PPO iteration: 730/1000:
	 start solving instance: 54...
	 start solving instance: 27...
	 start solving instance: 117...
	 start solving instance: 2...
	 start solving instance: 49...
	 start solving instance: 1...
	 start solving instance: 20...
	 start solving instance: 124...
	 start solving instance: 10...
	 start solving instance: 17...
	 start solving instance: 84...
	 start solving instance: 53...
	 start solving instance: 63...
	 start solving instance: 59...
	 start solving instance: 43...
	 start solving instance: 29...
	 start solving instance: 61...
	 start solving instance: 40...
	 start solving instance: 95...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.816248661439299e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2387293577194214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.816248837361159e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.816248661439299e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2387293577194214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.816248837361159e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.816248661439299e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2387293577194214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.816248837361159e+19 - Differentiable computation graph = True!
PPO iteration: 731/1000:
	 New training batch of size 20...
	 start solving instance: 79...
	 start solving instance: 39...
	 start solving instance: 147...
	 start solving instance: 8...
	 start solving instance: 17...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 49...
	 start solving instance: 40...
	 start solving instance: 6...
	 start solving instance: 130...
	 start solving instance: 57...
	 start solving instance: 128...
	 start solving instance: 26...
	 start solving instance: 90...
	 start solving instance: 43...
	 start solving instance: 74...
	 start solving instance: 126...
	 start solving instance: 5...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.447278595593019e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2151802033185959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.447278683553949e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.447278595593019e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2151802033185959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.447278683553949e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.447278595593019e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2151802033185959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.447278683553949e+19 - Differentiable computation graph = True!
PPO iteration: 732/1000:
	 start solving instance: 49...
	 start solving instance: 147...
	 start solving instance: 42...
	 start solving instance: 74...
	 start solving instance: 128...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 5...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 6...
	 start solving instance: 40...
	 start solving instance: 126...
	 start solving instance: 43...
	 start solving instance: 115...
	 start solving instance: 107...
	 start solving instance: 130...
	 start solving instance: 8...
	 start solving instance: 79...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.517130833188419e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2077028751373291
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.51713109707121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.517130833188419e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2077028751373291
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.51713109707121e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.517130833188419e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2077028751373291
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.51713109707121e+19 - Differentiable computation graph = True!
PPO iteration: 733/1000:
	 start solving instance: 115...
	 start solving instance: 17...
	 start solving instance: 126...
	 start solving instance: 8...
	 start solving instance: 90...
	 start solving instance: 57...
	 start solving instance: 49...
	 start solving instance: 128...
	 start solving instance: 42...
	 start solving instance: 6...
	 start solving instance: 40...
	 start solving instance: 107...
	 start solving instance: 130...
	 start solving instance: 79...
	 start solving instance: 5...
	 start solving instance: 39...
	 start solving instance: 43...
	 start solving instance: 74...
	 start solving instance: 26...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.606080796109916e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2161025106906891
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.606080708148986e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.606080796109916e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2161025106906891
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.606080708148986e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.606080796109916e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2161025106906891
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.606080708148986e+19 - Differentiable computation graph = True!
PPO iteration: 734/1000:
	 start solving instance: 126...
	 start solving instance: 128...
	 start solving instance: 5...
	 start solving instance: 42...
	 start solving instance: 57...
	 start solving instance: 17...
	 start solving instance: 147...
	 start solving instance: 8...
	 start solving instance: 130...
	 start solving instance: 43...
	 start solving instance: 74...
	 start solving instance: 115...
	 start solving instance: 90...
	 start solving instance: 26...
	 start solving instance: 6...
	 start solving instance: 79...
	 start solving instance: 107...
	 start solving instance: 49...
	 start solving instance: 40...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.522345508975705e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2109764665365219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5223454210147746e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.522345508975705e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2109764665365219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5223454210147746e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.522345508975705e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2109764665365219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5223454210147746e+19 - Differentiable computation graph = True!
PPO iteration: 735/1000:
	 start solving instance: 115...
	 start solving instance: 147...
	 start solving instance: 49...
	 start solving instance: 90...
	 start solving instance: 126...
	 start solving instance: 6...
	 start solving instance: 107...
	 start solving instance: 128...
	 start solving instance: 39...
	 start solving instance: 42...
	 start solving instance: 79...
	 start solving instance: 17...
	 start solving instance: 43...
	 start solving instance: 8...
	 start solving instance: 57...
	 start solving instance: 5...
	 start solving instance: 40...
	 start solving instance: 74...
	 start solving instance: 26...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.584066638181376e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2134314775466919
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.584066726142306e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.584066638181376e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2134314775466919
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.584066726142306e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.584066638181376e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2134314775466919
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.584066726142306e+19 - Differentiable computation graph = True!
PPO iteration: 736/1000:
	 start solving instance: 43...
	 start solving instance: 74...
	 start solving instance: 26...
	 start solving instance: 17...
	 start solving instance: 42...
	 start solving instance: 5...
	 start solving instance: 57...
	 start solving instance: 39...
	 start solving instance: 49...
	 start solving instance: 6...
	 start solving instance: 130...
	 start solving instance: 40...
	 start solving instance: 128...
	 start solving instance: 90...
	 start solving instance: 115...
	 start solving instance: 8...
	 start solving instance: 107...
	 start solving instance: 79...
	 start solving instance: 126...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.689158839173508e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20640884339809418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689158927134438e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.689158839173508e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20640884339809418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689158927134438e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.689158839173508e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20640884339809418
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.689158927134438e+19 - Differentiable computation graph = True!
PPO iteration: 737/1000:
	 start solving instance: 43...
	 start solving instance: 42...
	 start solving instance: 57...
	 start solving instance: 107...
	 start solving instance: 130...
	 start solving instance: 26...
	 start solving instance: 39...
	 start solving instance: 74...
	 start solving instance: 40...
	 start solving instance: 17...
	 start solving instance: 128...
	 start solving instance: 115...
	 start solving instance: 5...
	 start solving instance: 90...
	 start solving instance: 147...
	 start solving instance: 126...
	 start solving instance: 8...
	 start solving instance: 79...
	 start solving instance: 49...
	 start solving instance: 6...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.491899416276076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2054297775030136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.491899504237006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.491899416276076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2054297775030136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.491899504237006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.491899416276076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2054297775030136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.491899504237006e+19 - Differentiable computation graph = True!
PPO iteration: 738/1000:
	 start solving instance: 147...
	 start solving instance: 26...
	 start solving instance: 8...
	 start solving instance: 128...
	 start solving instance: 74...
	 start solving instance: 90...
	 start solving instance: 39...
	 start solving instance: 107...
	 start solving instance: 6...
	 start solving instance: 130...
	 start solving instance: 79...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 5...
	 start solving instance: 115...
	 start solving instance: 40...
	 start solving instance: 42...
	 start solving instance: 126...
	 start solving instance: 17...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.563717052896358e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2163173258304596
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.563716964935428e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.563717052896358e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2163173258304596
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.563716964935428e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.563717052896358e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2163173258304596
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.563716964935428e+19 - Differentiable computation graph = True!
PPO iteration: 739/1000:
	 start solving instance: 8...
	 start solving instance: 42...
	 start solving instance: 90...
	 start solving instance: 74...
	 start solving instance: 107...
	 start solving instance: 43...
	 start solving instance: 130...
	 start solving instance: 40...
	 start solving instance: 5...
	 start solving instance: 115...
	 start solving instance: 57...
	 start solving instance: 128...
	 start solving instance: 39...
	 start solving instance: 49...
	 start solving instance: 17...
	 start solving instance: 79...
	 start solving instance: 6...
	 start solving instance: 26...
	 start solving instance: 147...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.483432648976619e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21094337105751038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.48343282489848e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.483432648976619e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21094337105751038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.48343282489848e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.483432648976619e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21094337105751038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.48343282489848e+19 - Differentiable computation graph = True!
PPO iteration: 740/1000:
	 start solving instance: 17...
	 start solving instance: 128...
	 start solving instance: 90...
	 start solving instance: 39...
	 start solving instance: 130...
	 start solving instance: 126...
	 start solving instance: 107...
	 start solving instance: 5...
	 start solving instance: 8...
	 start solving instance: 49...
	 start solving instance: 26...
	 start solving instance: 6...
	 start solving instance: 115...
	 start solving instance: 74...
	 start solving instance: 43...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 42...
	 start solving instance: 147...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.347107632724952e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2140134871006012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.347107896607742e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.347107632724952e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2140134871006012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.347107896607742e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.347107632724952e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2140134871006012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.347107896607742e+19 - Differentiable computation graph = True!
PPO iteration: 741/1000:
	 New training batch of size 20...
	 start solving instance: 106...
	 start solving instance: 145...
	 start solving instance: 109...
	 start solving instance: 40...
	 start solving instance: 90...
	 start solving instance: 49...
	 start solving instance: 56...
	 start solving instance: 20...
	 start solving instance: 7...
	 start solving instance: 84...
	 start solving instance: 22...
	 start solving instance: 148...
	 start solving instance: 47...
	 start solving instance: 2...
	 start solving instance: 137...
	 start solving instance: 11...
	 start solving instance: 18...
	 start solving instance: 134...
	 start solving instance: 46...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.621435959776924e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20977389812469482
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.621436047737854e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.621435959776924e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20977389812469482
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.621436047737854e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.621435959776924e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20977389812469482
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.621436047737854e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.058018054206831e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20535235106945038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 40580181421677608960.0000
PPO iteration: 742/1000:
	 start solving instance: 40...
	 start solving instance: 56...
	 start solving instance: 90...
	 start solving instance: 134...
	 start solving instance: 106...
	 start solving instance: 148...
	 start solving instance: 84...
	 start solving instance: 145...
	 start solving instance: 22...
	 start solving instance: 137...
	 start solving instance: 2...
	 start solving instance: 11...
	 start solving instance: 47...
	 start solving instance: 20...
	 start solving instance: 18...
	 start solving instance: 46...
	 start solving instance: 7...
	 start solving instance: 60...
	 start solving instance: 109...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.28870931561935e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21511471271514893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.28870931561935e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.28870931561935e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21511471271514893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.28870931561935e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.28870931561935e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21511471271514893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.28870931561935e+19 - Differentiable computation graph = True!
PPO iteration: 743/1000:
	 start solving instance: 106...
	 start solving instance: 46...
	 start solving instance: 137...
	 start solving instance: 109...
	 start solving instance: 22...
	 start solving instance: 56...
	 start solving instance: 84...
	 start solving instance: 20...
	 start solving instance: 148...
	 start solving instance: 2...
	 start solving instance: 145...
	 start solving instance: 7...
	 start solving instance: 11...
	 start solving instance: 47...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 60...
	 start solving instance: 90...
	 start solving instance: 49...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.306632586605122e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22022810578346252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.306632674566052e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.306632586605122e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22022810578346252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.306632674566052e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.306632586605122e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22022810578346252
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.306632674566052e+19 - Differentiable computation graph = True!
PPO iteration: 744/1000:
	 start solving instance: 40...
	 start solving instance: 109...
	 start solving instance: 90...
	 start solving instance: 137...
	 start solving instance: 134...
	 start solving instance: 106...
	 start solving instance: 148...
	 start solving instance: 2...
	 start solving instance: 145...
	 start solving instance: 11...
	 start solving instance: 22...
	 start solving instance: 20...
	 start solving instance: 56...
	 start solving instance: 46...
	 start solving instance: 47...
	 start solving instance: 7...
	 start solving instance: 49...
	 start solving instance: 60...
	 start solving instance: 18...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.588756363137096e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21081624925136566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.588756363137096e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.588756363137096e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21081624925136566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.588756363137096e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.588756363137096e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21081624925136566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.588756363137096e+19 - Differentiable computation graph = True!
PPO iteration: 745/1000:
	 start solving instance: 60...
	 start solving instance: 7...
	 start solving instance: 134...
	 start solving instance: 47...
	 start solving instance: 109...
	 start solving instance: 49...
	 start solving instance: 46...
	 start solving instance: 137...
	 start solving instance: 145...
	 start solving instance: 90...
	 start solving instance: 20...
	 start solving instance: 84...
	 start solving instance: 148...
	 start solving instance: 56...
	 start solving instance: 2...
	 start solving instance: 106...
	 start solving instance: 22...
	 start solving instance: 40...
	 start solving instance: 11...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5080873940304265e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20166893303394318
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5080873940304265e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5080873940304265e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20166893303394318
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5080873940304265e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5080873940304265e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20166893303394318
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5080873940304265e+19 - Differentiable computation graph = True!
PPO iteration: 746/1000:
	 start solving instance: 49...
	 start solving instance: 134...
	 start solving instance: 148...
	 start solving instance: 18...
	 start solving instance: 2...
	 start solving instance: 90...
	 start solving instance: 47...
	 start solving instance: 137...
	 start solving instance: 60...
	 start solving instance: 84...
	 start solving instance: 56...
	 start solving instance: 145...
	 start solving instance: 46...
	 start solving instance: 11...
	 start solving instance: 20...
	 start solving instance: 40...
	 start solving instance: 22...
	 start solving instance: 7...
	 start solving instance: 109...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.311326533685493e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2114054262638092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3113267096073535e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.311326533685493e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2114054262638092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3113267096073535e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.311326533685493e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2114054262638092
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3113267096073535e+19 - Differentiable computation graph = True!
PPO iteration: 747/1000:
	 start solving instance: 106...
	 start solving instance: 18...
	 start solving instance: 49...
	 start solving instance: 56...
	 start solving instance: 20...
	 start solving instance: 22...
	 start solving instance: 47...
	 start solving instance: 90...
	 start solving instance: 46...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 7...
	 start solving instance: 137...
	 start solving instance: 11...
	 start solving instance: 2...
	 start solving instance: 145...
	 start solving instance: 109...
	 start solving instance: 148...
	 start solving instance: 60...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.060833507661379e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22309303283691406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.06083377154417e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.060833507661379e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22309303283691406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.06083377154417e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.060833507661379e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22309303283691406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.06083377154417e+19 - Differentiable computation graph = True!
PPO iteration: 748/1000:
	 start solving instance: 20...
	 start solving instance: 49...
	 start solving instance: 145...
	 start solving instance: 134...
	 start solving instance: 18...
	 start solving instance: 11...
	 start solving instance: 109...
	 start solving instance: 56...
	 start solving instance: 84...
	 start solving instance: 148...
	 start solving instance: 22...
	 start solving instance: 2...
	 start solving instance: 7...
	 start solving instance: 46...
	 start solving instance: 106...
	 start solving instance: 40...
	 start solving instance: 60...
	 start solving instance: 90...
	 start solving instance: 47...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.520959244715405e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22358019649982452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.520959156754475e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.520959244715405e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22358019649982452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.520959156754475e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.520959244715405e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22358019649982452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.520959156754475e+19 - Differentiable computation graph = True!
PPO iteration: 749/1000:
	 start solving instance: 145...
	 start solving instance: 22...
	 start solving instance: 47...
	 start solving instance: 20...
	 start solving instance: 134...
	 start solving instance: 56...
	 start solving instance: 2...
	 start solving instance: 18...
	 start solving instance: 49...
	 start solving instance: 84...
	 start solving instance: 106...
	 start solving instance: 46...
	 start solving instance: 40...
	 start solving instance: 7...
	 start solving instance: 148...
	 start solving instance: 109...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 11...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.15390813452285e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21576862037181854
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.15390831044471e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.15390813452285e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21576862037181854
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.15390831044471e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.15390813452285e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21576862037181854
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.15390831044471e+19 - Differentiable computation graph = True!
PPO iteration: 750/1000:
	 start solving instance: 46...
	 start solving instance: 20...
	 start solving instance: 109...
	 start solving instance: 7...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 18...
	 start solving instance: 56...
	 start solving instance: 106...
	 start solving instance: 145...
	 start solving instance: 2...
	 start solving instance: 84...
	 start solving instance: 11...
	 start solving instance: 47...
	 start solving instance: 22...
	 start solving instance: 40...
	 start solving instance: 60...
	 start solving instance: 49...
	 start solving instance: 148...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.240842384767378e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21958331763744354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2408422968064475e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.240842384767378e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21958331763744354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2408422968064475e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.240842384767378e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21958331763744354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2408422968064475e+19 - Differentiable computation graph = True!
PPO iteration: 751/1000:
	 New training batch of size 20...
	 start solving instance: 127...
	 start solving instance: 138...
	 start solving instance: 146...
	 start solving instance: 125...
	 start solving instance: 91...
	 start solving instance: 96...
	 start solving instance: 43...
	 start solving instance: 137...
	 start solving instance: 40...
	 start solving instance: 71...
	 start solving instance: 95...
	 start solving instance: 130...
	 start solving instance: 120...
	 start solving instance: 78...
	 start solving instance: 76...
	 start solving instance: 114...
	 start solving instance: 88...
	 start solving instance: 112...
	 start solving instance: 110...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.983924340556122e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2289993315935135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.983924252595192e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.983924340556122e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2289993315935135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.983924252595192e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.983924340556122e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2289993315935135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.983924252595192e+19 - Differentiable computation graph = True!
PPO iteration: 752/1000:
	 start solving instance: 71...
	 start solving instance: 95...
	 start solving instance: 130...
	 start solving instance: 91...
	 start solving instance: 40...
	 start solving instance: 88...
	 start solving instance: 78...
	 start solving instance: 125...
	 start solving instance: 138...
	 start solving instance: 137...
	 start solving instance: 112...
	 start solving instance: 96...
	 start solving instance: 127...
	 start solving instance: 146...
	 start solving instance: 48...
	 start solving instance: 76...
	 start solving instance: 110...
	 start solving instance: 43...
	 start solving instance: 114...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.448453753620786e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23235984146595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.448453841581716e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.448453753620786e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23235984146595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.448453841581716e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.448453753620786e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23235984146595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.448453841581716e+19 - Differentiable computation graph = True!
PPO iteration: 753/1000:
	 start solving instance: 137...
	 start solving instance: 127...
	 start solving instance: 110...
	 start solving instance: 76...
	 start solving instance: 40...
	 start solving instance: 146...
	 start solving instance: 120...
	 start solving instance: 71...
	 start solving instance: 43...
	 start solving instance: 125...
	 start solving instance: 88...
	 start solving instance: 96...
	 start solving instance: 78...
	 start solving instance: 95...
	 start solving instance: 112...
	 start solving instance: 114...
	 start solving instance: 130...
	 start solving instance: 91...
	 start solving instance: 138...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.311239276442713e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.229760080575943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3112391884817826e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.311239276442713e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.229760080575943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3112391884817826e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.311239276442713e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.229760080575943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3112391884817826e+19 - Differentiable computation graph = True!
PPO iteration: 754/1000:
	 start solving instance: 146...
	 start solving instance: 43...
	 start solving instance: 112...
	 start solving instance: 137...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 127...
	 start solving instance: 95...
	 start solving instance: 71...
	 start solving instance: 40...
	 start solving instance: 78...
	 start solving instance: 91...
	 start solving instance: 120...
	 start solving instance: 130...
	 start solving instance: 88...
	 start solving instance: 48...
	 start solving instance: 110...
	 start solving instance: 125...
	 start solving instance: 138...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.354652569475681e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23065710067749023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.354652745397541e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.354652569475681e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23065710067749023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.354652745397541e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.354652569475681e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23065710067749023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.354652745397541e+19 - Differentiable computation graph = True!
PPO iteration: 755/1000:
	 start solving instance: 114...
	 start solving instance: 88...
	 start solving instance: 48...
	 start solving instance: 96...
	 start solving instance: 91...
	 start solving instance: 137...
	 start solving instance: 43...
	 start solving instance: 120...
	 start solving instance: 71...
	 start solving instance: 112...
	 start solving instance: 127...
	 start solving instance: 138...
	 start solving instance: 76...
	 start solving instance: 95...
	 start solving instance: 40...
	 start solving instance: 110...
	 start solving instance: 125...
	 start solving instance: 78...
	 start solving instance: 130...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1936362164232336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23802052438259125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.193636304384164e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1936362164232336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23802052438259125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.193636304384164e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1936362164232336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23802052438259125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.193636304384164e+19 - Differentiable computation graph = True!
PPO iteration: 756/1000:
	 start solving instance: 130...
	 start solving instance: 76...
	 start solving instance: 138...
	 start solving instance: 110...
	 start solving instance: 146...
	 start solving instance: 95...
	 start solving instance: 127...
	 start solving instance: 40...
	 start solving instance: 137...
	 start solving instance: 91...
	 start solving instance: 48...
	 start solving instance: 114...
	 start solving instance: 120...
	 start solving instance: 96...
	 start solving instance: 71...
	 start solving instance: 78...
	 start solving instance: 112...
	 start solving instance: 43...
	 start solving instance: 88...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.373591613283657e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22894762456417084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.373591613283657e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.373591613283657e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22894762456417084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.373591613283657e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.373591613283657e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22894762456417084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.373591613283657e+19 - Differentiable computation graph = True!
PPO iteration: 757/1000:
	 start solving instance: 137...
	 start solving instance: 138...
	 start solving instance: 88...
	 start solving instance: 96...
	 start solving instance: 114...
	 start solving instance: 71...
	 start solving instance: 43...
	 start solving instance: 112...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 91...
	 start solving instance: 48...
	 start solving instance: 76...
	 start solving instance: 146...
	 start solving instance: 40...
	 start solving instance: 127...
	 start solving instance: 78...
	 start solving instance: 125...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4647054150886176e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2349487841129303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.464705503049548e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4647054150886176e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2349487841129303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.464705503049548e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4647054150886176e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2349487841129303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.464705503049548e+19 - Differentiable computation graph = True!
PPO iteration: 758/1000:
	 start solving instance: 76...
	 start solving instance: 138...
	 start solving instance: 43...
	 start solving instance: 71...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 112...
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 96...
	 start solving instance: 95...
	 start solving instance: 146...
	 start solving instance: 125...
	 start solving instance: 78...
	 start solving instance: 120...
	 start solving instance: 91...
	 start solving instance: 137...
	 start solving instance: 110...
	 start solving instance: 114...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2918808349194374e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2232249528169632
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.291880746958507e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2918808349194374e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2232249528169632
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.291880746958507e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2918808349194374e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2232249528169632
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.291880746958507e+19 - Differentiable computation graph = True!
PPO iteration: 759/1000:
	 start solving instance: 138...
	 start solving instance: 78...
	 start solving instance: 112...
	 start solving instance: 95...
	 start solving instance: 127...
	 start solving instance: 88...
	 start solving instance: 76...
	 start solving instance: 146...
	 start solving instance: 91...
	 start solving instance: 43...
	 start solving instance: 137...
	 start solving instance: 110...
	 start solving instance: 130...
	 start solving instance: 96...
	 start solving instance: 120...
	 start solving instance: 48...
	 start solving instance: 125...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.400273681857223e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2270352840423584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.400273681857223e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.400273681857223e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2270352840423584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.400273681857223e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.400273681857223e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2270352840423584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.400273681857223e+19 - Differentiable computation graph = True!
PPO iteration: 760/1000:
	 start solving instance: 114...
	 start solving instance: 88...
	 start solving instance: 127...
	 start solving instance: 137...
	 start solving instance: 91...
	 start solving instance: 112...
	 start solving instance: 138...
	 start solving instance: 146...
	 start solving instance: 110...
	 start solving instance: 40...
	 start solving instance: 76...
	 start solving instance: 78...
	 start solving instance: 48...
	 start solving instance: 43...
	 start solving instance: 71...
	 start solving instance: 120...
	 start solving instance: 95...
	 start solving instance: 125...
	 start solving instance: 130...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2585232354294576e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23111943900585175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.258523323390388e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2585232354294576e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23111943900585175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.258523323390388e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2585232354294576e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23111943900585175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.258523323390388e+19 - Differentiable computation graph = True!
PPO iteration: 761/1000:
	 New training batch of size 20...
	 start solving instance: 4...
	 start solving instance: 90...
	 start solving instance: 35...
	 start solving instance: 54...
	 start solving instance: 69...
	 start solving instance: 134...
	 start solving instance: 145...
	 start solving instance: 61...
	 start solving instance: 118...
	 start solving instance: 28...
	 start solving instance: 101...
	 start solving instance: 127...
	 start solving instance: 5...
	 start solving instance: 137...
	 start solving instance: 148...
	 start solving instance: 79...
	 start solving instance: 21...
	 start solving instance: 98...
	 start solving instance: 116...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6854651837916224e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21432319283485413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.685465447674413e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6854651837916224e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21432319283485413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.685465447674413e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6854651837916224e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21432319283485413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.685465447674413e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.3311325204217384e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20535235106945038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43311324324608081920.0000
PPO iteration: 762/1000:
	 start solving instance: 28...
	 start solving instance: 54...
	 start solving instance: 145...
	 start solving instance: 134...
	 start solving instance: 4...
	 start solving instance: 79...
	 start solving instance: 116...
	 start solving instance: 5...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 61...
	 start solving instance: 127...
	 start solving instance: 137...
	 start solving instance: 21...
	 start solving instance: 69...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 118...
	 start solving instance: 90...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6877110022620525e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21951603889465332
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.687711090222983e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6877110022620525e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21951603889465332
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.687711090222983e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6877110022620525e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21951603889465332
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.687711090222983e+19 - Differentiable computation graph = True!
PPO iteration: 763/1000:
	 start solving instance: 137...
	 start solving instance: 116...
	 start solving instance: 98...
	 start solving instance: 23...
	 start solving instance: 69...
	 start solving instance: 148...
	 start solving instance: 21...
	 start solving instance: 5...
	 start solving instance: 35...
	 start solving instance: 61...
	 start solving instance: 134...
	 start solving instance: 127...
	 start solving instance: 54...
	 start solving instance: 79...
	 start solving instance: 28...
	 start solving instance: 118...
	 start solving instance: 145...
	 start solving instance: 90...
	 start solving instance: 4...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5956232970376734e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20727770030498505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.595623472959534e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5956232970376734e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20727770030498505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.595623472959534e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5956232970376734e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20727770030498505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.595623472959534e+19 - Differentiable computation graph = True!
PPO iteration: 764/1000:
	 start solving instance: 28...
	 start solving instance: 134...
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 116...
	 start solving instance: 148...
	 start solving instance: 61...
	 start solving instance: 23...
	 start solving instance: 90...
	 start solving instance: 4...
	 start solving instance: 137...
	 start solving instance: 79...
	 start solving instance: 69...
	 start solving instance: 118...
	 start solving instance: 54...
	 start solving instance: 21...
	 start solving instance: 145...
	 start solving instance: 35...
	 start solving instance: 127...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.571719034640521e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21024517714977264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5717192105623814e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.571719034640521e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21024517714977264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5717192105623814e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.571719034640521e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21024517714977264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5717192105623814e+19 - Differentiable computation graph = True!
PPO iteration: 765/1000:
	 start solving instance: 54...
	 start solving instance: 4...
	 start solving instance: 101...
	 start solving instance: 21...
	 start solving instance: 28...
	 start solving instance: 79...
	 start solving instance: 118...
	 start solving instance: 137...
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 148...
	 start solving instance: 116...
	 start solving instance: 23...
	 start solving instance: 90...
	 start solving instance: 35...
	 start solving instance: 61...
	 start solving instance: 127...
	 start solving instance: 69...
	 start solving instance: 134...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.658544917019015e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21596212685108185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6585450049799455e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.658544917019015e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21596212685108185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6585450049799455e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.658544917019015e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21596212685108185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6585450049799455e+19 - Differentiable computation graph = True!
PPO iteration: 766/1000:
	 start solving instance: 4...
	 start solving instance: 79...
	 start solving instance: 54...
	 start solving instance: 101...
	 start solving instance: 35...
	 start solving instance: 23...
	 start solving instance: 90...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 127...
	 start solving instance: 137...
	 start solving instance: 61...
	 start solving instance: 118...
	 start solving instance: 116...
	 start solving instance: 5...
	 start solving instance: 21...
	 start solving instance: 98...
	 start solving instance: 148...
	 start solving instance: 145...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6730493225689154e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20883408188819885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.673049322568915e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6730493225689154e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20883408188819885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.673049322568915e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6730493225689154e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20883408188819885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.673049322568915e+19 - Differentiable computation graph = True!
PPO iteration: 767/1000:
	 start solving instance: 61...
	 start solving instance: 98...
	 start solving instance: 5...
	 start solving instance: 28...
	 start solving instance: 23...
	 start solving instance: 134...
	 start solving instance: 21...
	 start solving instance: 101...
	 start solving instance: 148...
	 start solving instance: 137...
	 start solving instance: 79...
	 start solving instance: 69...
	 start solving instance: 90...
	 start solving instance: 4...
	 start solving instance: 145...
	 start solving instance: 127...
	 start solving instance: 35...
	 start solving instance: 118...
	 start solving instance: 116...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5249167828879566e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21871542930603027
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.524916958809817e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5249167828879566e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21871542930603027
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.524916958809817e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5249167828879566e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21871542930603027
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.524916958809817e+19 - Differentiable computation graph = True!
PPO iteration: 768/1000:
	 start solving instance: 116...
	 start solving instance: 23...
	 start solving instance: 148...
	 start solving instance: 101...
	 start solving instance: 61...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 4...
	 start solving instance: 98...
	 start solving instance: 145...
	 start solving instance: 118...
	 start solving instance: 69...
	 start solving instance: 54...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 137...
	 start solving instance: 35...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.528342333354525e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2201382964849472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.528342597237316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.528342333354525e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2201382964849472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.528342597237316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.528342333354525e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2201382964849472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.528342597237316e+19 - Differentiable computation graph = True!
PPO iteration: 769/1000:
	 start solving instance: 4...
	 start solving instance: 118...
	 start solving instance: 148...
	 start solving instance: 90...
	 start solving instance: 61...
	 start solving instance: 28...
	 start solving instance: 127...
	 start solving instance: 21...
	 start solving instance: 69...
	 start solving instance: 116...
	 start solving instance: 98...
	 start solving instance: 101...
	 start solving instance: 23...
	 start solving instance: 137...
	 start solving instance: 145...
	 start solving instance: 79...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 54...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.626956035913941e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21177516877651215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.626956035913941e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.626956035913941e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21177516877651215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.626956035913941e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.626956035913941e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21177516877651215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.626956035913941e+19 - Differentiable computation graph = True!
PPO iteration: 770/1000:
	 start solving instance: 61...
	 start solving instance: 5...
	 start solving instance: 127...
	 start solving instance: 35...
	 start solving instance: 98...
	 start solving instance: 90...
	 start solving instance: 145...
	 start solving instance: 4...
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 116...
	 start solving instance: 134...
	 start solving instance: 23...
	 start solving instance: 21...
	 start solving instance: 137...
	 start solving instance: 148...
	 start solving instance: 54...
	 start solving instance: 28...
	 start solving instance: 118...
	 start solving instance: 69...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6862740725059446e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22452197968959808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.686274248427805e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6862740725059446e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22452197968959808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.686274248427805e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6862740725059446e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22452197968959808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.686274248427805e+19 - Differentiable computation graph = True!
PPO iteration: 771/1000:
	 New training batch of size 20...
	 start solving instance: 53...
	 start solving instance: 46...
	 start solving instance: 95...
	 start solving instance: 9...
	 start solving instance: 18...
	 start solving instance: 29...
	 start solving instance: 118...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 121...
	 start solving instance: 96...
	 start solving instance: 55...
	 start solving instance: 48...
	 start solving instance: 105...
	 start solving instance: 134...
	 start solving instance: 86...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 150...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6497892860247094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22605302929878235
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64978937398564e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6497892860247094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22605302929878235
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64978937398564e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6497892860247094e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22605302929878235
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64978937398564e+19 - Differentiable computation graph = True!
PPO iteration: 772/1000:
	 start solving instance: 46...
	 start solving instance: 10...
	 start solving instance: 123...
	 start solving instance: 129...
	 start solving instance: 134...
	 start solving instance: 137...
	 start solving instance: 95...
	 start solving instance: 48...
	 start solving instance: 86...
	 start solving instance: 18...
	 start solving instance: 29...
	 start solving instance: 9...
	 start solving instance: 150...
	 start solving instance: 105...
	 start solving instance: 118...
	 start solving instance: 53...
	 start solving instance: 121...
	 start solving instance: 22...
	 start solving instance: 55...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.542506857870047e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23308978974819183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5425069458309775e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.542506857870047e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23308978974819183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5425069458309775e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.542506857870047e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23308978974819183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5425069458309775e+19 - Differentiable computation graph = True!
PPO iteration: 773/1000:
	 start solving instance: 46...
	 start solving instance: 134...
	 start solving instance: 95...
	 start solving instance: 150...
	 start solving instance: 48...
	 start solving instance: 18...
	 start solving instance: 53...
	 start solving instance: 96...
	 start solving instance: 105...
	 start solving instance: 121...
	 start solving instance: 86...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 55...
	 start solving instance: 29...
	 start solving instance: 118...
	 start solving instance: 137...
	 start solving instance: 10...
	 start solving instance: 9...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3298781975567716e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22524428367614746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.329878109595841e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3298781975567716e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22524428367614746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.329878109595841e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3298781975567716e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22524428367614746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.329878109595841e+19 - Differentiable computation graph = True!
PPO iteration: 774/1000:
	 start solving instance: 105...
	 start solving instance: 150...
	 start solving instance: 118...
	 start solving instance: 134...
	 start solving instance: 95...
	 start solving instance: 48...
	 start solving instance: 9...
	 start solving instance: 18...
	 start solving instance: 29...
	 start solving instance: 86...
	 start solving instance: 137...
	 start solving instance: 22...
	 start solving instance: 55...
	 start solving instance: 96...
	 start solving instance: 129...
	 start solving instance: 53...
	 start solving instance: 123...
	 start solving instance: 121...
	 start solving instance: 10...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.445020814436079e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2299395352602005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4450207264751485e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.445020814436079e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2299395352602005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4450207264751485e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.445020814436079e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2299395352602005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4450207264751485e+19 - Differentiable computation graph = True!
PPO iteration: 775/1000:
	 start solving instance: 18...
	 start solving instance: 86...
	 start solving instance: 105...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 123...
	 start solving instance: 96...
	 start solving instance: 129...
	 start solving instance: 48...
	 start solving instance: 134...
	 start solving instance: 53...
	 start solving instance: 9...
	 start solving instance: 95...
	 start solving instance: 150...
	 start solving instance: 121...
	 start solving instance: 137...
	 start solving instance: 46...
	 start solving instance: 29...
	 start solving instance: 118...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4684673281523555e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21289372444152832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.468467592035146e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4684673281523555e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21289372444152832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.468467592035146e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4684673281523555e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21289372444152832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.468467592035146e+19 - Differentiable computation graph = True!
PPO iteration: 776/1000:
	 start solving instance: 22...
	 start solving instance: 118...
	 start solving instance: 48...
	 start solving instance: 86...
	 start solving instance: 105...
	 start solving instance: 55...
	 start solving instance: 53...
	 start solving instance: 129...
	 start solving instance: 18...
	 start solving instance: 150...
	 start solving instance: 137...
	 start solving instance: 29...
	 start solving instance: 46...
	 start solving instance: 134...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 95...
	 start solving instance: 123...
	 start solving instance: 96...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.715172404677386e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21908140182495117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.715172492638316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.715172404677386e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21908140182495117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.715172492638316e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.715172404677386e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21908140182495117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.715172492638316e+19 - Differentiable computation graph = True!
PPO iteration: 777/1000:
	 start solving instance: 29...
	 start solving instance: 55...
	 start solving instance: 129...
	 start solving instance: 150...
	 start solving instance: 48...
	 start solving instance: 121...
	 start solving instance: 86...
	 start solving instance: 22...
	 start solving instance: 95...
	 start solving instance: 137...
	 start solving instance: 9...
	 start solving instance: 53...
	 start solving instance: 134...
	 start solving instance: 105...
	 start solving instance: 96...
	 start solving instance: 10...
	 start solving instance: 18...
	 start solving instance: 123...
	 start solving instance: 46...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5682041158688467e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2274443358182907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.568204291790707e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5682041158688467e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2274443358182907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.568204291790707e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5682041158688467e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2274443358182907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.568204291790707e+19 - Differentiable computation graph = True!
PPO iteration: 778/1000:
	 start solving instance: 22...
	 start solving instance: 55...
	 start solving instance: 96...
	 start solving instance: 46...
	 start solving instance: 10...
	 start solving instance: 118...
	 start solving instance: 105...
	 start solving instance: 53...
	 start solving instance: 150...
	 start solving instance: 86...
	 start solving instance: 18...
	 start solving instance: 123...
	 start solving instance: 48...
	 start solving instance: 134...
	 start solving instance: 121...
	 start solving instance: 95...
	 start solving instance: 29...
	 start solving instance: 129...
	 start solving instance: 9...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.567176028516411e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22908525168895721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.567176028516411e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.567176028516411e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22908525168895721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.567176028516411e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.567176028516411e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22908525168895721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.567176028516411e+19 - Differentiable computation graph = True!
PPO iteration: 779/1000:
	 start solving instance: 121...
	 start solving instance: 134...
	 start solving instance: 129...
	 start solving instance: 53...
	 start solving instance: 10...
	 start solving instance: 48...
	 start solving instance: 96...
	 start solving instance: 55...
	 start solving instance: 123...
	 start solving instance: 150...
	 start solving instance: 118...
	 start solving instance: 22...
	 start solving instance: 29...
	 start solving instance: 95...
	 start solving instance: 86...
	 start solving instance: 18...
	 start solving instance: 46...
	 start solving instance: 9...
	 start solving instance: 105...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.388349346312597e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2243196815252304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.388349258351667e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.388349346312597e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2243196815252304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.388349258351667e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.388349346312597e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2243196815252304
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.388349258351667e+19 - Differentiable computation graph = True!
PPO iteration: 780/1000:
	 start solving instance: 134...
	 start solving instance: 55...
	 start solving instance: 121...
	 start solving instance: 118...
	 start solving instance: 129...
	 start solving instance: 9...
	 start solving instance: 96...
	 start solving instance: 10...
	 start solving instance: 123...
	 start solving instance: 53...
	 start solving instance: 137...
	 start solving instance: 46...
	 start solving instance: 95...
	 start solving instance: 150...
	 start solving instance: 105...
	 start solving instance: 29...
	 start solving instance: 48...
	 start solving instance: 22...
	 start solving instance: 86...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.379285500218793e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22969713807106018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.379285764101584e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.379285500218793e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22969713807106018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.379285764101584e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.379285500218793e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22969713807106018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.379285764101584e+19 - Differentiable computation graph = True!
PPO iteration: 781/1000:
	 New training batch of size 20...
	 start solving instance: 25...
	 start solving instance: 26...
	 start solving instance: 103...
	 start solving instance: 102...
	 start solving instance: 38...
	 start solving instance: 110...
	 start solving instance: 54...
	 start solving instance: 138...
	 start solving instance: 28...
	 start solving instance: 7...
	 start solving instance: 104...
	 start solving instance: 79...
	 start solving instance: 123...
	 start solving instance: 92...
	 start solving instance: 137...
	 start solving instance: 145...
	 start solving instance: 106...
	 start solving instance: 135...
	 start solving instance: 41...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.201901377270621e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20688720047473907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2019015531924816e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.201901377270621e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20688720047473907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2019015531924816e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.201901377270621e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20688720047473907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2019015531924816e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.5153371338993304e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21100807189941406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45153371338993303552.0000
PPO iteration: 782/1000:
	 start solving instance: 7...
	 start solving instance: 103...
	 start solving instance: 123...
	 start solving instance: 38...
	 start solving instance: 104...
	 start solving instance: 111...
	 start solving instance: 145...
	 start solving instance: 106...
	 start solving instance: 137...
	 start solving instance: 138...
	 start solving instance: 54...
	 start solving instance: 102...
	 start solving instance: 79...
	 start solving instance: 110...
	 start solving instance: 92...
	 start solving instance: 28...
	 start solving instance: 25...
	 start solving instance: 135...
	 start solving instance: 41...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.84425856817462e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19733698666095734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.84425856817462e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.84425856817462e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19733698666095734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.84425856817462e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.84425856817462e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19733698666095734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.84425856817462e+19 - Differentiable computation graph = True!
PPO iteration: 783/1000:
	 start solving instance: 7...
	 start solving instance: 102...
	 start solving instance: 28...
	 start solving instance: 38...
	 start solving instance: 123...
	 start solving instance: 104...
	 start solving instance: 138...
	 start solving instance: 103...
	 start solving instance: 79...
	 start solving instance: 41...
	 start solving instance: 26...
	 start solving instance: 54...
	 start solving instance: 111...
	 start solving instance: 106...
	 start solving instance: 25...
	 start solving instance: 135...
	 start solving instance: 110...
	 start solving instance: 145...
	 start solving instance: 92...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.314657438191143e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2082359343767166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.314657350230213e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.314657438191143e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2082359343767166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.314657350230213e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.314657438191143e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2082359343767166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.314657350230213e+19 - Differentiable computation graph = True!
PPO iteration: 784/1000:
	 start solving instance: 102...
	 start solving instance: 25...
	 start solving instance: 41...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 138...
	 start solving instance: 145...
	 start solving instance: 54...
	 start solving instance: 104...
	 start solving instance: 103...
	 start solving instance: 79...
	 start solving instance: 7...
	 start solving instance: 28...
	 start solving instance: 137...
	 start solving instance: 123...
	 start solving instance: 110...
	 start solving instance: 106...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.480751951667171e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20241418480873108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480752215549962e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.480751951667171e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20241418480873108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480752215549962e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.480751951667171e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20241418480873108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480752215549962e+19 - Differentiable computation graph = True!
PPO iteration: 785/1000:
	 start solving instance: 145...
	 start solving instance: 28...
	 start solving instance: 7...
	 start solving instance: 54...
	 start solving instance: 135...
	 start solving instance: 41...
	 start solving instance: 102...
	 start solving instance: 110...
	 start solving instance: 123...
	 start solving instance: 25...
	 start solving instance: 92...
	 start solving instance: 106...
	 start solving instance: 38...
	 start solving instance: 138...
	 start solving instance: 26...
	 start solving instance: 104...
	 start solving instance: 103...
	 start solving instance: 111...
	 start solving instance: 79...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2170253796130056e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20181547105312347
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.217025555534866e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2170253796130056e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20181547105312347
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.217025555534866e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2170253796130056e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20181547105312347
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.217025555534866e+19 - Differentiable computation graph = True!
PPO iteration: 786/1000:
	 start solving instance: 106...
	 start solving instance: 28...
	 start solving instance: 110...
	 start solving instance: 25...
	 start solving instance: 38...
	 start solving instance: 7...
	 start solving instance: 79...
	 start solving instance: 135...
	 start solving instance: 54...
	 start solving instance: 145...
	 start solving instance: 26...
	 start solving instance: 92...
	 start solving instance: 111...
	 start solving instance: 102...
	 start solving instance: 137...
	 start solving instance: 123...
	 start solving instance: 41...
	 start solving instance: 103...
	 start solving instance: 138...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.304380786791437e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20427750051021576
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304380874752367e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.304380786791437e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20427750051021576
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304380874752367e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.304380786791437e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20427750051021576
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304380874752367e+19 - Differentiable computation graph = True!
PPO iteration: 787/1000:
	 start solving instance: 41...
	 start solving instance: 28...
	 start solving instance: 25...
	 start solving instance: 102...
	 start solving instance: 104...
	 start solving instance: 138...
	 start solving instance: 7...
	 start solving instance: 135...
	 start solving instance: 106...
	 start solving instance: 110...
	 start solving instance: 137...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 79...
	 start solving instance: 145...
	 start solving instance: 103...
	 start solving instance: 123...
	 start solving instance: 54...
	 start solving instance: 38...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.402696125875539e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20028169453144073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.402696125875539e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.402696125875539e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20028169453144073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.402696125875539e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.402696125875539e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20028169453144073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.402696125875539e+19 - Differentiable computation graph = True!
PPO iteration: 788/1000:
	 start solving instance: 110...
	 start solving instance: 135...
	 start solving instance: 92...
	 start solving instance: 38...
	 start solving instance: 28...
	 start solving instance: 138...
	 start solving instance: 79...
	 start solving instance: 25...
	 start solving instance: 123...
	 start solving instance: 103...
	 start solving instance: 54...
	 start solving instance: 104...
	 start solving instance: 41...
	 start solving instance: 111...
	 start solving instance: 102...
	 start solving instance: 26...
	 start solving instance: 145...
	 start solving instance: 7...
	 start solving instance: 106...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.302846748168364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396943390369415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.302846836129294e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.302846748168364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396943390369415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.302846836129294e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.302846748168364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20396943390369415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.302846836129294e+19 - Differentiable computation graph = True!
PPO iteration: 789/1000:
	 start solving instance: 54...
	 start solving instance: 138...
	 start solving instance: 79...
	 start solving instance: 102...
	 start solving instance: 145...
	 start solving instance: 38...
	 start solving instance: 92...
	 start solving instance: 26...
	 start solving instance: 123...
	 start solving instance: 41...
	 start solving instance: 103...
	 start solving instance: 111...
	 start solving instance: 28...
	 start solving instance: 7...
	 start solving instance: 106...
	 start solving instance: 25...
	 start solving instance: 110...
	 start solving instance: 135...
	 start solving instance: 137...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2465200868913526e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20694831013679504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246520174852283e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2465200868913526e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20694831013679504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246520174852283e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2465200868913526e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20694831013679504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.246520174852283e+19 - Differentiable computation graph = True!
PPO iteration: 790/1000:
	 start solving instance: 106...
	 start solving instance: 7...
	 start solving instance: 145...
	 start solving instance: 103...
	 start solving instance: 79...
	 start solving instance: 110...
	 start solving instance: 26...
	 start solving instance: 111...
	 start solving instance: 25...
	 start solving instance: 54...
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 41...
	 start solving instance: 137...
	 start solving instance: 123...
	 start solving instance: 138...
	 start solving instance: 28...
	 start solving instance: 135...
	 start solving instance: 104...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8943392997184215e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20125415921211243
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.894339563601212e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8943392997184215e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20125415921211243
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.894339563601212e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8943392997184215e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20125415921211243
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.894339563601212e+19 - Differentiable computation graph = True!
PPO iteration: 791/1000:
	 New training batch of size 20...
	 start solving instance: 116...
	 start solving instance: 5...
	 start solving instance: 89...
	 start solving instance: 97...
	 start solving instance: 35...
	 start solving instance: 33...
	 start solving instance: 40...
	 start solving instance: 66...
	 start solving instance: 11...
	 start solving instance: 113...
	 start solving instance: 67...
	 start solving instance: 8...
	 start solving instance: 98...
	 start solving instance: 14...
	 start solving instance: 145...
	 start solving instance: 22...
	 start solving instance: 56...
	 start solving instance: 101...
	 start solving instance: 21...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3573536737209405e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20856332778930664
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.35735358576001e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3573536737209405e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20856332778930664
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.35735358576001e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3573536737209405e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20856332778930664
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.35735358576001e+19 - Differentiable computation graph = True!
PPO iteration: 792/1000:
	 start solving instance: 11...
	 start solving instance: 97...
	 start solving instance: 5...
	 start solving instance: 33...
	 start solving instance: 89...
	 start solving instance: 113...
	 start solving instance: 101...
	 start solving instance: 98...
	 start solving instance: 35...
	 start solving instance: 8...
	 start solving instance: 66...
	 start solving instance: 145...
	 start solving instance: 114...
	 start solving instance: 116...
	 start solving instance: 67...
	 start solving instance: 56...
	 start solving instance: 21...
	 start solving instance: 14...
	 start solving instance: 40...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3440937394118223e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20384466648101807
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.344093915333683e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3440937394118223e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20384466648101807
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.344093915333683e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3440937394118223e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20384466648101807
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.344093915333683e+19 - Differentiable computation graph = True!
PPO iteration: 793/1000:
	 start solving instance: 11...
	 start solving instance: 67...
	 start solving instance: 114...
	 start solving instance: 56...
	 start solving instance: 40...
	 start solving instance: 22...
	 start solving instance: 116...
	 start solving instance: 113...
	 start solving instance: 35...
	 start solving instance: 98...
	 start solving instance: 5...
	 start solving instance: 66...
	 start solving instance: 145...
	 start solving instance: 21...
	 start solving instance: 14...
	 start solving instance: 8...
	 start solving instance: 97...
	 start solving instance: 33...
	 start solving instance: 101...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.409973661398393e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20683231949806213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.409973573437463e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.409973661398393e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20683231949806213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.409973573437463e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.409973661398393e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20683231949806213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.409973573437463e+19 - Differentiable computation graph = True!
PPO iteration: 794/1000:
	 start solving instance: 67...
	 start solving instance: 98...
	 start solving instance: 101...
	 start solving instance: 40...
	 start solving instance: 22...
	 start solving instance: 21...
	 start solving instance: 8...
	 start solving instance: 11...
	 start solving instance: 113...
	 start solving instance: 89...
	 start solving instance: 116...
	 start solving instance: 97...
	 start solving instance: 66...
	 start solving instance: 35...
	 start solving instance: 114...
	 start solving instance: 33...
	 start solving instance: 56...
	 start solving instance: 5...
	 start solving instance: 14...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.211229809842533e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2076158970594406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.211229809842533e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.211229809842533e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2076158970594406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.211229809842533e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.211229809842533e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2076158970594406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.211229809842533e+19 - Differentiable computation graph = True!
PPO iteration: 795/1000:
	 start solving instance: 35...
	 start solving instance: 21...
	 start solving instance: 101...
	 start solving instance: 11...
	 start solving instance: 66...
	 start solving instance: 22...
	 start solving instance: 98...
	 start solving instance: 113...
	 start solving instance: 33...
	 start solving instance: 5...
	 start solving instance: 145...
	 start solving instance: 40...
	 start solving instance: 89...
	 start solving instance: 8...
	 start solving instance: 67...
	 start solving instance: 56...
	 start solving instance: 114...
	 start solving instance: 116...
	 start solving instance: 97...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.247502434560073e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20908871293067932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2475026984428634e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.247502434560073e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20908871293067932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2475026984428634e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.247502434560073e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20908871293067932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2475026984428634e+19 - Differentiable computation graph = True!
PPO iteration: 796/1000:
	 start solving instance: 67...
	 start solving instance: 33...
	 start solving instance: 22...
	 start solving instance: 35...
	 start solving instance: 113...
	 start solving instance: 114...
	 start solving instance: 116...
	 start solving instance: 8...
	 start solving instance: 101...
	 start solving instance: 21...
	 start solving instance: 5...
	 start solving instance: 97...
	 start solving instance: 98...
	 start solving instance: 145...
	 start solving instance: 66...
	 start solving instance: 89...
	 start solving instance: 56...
	 start solving instance: 40...
	 start solving instance: 14...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.303648951851989e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21541862189769745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.303649039812919e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.303648951851989e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21541862189769745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.303649039812919e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.303648951851989e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21541862189769745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.303649039812919e+19 - Differentiable computation graph = True!
PPO iteration: 797/1000:
	 start solving instance: 35...
	 start solving instance: 114...
	 start solving instance: 98...
	 start solving instance: 97...
	 start solving instance: 89...
	 start solving instance: 5...
	 start solving instance: 145...
	 start solving instance: 116...
	 start solving instance: 67...
	 start solving instance: 14...
	 start solving instance: 33...
	 start solving instance: 40...
	 start solving instance: 56...
	 start solving instance: 66...
	 start solving instance: 113...
	 start solving instance: 21...
	 start solving instance: 11...
	 start solving instance: 22...
	 start solving instance: 8...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2242972856363254e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20869646966457367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224297285636325e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2242972856363254e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20869646966457367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224297285636325e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2242972856363254e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20869646966457367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224297285636325e+19 - Differentiable computation graph = True!
PPO iteration: 798/1000:
	 start solving instance: 21...
	 start solving instance: 145...
	 start solving instance: 8...
	 start solving instance: 116...
	 start solving instance: 66...
	 start solving instance: 14...
	 start solving instance: 67...
	 start solving instance: 113...
	 start solving instance: 22...
	 start solving instance: 98...
	 start solving instance: 40...
	 start solving instance: 89...
	 start solving instance: 11...
	 start solving instance: 35...
	 start solving instance: 33...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 97...
	 start solving instance: 114...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1689086397192025e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20901314914226532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.168908727680133e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1689086397192025e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20901314914226532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.168908727680133e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1689086397192025e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20901314914226532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.168908727680133e+19 - Differentiable computation graph = True!
PPO iteration: 799/1000:
	 start solving instance: 116...
	 start solving instance: 113...
	 start solving instance: 56...
	 start solving instance: 145...
	 start solving instance: 114...
	 start solving instance: 67...
	 start solving instance: 8...
	 start solving instance: 97...
	 start solving instance: 89...
	 start solving instance: 5...
	 start solving instance: 14...
	 start solving instance: 35...
	 start solving instance: 40...
	 start solving instance: 21...
	 start solving instance: 66...
	 start solving instance: 11...
	 start solving instance: 98...
	 start solving instance: 101...
	 start solving instance: 22...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2530953423473135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20540283620357513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.253095254386383e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2530953423473135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20540283620357513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.253095254386383e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2530953423473135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20540283620357513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.253095254386383e+19 - Differentiable computation graph = True!
PPO iteration: 800/1000:
	 start solving instance: 35...
	 start solving instance: 116...
	 start solving instance: 67...
	 start solving instance: 22...
	 start solving instance: 14...
	 start solving instance: 40...
	 start solving instance: 11...
	 start solving instance: 145...
	 start solving instance: 8...
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 114...
	 start solving instance: 89...
	 start solving instance: 33...
	 start solving instance: 113...
	 start solving instance: 21...
	 start solving instance: 97...
	 start solving instance: 66...
	 start solving instance: 56...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1651973921512725e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20128880441188812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.165197656034063e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1651973921512725e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20128880441188812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.165197656034063e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1651973921512725e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20128880441188812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.165197656034063e+19 - Differentiable computation graph = True!
PPO iteration: 801/1000:
	 New training batch of size 20...
	 start solving instance: 149...
	 start solving instance: 123...
	 start solving instance: 44...
	 start solving instance: 68...
	 start solving instance: 59...
	 start solving instance: 91...
	 start solving instance: 25...
	 start solving instance: 56...
	 start solving instance: 48...
	 start solving instance: 23...
	 start solving instance: 111...
	 start solving instance: 46...
	 start solving instance: 72...
	 start solving instance: 143...
	 start solving instance: 139...
	 start solving instance: 108...
	 start solving instance: 31...
	 start solving instance: 150...
	 start solving instance: 16...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0602269290865675e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21531115472316742
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.060226841125637e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0602269290865675e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21531115472316742
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.060226841125637e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0602269290865675e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21531115472316742
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.060226841125637e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.422009531402541e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2039039582014084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 44220097073244012544.0000
PPO iteration: 802/1000:
	 start solving instance: 25...
	 start solving instance: 31...
	 start solving instance: 68...
	 start solving instance: 150...
	 start solving instance: 111...
	 start solving instance: 91...
	 start solving instance: 1...
	 start solving instance: 59...
	 start solving instance: 48...
	 start solving instance: 72...
	 start solving instance: 16...
	 start solving instance: 108...
	 start solving instance: 149...
	 start solving instance: 139...
	 start solving instance: 56...
	 start solving instance: 46...
	 start solving instance: 123...
	 start solving instance: 44...
	 start solving instance: 143...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.126671912088885e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21796467900276184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1266720880107454e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.126671912088885e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21796467900276184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1266720880107454e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.126671912088885e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21796467900276184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1266720880107454e+19 - Differentiable computation graph = True!
PPO iteration: 803/1000:
	 start solving instance: 139...
	 start solving instance: 48...
	 start solving instance: 149...
	 start solving instance: 23...
	 start solving instance: 108...
	 start solving instance: 44...
	 start solving instance: 68...
	 start solving instance: 72...
	 start solving instance: 123...
	 start solving instance: 143...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 91...
	 start solving instance: 1...
	 start solving instance: 56...
	 start solving instance: 25...
	 start solving instance: 31...
	 start solving instance: 150...
	 start solving instance: 111...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.152165100729569e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20820088684558868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.15216536461236e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.152165100729569e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20820088684558868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.15216536461236e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.152165100729569e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20820088684558868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.15216536461236e+19 - Differentiable computation graph = True!
PPO iteration: 804/1000:
	 start solving instance: 72...
	 start solving instance: 59...
	 start solving instance: 1...
	 start solving instance: 48...
	 start solving instance: 56...
	 start solving instance: 143...
	 start solving instance: 139...
	 start solving instance: 25...
	 start solving instance: 150...
	 start solving instance: 31...
	 start solving instance: 44...
	 start solving instance: 46...
	 start solving instance: 108...
	 start solving instance: 91...
	 start solving instance: 23...
	 start solving instance: 123...
	 start solving instance: 149...
	 start solving instance: 68...
	 start solving instance: 111...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2493559472817124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22568033635616302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249356035242643e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2493559472817124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22568033635616302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249356035242643e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2493559472817124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22568033635616302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249356035242643e+19 - Differentiable computation graph = True!
PPO iteration: 805/1000:
	 start solving instance: 139...
	 start solving instance: 59...
	 start solving instance: 149...
	 start solving instance: 123...
	 start solving instance: 150...
	 start solving instance: 111...
	 start solving instance: 16...
	 start solving instance: 31...
	 start solving instance: 108...
	 start solving instance: 72...
	 start solving instance: 56...
	 start solving instance: 48...
	 start solving instance: 143...
	 start solving instance: 25...
	 start solving instance: 46...
	 start solving instance: 23...
	 start solving instance: 1...
	 start solving instance: 68...
	 start solving instance: 91...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.188330413112238e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21756158769130707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.188330501073168e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.188330413112238e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21756158769130707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.188330501073168e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.188330413112238e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21756158769130707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.188330501073168e+19 - Differentiable computation graph = True!
PPO iteration: 806/1000:
	 start solving instance: 150...
	 start solving instance: 72...
	 start solving instance: 16...
	 start solving instance: 123...
	 start solving instance: 46...
	 start solving instance: 23...
	 start solving instance: 48...
	 start solving instance: 143...
	 start solving instance: 44...
	 start solving instance: 91...
	 start solving instance: 149...
	 start solving instance: 111...
	 start solving instance: 59...
	 start solving instance: 31...
	 start solving instance: 68...
	 start solving instance: 1...
	 start solving instance: 56...
	 start solving instance: 139...
	 start solving instance: 108...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0904844335518004e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20578601956367493
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.090484521512731e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0904844335518004e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20578601956367493
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.090484521512731e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0904844335518004e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20578601956367493
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.090484521512731e+19 - Differentiable computation graph = True!
PPO iteration: 807/1000:
	 start solving instance: 68...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 143...
	 start solving instance: 56...
	 start solving instance: 123...
	 start solving instance: 31...
	 start solving instance: 111...
	 start solving instance: 108...
	 start solving instance: 150...
	 start solving instance: 91...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 139...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 23...
	 start solving instance: 46...
	 start solving instance: 59...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.27806674674992e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2246035635471344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.278066922671781e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.27806674674992e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2246035635471344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.278066922671781e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.27806674674992e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2246035635471344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.278066922671781e+19 - Differentiable computation graph = True!
PPO iteration: 808/1000:
	 start solving instance: 139...
	 start solving instance: 59...
	 start solving instance: 123...
	 start solving instance: 108...
	 start solving instance: 111...
	 start solving instance: 150...
	 start solving instance: 91...
	 start solving instance: 149...
	 start solving instance: 44...
	 start solving instance: 56...
	 start solving instance: 48...
	 start solving instance: 1...
	 start solving instance: 72...
	 start solving instance: 23...
	 start solving instance: 25...
	 start solving instance: 68...
	 start solving instance: 16...
	 start solving instance: 143...
	 start solving instance: 46...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.163249585312435e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2116214781999588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.163249761234295e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.163249585312435e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2116214781999588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.163249761234295e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.163249585312435e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2116214781999588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.163249761234295e+19 - Differentiable computation graph = True!
PPO iteration: 809/1000:
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 23...
	 start solving instance: 25...
	 start solving instance: 91...
	 start solving instance: 72...
	 start solving instance: 149...
	 start solving instance: 59...
	 start solving instance: 139...
	 start solving instance: 68...
	 start solving instance: 143...
	 start solving instance: 1...
	 start solving instance: 108...
	 start solving instance: 46...
	 start solving instance: 31...
	 start solving instance: 48...
	 start solving instance: 56...
	 start solving instance: 44...
	 start solving instance: 150...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2792190349358295e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22053050994873047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.27921921085769e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2792190349358295e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22053050994873047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.27921921085769e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2792190349358295e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22053050994873047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.27921921085769e+19 - Differentiable computation graph = True!
PPO iteration: 810/1000:
	 start solving instance: 149...
	 start solving instance: 111...
	 start solving instance: 56...
	 start solving instance: 1...
	 start solving instance: 46...
	 start solving instance: 48...
	 start solving instance: 68...
	 start solving instance: 25...
	 start solving instance: 91...
	 start solving instance: 23...
	 start solving instance: 59...
	 start solving instance: 72...
	 start solving instance: 108...
	 start solving instance: 143...
	 start solving instance: 123...
	 start solving instance: 44...
	 start solving instance: 139...
	 start solving instance: 31...
	 start solving instance: 16...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.437387213067686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22308503091335297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.437387476950476e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.437387213067686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22308503091335297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.437387476950476e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.437387213067686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22308503091335297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.437387476950476e+19 - Differentiable computation graph = True!
PPO iteration: 811/1000:
	 New training batch of size 20...
	 start solving instance: 90...
	 start solving instance: 105...
	 start solving instance: 13...
	 start solving instance: 38...
	 start solving instance: 31...
	 start solving instance: 75...
	 start solving instance: 128...
	 start solving instance: 135...
	 start solving instance: 4...
	 start solving instance: 76...
	 start solving instance: 55...
	 start solving instance: 146...
	 start solving instance: 120...
	 start solving instance: 150...
	 start solving instance: 122...
	 start solving instance: 103...
	 start solving instance: 21...
	 start solving instance: 51...
	 start solving instance: 34...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2945865131330686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21149025857448578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.294586425172138e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2945865131330686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21149025857448578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.294586425172138e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2945865131330686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21149025857448578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.294586425172138e+19 - Differentiable computation graph = True!
PPO iteration: 812/1000:
	 start solving instance: 90...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 96...
	 start solving instance: 103...
	 start solving instance: 120...
	 start solving instance: 31...
	 start solving instance: 146...
	 start solving instance: 55...
	 start solving instance: 34...
	 start solving instance: 4...
	 start solving instance: 128...
	 start solving instance: 122...
	 start solving instance: 21...
	 start solving instance: 13...
	 start solving instance: 135...
	 start solving instance: 76...
	 start solving instance: 38...
	 start solving instance: 51...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4885101057127586e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21447180211544037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.488510369595549e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4885101057127586e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21447180211544037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.488510369595549e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4885101057127586e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21447180211544037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.488510369595549e+19 - Differentiable computation graph = True!
PPO iteration: 813/1000:
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 21...
	 start solving instance: 150...
	 start solving instance: 4...
	 start solving instance: 96...
	 start solving instance: 105...
	 start solving instance: 122...
	 start solving instance: 13...
	 start solving instance: 128...
	 start solving instance: 76...
	 start solving instance: 75...
	 start solving instance: 31...
	 start solving instance: 135...
	 start solving instance: 103...
	 start solving instance: 120...
	 start solving instance: 51...
	 start solving instance: 146...
	 start solving instance: 38...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.196784514037742e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20592930912971497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.196784426076812e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.196784514037742e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20592930912971497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.196784426076812e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.196784514037742e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20592930912971497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.196784426076812e+19 - Differentiable computation graph = True!
PPO iteration: 814/1000:
	 start solving instance: 135...
	 start solving instance: 51...
	 start solving instance: 105...
	 start solving instance: 96...
	 start solving instance: 128...
	 start solving instance: 146...
	 start solving instance: 21...
	 start solving instance: 13...
	 start solving instance: 150...
	 start solving instance: 90...
	 start solving instance: 38...
	 start solving instance: 103...
	 start solving instance: 4...
	 start solving instance: 31...
	 start solving instance: 120...
	 start solving instance: 34...
	 start solving instance: 76...
	 start solving instance: 55...
	 start solving instance: 75...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.45386581373549e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20200596749782562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.453866077618281e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.45386581373549e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20200596749782562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.453866077618281e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.45386581373549e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20200596749782562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.453866077618281e+19 - Differentiable computation graph = True!
PPO iteration: 815/1000:
	 start solving instance: 150...
	 start solving instance: 105...
	 start solving instance: 13...
	 start solving instance: 135...
	 start solving instance: 34...
	 start solving instance: 122...
	 start solving instance: 31...
	 start solving instance: 4...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 55...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 76...
	 start solving instance: 38...
	 start solving instance: 120...
	 start solving instance: 51...
	 start solving instance: 75...
	 start solving instance: 96...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.502837182027331e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2113252729177475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.502837445910122e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.502837182027331e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2113252729177475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.502837445910122e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.502837182027331e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2113252729177475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.502837445910122e+19 - Differentiable computation graph = True!
PPO iteration: 816/1000:
	 start solving instance: 96...
	 start solving instance: 75...
	 start solving instance: 128...
	 start solving instance: 21...
	 start solving instance: 105...
	 start solving instance: 31...
	 start solving instance: 4...
	 start solving instance: 90...
	 start solving instance: 120...
	 start solving instance: 34...
	 start solving instance: 146...
	 start solving instance: 150...
	 start solving instance: 55...
	 start solving instance: 122...
	 start solving instance: 38...
	 start solving instance: 51...
	 start solving instance: 76...
	 start solving instance: 103...
	 start solving instance: 13...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5670039769368966e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2207074910402298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.567004064897827e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5670039769368966e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2207074910402298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.567004064897827e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5670039769368966e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2207074910402298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.567004064897827e+19 - Differentiable computation graph = True!
PPO iteration: 817/1000:
	 start solving instance: 146...
	 start solving instance: 103...
	 start solving instance: 21...
	 start solving instance: 90...
	 start solving instance: 55...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 34...
	 start solving instance: 135...
	 start solving instance: 120...
	 start solving instance: 128...
	 start solving instance: 51...
	 start solving instance: 76...
	 start solving instance: 96...
	 start solving instance: 38...
	 start solving instance: 122...
	 start solving instance: 150...
	 start solving instance: 31...
	 start solving instance: 13...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.311119649577611e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2080824375152588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3111195616166806e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.311119649577611e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2080824375152588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3111195616166806e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.311119649577611e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2080824375152588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3111195616166806e+19 - Differentiable computation graph = True!
PPO iteration: 818/1000:
	 start solving instance: 105...
	 start solving instance: 55...
	 start solving instance: 90...
	 start solving instance: 150...
	 start solving instance: 146...
	 start solving instance: 120...
	 start solving instance: 21...
	 start solving instance: 122...
	 start solving instance: 38...
	 start solving instance: 4...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 13...
	 start solving instance: 76...
	 start solving instance: 128...
	 start solving instance: 75...
	 start solving instance: 51...
	 start solving instance: 135...
	 start solving instance: 96...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.376393696676812e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21394503116607666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376393608715882e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.376393696676812e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21394503116607666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376393608715882e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.376393696676812e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21394503116607666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376393608715882e+19 - Differentiable computation graph = True!
PPO iteration: 819/1000:
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 4...
	 start solving instance: 76...
	 start solving instance: 146...
	 start solving instance: 128...
	 start solving instance: 90...
	 start solving instance: 122...
	 start solving instance: 120...
	 start solving instance: 51...
	 start solving instance: 96...
	 start solving instance: 75...
	 start solving instance: 34...
	 start solving instance: 21...
	 start solving instance: 105...
	 start solving instance: 103...
	 start solving instance: 13...
	 start solving instance: 135...
	 start solving instance: 150...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3530467547335465e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2187848836183548
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.353047018616337e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3530467547335465e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2187848836183548
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.353047018616337e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3530467547335465e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2187848836183548
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.353047018616337e+19 - Differentiable computation graph = True!
PPO iteration: 820/1000:
	 start solving instance: 55...
	 start solving instance: 21...
	 start solving instance: 135...
	 start solving instance: 146...
	 start solving instance: 4...
	 start solving instance: 128...
	 start solving instance: 120...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 105...
	 start solving instance: 122...
	 start solving instance: 13...
	 start solving instance: 90...
	 start solving instance: 76...
	 start solving instance: 34...
	 start solving instance: 51...
	 start solving instance: 38...
	 start solving instance: 96...
	 start solving instance: 150...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3565623771926626e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21428881585597992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.356562377192663e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3565623771926626e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21428881585597992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.356562377192663e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3565623771926626e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21428881585597992
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.356562377192663e+19 - Differentiable computation graph = True!
PPO iteration: 821/1000:
	 New training batch of size 20...
	 start solving instance: 73...
	 start solving instance: 102...
	 start solving instance: 135...
	 start solving instance: 26...
	 start solving instance: 28...
	 start solving instance: 1...
	 start solving instance: 22...
	 start solving instance: 150...
	 start solving instance: 142...
	 start solving instance: 123...
	 start solving instance: 121...
	 start solving instance: 71...
	 start solving instance: 46...
	 start solving instance: 13...
	 start solving instance: 125...
	 start solving instance: 96...
	 start solving instance: 87...
	 start solving instance: 98...
	 start solving instance: 134...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.1272447337073685e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22517552971839905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.127244821668299e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.1272447337073685e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22517552971839905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.127244821668299e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.1272447337073685e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22517552971839905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.127244821668299e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.0890383558589494e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20799122750759125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 40890384438198796288.0000
PPO iteration: 822/1000:
	 start solving instance: 46...
	 start solving instance: 98...
	 start solving instance: 28...
	 start solving instance: 142...
	 start solving instance: 96...
	 start solving instance: 102...
	 start solving instance: 87...
	 start solving instance: 71...
	 start solving instance: 26...
	 start solving instance: 22...
	 start solving instance: 32...
	 start solving instance: 73...
	 start solving instance: 135...
	 start solving instance: 125...
	 start solving instance: 1...
	 start solving instance: 150...
	 start solving instance: 13...
	 start solving instance: 134...
	 start solving instance: 121...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9865104119455285e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2203691452741623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9865104119455285e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9865104119455285e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2203691452741623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9865104119455285e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9865104119455285e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2203691452741623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.9865104119455285e+19 - Differentiable computation graph = True!
PPO iteration: 823/1000:
	 start solving instance: 96...
	 start solving instance: 125...
	 start solving instance: 150...
	 start solving instance: 1...
	 start solving instance: 123...
	 start solving instance: 87...
	 start solving instance: 46...
	 start solving instance: 32...
	 start solving instance: 134...
	 start solving instance: 13...
	 start solving instance: 73...
	 start solving instance: 135...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 121...
	 start solving instance: 71...
	 start solving instance: 142...
	 start solving instance: 102...
	 start solving instance: 98...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.989584118691209e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23470787703990936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.989584206652139e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.989584118691209e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23470787703990936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.989584206652139e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.989584118691209e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23470787703990936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.989584206652139e+19 - Differentiable computation graph = True!
PPO iteration: 824/1000:
	 start solving instance: 125...
	 start solving instance: 98...
	 start solving instance: 142...
	 start solving instance: 96...
	 start solving instance: 71...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 1...
	 start solving instance: 13...
	 start solving instance: 150...
	 start solving instance: 123...
	 start solving instance: 102...
	 start solving instance: 22...
	 start solving instance: 32...
	 start solving instance: 87...
	 start solving instance: 73...
	 start solving instance: 135...
	 start solving instance: 121...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.975422760769175e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22573404014110565
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.975422936691035e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.975422760769175e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22573404014110565
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.975422936691035e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.975422760769175e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22573404014110565
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.975422936691035e+19 - Differentiable computation graph = True!
PPO iteration: 825/1000:
	 start solving instance: 125...
	 start solving instance: 28...
	 start solving instance: 135...
	 start solving instance: 96...
	 start solving instance: 87...
	 start solving instance: 123...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 134...
	 start solving instance: 142...
	 start solving instance: 22...
	 start solving instance: 71...
	 start solving instance: 26...
	 start solving instance: 13...
	 start solving instance: 98...
	 start solving instance: 32...
	 start solving instance: 121...
	 start solving instance: 150...
	 start solving instance: 73...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9849760214787346e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148272842168808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.984975933517804e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9849760214787346e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148272842168808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.984975933517804e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9849760214787346e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2148272842168808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.984975933517804e+19 - Differentiable computation graph = True!
PPO iteration: 826/1000:
	 start solving instance: 135...
	 start solving instance: 150...
	 start solving instance: 121...
	 start solving instance: 96...
	 start solving instance: 1...
	 start solving instance: 46...
	 start solving instance: 87...
	 start solving instance: 22...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 13...
	 start solving instance: 26...
	 start solving instance: 125...
	 start solving instance: 102...
	 start solving instance: 123...
	 start solving instance: 98...
	 start solving instance: 134...
	 start solving instance: 71...
	 start solving instance: 73...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.91293566778313e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22712314128875732
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.912935931665921e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.91293566778313e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22712314128875732
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.912935931665921e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.91293566778313e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22712314128875732
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.912935931665921e+19 - Differentiable computation graph = True!
PPO iteration: 827/1000:
	 start solving instance: 135...
	 start solving instance: 98...
	 start solving instance: 73...
	 start solving instance: 121...
	 start solving instance: 13...
	 start solving instance: 71...
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 87...
	 start solving instance: 46...
	 start solving instance: 96...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 134...
	 start solving instance: 150...
	 start solving instance: 125...
	 start solving instance: 1...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.012736139213102e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22262434661388397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.012736403095893e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.012736139213102e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22262434661388397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.012736403095893e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.012736139213102e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22262434661388397
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.012736403095893e+19 - Differentiable computation graph = True!
PPO iteration: 828/1000:
	 start solving instance: 26...
	 start solving instance: 125...
	 start solving instance: 22...
	 start solving instance: 13...
	 start solving instance: 134...
	 start solving instance: 87...
	 start solving instance: 28...
	 start solving instance: 32...
	 start solving instance: 135...
	 start solving instance: 96...
	 start solving instance: 98...
	 start solving instance: 123...
	 start solving instance: 73...
	 start solving instance: 71...
	 start solving instance: 102...
	 start solving instance: 150...
	 start solving instance: 121...
	 start solving instance: 142...
	 start solving instance: 46...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.897853886687252e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21275587379932404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.897854150570043e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.897853886687252e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21275587379932404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.897854150570043e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.897853886687252e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21275587379932404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.897854150570043e+19 - Differentiable computation graph = True!
PPO iteration: 829/1000:
	 start solving instance: 134...
	 start solving instance: 87...
	 start solving instance: 96...
	 start solving instance: 26...
	 start solving instance: 98...
	 start solving instance: 121...
	 start solving instance: 46...
	 start solving instance: 142...
	 start solving instance: 135...
	 start solving instance: 1...
	 start solving instance: 71...
	 start solving instance: 102...
	 start solving instance: 73...
	 start solving instance: 28...
	 start solving instance: 125...
	 start solving instance: 22...
	 start solving instance: 123...
	 start solving instance: 32...
	 start solving instance: 150...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.812628189551358e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2262066900730133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8126283654732186e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.812628189551358e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2262066900730133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8126283654732186e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.812628189551358e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2262066900730133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.8126283654732186e+19 - Differentiable computation graph = True!
PPO iteration: 830/1000:
	 start solving instance: 96...
	 start solving instance: 121...
	 start solving instance: 28...
	 start solving instance: 98...
	 start solving instance: 123...
	 start solving instance: 142...
	 start solving instance: 87...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 22...
	 start solving instance: 102...
	 start solving instance: 1...
	 start solving instance: 13...
	 start solving instance: 125...
	 start solving instance: 73...
	 start solving instance: 26...
	 start solving instance: 46...
	 start solving instance: 150...
	 start solving instance: 32...
	 start solving instance: 71...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8092589340801316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21936647593975067
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.809259022041062e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8092589340801316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21936647593975067
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.809259022041062e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8092589340801316e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21936647593975067
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.809259022041062e+19 - Differentiable computation graph = True!
PPO iteration: 831/1000:
	 New training batch of size 20...
	 start solving instance: 105...
	 start solving instance: 70...
	 start solving instance: 25...
	 start solving instance: 48...
	 start solving instance: 8...
	 start solving instance: 91...
	 start solving instance: 56...
	 start solving instance: 149...
	 start solving instance: 22...
	 start solving instance: 32...
	 start solving instance: 90...
	 start solving instance: 124...
	 start solving instance: 53...
	 start solving instance: 148...
	 start solving instance: 121...
	 start solving instance: 142...
	 start solving instance: 132...
	 start solving instance: 113...
	 start solving instance: 141...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1380086686196276e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22565971314907074
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.138008932502418e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1380086686196276e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22565971314907074
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.138008932502418e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1380086686196276e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22565971314907074
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.138008932502418e+19 - Differentiable computation graph = True!
PPO iteration: 832/1000:
	 start solving instance: 25...
	 start solving instance: 109...
	 start solving instance: 141...
	 start solving instance: 149...
	 start solving instance: 22...
	 start solving instance: 70...
	 start solving instance: 8...
	 start solving instance: 91...
	 start solving instance: 53...
	 start solving instance: 32...
	 start solving instance: 56...
	 start solving instance: 121...
	 start solving instance: 113...
	 start solving instance: 142...
	 start solving instance: 148...
	 start solving instance: 124...
	 start solving instance: 132...
	 start solving instance: 48...
	 start solving instance: 90...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.171636132243529e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22547464072704315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1716363961263194e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.171636132243529e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22547464072704315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1716363961263194e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.171636132243529e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22547464072704315
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1716363961263194e+19 - Differentiable computation graph = True!
PPO iteration: 833/1000:
	 start solving instance: 142...
	 start solving instance: 124...
	 start solving instance: 53...
	 start solving instance: 48...
	 start solving instance: 149...
	 start solving instance: 70...
	 start solving instance: 91...
	 start solving instance: 141...
	 start solving instance: 25...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 22...
	 start solving instance: 8...
	 start solving instance: 32...
	 start solving instance: 90...
	 start solving instance: 56...
	 start solving instance: 121...
	 start solving instance: 132...
	 start solving instance: 113...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.447666679217159e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2324034720659256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.447666591256229e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.447666679217159e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2324034720659256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.447666591256229e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.447666679217159e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2324034720659256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.447666591256229e+19 - Differentiable computation graph = True!
PPO iteration: 834/1000:
	 start solving instance: 149...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 32...
	 start solving instance: 141...
	 start solving instance: 25...
	 start solving instance: 70...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 132...
	 start solving instance: 109...
	 start solving instance: 8...
	 start solving instance: 22...
	 start solving instance: 53...
	 start solving instance: 48...
	 start solving instance: 121...
	 start solving instance: 56...
	 start solving instance: 124...
	 start solving instance: 142...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.209591625478077e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22931228578090668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209591537517147e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.209591625478077e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22931228578090668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209591537517147e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.209591625478077e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22931228578090668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209591537517147e+19 - Differentiable computation graph = True!
PPO iteration: 835/1000:
	 start solving instance: 32...
	 start solving instance: 90...
	 start solving instance: 8...
	 start solving instance: 141...
	 start solving instance: 132...
	 start solving instance: 109...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 70...
	 start solving instance: 56...
	 start solving instance: 148...
	 start solving instance: 149...
	 start solving instance: 142...
	 start solving instance: 48...
	 start solving instance: 53...
	 start solving instance: 22...
	 start solving instance: 105...
	 start solving instance: 25...
	 start solving instance: 121...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.230187149523996e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22718386352062225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.230187149523996e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.230187149523996e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22718386352062225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.230187149523996e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.230187149523996e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22718386352062225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.230187149523996e+19 - Differentiable computation graph = True!
PPO iteration: 836/1000:
	 start solving instance: 32...
	 start solving instance: 56...
	 start solving instance: 48...
	 start solving instance: 148...
	 start solving instance: 25...
	 start solving instance: 142...
	 start solving instance: 121...
	 start solving instance: 113...
	 start solving instance: 149...
	 start solving instance: 70...
	 start solving instance: 91...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 109...
	 start solving instance: 124...
	 start solving instance: 22...
	 start solving instance: 53...
	 start solving instance: 8...
	 start solving instance: 141...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3905722949411694e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23907044529914856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.39057247086303e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3905722949411694e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23907044529914856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.39057247086303e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3905722949411694e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23907044529914856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.39057247086303e+19 - Differentiable computation graph = True!
PPO iteration: 837/1000:
	 start solving instance: 70...
	 start solving instance: 149...
	 start solving instance: 132...
	 start solving instance: 8...
	 start solving instance: 121...
	 start solving instance: 48...
	 start solving instance: 142...
	 start solving instance: 91...
	 start solving instance: 56...
	 start solving instance: 109...
	 start solving instance: 25...
	 start solving instance: 124...
	 start solving instance: 105...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 141...
	 start solving instance: 53...
	 start solving instance: 22...
	 start solving instance: 148...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.172442558051805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23160548508167267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.172442558051805e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.172442558051805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23160548508167267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.172442558051805e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.172442558051805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23160548508167267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.172442558051805e+19 - Differentiable computation graph = True!
PPO iteration: 838/1000:
	 start solving instance: 121...
	 start solving instance: 124...
	 start solving instance: 91...
	 start solving instance: 56...
	 start solving instance: 141...
	 start solving instance: 25...
	 start solving instance: 48...
	 start solving instance: 8...
	 start solving instance: 113...
	 start solving instance: 149...
	 start solving instance: 53...
	 start solving instance: 22...
	 start solving instance: 70...
	 start solving instance: 32...
	 start solving instance: 132...
	 start solving instance: 109...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 142...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9715415526431785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22681252658367157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9715415526431785e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9715415526431785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22681252658367157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9715415526431785e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9715415526431785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22681252658367157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9715415526431785e+19 - Differentiable computation graph = True!
PPO iteration: 839/1000:
	 start solving instance: 109...
	 start solving instance: 91...
	 start solving instance: 32...
	 start solving instance: 25...
	 start solving instance: 148...
	 start solving instance: 142...
	 start solving instance: 90...
	 start solving instance: 56...
	 start solving instance: 70...
	 start solving instance: 53...
	 start solving instance: 113...
	 start solving instance: 132...
	 start solving instance: 105...
	 start solving instance: 8...
	 start solving instance: 22...
	 start solving instance: 141...
	 start solving instance: 149...
	 start solving instance: 48...
	 start solving instance: 121...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.257648551939329e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2254287749528885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257648551939329e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.257648551939329e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2254287749528885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257648551939329e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.257648551939329e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2254287749528885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257648551939329e+19 - Differentiable computation graph = True!
PPO iteration: 840/1000:
	 start solving instance: 121...
	 start solving instance: 53...
	 start solving instance: 70...
	 start solving instance: 148...
	 start solving instance: 8...
	 start solving instance: 91...
	 start solving instance: 90...
	 start solving instance: 149...
	 start solving instance: 105...
	 start solving instance: 141...
	 start solving instance: 25...
	 start solving instance: 132...
	 start solving instance: 48...
	 start solving instance: 56...
	 start solving instance: 109...
	 start solving instance: 124...
	 start solving instance: 32...
	 start solving instance: 142...
	 start solving instance: 113...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.399274797533621e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23973269760608673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.399274885494551e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.399274797533621e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23973269760608673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.399274885494551e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.399274797533621e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23973269760608673
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.399274885494551e+19 - Differentiable computation graph = True!
PPO iteration: 841/1000:
	 New training batch of size 20...
	 start solving instance: 150...
	 start solving instance: 105...
	 start solving instance: 10...
	 start solving instance: 56...
	 start solving instance: 73...
	 start solving instance: 95...
	 start solving instance: 116...
	 start solving instance: 60...
	 start solving instance: 48...
	 start solving instance: 59...
	 start solving instance: 6...
	 start solving instance: 35...
	 start solving instance: 85...
	 start solving instance: 40...
	 start solving instance: 125...
	 start solving instance: 128...
	 start solving instance: 25...
	 start solving instance: 108...
	 start solving instance: 123...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.398242136212814e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20896755158901215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.398242224173744e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.398242136212814e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20896755158901215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.398242224173744e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.398242136212814e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20896755158901215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.398242224173744e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.5015413416032993e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20749790966510773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45015413416032993280.0000
PPO iteration: 842/1000:
	 start solving instance: 85...
	 start solving instance: 60...
	 start solving instance: 116...
	 start solving instance: 128...
	 start solving instance: 73...
	 start solving instance: 59...
	 start solving instance: 52...
	 start solving instance: 95...
	 start solving instance: 6...
	 start solving instance: 25...
	 start solving instance: 150...
	 start solving instance: 105...
	 start solving instance: 125...
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 10...
	 start solving instance: 56...
	 start solving instance: 40...
	 start solving instance: 108...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.364119980317344e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21896274387836456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.364119980317344e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.364119980317344e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21896274387836456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.364119980317344e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.364119980317344e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21896274387836456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.364119980317344e+19 - Differentiable computation graph = True!
PPO iteration: 843/1000:
	 start solving instance: 123...
	 start solving instance: 56...
	 start solving instance: 128...
	 start solving instance: 40...
	 start solving instance: 150...
	 start solving instance: 52...
	 start solving instance: 10...
	 start solving instance: 105...
	 start solving instance: 48...
	 start solving instance: 108...
	 start solving instance: 85...
	 start solving instance: 6...
	 start solving instance: 60...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 73...
	 start solving instance: 59...
	 start solving instance: 125...
	 start solving instance: 116...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.339750932364898e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21191516518592834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.339750844403968e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.339750932364898e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21191516518592834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.339750844403968e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.339750932364898e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21191516518592834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.339750844403968e+19 - Differentiable computation graph = True!
PPO iteration: 844/1000:
	 start solving instance: 56...
	 start solving instance: 128...
	 start solving instance: 105...
	 start solving instance: 40...
	 start solving instance: 35...
	 start solving instance: 73...
	 start solving instance: 52...
	 start solving instance: 85...
	 start solving instance: 10...
	 start solving instance: 6...
	 start solving instance: 123...
	 start solving instance: 95...
	 start solving instance: 48...
	 start solving instance: 25...
	 start solving instance: 59...
	 start solving instance: 108...
	 start solving instance: 125...
	 start solving instance: 60...
	 start solving instance: 116...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5270468447742145e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2113998383283615
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.527046932735145e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5270468447742145e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2113998383283615
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.527046932735145e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5270468447742145e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2113998383283615
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.527046932735145e+19 - Differentiable computation graph = True!
PPO iteration: 845/1000:
	 start solving instance: 73...
	 start solving instance: 105...
	 start solving instance: 56...
	 start solving instance: 150...
	 start solving instance: 6...
	 start solving instance: 52...
	 start solving instance: 10...
	 start solving instance: 35...
	 start solving instance: 108...
	 start solving instance: 25...
	 start solving instance: 123...
	 start solving instance: 59...
	 start solving instance: 128...
	 start solving instance: 48...
	 start solving instance: 125...
	 start solving instance: 95...
	 start solving instance: 85...
	 start solving instance: 40...
	 start solving instance: 60...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.355622954457891e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2225605994462967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.355622954457891e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.355622954457891e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2225605994462967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.355622954457891e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.355622954457891e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2225605994462967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.355622954457891e+19 - Differentiable computation graph = True!
PPO iteration: 846/1000:
	 start solving instance: 125...
	 start solving instance: 48...
	 start solving instance: 60...
	 start solving instance: 128...
	 start solving instance: 85...
	 start solving instance: 40...
	 start solving instance: 35...
	 start solving instance: 108...
	 start solving instance: 52...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 25...
	 start solving instance: 116...
	 start solving instance: 123...
	 start solving instance: 10...
	 start solving instance: 150...
	 start solving instance: 59...
	 start solving instance: 95...
	 start solving instance: 105...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.329237841984755e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2143022119998932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3292377540238246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.329237841984755e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2143022119998932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3292377540238246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.329237841984755e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2143022119998932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3292377540238246e+19 - Differentiable computation graph = True!
PPO iteration: 847/1000:
	 start solving instance: 125...
	 start solving instance: 85...
	 start solving instance: 60...
	 start solving instance: 59...
	 start solving instance: 95...
	 start solving instance: 128...
	 start solving instance: 35...
	 start solving instance: 6...
	 start solving instance: 52...
	 start solving instance: 105...
	 start solving instance: 150...
	 start solving instance: 123...
	 start solving instance: 116...
	 start solving instance: 108...
	 start solving instance: 73...
	 start solving instance: 40...
	 start solving instance: 56...
	 start solving instance: 10...
	 start solving instance: 25...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.497954294868843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2123829573392868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497954294868843e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.497954294868843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2123829573392868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497954294868843e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.497954294868843e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2123829573392868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.497954294868843e+19 - Differentiable computation graph = True!
PPO iteration: 848/1000:
	 start solving instance: 25...
	 start solving instance: 60...
	 start solving instance: 48...
	 start solving instance: 59...
	 start solving instance: 95...
	 start solving instance: 10...
	 start solving instance: 73...
	 start solving instance: 125...
	 start solving instance: 85...
	 start solving instance: 123...
	 start solving instance: 108...
	 start solving instance: 105...
	 start solving instance: 56...
	 start solving instance: 150...
	 start solving instance: 40...
	 start solving instance: 116...
	 start solving instance: 35...
	 start solving instance: 6...
	 start solving instance: 128...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.632969396947643e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2233760803937912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6329694849085735e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.632969396947643e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2233760803937912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6329694849085735e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.632969396947643e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2233760803937912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6329694849085735e+19 - Differentiable computation graph = True!
PPO iteration: 849/1000:
	 start solving instance: 73...
	 start solving instance: 60...
	 start solving instance: 150...
	 start solving instance: 56...
	 start solving instance: 125...
	 start solving instance: 95...
	 start solving instance: 6...
	 start solving instance: 59...
	 start solving instance: 128...
	 start solving instance: 25...
	 start solving instance: 105...
	 start solving instance: 85...
	 start solving instance: 116...
	 start solving instance: 10...
	 start solving instance: 40...
	 start solving instance: 48...
	 start solving instance: 35...
	 start solving instance: 123...
	 start solving instance: 108...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.416799077739906e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22491970658302307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416799341622696e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.416799077739906e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22491970658302307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416799341622696e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.416799077739906e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22491970658302307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416799341622696e+19 - Differentiable computation graph = True!
PPO iteration: 850/1000:
	 start solving instance: 48...
	 start solving instance: 108...
	 start solving instance: 52...
	 start solving instance: 59...
	 start solving instance: 105...
	 start solving instance: 125...
	 start solving instance: 35...
	 start solving instance: 95...
	 start solving instance: 128...
	 start solving instance: 10...
	 start solving instance: 150...
	 start solving instance: 60...
	 start solving instance: 123...
	 start solving instance: 85...
	 start solving instance: 6...
	 start solving instance: 116...
	 start solving instance: 56...
	 start solving instance: 25...
	 start solving instance: 73...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.263476843175844e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21077366173267365
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.263476843175844e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.263476843175844e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21077366173267365
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.263476843175844e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.263476843175844e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21077366173267365
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.263476843175844e+19 - Differentiable computation graph = True!
PPO iteration: 851/1000:
	 New training batch of size 20...
	 start solving instance: 78...
	 start solving instance: 56...
	 start solving instance: 31...
	 start solving instance: 88...
	 start solving instance: 13...
	 start solving instance: 4...
	 start solving instance: 129...
	 start solving instance: 114...
	 start solving instance: 145...
	 start solving instance: 22...
	 start solving instance: 36...
	 start solving instance: 33...
	 start solving instance: 70...
	 start solving instance: 14...
	 start solving instance: 1...
	 start solving instance: 25...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 137...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.515462038420246e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21029376983642578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.515462038420246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.515462038420246e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21029376983642578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.515462038420246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.515462038420246e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21029376983642578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.515462038420246e+19 - Differentiable computation graph = True!
PPO iteration: 852/1000:
	 start solving instance: 31...
	 start solving instance: 22...
	 start solving instance: 141...
	 start solving instance: 70...
	 start solving instance: 137...
	 start solving instance: 55...
	 start solving instance: 13...
	 start solving instance: 48...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 33...
	 start solving instance: 114...
	 start solving instance: 56...
	 start solving instance: 14...
	 start solving instance: 129...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 88...
	 start solving instance: 1...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.252724499065497e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20549693703651428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.252724499065497e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.252724499065497e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20549693703651428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.252724499065497e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.252724499065497e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20549693703651428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.252724499065497e+19 - Differentiable computation graph = True!
PPO iteration: 853/1000:
	 start solving instance: 14...
	 start solving instance: 4...
	 start solving instance: 31...
	 start solving instance: 88...
	 start solving instance: 56...
	 start solving instance: 78...
	 start solving instance: 48...
	 start solving instance: 55...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 36...
	 start solving instance: 22...
	 start solving instance: 25...
	 start solving instance: 13...
	 start solving instance: 141...
	 start solving instance: 33...
	 start solving instance: 137...
	 start solving instance: 70...
	 start solving instance: 145...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3049145337160244e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21038027107715607
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304914797598815e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3049145337160244e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21038027107715607
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304914797598815e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3049145337160244e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21038027107715607
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304914797598815e+19 - Differentiable computation graph = True!
PPO iteration: 854/1000:
	 start solving instance: 137...
	 start solving instance: 48...
	 start solving instance: 78...
	 start solving instance: 88...
	 start solving instance: 33...
	 start solving instance: 14...
	 start solving instance: 25...
	 start solving instance: 1...
	 start solving instance: 4...
	 start solving instance: 56...
	 start solving instance: 70...
	 start solving instance: 141...
	 start solving instance: 22...
	 start solving instance: 31...
	 start solving instance: 13...
	 start solving instance: 114...
	 start solving instance: 129...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.327451531413805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21433201432228088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.327451707335665e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.327451531413805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21433201432228088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.327451707335665e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.327451531413805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21433201432228088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.327451707335665e+19 - Differentiable computation graph = True!
PPO iteration: 855/1000:
	 start solving instance: 25...
	 start solving instance: 13...
	 start solving instance: 141...
	 start solving instance: 55...
	 start solving instance: 56...
	 start solving instance: 70...
	 start solving instance: 1...
	 start solving instance: 129...
	 start solving instance: 88...
	 start solving instance: 137...
	 start solving instance: 33...
	 start solving instance: 31...
	 start solving instance: 4...
	 start solving instance: 22...
	 start solving instance: 114...
	 start solving instance: 14...
	 start solving instance: 36...
	 start solving instance: 48...
	 start solving instance: 78...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.499827862682573e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21097324788570404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.499827862682573e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.499827862682573e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21097324788570404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.499827862682573e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.499827862682573e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21097324788570404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.499827862682573e+19 - Differentiable computation graph = True!
PPO iteration: 856/1000:
	 start solving instance: 137...
	 start solving instance: 22...
	 start solving instance: 78...
	 start solving instance: 31...
	 start solving instance: 114...
	 start solving instance: 4...
	 start solving instance: 14...
	 start solving instance: 129...
	 start solving instance: 33...
	 start solving instance: 56...
	 start solving instance: 13...
	 start solving instance: 70...
	 start solving instance: 141...
	 start solving instance: 55...
	 start solving instance: 48...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 1...
	 start solving instance: 25...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.155418951460344e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2053307145833969
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1554190394212745e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.155418951460344e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2053307145833969
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1554190394212745e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.155418951460344e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2053307145833969
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1554190394212745e+19 - Differentiable computation graph = True!
PPO iteration: 857/1000:
	 start solving instance: 55...
	 start solving instance: 70...
	 start solving instance: 13...
	 start solving instance: 31...
	 start solving instance: 33...
	 start solving instance: 141...
	 start solving instance: 48...
	 start solving instance: 1...
	 start solving instance: 145...
	 start solving instance: 137...
	 start solving instance: 78...
	 start solving instance: 14...
	 start solving instance: 4...
	 start solving instance: 22...
	 start solving instance: 56...
	 start solving instance: 88...
	 start solving instance: 25...
	 start solving instance: 36...
	 start solving instance: 114...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.297808346085243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20815622806549072
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.297808434046173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.297808346085243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20815622806549072
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.297808434046173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.297808346085243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20815622806549072
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.297808434046173e+19 - Differentiable computation graph = True!
PPO iteration: 858/1000:
	 start solving instance: 1...
	 start solving instance: 36...
	 start solving instance: 70...
	 start solving instance: 145...
	 start solving instance: 48...
	 start solving instance: 55...
	 start solving instance: 78...
	 start solving instance: 141...
	 start solving instance: 14...
	 start solving instance: 33...
	 start solving instance: 22...
	 start solving instance: 31...
	 start solving instance: 25...
	 start solving instance: 4...
	 start solving instance: 88...
	 start solving instance: 13...
	 start solving instance: 137...
	 start solving instance: 114...
	 start solving instance: 129...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.415987726119537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2173820585012436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.415987902041398e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.415987726119537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2173820585012436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.415987902041398e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.415987726119537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2173820585012436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.415987902041398e+19 - Differentiable computation graph = True!
PPO iteration: 859/1000:
	 start solving instance: 137...
	 start solving instance: 22...
	 start solving instance: 36...
	 start solving instance: 78...
	 start solving instance: 145...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 4...
	 start solving instance: 25...
	 start solving instance: 31...
	 start solving instance: 114...
	 start solving instance: 56...
	 start solving instance: 13...
	 start solving instance: 33...
	 start solving instance: 14...
	 start solving instance: 70...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.298970837739058e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21489600837230682
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.298970837739058e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.298970837739058e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21489600837230682
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.298970837739058e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.298970837739058e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21489600837230682
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.298970837739058e+19 - Differentiable computation graph = True!
PPO iteration: 860/1000:
	 start solving instance: 13...
	 start solving instance: 78...
	 start solving instance: 4...
	 start solving instance: 137...
	 start solving instance: 141...
	 start solving instance: 56...
	 start solving instance: 55...
	 start solving instance: 145...
	 start solving instance: 36...
	 start solving instance: 114...
	 start solving instance: 14...
	 start solving instance: 31...
	 start solving instance: 1...
	 start solving instance: 48...
	 start solving instance: 25...
	 start solving instance: 88...
	 start solving instance: 70...
	 start solving instance: 33...
	 start solving instance: 22...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.397976846047264e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21248288452625275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3979770219691246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.397976846047264e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21248288452625275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3979770219691246e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.397976846047264e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21248288452625275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3979770219691246e+19 - Differentiable computation graph = True!
PPO iteration: 861/1000:
	 New training batch of size 20...
	 start solving instance: 28...
	 start solving instance: 135...
	 start solving instance: 7...
	 start solving instance: 34...
	 start solving instance: 48...
	 start solving instance: 47...
	 start solving instance: 5...
	 start solving instance: 75...
	 start solving instance: 127...
	 start solving instance: 96...
	 start solving instance: 129...
	 start solving instance: 112...
	 start solving instance: 93...
	 start solving instance: 3...
	 start solving instance: 40...
	 start solving instance: 42...
	 start solving instance: 36...
	 start solving instance: 24...
	 start solving instance: 132...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6867342840928666e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2287931740283966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6867342840928666e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6867342840928666e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2287931740283966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6867342840928666e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6867342840928666e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2287931740283966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6867342840928666e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.2835509348274065e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20262177288532257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 42835508468664762368.0000
PPO iteration: 862/1000:
	 start solving instance: 5...
	 start solving instance: 75...
	 start solving instance: 36...
	 start solving instance: 112...
	 start solving instance: 129...
	 start solving instance: 93...
	 start solving instance: 132...
	 start solving instance: 127...
	 start solving instance: 24...
	 start solving instance: 48...
	 start solving instance: 67...
	 start solving instance: 96...
	 start solving instance: 42...
	 start solving instance: 40...
	 start solving instance: 135...
	 start solving instance: 3...
	 start solving instance: 28...
	 start solving instance: 34...
	 start solving instance: 47...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.751929166354868e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21272650361061096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751929166354868e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.751929166354868e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21272650361061096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751929166354868e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.751929166354868e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21272650361061096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751929166354868e+19 - Differentiable computation graph = True!
PPO iteration: 863/1000:
	 start solving instance: 28...
	 start solving instance: 93...
	 start solving instance: 3...
	 start solving instance: 40...
	 start solving instance: 47...
	 start solving instance: 5...
	 start solving instance: 129...
	 start solving instance: 42...
	 start solving instance: 7...
	 start solving instance: 127...
	 start solving instance: 112...
	 start solving instance: 96...
	 start solving instance: 132...
	 start solving instance: 135...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 36...
	 start solving instance: 24...
	 start solving instance: 75...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.495251079561258e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21371221542358398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495251255483118e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.495251079561258e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21371221542358398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495251255483118e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.495251079561258e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21371221542358398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495251255483118e+19 - Differentiable computation graph = True!
PPO iteration: 864/1000:
	 start solving instance: 132...
	 start solving instance: 42...
	 start solving instance: 129...
	 start solving instance: 7...
	 start solving instance: 24...
	 start solving instance: 75...
	 start solving instance: 93...
	 start solving instance: 40...
	 start solving instance: 48...
	 start solving instance: 112...
	 start solving instance: 127...
	 start solving instance: 3...
	 start solving instance: 96...
	 start solving instance: 34...
	 start solving instance: 28...
	 start solving instance: 36...
	 start solving instance: 67...
	 start solving instance: 47...
	 start solving instance: 5...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.684704849510783e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23214688897132874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.684705025432643e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.684704849510783e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23214688897132874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.684705025432643e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.684704849510783e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23214688897132874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.684705025432643e+19 - Differentiable computation graph = True!
PPO iteration: 865/1000:
	 start solving instance: 75...
	 start solving instance: 132...
	 start solving instance: 36...
	 start solving instance: 40...
	 start solving instance: 129...
	 start solving instance: 3...
	 start solving instance: 67...
	 start solving instance: 135...
	 start solving instance: 93...
	 start solving instance: 96...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 42...
	 start solving instance: 28...
	 start solving instance: 34...
	 start solving instance: 7...
	 start solving instance: 5...
	 start solving instance: 48...
	 start solving instance: 47...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.601652139195095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.224989652633667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601652315116955e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.601652139195095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.224989652633667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601652315116955e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.601652139195095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.224989652633667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601652315116955e+19 - Differentiable computation graph = True!
PPO iteration: 866/1000:
	 start solving instance: 48...
	 start solving instance: 93...
	 start solving instance: 34...
	 start solving instance: 5...
	 start solving instance: 127...
	 start solving instance: 67...
	 start solving instance: 96...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 135...
	 start solving instance: 129...
	 start solving instance: 24...
	 start solving instance: 3...
	 start solving instance: 42...
	 start solving instance: 7...
	 start solving instance: 40...
	 start solving instance: 132...
	 start solving instance: 47...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.601751710968106e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21615438163280487
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601751710968106e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.601751710968106e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21615438163280487
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601751710968106e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.601751710968106e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21615438163280487
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.601751710968106e+19 - Differentiable computation graph = True!
PPO iteration: 867/1000:
	 start solving instance: 47...
	 start solving instance: 42...
	 start solving instance: 127...
	 start solving instance: 24...
	 start solving instance: 34...
	 start solving instance: 96...
	 start solving instance: 48...
	 start solving instance: 36...
	 start solving instance: 5...
	 start solving instance: 7...
	 start solving instance: 3...
	 start solving instance: 40...
	 start solving instance: 129...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 67...
	 start solving instance: 132...
	 start solving instance: 28...
	 start solving instance: 75...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.510568947793852e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22086088359355927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5105692116766425e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.510568947793852e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22086088359355927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5105692116766425e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.510568947793852e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22086088359355927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5105692116766425e+19 - Differentiable computation graph = True!
PPO iteration: 868/1000:
	 start solving instance: 96...
	 start solving instance: 28...
	 start solving instance: 40...
	 start solving instance: 93...
	 start solving instance: 127...
	 start solving instance: 24...
	 start solving instance: 67...
	 start solving instance: 129...
	 start solving instance: 132...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 3...
	 start solving instance: 7...
	 start solving instance: 75...
	 start solving instance: 48...
	 start solving instance: 5...
	 start solving instance: 135...
	 start solving instance: 42...
	 start solving instance: 34...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7485841881003826e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22596588730812073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.748584451983173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7485841881003826e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22596588730812073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.748584451983173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7485841881003826e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22596588730812073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.748584451983173e+19 - Differentiable computation graph = True!
PPO iteration: 869/1000:
	 start solving instance: 129...
	 start solving instance: 96...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 47...
	 start solving instance: 36...
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 24...
	 start solving instance: 75...
	 start solving instance: 5...
	 start solving instance: 132...
	 start solving instance: 127...
	 start solving instance: 93...
	 start solving instance: 42...
	 start solving instance: 40...
	 start solving instance: 48...
	 start solving instance: 28...
	 start solving instance: 112...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.737716439249584e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23436187207698822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.737716439249584e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.737716439249584e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23436187207698822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.737716439249584e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.737716439249584e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23436187207698822
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.737716439249584e+19 - Differentiable computation graph = True!
PPO iteration: 870/1000:
	 start solving instance: 135...
	 start solving instance: 28...
	 start solving instance: 132...
	 start solving instance: 127...
	 start solving instance: 48...
	 start solving instance: 40...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 75...
	 start solving instance: 3...
	 start solving instance: 24...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 5...
	 start solving instance: 7...
	 start solving instance: 129...
	 start solving instance: 93...
	 start solving instance: 47...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5480642294414783e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22536683082580566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5480643174024086e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5480642294414783e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22536683082580566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5480643174024086e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5480642294414783e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22536683082580566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5480643174024086e+19 - Differentiable computation graph = True!
PPO iteration: 871/1000:
	 New training batch of size 20...
	 start solving instance: 93...
	 start solving instance: 104...
	 start solving instance: 31...
	 start solving instance: 142...
	 start solving instance: 33...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 92...
	 start solving instance: 53...
	 start solving instance: 129...
	 start solving instance: 68...
	 start solving instance: 65...
	 start solving instance: 150...
	 start solving instance: 120...
	 start solving instance: 17...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 121...
	 start solving instance: 133...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8134022457373124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23742441833019257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.813402421659173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8134022457373124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23742441833019257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.813402421659173e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8134022457373124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23742441833019257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.813402421659173e+19 - Differentiable computation graph = True!
PPO iteration: 872/1000:
	 start solving instance: 33...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 104...
	 start solving instance: 53...
	 start solving instance: 133...
	 start solving instance: 61...
	 start solving instance: 92...
	 start solving instance: 129...
	 start solving instance: 120...
	 start solving instance: 142...
	 start solving instance: 150...
	 start solving instance: 121...
	 start solving instance: 31...
	 start solving instance: 40...
	 start solving instance: 68...
	 start solving instance: 65...
	 start solving instance: 93...
	 start solving instance: 17...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.675104793586345e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22857332229614258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.675104969508205e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.675104793586345e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22857332229614258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.675104969508205e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.675104793586345e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22857332229614258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.675104969508205e+19 - Differentiable computation graph = True!
PPO iteration: 873/1000:
	 start solving instance: 128...
	 start solving instance: 75...
	 start solving instance: 61...
	 start solving instance: 68...
	 start solving instance: 121...
	 start solving instance: 142...
	 start solving instance: 92...
	 start solving instance: 17...
	 start solving instance: 53...
	 start solving instance: 40...
	 start solving instance: 104...
	 start solving instance: 133...
	 start solving instance: 129...
	 start solving instance: 65...
	 start solving instance: 120...
	 start solving instance: 93...
	 start solving instance: 102...
	 start solving instance: 150...
	 start solving instance: 31...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7145313454179274e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22468619048595428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714531257456997e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7145313454179274e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22468619048595428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714531257456997e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7145313454179274e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22468619048595428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714531257456997e+19 - Differentiable computation graph = True!
PPO iteration: 874/1000:
	 start solving instance: 104...
	 start solving instance: 133...
	 start solving instance: 17...
	 start solving instance: 40...
	 start solving instance: 129...
	 start solving instance: 93...
	 start solving instance: 120...
	 start solving instance: 121...
	 start solving instance: 128...
	 start solving instance: 75...
	 start solving instance: 33...
	 start solving instance: 53...
	 start solving instance: 68...
	 start solving instance: 92...
	 start solving instance: 102...
	 start solving instance: 150...
	 start solving instance: 142...
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.78147735387879e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2278081476688385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.78147744183972e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.78147735387879e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2278081476688385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.78147744183972e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.78147735387879e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2278081476688385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.78147744183972e+19 - Differentiable computation graph = True!
PPO iteration: 875/1000:
	 start solving instance: 93...
	 start solving instance: 92...
	 start solving instance: 31...
	 start solving instance: 33...
	 start solving instance: 129...
	 start solving instance: 133...
	 start solving instance: 68...
	 start solving instance: 53...
	 start solving instance: 128...
	 start solving instance: 104...
	 start solving instance: 142...
	 start solving instance: 65...
	 start solving instance: 120...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 17...
	 start solving instance: 40...
	 start solving instance: 61...
	 start solving instance: 121...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.793662053776873e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24346418678760529
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.793662229698734e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.793662053776873e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24346418678760529
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.793662229698734e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.793662053776873e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24346418678760529
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.793662229698734e+19 - Differentiable computation graph = True!
PPO iteration: 876/1000:
	 start solving instance: 104...
	 start solving instance: 129...
	 start solving instance: 121...
	 start solving instance: 142...
	 start solving instance: 53...
	 start solving instance: 102...
	 start solving instance: 120...
	 start solving instance: 68...
	 start solving instance: 150...
	 start solving instance: 17...
	 start solving instance: 65...
	 start solving instance: 40...
	 start solving instance: 75...
	 start solving instance: 93...
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 128...
	 start solving instance: 92...
	 start solving instance: 33...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.96712698951807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24898819625377655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.96712690155714e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.96712698951807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24898819625377655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.96712690155714e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.96712698951807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24898819625377655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.96712690155714e+19 - Differentiable computation graph = True!
PPO iteration: 877/1000:
	 start solving instance: 68...
	 start solving instance: 65...
	 start solving instance: 17...
	 start solving instance: 128...
	 start solving instance: 53...
	 start solving instance: 93...
	 start solving instance: 150...
	 start solving instance: 142...
	 start solving instance: 92...
	 start solving instance: 40...
	 start solving instance: 33...
	 start solving instance: 121...
	 start solving instance: 31...
	 start solving instance: 133...
	 start solving instance: 120...
	 start solving instance: 104...
	 start solving instance: 129...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.58438118646785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23588190972805023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.58438118646785e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.58438118646785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23588190972805023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.58438118646785e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.58438118646785e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23588190972805023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.58438118646785e+19 - Differentiable computation graph = True!
PPO iteration: 878/1000:
	 start solving instance: 120...
	 start solving instance: 142...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 65...
	 start solving instance: 150...
	 start solving instance: 31...
	 start solving instance: 129...
	 start solving instance: 68...
	 start solving instance: 33...
	 start solving instance: 121...
	 start solving instance: 133...
	 start solving instance: 92...
	 start solving instance: 17...
	 start solving instance: 53...
	 start solving instance: 93...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 104...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6555130796761206e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23565764725208282
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.65551299171519e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6555130796761206e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23565764725208282
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.65551299171519e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6555130796761206e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23565764725208282
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.65551299171519e+19 - Differentiable computation graph = True!
PPO iteration: 879/1000:
	 start solving instance: 150...
	 start solving instance: 102...
	 start solving instance: 133...
	 start solving instance: 129...
	 start solving instance: 121...
	 start solving instance: 142...
	 start solving instance: 75...
	 start solving instance: 33...
	 start solving instance: 31...
	 start solving instance: 68...
	 start solving instance: 93...
	 start solving instance: 104...
	 start solving instance: 65...
	 start solving instance: 61...
	 start solving instance: 53...
	 start solving instance: 128...
	 start solving instance: 40...
	 start solving instance: 92...
	 start solving instance: 17...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8683584757214636e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23606574535369873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.868358651643324e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8683584757214636e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23606574535369873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.868358651643324e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8683584757214636e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23606574535369873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.868358651643324e+19 - Differentiable computation graph = True!
PPO iteration: 880/1000:
	 start solving instance: 129...
	 start solving instance: 133...
	 start solving instance: 75...
	 start solving instance: 68...
	 start solving instance: 31...
	 start solving instance: 17...
	 start solving instance: 121...
	 start solving instance: 40...
	 start solving instance: 150...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 61...
	 start solving instance: 33...
	 start solving instance: 128...
	 start solving instance: 65...
	 start solving instance: 93...
	 start solving instance: 53...
	 start solving instance: 92...
	 start solving instance: 102...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.63524547397807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22486160695552826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.63524547397807e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.63524547397807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22486160695552826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.63524547397807e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.63524547397807e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22486160695552826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.63524547397807e+19 - Differentiable computation graph = True!
PPO iteration: 881/1000:
	 New training batch of size 20...
	 start solving instance: 94...
	 start solving instance: 22...
	 start solving instance: 130...
	 start solving instance: 28...
	 start solving instance: 48...
	 start solving instance: 88...
	 start solving instance: 91...
	 start solving instance: 112...
	 start solving instance: 47...
	 start solving instance: 123...
	 start solving instance: 75...
	 start solving instance: 53...
	 start solving instance: 67...
	 start solving instance: 145...
	 start solving instance: 40...
	 start solving instance: 143...
	 start solving instance: 104...
	 start solving instance: 78...
	 start solving instance: 116...
	 start solving instance: 43...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.110503989426625e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22428074479103088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.110503989426625e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.110503989426625e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22428074479103088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.110503989426625e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.110503989426625e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22428074479103088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.110503989426625e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.516916208518677e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2069697380065918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45169164724014678016.0000
PPO iteration: 882/1000:
	 start solving instance: 53...
	 start solving instance: 47...
	 start solving instance: 75...
	 start solving instance: 94...
	 start solving instance: 28...
	 start solving instance: 67...
	 start solving instance: 78...
	 start solving instance: 88...
	 start solving instance: 22...
	 start solving instance: 91...
	 start solving instance: 116...
	 start solving instance: 43...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 112...
	 start solving instance: 123...
	 start solving instance: 48...
	 start solving instance: 40...
	 start solving instance: 143...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.209421684960888e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22073021531105042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209421772921818e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.209421684960888e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22073021531105042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209421772921818e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.209421684960888e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22073021531105042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209421772921818e+19 - Differentiable computation graph = True!
PPO iteration: 883/1000:
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 53...
	 start solving instance: 67...
	 start solving instance: 123...
	 start solving instance: 47...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 94...
	 start solving instance: 143...
	 start solving instance: 40...
	 start solving instance: 112...
	 start solving instance: 75...
	 start solving instance: 43...
	 start solving instance: 145...
	 start solving instance: 104...
	 start solving instance: 88...
	 start solving instance: 78...
	 start solving instance: 22...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2806176137263605e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20787863433361053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.280617789648221e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2806176137263605e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20787863433361053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.280617789648221e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2806176137263605e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20787863433361053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.280617789648221e+19 - Differentiable computation graph = True!
PPO iteration: 884/1000:
	 start solving instance: 116...
	 start solving instance: 104...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 123...
	 start solving instance: 47...
	 start solving instance: 43...
	 start solving instance: 78...
	 start solving instance: 88...
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 112...
	 start solving instance: 53...
	 start solving instance: 94...
	 start solving instance: 91...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 40...
	 start solving instance: 75...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3570736061191134e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21462230384349823
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.357073870001904e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3570736061191134e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21462230384349823
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.357073870001904e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3570736061191134e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21462230384349823
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.357073870001904e+19 - Differentiable computation graph = True!
PPO iteration: 885/1000:
	 start solving instance: 116...
	 start solving instance: 112...
	 start solving instance: 104...
	 start solving instance: 40...
	 start solving instance: 123...
	 start solving instance: 94...
	 start solving instance: 67...
	 start solving instance: 78...
	 start solving instance: 22...
	 start solving instance: 145...
	 start solving instance: 88...
	 start solving instance: 28...
	 start solving instance: 48...
	 start solving instance: 130...
	 start solving instance: 47...
	 start solving instance: 43...
	 start solving instance: 53...
	 start solving instance: 143...
	 start solving instance: 75...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2118209072936255e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2167094200849533
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2118209072936255e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2118209072936255e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2167094200849533
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2118209072936255e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2118209072936255e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2167094200849533
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2118209072936255e+19 - Differentiable computation graph = True!
PPO iteration: 886/1000:
	 start solving instance: 143...
	 start solving instance: 22...
	 start solving instance: 116...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 94...
	 start solving instance: 104...
	 start solving instance: 48...
	 start solving instance: 75...
	 start solving instance: 123...
	 start solving instance: 88...
	 start solving instance: 78...
	 start solving instance: 28...
	 start solving instance: 130...
	 start solving instance: 43...
	 start solving instance: 91...
	 start solving instance: 53...
	 start solving instance: 47...
	 start solving instance: 40...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.320327047909537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2254527062177658
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.320327311792328e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.320327047909537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2254527062177658
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.320327311792328e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.320327047909537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2254527062177658
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.320327311792328e+19 - Differentiable computation graph = True!
PPO iteration: 887/1000:
	 start solving instance: 28...
	 start solving instance: 40...
	 start solving instance: 91...
	 start solving instance: 43...
	 start solving instance: 78...
	 start solving instance: 88...
	 start solving instance: 104...
	 start solving instance: 75...
	 start solving instance: 22...
	 start solving instance: 53...
	 start solving instance: 47...
	 start solving instance: 116...
	 start solving instance: 94...
	 start solving instance: 123...
	 start solving instance: 67...
	 start solving instance: 145...
	 start solving instance: 130...
	 start solving instance: 143...
	 start solving instance: 48...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.075426577828943e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22313790023326874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.075426489868013e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.075426577828943e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22313790023326874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.075426489868013e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.075426577828943e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22313790023326874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.075426489868013e+19 - Differentiable computation graph = True!
PPO iteration: 888/1000:
	 start solving instance: 53...
	 start solving instance: 78...
	 start solving instance: 67...
	 start solving instance: 112...
	 start solving instance: 40...
	 start solving instance: 47...
	 start solving instance: 48...
	 start solving instance: 22...
	 start solving instance: 116...
	 start solving instance: 145...
	 start solving instance: 130...
	 start solving instance: 104...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 43...
	 start solving instance: 75...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 91...
	 start solving instance: 123...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.336486878166217e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21798749268054962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.336487054088077e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.336486878166217e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21798749268054962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.336487054088077e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.336486878166217e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21798749268054962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.336487054088077e+19 - Differentiable computation graph = True!
PPO iteration: 889/1000:
	 start solving instance: 123...
	 start solving instance: 67...
	 start solving instance: 75...
	 start solving instance: 145...
	 start solving instance: 91...
	 start solving instance: 112...
	 start solving instance: 78...
	 start solving instance: 40...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 88...
	 start solving instance: 53...
	 start solving instance: 116...
	 start solving instance: 22...
	 start solving instance: 43...
	 start solving instance: 48...
	 start solving instance: 47...
	 start solving instance: 94...
	 start solving instance: 130...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1105025820517414e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2106049805879593
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.110502670012672e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1105025820517414e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2106049805879593
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.110502670012672e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1105025820517414e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2106049805879593
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.110502670012672e+19 - Differentiable computation graph = True!
PPO iteration: 890/1000:
	 start solving instance: 40...
	 start solving instance: 94...
	 start solving instance: 123...
	 start solving instance: 43...
	 start solving instance: 47...
	 start solving instance: 53...
	 start solving instance: 116...
	 start solving instance: 78...
	 start solving instance: 28...
	 start solving instance: 112...
	 start solving instance: 104...
	 start solving instance: 67...
	 start solving instance: 143...
	 start solving instance: 130...
	 start solving instance: 88...
	 start solving instance: 22...
	 start solving instance: 75...
	 start solving instance: 145...
	 start solving instance: 91...
	 start solving instance: 48...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.157635566901941e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21422886848449707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.157635654862871e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.157635566901941e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21422886848449707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.157635654862871e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.157635566901941e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21422886848449707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.157635654862871e+19 - Differentiable computation graph = True!
PPO iteration: 891/1000:
	 New training batch of size 20...
	 start solving instance: 79...
	 start solving instance: 16...
	 start solving instance: 66...
	 start solving instance: 65...
	 start solving instance: 120...
	 start solving instance: 128...
	 start solving instance: 20...
	 start solving instance: 52...
	 start solving instance: 110...
	 start solving instance: 115...
	 start solving instance: 61...
	 start solving instance: 35...
	 start solving instance: 114...
	 start solving instance: 106...
	 start solving instance: 84...
	 start solving instance: 68...
	 start solving instance: 104...
	 start solving instance: 101...
	 start solving instance: 118...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.604106600992012e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22620411217212677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.604106864874802e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.604106600992012e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22620411217212677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.604106864874802e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.604106600992012e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22620411217212677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.604106864874802e+19 - Differentiable computation graph = True!
PPO iteration: 892/1000:
	 start solving instance: 65...
	 start solving instance: 106...
	 start solving instance: 120...
	 start solving instance: 110...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 79...
	 start solving instance: 128...
	 start solving instance: 35...
	 start solving instance: 118...
	 start solving instance: 66...
	 start solving instance: 52...
	 start solving instance: 104...
	 start solving instance: 114...
	 start solving instance: 84...
	 start solving instance: 115...
	 start solving instance: 101...
	 start solving instance: 61...
	 start solving instance: 20...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7116518564061774e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.223350390791893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711651856406177e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7116518564061774e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.223350390791893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711651856406177e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7116518564061774e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.223350390791893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711651856406177e+19 - Differentiable computation graph = True!
PPO iteration: 893/1000:
	 start solving instance: 65...
	 start solving instance: 104...
	 start solving instance: 106...
	 start solving instance: 101...
	 start solving instance: 115...
	 start solving instance: 20...
	 start solving instance: 114...
	 start solving instance: 66...
	 start solving instance: 61...
	 start solving instance: 16...
	 start solving instance: 110...
	 start solving instance: 128...
	 start solving instance: 118...
	 start solving instance: 84...
	 start solving instance: 52...
	 start solving instance: 35...
	 start solving instance: 120...
	 start solving instance: 75...
	 start solving instance: 79...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.432195055278537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23600366711616516
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.432195143239467e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.432195055278537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23600366711616516
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.432195143239467e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.432195055278537e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23600366711616516
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.432195143239467e+19 - Differentiable computation graph = True!
PPO iteration: 894/1000:
	 start solving instance: 114...
	 start solving instance: 118...
	 start solving instance: 68...
	 start solving instance: 61...
	 start solving instance: 104...
	 start solving instance: 35...
	 start solving instance: 106...
	 start solving instance: 84...
	 start solving instance: 16...
	 start solving instance: 52...
	 start solving instance: 101...
	 start solving instance: 66...
	 start solving instance: 115...
	 start solving instance: 75...
	 start solving instance: 128...
	 start solving instance: 65...
	 start solving instance: 20...
	 start solving instance: 120...
	 start solving instance: 110...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.392781873508348e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23210124671459198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3927820494302085e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.392781873508348e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23210124671459198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3927820494302085e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.392781873508348e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23210124671459198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3927820494302085e+19 - Differentiable computation graph = True!
PPO iteration: 895/1000:
	 start solving instance: 115...
	 start solving instance: 20...
	 start solving instance: 75...
	 start solving instance: 118...
	 start solving instance: 106...
	 start solving instance: 120...
	 start solving instance: 68...
	 start solving instance: 128...
	 start solving instance: 110...
	 start solving instance: 66...
	 start solving instance: 61...
	 start solving instance: 52...
	 start solving instance: 114...
	 start solving instance: 79...
	 start solving instance: 65...
	 start solving instance: 16...
	 start solving instance: 104...
	 start solving instance: 35...
	 start solving instance: 84...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0291169273264996e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23250983655452728
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0291169273265e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0291169273264996e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23250983655452728
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0291169273265e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0291169273264996e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23250983655452728
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0291169273265e+19 - Differentiable computation graph = True!
PPO iteration: 896/1000:
	 start solving instance: 66...
	 start solving instance: 104...
	 start solving instance: 68...
	 start solving instance: 61...
	 start solving instance: 115...
	 start solving instance: 75...
	 start solving instance: 118...
	 start solving instance: 110...
	 start solving instance: 120...
	 start solving instance: 16...
	 start solving instance: 106...
	 start solving instance: 65...
	 start solving instance: 20...
	 start solving instance: 101...
	 start solving instance: 128...
	 start solving instance: 79...
	 start solving instance: 84...
	 start solving instance: 35...
	 start solving instance: 114...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8192523512845225e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23824428021907806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.819252263323592e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8192523512845225e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23824428021907806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.819252263323592e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8192523512845225e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23824428021907806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.819252263323592e+19 - Differentiable computation graph = True!
PPO iteration: 897/1000:
	 start solving instance: 106...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 65...
	 start solving instance: 66...
	 start solving instance: 52...
	 start solving instance: 20...
	 start solving instance: 35...
	 start solving instance: 75...
	 start solving instance: 118...
	 start solving instance: 114...
	 start solving instance: 84...
	 start solving instance: 101...
	 start solving instance: 115...
	 start solving instance: 120...
	 start solving instance: 79...
	 start solving instance: 16...
	 start solving instance: 128...
	 start solving instance: 104...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.527471168301606e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24071691930294037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.527471344223466e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.527471168301606e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24071691930294037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.527471344223466e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.527471168301606e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24071691930294037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.527471344223466e+19 - Differentiable computation graph = True!
PPO iteration: 898/1000:
	 start solving instance: 79...
	 start solving instance: 65...
	 start solving instance: 35...
	 start solving instance: 120...
	 start solving instance: 106...
	 start solving instance: 115...
	 start solving instance: 66...
	 start solving instance: 118...
	 start solving instance: 16...
	 start solving instance: 104...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 84...
	 start solving instance: 114...
	 start solving instance: 20...
	 start solving instance: 61...
	 start solving instance: 75...
	 start solving instance: 101...
	 start solving instance: 52...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8424177418678095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22633235156536102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.842417653906879e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8424177418678095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22633235156536102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.842417653906879e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8424177418678095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22633235156536102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.842417653906879e+19 - Differentiable computation graph = True!
PPO iteration: 899/1000:
	 start solving instance: 84...
	 start solving instance: 128...
	 start solving instance: 106...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 65...
	 start solving instance: 101...
	 start solving instance: 61...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 20...
	 start solving instance: 75...
	 start solving instance: 16...
	 start solving instance: 115...
	 start solving instance: 104...
	 start solving instance: 118...
	 start solving instance: 120...
	 start solving instance: 114...
	 start solving instance: 35...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7349080226694536e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24349188804626465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.734908286552244e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7349080226694536e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24349188804626465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.734908286552244e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7349080226694536e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.24349188804626465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.734908286552244e+19 - Differentiable computation graph = True!
PPO iteration: 900/1000:
	 start solving instance: 61...
	 start solving instance: 115...
	 start solving instance: 52...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 68...
	 start solving instance: 106...
	 start solving instance: 66...
	 start solving instance: 114...
	 start solving instance: 128...
	 start solving instance: 84...
	 start solving instance: 101...
	 start solving instance: 79...
	 start solving instance: 104...
	 start solving instance: 20...
	 start solving instance: 75...
	 start solving instance: 120...
	 start solving instance: 35...
	 start solving instance: 110...
	 start solving instance: 16...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.660602850942491e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22284846007823944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.660602850942491e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.660602850942491e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22284846007823944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.660602850942491e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.660602850942491e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22284846007823944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.660602850942491e+19 - Differentiable computation graph = True!
PPO iteration: 901/1000:
	 New training batch of size 20...
	 start solving instance: 7...
	 start solving instance: 1...
	 start solving instance: 3...
	 start solving instance: 65...
	 start solving instance: 106...
	 start solving instance: 4...
	 start solving instance: 66...
	 start solving instance: 126...
	 start solving instance: 74...
	 start solving instance: 17...
	 start solving instance: 47...
	 start solving instance: 14...
	 start solving instance: 145...
	 start solving instance: 134...
	 start solving instance: 23...
	 start solving instance: 94...
	 start solving instance: 10...
	 start solving instance: 113...
	 start solving instance: 35...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.792806369847673e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19757063686847687
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.792806369847673e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.792806369847673e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19757063686847687
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.792806369847673e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.792806369847673e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19757063686847687
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.792806369847673e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.3775920763901575e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20856638252735138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43775920763901575168.0000
PPO iteration: 902/1000:
	 start solving instance: 74...
	 start solving instance: 126...
	 start solving instance: 35...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 113...
	 start solving instance: 66...
	 start solving instance: 23...
	 start solving instance: 145...
	 start solving instance: 4...
	 start solving instance: 14...
	 start solving instance: 7...
	 start solving instance: 3...
	 start solving instance: 106...
	 start solving instance: 94...
	 start solving instance: 47...
	 start solving instance: 17...
	 start solving instance: 84...
	 start solving instance: 10...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5765720150827336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21306490898132324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5765720150827336e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5765720150827336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21306490898132324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5765720150827336e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5765720150827336e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21306490898132324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5765720150827336e+19 - Differentiable computation graph = True!
PPO iteration: 903/1000:
	 start solving instance: 3...
	 start solving instance: 23...
	 start solving instance: 94...
	 start solving instance: 126...
	 start solving instance: 145...
	 start solving instance: 10...
	 start solving instance: 14...
	 start solving instance: 106...
	 start solving instance: 7...
	 start solving instance: 84...
	 start solving instance: 17...
	 start solving instance: 35...
	 start solving instance: 47...
	 start solving instance: 66...
	 start solving instance: 1...
	 start solving instance: 65...
	 start solving instance: 74...
	 start solving instance: 113...
	 start solving instance: 134...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.39193111539124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20800462365150452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.39193102743031e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.39193111539124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20800462365150452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.39193102743031e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.39193111539124e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20800462365150452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.39193102743031e+19 - Differentiable computation graph = True!
PPO iteration: 904/1000:
	 start solving instance: 113...
	 start solving instance: 3...
	 start solving instance: 35...
	 start solving instance: 4...
	 start solving instance: 65...
	 start solving instance: 23...
	 start solving instance: 1...
	 start solving instance: 66...
	 start solving instance: 47...
	 start solving instance: 17...
	 start solving instance: 94...
	 start solving instance: 106...
	 start solving instance: 126...
	 start solving instance: 14...
	 start solving instance: 7...
	 start solving instance: 134...
	 start solving instance: 10...
	 start solving instance: 145...
	 start solving instance: 74...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.637762212113584e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21214579045772552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.637762475996375e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.637762212113584e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21214579045772552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.637762475996375e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.637762212113584e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21214579045772552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.637762475996375e+19 - Differentiable computation graph = True!
PPO iteration: 905/1000:
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 17...
	 start solving instance: 4...
	 start solving instance: 94...
	 start solving instance: 7...
	 start solving instance: 74...
	 start solving instance: 84...
	 start solving instance: 66...
	 start solving instance: 23...
	 start solving instance: 106...
	 start solving instance: 145...
	 start solving instance: 113...
	 start solving instance: 65...
	 start solving instance: 35...
	 start solving instance: 14...
	 start solving instance: 1...
	 start solving instance: 3...
	 start solving instance: 10...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.635240900009698e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21592865884304047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.635241075931559e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.635240900009698e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21592865884304047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.635241075931559e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.635240900009698e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21592865884304047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.635241075931559e+19 - Differentiable computation graph = True!
PPO iteration: 906/1000:
	 start solving instance: 106...
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 47...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 145...
	 start solving instance: 94...
	 start solving instance: 66...
	 start solving instance: 10...
	 start solving instance: 74...
	 start solving instance: 14...
	 start solving instance: 17...
	 start solving instance: 65...
	 start solving instance: 3...
	 start solving instance: 84...
	 start solving instance: 4...
	 start solving instance: 23...
	 start solving instance: 1...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.334352945999029e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2057923823595047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.33435312192089e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.334352945999029e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2057923823595047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.33435312192089e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.334352945999029e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2057923823595047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.33435312192089e+19 - Differentiable computation graph = True!
PPO iteration: 907/1000:
	 start solving instance: 1...
	 start solving instance: 94...
	 start solving instance: 17...
	 start solving instance: 126...
	 start solving instance: 84...
	 start solving instance: 35...
	 start solving instance: 66...
	 start solving instance: 23...
	 start solving instance: 4...
	 start solving instance: 106...
	 start solving instance: 3...
	 start solving instance: 10...
	 start solving instance: 7...
	 start solving instance: 47...
	 start solving instance: 134...
	 start solving instance: 113...
	 start solving instance: 65...
	 start solving instance: 145...
	 start solving instance: 74...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.700673980470741e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20630665123462677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.700673892509811e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.700673980470741e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20630665123462677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.700673892509811e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.700673980470741e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20630665123462677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.700673892509811e+19 - Differentiable computation graph = True!
PPO iteration: 908/1000:
	 start solving instance: 94...
	 start solving instance: 113...
	 start solving instance: 17...
	 start solving instance: 134...
	 start solving instance: 35...
	 start solving instance: 126...
	 start solving instance: 106...
	 start solving instance: 1...
	 start solving instance: 7...
	 start solving instance: 10...
	 start solving instance: 4...
	 start solving instance: 66...
	 start solving instance: 47...
	 start solving instance: 74...
	 start solving instance: 3...
	 start solving instance: 65...
	 start solving instance: 14...
	 start solving instance: 84...
	 start solving instance: 23...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.340811037495934e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2104996293783188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.340811213417795e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.340811037495934e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2104996293783188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.340811213417795e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.340811037495934e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2104996293783188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.340811213417795e+19 - Differentiable computation graph = True!
PPO iteration: 909/1000:
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 47...
	 start solving instance: 74...
	 start solving instance: 65...
	 start solving instance: 14...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 23...
	 start solving instance: 145...
	 start solving instance: 106...
	 start solving instance: 3...
	 start solving instance: 66...
	 start solving instance: 113...
	 start solving instance: 94...
	 start solving instance: 10...
	 start solving instance: 17...
	 start solving instance: 1...
	 start solving instance: 4...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6818320455297296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20673298835754395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.68183222145159e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6818320455297296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20673298835754395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.68183222145159e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6818320455297296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20673298835754395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.68183222145159e+19 - Differentiable computation graph = True!
PPO iteration: 910/1000:
	 start solving instance: 47...
	 start solving instance: 74...
	 start solving instance: 3...
	 start solving instance: 4...
	 start solving instance: 10...
	 start solving instance: 134...
	 start solving instance: 113...
	 start solving instance: 145...
	 start solving instance: 126...
	 start solving instance: 17...
	 start solving instance: 66...
	 start solving instance: 14...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 35...
	 start solving instance: 106...
	 start solving instance: 7...
	 start solving instance: 23...
	 start solving instance: 84...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6051846501528135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21133168041706085
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.605184826074674e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6051846501528135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21133168041706085
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.605184826074674e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6051846501528135e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21133168041706085
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.605184826074674e+19 - Differentiable computation graph = True!
PPO iteration: 911/1000:
	 New training batch of size 20...
	 start solving instance: 144...
	 start solving instance: 23...
	 start solving instance: 133...
	 start solving instance: 143...
	 start solving instance: 63...
	 start solving instance: 98...
	 start solving instance: 124...
	 start solving instance: 76...
	 start solving instance: 137...
	 start solving instance: 107...
	 start solving instance: 52...
	 start solving instance: 86...
	 start solving instance: 26...
	 start solving instance: 35...
	 start solving instance: 95...
	 start solving instance: 5...
	 start solving instance: 59...
	 start solving instance: 132...
	 start solving instance: 109...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.695197884798835e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22702327370643616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.695197884798835e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.695197884798835e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22702327370643616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.695197884798835e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.695197884798835e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22702327370643616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.695197884798835e+19 - Differentiable computation graph = True!
PPO iteration: 912/1000:
	 start solving instance: 144...
	 start solving instance: 59...
	 start solving instance: 63...
	 start solving instance: 13...
	 start solving instance: 124...
	 start solving instance: 86...
	 start solving instance: 35...
	 start solving instance: 109...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 143...
	 start solving instance: 133...
	 start solving instance: 5...
	 start solving instance: 137...
	 start solving instance: 132...
	 start solving instance: 95...
	 start solving instance: 23...
	 start solving instance: 52...
	 start solving instance: 107...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.853965252787364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22267018258571625
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853965164826434e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.853965252787364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22267018258571625
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853965164826434e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.853965252787364e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22267018258571625
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.853965164826434e+19 - Differentiable computation graph = True!
PPO iteration: 913/1000:
	 start solving instance: 76...
	 start solving instance: 95...
	 start solving instance: 86...
	 start solving instance: 124...
	 start solving instance: 137...
	 start solving instance: 13...
	 start solving instance: 26...
	 start solving instance: 107...
	 start solving instance: 109...
	 start solving instance: 133...
	 start solving instance: 63...
	 start solving instance: 23...
	 start solving instance: 59...
	 start solving instance: 5...
	 start solving instance: 132...
	 start solving instance: 144...
	 start solving instance: 143...
	 start solving instance: 52...
	 start solving instance: 35...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.620321670712871e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20884501934051514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.620321582751941e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.620321670712871e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20884501934051514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.620321582751941e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.620321670712871e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20884501934051514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.620321582751941e+19 - Differentiable computation graph = True!
PPO iteration: 914/1000:
	 start solving instance: 109...
	 start solving instance: 143...
	 start solving instance: 132...
	 start solving instance: 86...
	 start solving instance: 35...
	 start solving instance: 137...
	 start solving instance: 107...
	 start solving instance: 144...
	 start solving instance: 59...
	 start solving instance: 76...
	 start solving instance: 13...
	 start solving instance: 124...
	 start solving instance: 5...
	 start solving instance: 95...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 52...
	 start solving instance: 133...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.653937523493983e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23076139390468597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.653937611454913e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.653937523493983e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23076139390468597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.653937611454913e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.653937523493983e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23076139390468597
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.653937611454913e+19 - Differentiable computation graph = True!
PPO iteration: 915/1000:
	 start solving instance: 5...
	 start solving instance: 26...
	 start solving instance: 137...
	 start solving instance: 133...
	 start solving instance: 63...
	 start solving instance: 98...
	 start solving instance: 86...
	 start solving instance: 52...
	 start solving instance: 76...
	 start solving instance: 144...
	 start solving instance: 59...
	 start solving instance: 124...
	 start solving instance: 107...
	 start solving instance: 95...
	 start solving instance: 132...
	 start solving instance: 23...
	 start solving instance: 143...
	 start solving instance: 109...
	 start solving instance: 13...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.640631145813707e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22240903973579407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.640631321735568e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.640631145813707e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22240903973579407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.640631321735568e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.640631145813707e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22240903973579407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.640631321735568e+19 - Differentiable computation graph = True!
PPO iteration: 916/1000:
	 start solving instance: 76...
	 start solving instance: 52...
	 start solving instance: 59...
	 start solving instance: 132...
	 start solving instance: 5...
	 start solving instance: 143...
	 start solving instance: 26...
	 start solving instance: 133...
	 start solving instance: 95...
	 start solving instance: 137...
	 start solving instance: 23...
	 start solving instance: 13...
	 start solving instance: 35...
	 start solving instance: 124...
	 start solving instance: 63...
	 start solving instance: 86...
	 start solving instance: 98...
	 start solving instance: 107...
	 start solving instance: 109...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.707610227584333e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21825098991394043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.707610491467124e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.707610227584333e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21825098991394043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.707610491467124e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.707610227584333e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21825098991394043
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.707610491467124e+19 - Differentiable computation graph = True!
PPO iteration: 917/1000:
	 start solving instance: 13...
	 start solving instance: 124...
	 start solving instance: 59...
	 start solving instance: 137...
	 start solving instance: 26...
	 start solving instance: 132...
	 start solving instance: 76...
	 start solving instance: 86...
	 start solving instance: 63...
	 start solving instance: 144...
	 start solving instance: 98...
	 start solving instance: 95...
	 start solving instance: 23...
	 start solving instance: 5...
	 start solving instance: 109...
	 start solving instance: 52...
	 start solving instance: 107...
	 start solving instance: 35...
	 start solving instance: 133...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5503413620030675e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23599444329738617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.550341625885858e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5503413620030675e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23599444329738617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.550341625885858e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5503413620030675e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23599444329738617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.550341625885858e+19 - Differentiable computation graph = True!
PPO iteration: 918/1000:
	 start solving instance: 133...
	 start solving instance: 137...
	 start solving instance: 35...
	 start solving instance: 98...
	 start solving instance: 86...
	 start solving instance: 132...
	 start solving instance: 144...
	 start solving instance: 59...
	 start solving instance: 143...
	 start solving instance: 5...
	 start solving instance: 124...
	 start solving instance: 52...
	 start solving instance: 23...
	 start solving instance: 76...
	 start solving instance: 107...
	 start solving instance: 13...
	 start solving instance: 26...
	 start solving instance: 63...
	 start solving instance: 95...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6563793189169476e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21986284852027893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.656379406877878e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6563793189169476e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21986284852027893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.656379406877878e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6563793189169476e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21986284852027893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.656379406877878e+19 - Differentiable computation graph = True!
PPO iteration: 919/1000:
	 start solving instance: 26...
	 start solving instance: 137...
	 start solving instance: 132...
	 start solving instance: 124...
	 start solving instance: 109...
	 start solving instance: 107...
	 start solving instance: 23...
	 start solving instance: 133...
	 start solving instance: 98...
	 start solving instance: 95...
	 start solving instance: 76...
	 start solving instance: 144...
	 start solving instance: 86...
	 start solving instance: 143...
	 start solving instance: 63...
	 start solving instance: 52...
	 start solving instance: 59...
	 start solving instance: 13...
	 start solving instance: 35...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9708994578934347e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21940313279628754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.970899545854365e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9708994578934347e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21940313279628754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.970899545854365e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9708994578934347e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21940313279628754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.970899545854365e+19 - Differentiable computation graph = True!
PPO iteration: 920/1000:
	 start solving instance: 107...
	 start solving instance: 124...
	 start solving instance: 23...
	 start solving instance: 137...
	 start solving instance: 132...
	 start solving instance: 86...
	 start solving instance: 63...
	 start solving instance: 133...
	 start solving instance: 109...
	 start solving instance: 144...
	 start solving instance: 13...
	 start solving instance: 52...
	 start solving instance: 76...
	 start solving instance: 143...
	 start solving instance: 98...
	 start solving instance: 95...
	 start solving instance: 35...
	 start solving instance: 59...
	 start solving instance: 26...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7647584439496186e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23236680030822754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.764758707832409e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7647584439496186e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23236680030822754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.764758707832409e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7647584439496186e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23236680030822754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.764758707832409e+19 - Differentiable computation graph = True!
PPO iteration: 921/1000:
	 New training batch of size 20...
	 start solving instance: 14...
	 start solving instance: 147...
	 start solving instance: 23...
	 start solving instance: 117...
	 start solving instance: 60...
	 start solving instance: 129...
	 start solving instance: 109...
	 start solving instance: 115...
	 start solving instance: 80...
	 start solving instance: 103...
	 start solving instance: 97...
	 start solving instance: 77...
	 start solving instance: 108...
	 start solving instance: 135...
	 start solving instance: 118...
	 start solving instance: 138...
	 start solving instance: 95...
	 start solving instance: 94...
	 start solving instance: 13...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.515719588023936e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20361526310443878
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.515719763945796e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.515719588023936e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20361526310443878
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.515719763945796e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.515719588023936e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20361526310443878
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.515719763945796e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.4084762145222925e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2120790034532547
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 44084764784050831360.0000
PPO iteration: 922/1000:
	 start solving instance: 115...
	 start solving instance: 135...
	 start solving instance: 129...
	 start solving instance: 77...
	 start solving instance: 117...
	 start solving instance: 13...
	 start solving instance: 113...
	 start solving instance: 109...
	 start solving instance: 108...
	 start solving instance: 80...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 60...
	 start solving instance: 23...
	 start solving instance: 147...
	 start solving instance: 138...
	 start solving instance: 94...
	 start solving instance: 118...
	 start solving instance: 14...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5631917502210716e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20550155639648438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.563191838182002e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5631917502210716e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20550155639648438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.563191838182002e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5631917502210716e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20550155639648438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.563191838182002e+19 - Differentiable computation graph = True!
PPO iteration: 923/1000:
	 start solving instance: 13...
	 start solving instance: 14...
	 start solving instance: 113...
	 start solving instance: 80...
	 start solving instance: 95...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 129...
	 start solving instance: 147...
	 start solving instance: 60...
	 start solving instance: 94...
	 start solving instance: 108...
	 start solving instance: 103...
	 start solving instance: 115...
	 start solving instance: 77...
	 start solving instance: 23...
	 start solving instance: 138...
	 start solving instance: 117...
	 start solving instance: 109...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.438101455821089e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20179620385169983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.43810171970388e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.438101455821089e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20179620385169983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.43810171970388e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.438101455821089e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20179620385169983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.43810171970388e+19 - Differentiable computation graph = True!
PPO iteration: 924/1000:
	 start solving instance: 23...
	 start solving instance: 118...
	 start solving instance: 77...
	 start solving instance: 113...
	 start solving instance: 138...
	 start solving instance: 135...
	 start solving instance: 94...
	 start solving instance: 115...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 14...
	 start solving instance: 108...
	 start solving instance: 129...
	 start solving instance: 80...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 13...
	 start solving instance: 109...
	 start solving instance: 60...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.653444238597297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1974577158689499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.653444150636367e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.653444238597297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1974577158689499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.653444150636367e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.653444238597297e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1974577158689499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.653444150636367e+19 - Differentiable computation graph = True!
PPO iteration: 925/1000:
	 start solving instance: 23...
	 start solving instance: 13...
	 start solving instance: 14...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 115...
	 start solving instance: 97...
	 start solving instance: 108...
	 start solving instance: 118...
	 start solving instance: 109...
	 start solving instance: 103...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 147...
	 start solving instance: 117...
	 start solving instance: 60...
	 start solving instance: 80...
	 start solving instance: 138...
	 start solving instance: 94...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.581914410140702e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19699276983737946
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.581914322179772e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.581914410140702e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19699276983737946
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.581914322179772e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.581914410140702e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19699276983737946
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.581914322179772e+19 - Differentiable computation graph = True!
PPO iteration: 926/1000:
	 start solving instance: 108...
	 start solving instance: 135...
	 start solving instance: 13...
	 start solving instance: 103...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 117...
	 start solving instance: 80...
	 start solving instance: 97...
	 start solving instance: 14...
	 start solving instance: 94...
	 start solving instance: 60...
	 start solving instance: 113...
	 start solving instance: 77...
	 start solving instance: 115...
	 start solving instance: 118...
	 start solving instance: 23...
	 start solving instance: 138...
	 start solving instance: 147...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.568392704103243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19612732529640198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5683929679860335e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.568392704103243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19612732529640198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5683929679860335e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.568392704103243e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19612732529640198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5683929679860335e+19 - Differentiable computation graph = True!
PPO iteration: 927/1000:
	 start solving instance: 113...
	 start solving instance: 108...
	 start solving instance: 147...
	 start solving instance: 94...
	 start solving instance: 135...
	 start solving instance: 80...
	 start solving instance: 60...
	 start solving instance: 117...
	 start solving instance: 138...
	 start solving instance: 115...
	 start solving instance: 14...
	 start solving instance: 95...
	 start solving instance: 23...
	 start solving instance: 97...
	 start solving instance: 129...
	 start solving instance: 109...
	 start solving instance: 103...
	 start solving instance: 13...
	 start solving instance: 118...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.510555577732458e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2002924233675003
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.510555577732458e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.510555577732458e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2002924233675003
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.510555577732458e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.510555577732458e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2002924233675003
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.510555577732458e+19 - Differentiable computation graph = True!
PPO iteration: 928/1000:
	 start solving instance: 115...
	 start solving instance: 103...
	 start solving instance: 97...
	 start solving instance: 13...
	 start solving instance: 14...
	 start solving instance: 77...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 135...
	 start solving instance: 129...
	 start solving instance: 60...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 109...
	 start solving instance: 80...
	 start solving instance: 94...
	 start solving instance: 118...
	 start solving instance: 23...
	 start solving instance: 138...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5227902394389076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2004929631948471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.522790503321698e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5227902394389076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2004929631948471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.522790503321698e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5227902394389076e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2004929631948471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.522790503321698e+19 - Differentiable computation graph = True!
PPO iteration: 929/1000:
	 start solving instance: 80...
	 start solving instance: 94...
	 start solving instance: 115...
	 start solving instance: 108...
	 start solving instance: 147...
	 start solving instance: 113...
	 start solving instance: 97...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 95...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 60...
	 start solving instance: 13...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 109...
	 start solving instance: 138...
	 start solving instance: 23...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.637078227920177e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19676952064037323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.637078139959247e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.637078227920177e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19676952064037323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.637078139959247e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.637078227920177e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19676952064037323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.637078139959247e+19 - Differentiable computation graph = True!
PPO iteration: 930/1000:
	 start solving instance: 113...
	 start solving instance: 108...
	 start solving instance: 117...
	 start solving instance: 147...
	 start solving instance: 115...
	 start solving instance: 95...
	 start solving instance: 138...
	 start solving instance: 77...
	 start solving instance: 14...
	 start solving instance: 135...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 129...
	 start solving instance: 60...
	 start solving instance: 94...
	 start solving instance: 103...
	 start solving instance: 80...
	 start solving instance: 23...
	 start solving instance: 109...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4164753815166884e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1921490877866745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416475645399479e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4164753815166884e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1921490877866745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416475645399479e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4164753815166884e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.1921490877866745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.416475645399479e+19 - Differentiable computation graph = True!
PPO iteration: 931/1000:
	 New training batch of size 20...
	 start solving instance: 46...
	 start solving instance: 22...
	 start solving instance: 54...
	 start solving instance: 47...
	 start solving instance: 142...
	 start solving instance: 78...
	 start solving instance: 114...
	 start solving instance: 143...
	 start solving instance: 102...
	 start solving instance: 52...
	 start solving instance: 55...
	 start solving instance: 129...
	 start solving instance: 124...
	 start solving instance: 2...
	 start solving instance: 97...
	 start solving instance: 12...
	 start solving instance: 65...
	 start solving instance: 92...
	 start solving instance: 121...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.084162153731158e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2103743553161621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.084162329653019e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.084162153731158e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2103743553161621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.084162329653019e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.084162153731158e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2103743553161621
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.084162329653019e+19 - Differentiable computation graph = True!
PPO iteration: 932/1000:
	 start solving instance: 121...
	 start solving instance: 65...
	 start solving instance: 78...
	 start solving instance: 2...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 103...
	 start solving instance: 92...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 46...
	 start solving instance: 47...
	 start solving instance: 124...
	 start solving instance: 97...
	 start solving instance: 102...
	 start solving instance: 143...
	 start solving instance: 142...
	 start solving instance: 52...
	 start solving instance: 12...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2495005550509975e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21748986840248108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249500730972858e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2495005550509975e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21748986840248108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249500730972858e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2495005550509975e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21748986840248108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249500730972858e+19 - Differentiable computation graph = True!
PPO iteration: 933/1000:
	 start solving instance: 114...
	 start solving instance: 22...
	 start solving instance: 92...
	 start solving instance: 46...
	 start solving instance: 102...
	 start solving instance: 65...
	 start solving instance: 142...
	 start solving instance: 97...
	 start solving instance: 124...
	 start solving instance: 2...
	 start solving instance: 55...
	 start solving instance: 121...
	 start solving instance: 78...
	 start solving instance: 54...
	 start solving instance: 47...
	 start solving instance: 12...
	 start solving instance: 52...
	 start solving instance: 143...
	 start solving instance: 129...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.350276337275272e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21503257751464844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.350276249314342e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.350276337275272e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21503257751464844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.350276249314342e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.350276337275272e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21503257751464844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.350276249314342e+19 - Differentiable computation graph = True!
PPO iteration: 934/1000:
	 start solving instance: 52...
	 start solving instance: 78...
	 start solving instance: 2...
	 start solving instance: 22...
	 start solving instance: 121...
	 start solving instance: 12...
	 start solving instance: 92...
	 start solving instance: 124...
	 start solving instance: 143...
	 start solving instance: 47...
	 start solving instance: 54...
	 start solving instance: 55...
	 start solving instance: 142...
	 start solving instance: 129...
	 start solving instance: 65...
	 start solving instance: 103...
	 start solving instance: 114...
	 start solving instance: 97...
	 start solving instance: 102...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.353414783265596e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21041817963123322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3534146953046655e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.353414783265596e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21041817963123322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3534146953046655e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.353414783265596e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21041817963123322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3534146953046655e+19 - Differentiable computation graph = True!
PPO iteration: 935/1000:
	 start solving instance: 103...
	 start solving instance: 46...
	 start solving instance: 54...
	 start solving instance: 55...
	 start solving instance: 97...
	 start solving instance: 12...
	 start solving instance: 47...
	 start solving instance: 52...
	 start solving instance: 121...
	 start solving instance: 143...
	 start solving instance: 78...
	 start solving instance: 65...
	 start solving instance: 2...
	 start solving instance: 102...
	 start solving instance: 142...
	 start solving instance: 114...
	 start solving instance: 124...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.294481311860523e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21289196610450745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.294481311860523e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.294481311860523e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21289196610450745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.294481311860523e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.294481311860523e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21289196610450745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.294481311860523e+19 - Differentiable computation graph = True!
PPO iteration: 936/1000:
	 start solving instance: 142...
	 start solving instance: 2...
	 start solving instance: 22...
	 start solving instance: 121...
	 start solving instance: 12...
	 start solving instance: 102...
	 start solving instance: 46...
	 start solving instance: 78...
	 start solving instance: 54...
	 start solving instance: 92...
	 start solving instance: 103...
	 start solving instance: 114...
	 start solving instance: 55...
	 start solving instance: 124...
	 start solving instance: 97...
	 start solving instance: 129...
	 start solving instance: 52...
	 start solving instance: 143...
	 start solving instance: 47...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.167918199644902e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21411757171154022
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.167918287605832e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.167918199644902e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21411757171154022
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.167918287605832e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.167918199644902e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21411757171154022
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.167918287605832e+19 - Differentiable computation graph = True!
PPO iteration: 937/1000:
	 start solving instance: 114...
	 start solving instance: 12...
	 start solving instance: 22...
	 start solving instance: 55...
	 start solving instance: 92...
	 start solving instance: 65...
	 start solving instance: 47...
	 start solving instance: 103...
	 start solving instance: 46...
	 start solving instance: 143...
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 78...
	 start solving instance: 102...
	 start solving instance: 121...
	 start solving instance: 52...
	 start solving instance: 97...
	 start solving instance: 2...
	 start solving instance: 142...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3787890487286196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21648509800434113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.37878922465048e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3787890487286196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21648509800434113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.37878922465048e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3787890487286196e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21648509800434113
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.37878922465048e+19 - Differentiable computation graph = True!
PPO iteration: 938/1000:
	 start solving instance: 55...
	 start solving instance: 124...
	 start solving instance: 2...
	 start solving instance: 97...
	 start solving instance: 114...
	 start solving instance: 47...
	 start solving instance: 54...
	 start solving instance: 143...
	 start solving instance: 121...
	 start solving instance: 103...
	 start solving instance: 129...
	 start solving instance: 78...
	 start solving instance: 92...
	 start solving instance: 46...
	 start solving instance: 22...
	 start solving instance: 52...
	 start solving instance: 142...
	 start solving instance: 12...
	 start solving instance: 102...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.270298741080148e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20360898971557617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.270298653119218e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.270298741080148e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20360898971557617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.270298653119218e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.270298741080148e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20360898971557617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.270298653119218e+19 - Differentiable computation graph = True!
PPO iteration: 939/1000:
	 start solving instance: 97...
	 start solving instance: 52...
	 start solving instance: 103...
	 start solving instance: 54...
	 start solving instance: 78...
	 start solving instance: 12...
	 start solving instance: 114...
	 start solving instance: 2...
	 start solving instance: 22...
	 start solving instance: 102...
	 start solving instance: 124...
	 start solving instance: 46...
	 start solving instance: 92...
	 start solving instance: 129...
	 start solving instance: 142...
	 start solving instance: 143...
	 start solving instance: 65...
	 start solving instance: 121...
	 start solving instance: 55...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.065843762246829e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21405084431171417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.065844026129619e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.065843762246829e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21405084431171417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.065844026129619e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.065843762246829e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21405084431171417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.065844026129619e+19 - Differentiable computation graph = True!
PPO iteration: 940/1000:
	 start solving instance: 129...
	 start solving instance: 47...
	 start solving instance: 142...
	 start solving instance: 78...
	 start solving instance: 102...
	 start solving instance: 12...
	 start solving instance: 54...
	 start solving instance: 103...
	 start solving instance: 121...
	 start solving instance: 22...
	 start solving instance: 52...
	 start solving instance: 2...
	 start solving instance: 97...
	 start solving instance: 92...
	 start solving instance: 65...
	 start solving instance: 143...
	 start solving instance: 124...
	 start solving instance: 46...
	 start solving instance: 114...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2797981697004116e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21703389286994934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.279798433583202e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2797981697004116e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21703389286994934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.279798433583202e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2797981697004116e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21703389286994934
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.279798433583202e+19 - Differentiable computation graph = True!
PPO iteration: 941/1000:
	 New training batch of size 20...
	 start solving instance: 144...
	 start solving instance: 119...
	 start solving instance: 46...
	 start solving instance: 70...
	 start solving instance: 141...
	 start solving instance: 80...
	 start solving instance: 124...
	 start solving instance: 130...
	 start solving instance: 43...
	 start solving instance: 85...
	 start solving instance: 86...
	 start solving instance: 8...
	 start solving instance: 75...
	 start solving instance: 30...
	 start solving instance: 98...
	 start solving instance: 116...
	 start solving instance: 59...
	 start solving instance: 15...
	 start solving instance: 104...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.088072916729709e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22944144904613495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0880731806125e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.088072916729709e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22944144904613495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0880731806125e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.088072916729709e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22944144904613495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0880731806125e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.063077215069484e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2157938927412033
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 40630772150694838272.0000
PPO iteration: 942/1000:
	 start solving instance: 43...
	 start solving instance: 75...
	 start solving instance: 85...
	 start solving instance: 8...
	 start solving instance: 124...
	 start solving instance: 104...
	 start solving instance: 70...
	 start solving instance: 141...
	 start solving instance: 30...
	 start solving instance: 46...
	 start solving instance: 80...
	 start solving instance: 98...
	 start solving instance: 116...
	 start solving instance: 59...
	 start solving instance: 119...
	 start solving instance: 86...
	 start solving instance: 144...
	 start solving instance: 15...
	 start solving instance: 130...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.147980291554201e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22670936584472656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.147980291554201e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.147980291554201e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22670936584472656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.147980291554201e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.147980291554201e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22670936584472656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.147980291554201e+19 - Differentiable computation graph = True!
PPO iteration: 943/1000:
	 start solving instance: 80...
	 start solving instance: 15...
	 start solving instance: 46...
	 start solving instance: 30...
	 start solving instance: 85...
	 start solving instance: 130...
	 start solving instance: 98...
	 start solving instance: 86...
	 start solving instance: 70...
	 start solving instance: 104...
	 start solving instance: 141...
	 start solving instance: 119...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 75...
	 start solving instance: 43...
	 start solving instance: 67...
	 start solving instance: 8...
	 start solving instance: 144...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.08526098171237e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23134593665599823
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0852610696733e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.08526098171237e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23134593665599823
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0852610696733e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.08526098171237e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23134593665599823
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0852610696733e+19 - Differentiable computation graph = True!
PPO iteration: 944/1000:
	 start solving instance: 43...
	 start solving instance: 67...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 70...
	 start solving instance: 98...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 144...
	 start solving instance: 130...
	 start solving instance: 59...
	 start solving instance: 30...
	 start solving instance: 124...
	 start solving instance: 80...
	 start solving instance: 116...
	 start solving instance: 15...
	 start solving instance: 86...
	 start solving instance: 75...
	 start solving instance: 8...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.161001323976836e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2292473167181015
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.161001587859626e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.161001323976836e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2292473167181015
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.161001587859626e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.161001323976836e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2292473167181015
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.161001587859626e+19 - Differentiable computation graph = True!
PPO iteration: 945/1000:
	 start solving instance: 70...
	 start solving instance: 75...
	 start solving instance: 43...
	 start solving instance: 80...
	 start solving instance: 15...
	 start solving instance: 144...
	 start solving instance: 86...
	 start solving instance: 116...
	 start solving instance: 8...
	 start solving instance: 119...
	 start solving instance: 124...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 104...
	 start solving instance: 141...
	 start solving instance: 130...
	 start solving instance: 59...
	 start solving instance: 46...
	 start solving instance: 67...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.905618022076095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23734961450099945
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.905618022076095e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.905618022076095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23734961450099945
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.905618022076095e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.905618022076095e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.23734961450099945
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.905618022076095e+19 - Differentiable computation graph = True!
PPO iteration: 946/1000:
	 start solving instance: 104...
	 start solving instance: 144...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 141...
	 start solving instance: 98...
	 start solving instance: 70...
	 start solving instance: 43...
	 start solving instance: 80...
	 start solving instance: 124...
	 start solving instance: 8...
	 start solving instance: 119...
	 start solving instance: 86...
	 start solving instance: 30...
	 start solving instance: 130...
	 start solving instance: 67...
	 start solving instance: 75...
	 start solving instance: 116...
	 start solving instance: 59...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8971889020547734e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22253088653087616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.897189165937564e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8971889020547734e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22253088653087616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.897189165937564e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8971889020547734e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22253088653087616
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.897189165937564e+19 - Differentiable computation graph = True!
PPO iteration: 947/1000:
	 start solving instance: 8...
	 start solving instance: 144...
	 start solving instance: 80...
	 start solving instance: 75...
	 start solving instance: 141...
	 start solving instance: 43...
	 start solving instance: 119...
	 start solving instance: 98...
	 start solving instance: 124...
	 start solving instance: 86...
	 start solving instance: 59...
	 start solving instance: 67...
	 start solving instance: 130...
	 start solving instance: 104...
	 start solving instance: 70...
	 start solving instance: 30...
	 start solving instance: 15...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0483511680163014e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22576387226581573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.048351343938162e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0483511680163014e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22576387226581573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.048351343938162e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0483511680163014e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22576387226581573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.048351343938162e+19 - Differentiable computation graph = True!
PPO iteration: 948/1000:
	 start solving instance: 104...
	 start solving instance: 86...
	 start solving instance: 75...
	 start solving instance: 59...
	 start solving instance: 70...
	 start solving instance: 144...
	 start solving instance: 130...
	 start solving instance: 98...
	 start solving instance: 80...
	 start solving instance: 67...
	 start solving instance: 46...
	 start solving instance: 30...
	 start solving instance: 8...
	 start solving instance: 43...
	 start solving instance: 15...
	 start solving instance: 124...
	 start solving instance: 119...
	 start solving instance: 85...
	 start solving instance: 116...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.872934203311616e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22748056054115295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.872934379233477e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.872934203311616e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22748056054115295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.872934379233477e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.872934203311616e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22748056054115295
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.872934379233477e+19 - Differentiable computation graph = True!
PPO iteration: 949/1000:
	 start solving instance: 124...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 59...
	 start solving instance: 86...
	 start solving instance: 15...
	 start solving instance: 75...
	 start solving instance: 43...
	 start solving instance: 85...
	 start solving instance: 104...
	 start solving instance: 30...
	 start solving instance: 46...
	 start solving instance: 8...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 141...
	 start solving instance: 98...
	 start solving instance: 119...
	 start solving instance: 130...
	 start solving instance: 70...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.05739707008034e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21660199761390686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0573972460022006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.05739707008034e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21660199761390686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0573972460022006e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.05739707008034e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21660199761390686
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.0573972460022006e+19 - Differentiable computation graph = True!
PPO iteration: 950/1000:
	 start solving instance: 80...
	 start solving instance: 130...
	 start solving instance: 30...
	 start solving instance: 85...
	 start solving instance: 67...
	 start solving instance: 8...
	 start solving instance: 75...
	 start solving instance: 70...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 15...
	 start solving instance: 116...
	 start solving instance: 43...
	 start solving instance: 124...
	 start solving instance: 46...
	 start solving instance: 86...
	 start solving instance: 59...
	 start solving instance: 141...
	 start solving instance: 144...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.039579352210835e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2290896475315094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.039579440171765e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.039579352210835e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2290896475315094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.039579440171765e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.039579352210835e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2290896475315094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.039579440171765e+19 - Differentiable computation graph = True!
PPO iteration: 951/1000:
	 New training batch of size 20...
	 start solving instance: 114...
	 start solving instance: 52...
	 start solving instance: 67...
	 start solving instance: 59...
	 start solving instance: 18...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 43...
	 start solving instance: 147...
	 start solving instance: 120...
	 start solving instance: 134...
	 start solving instance: 70...
	 start solving instance: 130...
	 start solving instance: 63...
	 start solving instance: 122...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 24...
	 start solving instance: 91...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3573635253451253e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21683767437934875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.357363701266986e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3573635253451253e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21683767437934875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.357363701266986e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3573635253451253e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21683767437934875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.357363701266986e+19 - Differentiable computation graph = True!
PPO iteration: 952/1000:
	 start solving instance: 63...
	 start solving instance: 114...
	 start solving instance: 15...
	 start solving instance: 130...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 103...
	 start solving instance: 24...
	 start solving instance: 67...
	 start solving instance: 52...
	 start solving instance: 43...
	 start solving instance: 70...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 95...
	 start solving instance: 18...
	 start solving instance: 120...
	 start solving instance: 87...
	 start solving instance: 59...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3700056220803636e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21487103402614594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370005885963154e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3700056220803636e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21487103402614594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370005885963154e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3700056220803636e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21487103402614594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370005885963154e+19 - Differentiable computation graph = True!
PPO iteration: 953/1000:
	 start solving instance: 120...
	 start solving instance: 63...
	 start solving instance: 130...
	 start solving instance: 89...
	 start solving instance: 15...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 103...
	 start solving instance: 70...
	 start solving instance: 134...
	 start solving instance: 87...
	 start solving instance: 24...
	 start solving instance: 18...
	 start solving instance: 67...
	 start solving instance: 59...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 114...
	 start solving instance: 43...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.431132135397733e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21698521077632904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.431132135397733e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.431132135397733e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21698521077632904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.431132135397733e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.431132135397733e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21698521077632904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.431132135397733e+19 - Differentiable computation graph = True!
PPO iteration: 954/1000:
	 start solving instance: 120...
	 start solving instance: 130...
	 start solving instance: 114...
	 start solving instance: 134...
	 start solving instance: 15...
	 start solving instance: 89...
	 start solving instance: 63...
	 start solving instance: 24...
	 start solving instance: 18...
	 start solving instance: 122...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 147...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 59...
	 start solving instance: 70...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3917347865949844e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20446260273456573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.391734874555915e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3917347865949844e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20446260273456573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.391734874555915e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3917347865949844e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20446260273456573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.391734874555915e+19 - Differentiable computation graph = True!
PPO iteration: 955/1000:
	 start solving instance: 95...
	 start solving instance: 70...
	 start solving instance: 18...
	 start solving instance: 114...
	 start solving instance: 15...
	 start solving instance: 24...
	 start solving instance: 89...
	 start solving instance: 43...
	 start solving instance: 122...
	 start solving instance: 147...
	 start solving instance: 134...
	 start solving instance: 59...
	 start solving instance: 87...
	 start solving instance: 52...
	 start solving instance: 67...
	 start solving instance: 91...
	 start solving instance: 103...
	 start solving instance: 63...
	 start solving instance: 120...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6084360379775425e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22255904972553253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.608436301860333e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6084360379775425e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22255904972553253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.608436301860333e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6084360379775425e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22255904972553253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.608436301860333e+19 - Differentiable computation graph = True!
PPO iteration: 956/1000:
	 start solving instance: 15...
	 start solving instance: 89...
	 start solving instance: 120...
	 start solving instance: 95...
	 start solving instance: 52...
	 start solving instance: 43...
	 start solving instance: 63...
	 start solving instance: 67...
	 start solving instance: 134...
	 start solving instance: 18...
	 start solving instance: 122...
	 start solving instance: 87...
	 start solving instance: 59...
	 start solving instance: 147...
	 start solving instance: 70...
	 start solving instance: 114...
	 start solving instance: 24...
	 start solving instance: 130...
	 start solving instance: 103...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.319770782986813e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21105389297008514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.319770958908673e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.319770782986813e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21105389297008514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.319770958908673e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.319770782986813e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21105389297008514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.319770958908673e+19 - Differentiable computation graph = True!
PPO iteration: 957/1000:
	 start solving instance: 103...
	 start solving instance: 24...
	 start solving instance: 18...
	 start solving instance: 67...
	 start solving instance: 95...
	 start solving instance: 63...
	 start solving instance: 43...
	 start solving instance: 59...
	 start solving instance: 114...
	 start solving instance: 91...
	 start solving instance: 15...
	 start solving instance: 89...
	 start solving instance: 134...
	 start solving instance: 87...
	 start solving instance: 130...
	 start solving instance: 120...
	 start solving instance: 122...
	 start solving instance: 70...
	 start solving instance: 52...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.38455998943863e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2156386822462082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3845599014776996e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.38455998943863e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2156386822462082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3845599014776996e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.38455998943863e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2156386822462082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3845599014776996e+19 - Differentiable computation graph = True!
PPO iteration: 958/1000:
	 start solving instance: 122...
	 start solving instance: 18...
	 start solving instance: 67...
	 start solving instance: 91...
	 start solving instance: 63...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 87...
	 start solving instance: 134...
	 start solving instance: 15...
	 start solving instance: 43...
	 start solving instance: 103...
	 start solving instance: 114...
	 start solving instance: 59...
	 start solving instance: 89...
	 start solving instance: 130...
	 start solving instance: 120...
	 start solving instance: 24...
	 start solving instance: 70...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.553207480953424e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20725885033607483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5532073929924936e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.553207480953424e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20725885033607483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5532073929924936e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.553207480953424e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20725885033607483
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5532073929924936e+19 - Differentiable computation graph = True!
PPO iteration: 959/1000:
	 start solving instance: 89...
	 start solving instance: 67...
	 start solving instance: 147...
	 start solving instance: 43...
	 start solving instance: 134...
	 start solving instance: 120...
	 start solving instance: 70...
	 start solving instance: 114...
	 start solving instance: 63...
	 start solving instance: 95...
	 start solving instance: 15...
	 start solving instance: 59...
	 start solving instance: 52...
	 start solving instance: 91...
	 start solving instance: 24...
	 start solving instance: 130...
	 start solving instance: 18...
	 start solving instance: 122...
	 start solving instance: 103...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.382161822637055e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.217764213681221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.382162086519846e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.382161822637055e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.217764213681221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.382162086519846e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.382161822637055e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.217764213681221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.382162086519846e+19 - Differentiable computation graph = True!
PPO iteration: 960/1000:
	 start solving instance: 15...
	 start solving instance: 59...
	 start solving instance: 52...
	 start solving instance: 147...
	 start solving instance: 43...
	 start solving instance: 122...
	 start solving instance: 70...
	 start solving instance: 91...
	 start solving instance: 130...
	 start solving instance: 67...
	 start solving instance: 114...
	 start solving instance: 89...
	 start solving instance: 103...
	 start solving instance: 24...
	 start solving instance: 134...
	 start solving instance: 18...
	 start solving instance: 87...
	 start solving instance: 95...
	 start solving instance: 120...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.333075401448484e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19941270351409912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.333075489409414e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.333075401448484e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19941270351409912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.333075489409414e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.333075401448484e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19941270351409912
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.333075489409414e+19 - Differentiable computation graph = True!
PPO iteration: 961/1000:
	 New training batch of size 20...
	 start solving instance: 41...
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 130...
	 start solving instance: 119...
	 start solving instance: 75...
	 start solving instance: 100...
	 start solving instance: 21...
	 start solving instance: 108...
	 start solving instance: 111...
	 start solving instance: 54...
	 start solving instance: 36...
	 start solving instance: 117...
	 start solving instance: 53...
	 start solving instance: 43...
	 start solving instance: 25...
	 start solving instance: 102...
	 start solving instance: 143...
	 start solving instance: 109...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8435267532760495e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21688604354858398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.84352684123698e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8435267532760495e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21688604354858398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.84352684123698e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8435267532760495e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21688604354858398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.84352684123698e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 4.4660258845731114e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2051624059677124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 44660257966121811968.0000
PPO iteration: 962/1000:
	 start solving instance: 25...
	 start solving instance: 108...
	 start solving instance: 127...
	 start solving instance: 54...
	 start solving instance: 117...
	 start solving instance: 111...
	 start solving instance: 41...
	 start solving instance: 100...
	 start solving instance: 115...
	 start solving instance: 43...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 36...
	 start solving instance: 130...
	 start solving instance: 119...
	 start solving instance: 102...
	 start solving instance: 143...
	 start solving instance: 21...
	 start solving instance: 53...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.771380494620458e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2182421237230301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7713804066595275e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.771380494620458e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2182421237230301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7713804066595275e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.771380494620458e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2182421237230301
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7713804066595275e+19 - Differentiable computation graph = True!
PPO iteration: 963/1000:
	 start solving instance: 108...
	 start solving instance: 53...
	 start solving instance: 41...
	 start solving instance: 127...
	 start solving instance: 100...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 111...
	 start solving instance: 130...
	 start solving instance: 89...
	 start solving instance: 143...
	 start solving instance: 36...
	 start solving instance: 115...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 25...
	 start solving instance: 43...
	 start solving instance: 54...
	 start solving instance: 119...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.79964937837523e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21531163156032562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7996492904142995e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.79964937837523e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21531163156032562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7996492904142995e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.79964937837523e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21531163156032562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7996492904142995e+19 - Differentiable computation graph = True!
PPO iteration: 964/1000:
	 start solving instance: 130...
	 start solving instance: 143...
	 start solving instance: 41...
	 start solving instance: 115...
	 start solving instance: 108...
	 start solving instance: 119...
	 start solving instance: 54...
	 start solving instance: 111...
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 36...
	 start solving instance: 43...
	 start solving instance: 102...
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 25...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 75...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.64681092892739e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21258294582366943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64681101688832e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.64681092892739e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21258294582366943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64681101688832e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.64681092892739e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21258294582366943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.64681101688832e+19 - Differentiable computation graph = True!
PPO iteration: 965/1000:
	 start solving instance: 111...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 43...
	 start solving instance: 102...
	 start solving instance: 119...
	 start solving instance: 25...
	 start solving instance: 75...
	 start solving instance: 130...
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 143...
	 start solving instance: 115...
	 start solving instance: 100...
	 start solving instance: 36...
	 start solving instance: 89...
	 start solving instance: 108...
	 start solving instance: 117...
	 start solving instance: 54...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.73381343685377e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21742387115955353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7338136127756304e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.73381343685377e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21742387115955353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7338136127756304e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.73381343685377e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21742387115955353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7338136127756304e+19 - Differentiable computation graph = True!
PPO iteration: 966/1000:
	 start solving instance: 41...
	 start solving instance: 115...
	 start solving instance: 130...
	 start solving instance: 119...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 21...
	 start solving instance: 43...
	 start solving instance: 54...
	 start solving instance: 100...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 89...
	 start solving instance: 53...
	 start solving instance: 102...
	 start solving instance: 127...
	 start solving instance: 36...
	 start solving instance: 25...
	 start solving instance: 143...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9926761213103754e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21250157058238983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.992676033349445e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9926761213103754e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21250157058238983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.992676033349445e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9926761213103754e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21250157058238983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.992676033349445e+19 - Differentiable computation graph = True!
PPO iteration: 967/1000:
	 start solving instance: 109...
	 start solving instance: 119...
	 start solving instance: 21...
	 start solving instance: 102...
	 start solving instance: 54...
	 start solving instance: 43...
	 start solving instance: 53...
	 start solving instance: 117...
	 start solving instance: 75...
	 start solving instance: 36...
	 start solving instance: 130...
	 start solving instance: 108...
	 start solving instance: 127...
	 start solving instance: 41...
	 start solving instance: 89...
	 start solving instance: 25...
	 start solving instance: 100...
	 start solving instance: 143...
	 start solving instance: 111...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.671580023190486e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21612392365932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6715799352295555e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.671580023190486e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21612392365932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6715799352295555e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.671580023190486e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21612392365932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6715799352295555e+19 - Differentiable computation graph = True!
PPO iteration: 968/1000:
	 start solving instance: 43...
	 start solving instance: 25...
	 start solving instance: 111...
	 start solving instance: 115...
	 start solving instance: 100...
	 start solving instance: 21...
	 start solving instance: 36...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 143...
	 start solving instance: 109...
	 start solving instance: 75...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 102...
	 start solving instance: 127...
	 start solving instance: 41...
	 start solving instance: 119...
	 start solving instance: 130...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.714800154020686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21870191395282745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714800417903477e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.714800154020686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21870191395282745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714800417903477e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.714800154020686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21870191395282745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714800417903477e+19 - Differentiable computation graph = True!
PPO iteration: 969/1000:
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 115...
	 start solving instance: 54...
	 start solving instance: 36...
	 start solving instance: 89...
	 start solving instance: 75...
	 start solving instance: 100...
	 start solving instance: 119...
	 start solving instance: 25...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 130...
	 start solving instance: 43...
	 start solving instance: 111...
	 start solving instance: 108...
	 start solving instance: 117...
	 start solving instance: 143...
	 start solving instance: 41...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.77283114628168e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20250263810157776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.772831322203541e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.77283114628168e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20250263810157776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.772831322203541e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.77283114628168e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20250263810157776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.772831322203541e+19 - Differentiable computation graph = True!
PPO iteration: 970/1000:
	 start solving instance: 117...
	 start solving instance: 53...
	 start solving instance: 25...
	 start solving instance: 21...
	 start solving instance: 75...
	 start solving instance: 130...
	 start solving instance: 43...
	 start solving instance: 108...
	 start solving instance: 109...
	 start solving instance: 102...
	 start solving instance: 36...
	 start solving instance: 89...
	 start solving instance: 119...
	 start solving instance: 100...
	 start solving instance: 54...
	 start solving instance: 127...
	 start solving instance: 143...
	 start solving instance: 111...
	 start solving instance: 41...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.823067040906394e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21534375846385956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.823067128867324e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.823067040906394e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21534375846385956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.823067128867324e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.823067040906394e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21534375846385956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.823067128867324e+19 - Differentiable computation graph = True!
PPO iteration: 971/1000:
	 New training batch of size 20...
	 start solving instance: 132...
	 start solving instance: 104...
	 start solving instance: 38...
	 start solving instance: 142...
	 start solving instance: 141...
	 start solving instance: 55...
	 start solving instance: 7...
	 start solving instance: 145...
	 start solving instance: 111...
	 start solving instance: 48...
	 start solving instance: 50...
	 start solving instance: 93...
	 start solving instance: 75...
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 26...
	 start solving instance: 12...
	 start solving instance: 97...
	 start solving instance: 71...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6181170179577846e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2241123467683792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.618117281840575e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6181170179577846e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2241123467683792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.618117281840575e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6181170179577846e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2241123467683792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.618117281840575e+19 - Differentiable computation graph = True!
PPO iteration: 972/1000:
	 start solving instance: 97...
	 start solving instance: 141...
	 start solving instance: 7...
	 start solving instance: 75...
	 start solving instance: 93...
	 start solving instance: 145...
	 start solving instance: 26...
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 132...
	 start solving instance: 55...
	 start solving instance: 104...
	 start solving instance: 38...
	 start solving instance: 71...
	 start solving instance: 48...
	 start solving instance: 142...
	 start solving instance: 106...
	 start solving instance: 111...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.851940744017373e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2291601151227951
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.851940744017373e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.851940744017373e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2291601151227951
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.851940744017373e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.851940744017373e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2291601151227951
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.851940744017373e+19 - Differentiable computation graph = True!
PPO iteration: 973/1000:
	 start solving instance: 97...
	 start solving instance: 111...
	 start solving instance: 55...
	 start solving instance: 145...
	 start solving instance: 75...
	 start solving instance: 38...
	 start solving instance: 50...
	 start solving instance: 142...
	 start solving instance: 106...
	 start solving instance: 141...
	 start solving instance: 48...
	 start solving instance: 104...
	 start solving instance: 20...
	 start solving instance: 93...
	 start solving instance: 25...
	 start solving instance: 12...
	 start solving instance: 26...
	 start solving instance: 71...
	 start solving instance: 7...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.753305227147262e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20450825989246368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.753305315108192e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.753305227147262e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20450825989246368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.753305315108192e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.753305227147262e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20450825989246368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.753305315108192e+19 - Differentiable computation graph = True!
PPO iteration: 974/1000:
	 start solving instance: 97...
	 start solving instance: 26...
	 start solving instance: 106...
	 start solving instance: 55...
	 start solving instance: 20...
	 start solving instance: 111...
	 start solving instance: 132...
	 start solving instance: 71...
	 start solving instance: 48...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 25...
	 start solving instance: 93...
	 start solving instance: 104...
	 start solving instance: 12...
	 start solving instance: 145...
	 start solving instance: 142...
	 start solving instance: 38...
	 start solving instance: 75...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.761568276932324e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22843754291534424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7615683648932545e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.761568276932324e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22577159106731415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7615683648932545e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.761568276932324e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22577159106731415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7615683648932545e+19 - Differentiable computation graph = True!
PPO iteration: 975/1000:
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 25...
	 start solving instance: 12...
	 start solving instance: 48...
	 start solving instance: 20...
	 start solving instance: 93...
	 start solving instance: 50...
	 start solving instance: 75...
	 start solving instance: 38...
	 start solving instance: 71...
	 start solving instance: 141...
	 start solving instance: 97...
	 start solving instance: 26...
	 start solving instance: 7...
	 start solving instance: 106...
	 start solving instance: 55...
	 start solving instance: 104...
	 start solving instance: 111...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0287362324204985e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2272399514913559
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.028736496303289e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0287362324204985e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2272399514913559
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.028736496303289e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0287362324204985e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.22474311292171478
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.028736496303289e+19 - Differentiable computation graph = True!
PPO iteration: 976/1000:
	 start solving instance: 12...
	 start solving instance: 7...
	 start solving instance: 26...
	 start solving instance: 104...
	 start solving instance: 20...
	 start solving instance: 106...
	 start solving instance: 25...
	 start solving instance: 75...
	 start solving instance: 71...
	 start solving instance: 55...
	 start solving instance: 142...
	 start solving instance: 97...
	 start solving instance: 111...
	 start solving instance: 93...
	 start solving instance: 145...
	 start solving instance: 38...
	 start solving instance: 141...
	 start solving instance: 48...
	 start solving instance: 50...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.571063901632227e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2097475528717041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.571063901632227e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.571063901632227e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2097475528717041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.571063901632227e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.571063901632227e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2097475528717041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.571063901632227e+19 - Differentiable computation graph = True!
PPO iteration: 977/1000:
	 start solving instance: 25...
	 start solving instance: 142...
	 start solving instance: 26...
	 start solving instance: 38...
	 start solving instance: 75...
	 start solving instance: 12...
	 start solving instance: 50...
	 start solving instance: 97...
	 start solving instance: 106...
	 start solving instance: 20...
	 start solving instance: 7...
	 start solving instance: 111...
	 start solving instance: 104...
	 start solving instance: 55...
	 start solving instance: 48...
	 start solving instance: 145...
	 start solving instance: 71...
	 start solving instance: 132...
	 start solving instance: 93...
	 start solving instance: 141...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7412433207077686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20697636902332306
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7412432327468384e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7412433207077686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20928683876991272
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7412432327468384e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7412433207077686e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20697636902332306
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.7412432327468384e+19 - Differentiable computation graph = True!
PPO iteration: 978/1000:
	 start solving instance: 145...
	 start solving instance: 106...
	 start solving instance: 97...
	 start solving instance: 26...
	 start solving instance: 132...
	 start solving instance: 48...
	 start solving instance: 12...
	 start solving instance: 141...
	 start solving instance: 142...
	 start solving instance: 71...
	 start solving instance: 7...
	 start solving instance: 93...
	 start solving instance: 38...
	 start solving instance: 25...
	 start solving instance: 111...
	 start solving instance: 75...
	 start solving instance: 104...
	 start solving instance: 55...
	 start solving instance: 20...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8339938995023013e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2214195728302002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.833994075424162e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8339938995023013e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2214195728302002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.833994075424162e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8339938995023013e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2214195728302002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.833994075424162e+19 - Differentiable computation graph = True!
PPO iteration: 979/1000:
	 start solving instance: 71...
	 start solving instance: 55...
	 start solving instance: 106...
	 start solving instance: 20...
	 start solving instance: 26...
	 start solving instance: 75...
	 start solving instance: 48...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 7...
	 start solving instance: 38...
	 start solving instance: 25...
	 start solving instance: 97...
	 start solving instance: 12...
	 start solving instance: 141...
	 start solving instance: 111...
	 start solving instance: 145...
	 start solving instance: 132...
	 start solving instance: 50...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.502396673688779e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.212758406996727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.502396761649709e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.502396673688779e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.212758406996727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.502396761649709e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.502396673688779e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.212758406996727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.502396761649709e+19 - Differentiable computation graph = True!
PPO iteration: 980/1000:
	 start solving instance: 104...
	 start solving instance: 25...
	 start solving instance: 50...
	 start solving instance: 111...
	 start solving instance: 48...
	 start solving instance: 71...
	 start solving instance: 55...
	 start solving instance: 26...
	 start solving instance: 38...
	 start solving instance: 142...
	 start solving instance: 12...
	 start solving instance: 145...
	 start solving instance: 97...
	 start solving instance: 106...
	 start solving instance: 75...
	 start solving instance: 93...
	 start solving instance: 141...
	 start solving instance: 20...
	 start solving instance: 7...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.238211649266296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21524210274219513
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.238211825188156e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.238211649266296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21755258738994598
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.238211825188156e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.238211649266296e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2153865098953247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.238211825188156e+19 - Differentiable computation graph = True!
PPO iteration: 981/1000:
	 New training batch of size 20...
	 start solving instance: 88...
	 start solving instance: 44...
	 start solving instance: 73...
	 start solving instance: 22...
	 start solving instance: 28...
	 start solving instance: 51...
	 start solving instance: 21...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 36...
	 start solving instance: 92...
	 start solving instance: 13...
	 start solving instance: 98...
	 start solving instance: 127...
	 start solving instance: 150...
	 start solving instance: 66...
	 start solving instance: 121...
	 start solving instance: 75...
	 start solving instance: 142...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1199816037361936e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2139379233121872
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.119981779658054e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1199816037361936e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2139379233121872
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.119981779658054e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1199816037361936e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2139379233121872
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.119981779658054e+19 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 136...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 64...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 140...
	 start solving instance: 82...
		 value loss (over batch): 3.621803264580654e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20777593553066254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 36218033965220495360.0000
PPO iteration: 982/1000:
	 start solving instance: 87...
	 start solving instance: 51...
	 start solving instance: 142...
	 start solving instance: 73...
	 start solving instance: 66...
	 start solving instance: 111...
	 start solving instance: 21...
	 start solving instance: 150...
	 start solving instance: 75...
	 start solving instance: 92...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 146...
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 98...
	 start solving instance: 88...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8915762709782856e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2097613364458084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8915762709782856e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8915762709782856e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2097613364458084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8915762709782856e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8915762709782856e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2097613364458084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8915762709782856e+19 - Differentiable computation graph = True!
PPO iteration: 983/1000:
	 start solving instance: 150...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 142...
	 start solving instance: 87...
	 start solving instance: 92...
	 start solving instance: 66...
	 start solving instance: 111...
	 start solving instance: 146...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 88...
	 start solving instance: 73...
	 start solving instance: 98...
	 start solving instance: 51...
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 121...
	 start solving instance: 75...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8820617130780236e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20467345416545868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.882061976960814e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8820617130780236e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20467345416545868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.882061976960814e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8820617130780236e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20467345416545868
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.882061976960814e+19 - Differentiable computation graph = True!
PPO iteration: 984/1000:
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 13...
	 start solving instance: 87...
	 start solving instance: 51...
	 start solving instance: 22...
	 start solving instance: 88...
	 start solving instance: 98...
	 start solving instance: 28...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 75...
	 start solving instance: 44...
	 start solving instance: 146...
	 start solving instance: 127...
	 start solving instance: 66...
	 start solving instance: 73...
	 start solving instance: 150...
	 start solving instance: 21...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.080161690624658e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2103634923696518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0801618665465184e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.080161690624658e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2103634923696518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0801618665465184e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.080161690624658e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2103634923696518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0801618665465184e+19 - Differentiable computation graph = True!
PPO iteration: 985/1000:
	 start solving instance: 146...
	 start solving instance: 142...
	 start solving instance: 75...
	 start solving instance: 21...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 127...
	 start solving instance: 66...
	 start solving instance: 111...
	 start solving instance: 44...
	 start solving instance: 73...
	 start solving instance: 98...
	 start solving instance: 150...
	 start solving instance: 121...
	 start solving instance: 22...
	 start solving instance: 88...
	 start solving instance: 87...
	 start solving instance: 51...
	 start solving instance: 13...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.964697136740738e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21723142266273499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9646973126625985e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.964697136740738e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21408073604106903
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9646973126625985e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.964697136740738e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21408073604106903
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9646973126625985e+19 - Differentiable computation graph = True!
PPO iteration: 986/1000:
	 start solving instance: 150...
	 start solving instance: 75...
	 start solving instance: 92...
	 start solving instance: 127...
	 start solving instance: 22...
	 start solving instance: 21...
	 start solving instance: 121...
	 start solving instance: 73...
	 start solving instance: 66...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 111...
	 start solving instance: 98...
	 start solving instance: 146...
	 start solving instance: 44...
	 start solving instance: 13...
	 start solving instance: 87...
	 start solving instance: 142...
	 start solving instance: 51...
	 start solving instance: 88...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.886269763979848e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20195689797401428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.886270027862639e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.886269763979848e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20195689797401428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.886270027862639e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.886269763979848e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20195689797401428
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.886270027862639e+19 - Differentiable computation graph = True!
PPO iteration: 987/1000:
	 start solving instance: 127...
	 start solving instance: 87...
	 start solving instance: 75...
	 start solving instance: 98...
	 start solving instance: 88...
	 start solving instance: 142...
	 start solving instance: 111...
	 start solving instance: 22...
	 start solving instance: 36...
	 start solving instance: 28...
	 start solving instance: 121...
	 start solving instance: 150...
	 start solving instance: 146...
	 start solving instance: 66...
	 start solving instance: 73...
	 start solving instance: 51...
	 start solving instance: 92...
	 start solving instance: 44...
	 start solving instance: 13...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.844458767251805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21000449359416962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844458679290875e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.844458767251805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21000449359416962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844458679290875e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.844458767251805e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21000449359416962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844458679290875e+19 - Differentiable computation graph = True!
PPO iteration: 988/1000:
	 start solving instance: 51...
	 start solving instance: 87...
	 start solving instance: 21...
	 start solving instance: 127...
	 start solving instance: 98...
	 start solving instance: 142...
	 start solving instance: 66...
	 start solving instance: 150...
	 start solving instance: 146...
	 start solving instance: 121...
	 start solving instance: 92...
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 36...
	 start solving instance: 75...
	 start solving instance: 28...
	 start solving instance: 73...
	 start solving instance: 111...
	 start solving instance: 88...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.947155264348409e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20392408967018127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.947155264348409e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.947155264348409e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20392408967018127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.947155264348409e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.947155264348409e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20392408967018127
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.947155264348409e+19 - Differentiable computation graph = True!
PPO iteration: 989/1000:
	 start solving instance: 87...
	 start solving instance: 21...
	 start solving instance: 111...
	 start solving instance: 66...
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 22...
	 start solving instance: 127...
	 start solving instance: 146...
	 start solving instance: 44...
	 start solving instance: 73...
	 start solving instance: 75...
	 start solving instance: 150...
	 start solving instance: 92...
	 start solving instance: 142...
	 start solving instance: 51...
	 start solving instance: 28...
	 start solving instance: 98...
	 start solving instance: 88...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.034600039831946e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2119377851486206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0346003037147365e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.034600039831946e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2119377851486206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0346003037147365e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.034600039831946e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2119377851486206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0346003037147365e+19 - Differentiable computation graph = True!
PPO iteration: 990/1000:
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 146...
	 start solving instance: 21...
	 start solving instance: 73...
	 start solving instance: 22...
	 start solving instance: 88...
	 start solving instance: 92...
	 start solving instance: 13...
	 start solving instance: 111...
	 start solving instance: 142...
	 start solving instance: 98...
	 start solving instance: 127...
	 start solving instance: 150...
	 start solving instance: 44...
	 start solving instance: 51...
	 start solving instance: 28...
	 start solving instance: 66...
	 start solving instance: 75...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.610512951421069e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20455825328826904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.610512951421069e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.610512951421069e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20455825328826904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.610512951421069e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.610512951421069e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20455825328826904
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.610512951421069e+19 - Differentiable computation graph = True!
PPO iteration: 991/1000:
	 New training batch of size 20...
	 start solving instance: 78...
	 start solving instance: 39...
	 start solving instance: 146...
	 start solving instance: 33...
	 start solving instance: 138...
	 start solving instance: 137...
	 start solving instance: 87...
	 start solving instance: 85...
	 start solving instance: 47...
	 start solving instance: 103...
	 start solving instance: 128...
	 start solving instance: 142...
	 start solving instance: 112...
	 start solving instance: 143...
	 start solving instance: 144...
	 start solving instance: 43...
	 start solving instance: 149...
	 start solving instance: 50...
	 start solving instance: 25...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.242707156488086e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20360353589057922
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.242707068527156e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.242707156488086e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20240846276283264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.242707068527156e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.242707156488086e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20240846276283264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.242707068527156e+19 - Differentiable computation graph = True!
PPO iteration: 992/1000:
	 start solving instance: 146...
	 start solving instance: 85...
	 start solving instance: 128...
	 start solving instance: 149...
	 start solving instance: 78...
	 start solving instance: 142...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 143...
	 start solving instance: 66...
	 start solving instance: 137...
	 start solving instance: 39...
	 start solving instance: 87...
	 start solving instance: 25...
	 start solving instance: 43...
	 start solving instance: 138...
	 start solving instance: 144...
	 start solving instance: 103...
	 start solving instance: 50...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.012549290156433e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20351777970790863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.012549378117363e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.012549290156433e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20232267677783966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.012549378117363e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.012549290156433e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20232267677783966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.012549378117363e+19 - Differentiable computation graph = True!
PPO iteration: 993/1000:
	 start solving instance: 112...
	 start solving instance: 149...
	 start solving instance: 33...
	 start solving instance: 85...
	 start solving instance: 39...
	 start solving instance: 43...
	 start solving instance: 137...
	 start solving instance: 138...
	 start solving instance: 25...
	 start solving instance: 47...
	 start solving instance: 50...
	 start solving instance: 66...
	 start solving instance: 142...
	 start solving instance: 143...
	 start solving instance: 128...
	 start solving instance: 103...
	 start solving instance: 78...
	 start solving instance: 87...
	 start solving instance: 144...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1928079763042625e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20602357387542725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.192808152226123e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1928079763042625e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20482850074768066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.192808152226123e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1928079763042625e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20482850074768066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.192808152226123e+19 - Differentiable computation graph = True!
PPO iteration: 994/1000:
	 start solving instance: 47...
	 start solving instance: 78...
	 start solving instance: 43...
	 start solving instance: 112...
	 start solving instance: 143...
	 start solving instance: 137...
	 start solving instance: 66...
	 start solving instance: 50...
	 start solving instance: 87...
	 start solving instance: 128...
	 start solving instance: 39...
	 start solving instance: 144...
	 start solving instance: 146...
	 start solving instance: 142...
	 start solving instance: 85...
	 start solving instance: 149...
	 start solving instance: 25...
	 start solving instance: 103...
	 start solving instance: 33...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.944916130908676e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20707188546657562
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.944916218869606e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.944916130908676e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20587678253650665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.944916218869606e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.944916130908676e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20587678253650665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.944916218869606e+19 - Differentiable computation graph = True!
PPO iteration: 995/1000:
	 start solving instance: 144...
	 start solving instance: 146...
	 start solving instance: 128...
	 start solving instance: 138...
	 start solving instance: 39...
	 start solving instance: 25...
	 start solving instance: 85...
	 start solving instance: 143...
	 start solving instance: 149...
	 start solving instance: 50...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 78...
	 start solving instance: 43...
	 start solving instance: 103...
	 start solving instance: 142...
	 start solving instance: 112...
	 start solving instance: 47...
	 start solving instance: 87...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2055802552162294e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19970794022083282
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.20558051909902e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2055802552162294e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2009030133485794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.20558051909902e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2055802552162294e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2009030133485794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.20558051909902e+19 - Differentiable computation graph = True!
PPO iteration: 996/1000:
	 start solving instance: 85...
	 start solving instance: 149...
	 start solving instance: 33...
	 start solving instance: 39...
	 start solving instance: 103...
	 start solving instance: 112...
	 start solving instance: 142...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 143...
	 start solving instance: 66...
	 start solving instance: 87...
	 start solving instance: 144...
	 start solving instance: 137...
	 start solving instance: 47...
	 start solving instance: 43...
	 start solving instance: 25...
	 start solving instance: 50...
	 start solving instance: 146...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.326889636991546e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21151630580425262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.326889636991546e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.326889636991546e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21151630580425262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.326889636991546e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.326889636991546e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.21151630580425262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.326889636991546e+19 - Differentiable computation graph = True!
PPO iteration: 997/1000:
	 start solving instance: 146...
	 start solving instance: 39...
	 start solving instance: 112...
	 start solving instance: 103...
	 start solving instance: 47...
	 start solving instance: 138...
	 start solving instance: 149...
	 start solving instance: 25...
	 start solving instance: 50...
	 start solving instance: 66...
	 start solving instance: 33...
	 start solving instance: 85...
	 start solving instance: 78...
	 start solving instance: 43...
	 start solving instance: 142...
	 start solving instance: 143...
	 start solving instance: 144...
	 start solving instance: 87...
	 start solving instance: 128...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.267936110494383e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19562962651252747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.267936022533453e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.267936110494383e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19562962651252747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.267936022533453e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.267936110494383e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.19562962651252747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.267936022533453e+19 - Differentiable computation graph = True!
PPO iteration: 998/1000:
	 start solving instance: 78...
	 start solving instance: 39...
	 start solving instance: 47...
	 start solving instance: 33...
	 start solving instance: 144...
	 start solving instance: 85...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 143...
	 start solving instance: 25...
	 start solving instance: 128...
	 start solving instance: 149...
	 start solving instance: 142...
	 start solving instance: 43...
	 start solving instance: 138...
	 start solving instance: 50...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.586883147167087e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2018357813358307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.586883235128017e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.586883147167087e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2018357813358307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.586883235128017e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.586883147167087e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.2018357813358307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.586883235128017e+19 - Differentiable computation graph = True!
PPO iteration: 999/1000:
	 start solving instance: 144...
	 start solving instance: 25...
	 start solving instance: 39...
	 start solving instance: 128...
	 start solving instance: 142...
	 start solving instance: 85...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 149...
	 start solving instance: 143...
	 start solving instance: 78...
	 start solving instance: 66...
	 start solving instance: 138...
	 start solving instance: 47...
	 start solving instance: 43...
	 start solving instance: 50...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.12309330960373e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20893774926662445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.12309339756466e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.12309330960373e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20893774926662445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.12309339756466e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.12309330960373e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20893774926662445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.12309339756466e+19 - Differentiable computation graph = True!
PPO iteration: 1000/1000:
	 start solving instance: 146...
	 start solving instance: 25...
	 start solving instance: 142...
	 start solving instance: 103...
	 start solving instance: 85...
	 start solving instance: 43...
	 start solving instance: 149...
	 start solving instance: 144...
	 start solving instance: 143...
	 start solving instance: 87...
	 start solving instance: 78...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 138...
	 start solving instance: 128...
	 start solving instance: 39...
	 start solving instance: 112...
	 start solving instance: 50...
	 start solving instance: 47...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8389696533622266e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20793305337429047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.838969917245017e+19 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8389696533622266e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20673798024654388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.838969917245017e+19 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8389696533622266e+20
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 0.0
		 entropy bonus: 0.20793305337429047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 0.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.838969917245017e+19 - Differentiable computation graph = True!
===* END OF FILE *===
