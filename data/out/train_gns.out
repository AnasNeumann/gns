Lmod has detected the following error: These module(s) or extension(s) exist
but cannot be loaded as requested: "cuda/10.2"
   Try: "module spider cuda/10.2" to see how to load the module(s).



created virtual environment CPython3.12.4.final.0-64 in 4378ms
  creator CPython3Posix(dest=/localscratch/aneumann.43422712.0/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/home/aneumann/.local/share/virtualenv)
    added seed packages: pip==24.2+computecanada
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: pip in /localscratch/aneumann.43422712.0/env/lib/python3.12/site-packages (24.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pip-25.0+computecanada-py3-none-any.whl
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 24.2+computecanada
    Uninstalling pip-24.2+computecanada:
      Successfully uninstalled pip-24.2+computecanada
Successfully installed pip-25.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/numpy-2.2.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 1))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/pandas-2.2.3+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/seaborn-0.13.2+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 3))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/plotly-6.0.1+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/matplotlib-3.10.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.6.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/torchvision-0.21.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torchaudio-2.6.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 8))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch_geometric-2.6.1+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_dateutil-2.9.0.post0+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pytz-2025.2+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tzdata-2025.2+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/narwhals-1.34.1+computecanada-py3-none-any.whl (from plotly->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/packaging-24.2+computecanada-py3-none-any.whl (from plotly->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/contourpy-1.3.1+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cycler-0.12.1+computecanada-py3-none-any.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fonttools-4.57.0+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/kiwisolver-1.4.8+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/pillow-11.1.0+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyparsing-3.2.1+computecanada-py3-none-any.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.18.0+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.13.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/setuptools-78.1.0+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sympy-1.13.1+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.4.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jinja2-3.1.6+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2025.3.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/mpmath-1.3.0+computecanada-py3-none-any.whl (from sympy==1.13.1->torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/Pillow_SIMD-9.5.0.post2+computecanada-cp312-cp312-linux_x86_64.whl (from torchvision->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/aiohttp-3.11.14+computecanada-cp312-cp312-linux_x86_64.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-6.1.1+computecanada-cp36-abi3-linux_x86_64.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.32.3+computecanada-py3-none-any.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.17.0+computecanada-py2.py3-none-any.whl (from python-dateutil>=2.8.2->pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiohappyeyeballs-2.6.1+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiosignal-1.3.2+computecanada-py2.py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/attrs-25.3.0+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/frozenlist-1.5.0+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/multidict-6.2.0+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/propcache-0.3.1+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/yarl-1.18.3+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-2.1.5+computecanada-cp312-cp312-linux_x86_64.whl (from jinja2->torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-3.4.1+computecanada-cp312-cp312-linux_x86_64.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.10+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-2.4.0+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2025.1.31+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Installing collected packages: pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, sympy, six, setuptools, pyparsing, psutil, propcache, pillow-simd, pillow, packaging, numpy, networkx, narwhals, multidict, MarkupSafe, kiwisolver, idna, fsspec, frozenlist, fonttools, filelock, cycler, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, plotly, jinja2, contourpy, aiosignal, torch, pandas, matplotlib, aiohttp, torchvision, torchaudio, torch_geometric, seaborn
Successfully installed MarkupSafe-2.1.5+computecanada aiohappyeyeballs-2.6.1+computecanada aiohttp-3.11.14+computecanada aiosignal-1.3.2+computecanada attrs-25.3.0+computecanada certifi-2025.1.31+computecanada charset-normalizer-3.4.1+computecanada contourpy-1.3.1+computecanada cycler-0.12.1+computecanada filelock-3.18.0+computecanada fonttools-4.57.0+computecanada frozenlist-1.5.0+computecanada fsspec-2025.3.2+computecanada idna-3.10+computecanada jinja2-3.1.6+computecanada kiwisolver-1.4.8+computecanada matplotlib-3.10.0+computecanada mpmath-1.3.0+computecanada multidict-6.2.0+computecanada narwhals-1.34.1+computecanada networkx-3.4.2+computecanada numpy-2.2.2+computecanada packaging-24.2+computecanada pandas-2.2.3+computecanada pillow-11.1.0+computecanada pillow-simd-9.5.0.post2+computecanada plotly-6.0.1+computecanada propcache-0.3.1+computecanada psutil-6.1.1+computecanada pyparsing-3.2.1+computecanada python-dateutil-2.9.0.post0+computecanada pytz-2025.2+computecanada requests-2.32.3+computecanada seaborn-0.13.2+computecanada setuptools-78.1.0+computecanada six-1.17.0+computecanada sympy-1.13.1+computecanada torch-2.6.0+computecanada torch_geometric-2.6.1+computecanada torchaudio-2.6.0+computecanada torchvision-0.21.0+computecanada tqdm-4.67.1+computecanada typing-extensions-4.13.2+computecanada tzdata-2025.2+computecanada urllib3-2.4.0+computecanada yarl-1.18.3+computecanada
/localscratch/aneumann.43422712.0/env/lib/python3.12/site-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information
  return disable_fn(*args, **kwargs)
Execution mode: prod...
TPU Device: cuda...
Pre-training models with MAPPO (on several instances)...
Loading dataset....
End of loading 150 instances!
Dataset loaded after 11.302806854248047 seconds!
PPO iteration: 1/1000:
	 New training batch of size 20...
	 start solving instance: 147...
	 start solving instance: 47...
	 start solving instance: 64...
	 start solving instance: 138...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 113...
	 start solving instance: 77...
	 start solving instance: 38...
	 start solving instance: 78...
	 start solving instance: 116...
	 start solving instance: 22...
	 start solving instance: 125...
	 start solving instance: 146...
	 start solving instance: 57...
	 start solving instance: 36...
	 start solving instance: 10...
	 start solving instance: 83...
	 start solving instance: 25...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3671.826171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.6350154876709
		 entropy bonus: 0.32619771361351013
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -25.793731689453125
		 entropy bonus: 0.06981618702411652
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.81701946258545
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 434.3887634277344 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3671.826171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.36863136291504
		 entropy bonus: 0.32610997557640076
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -25.654943466186523
		 entropy bonus: 0.06678622961044312
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.81701946258545
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 433.9839172363281 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3671.826171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.5797061920166
		 entropy bonus: 0.3240768313407898
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -25.602598190307617
		 entropy bonus: 0.06671470403671265
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.81701946258545
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 434.1428527832031 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3204.081787109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -23.43312644958496
		 entropy bonus: 0.3198324143886566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.82402992248535
		 entropy bonus: 0.09342394024133682
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.332962989807129
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 378.9570
PPO iteration: 2/1000:
	 start solving instance: 57...
	 start solving instance: 113...
	 start solving instance: 22...
	 start solving instance: 36...
	 start solving instance: 99...
	 start solving instance: 38...
	 start solving instance: 137...
	 start solving instance: 78...
	 start solving instance: 125...
	 start solving instance: 47...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 146...
	 start solving instance: 10...
	 start solving instance: 77...
	 start solving instance: 138...
	 start solving instance: 116...
	 start solving instance: 83...
	 start solving instance: 64...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4198.9111328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.346168518066406
		 entropy bonus: 0.32723650336265564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.910680770874023
		 entropy bonus: 0.0663052424788475
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10.02124309539795
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 492.1298522949219 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4198.9111328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.99302673339844
		 entropy bonus: 0.3281411826610565
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.825368881225586
		 entropy bonus: 0.06642288714647293
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10.02124309539795
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 491.6912841796875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4198.9111328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.789485931396484
		 entropy bonus: 0.32794150710105896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.818622589111328
		 entropy bonus: 0.06692741066217422
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10.02124309539795
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 491.48095703125 - Differentiable computation graph = True!
PPO iteration: 3/1000:
	 start solving instance: 47...
	 start solving instance: 146...
	 start solving instance: 44...
	 start solving instance: 77...
	 start solving instance: 25...
	 start solving instance: 83...
	 start solving instance: 57...
	 start solving instance: 147...
	 start solving instance: 113...
	 start solving instance: 38...
	 start solving instance: 125...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 78...
	 start solving instance: 138...
	 start solving instance: 64...
	 start solving instance: 36...
	 start solving instance: 116...
	 start solving instance: 22...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 5569.07568359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.341434478759766
		 entropy bonus: 0.32970109581947327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -30.176013946533203
		 entropy bonus: 0.05657891556620598
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.282645225524902
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 629.6690673828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5569.07568359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.90678024291992
		 entropy bonus: 0.3301903307437897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -29.918838500976562
		 entropy bonus: 0.05698731169104576
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.282645225524902
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 628.9771728515625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5569.07568359375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.6719856262207
		 entropy bonus: 0.32964271306991577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -29.910226821899414
		 entropy bonus: 0.05574380233883858
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.282645225524902
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 628.7339477539062 - Differentiable computation graph = True!
PPO iteration: 4/1000:
	 start solving instance: 22...
	 start solving instance: 146...
	 start solving instance: 99...
	 start solving instance: 137...
	 start solving instance: 125...
	 start solving instance: 64...
	 start solving instance: 147...
	 start solving instance: 38...
	 start solving instance: 113...
	 start solving instance: 138...
	 start solving instance: 116...
	 start solving instance: 44...
	 start solving instance: 83...
	 start solving instance: 78...
	 start solving instance: 77...
	 start solving instance: 25...
	 start solving instance: 57...
	 start solving instance: 47...
	 start solving instance: 36...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 6635.5625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.945762634277344
		 entropy bonus: 0.32071638107299805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.376251220703125
		 entropy bonus: 0.0676104947924614
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.432254791259766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 738.271728515625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6635.5625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.526737213134766
		 entropy bonus: 0.31801173090934753
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.03453826904297
		 entropy bonus: 0.0693872720003128
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.432254791259766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 737.5110473632812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6635.5625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.510704040527344
		 entropy bonus: 0.3210171163082123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.993703842163086
		 entropy bonus: 0.07160667330026627
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.432254791259766
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 738.4536743164062 - Differentiable computation graph = True!
PPO iteration: 5/1000:
	 start solving instance: 64...
	 start solving instance: 147...
	 start solving instance: 38...
	 start solving instance: 78...
	 start solving instance: 44...
	 start solving instance: 77...
	 start solving instance: 47...
	 start solving instance: 36...
	 start solving instance: 57...
	 start solving instance: 116...
	 start solving instance: 10...
	 start solving instance: 146...
	 start solving instance: 137...
	 start solving instance: 25...
	 start solving instance: 125...
	 start solving instance: 83...
	 start solving instance: 99...
	 start solving instance: 22...
	 start solving instance: 138...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 3784.344482421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.82072067260742
		 entropy bonus: 0.32403564453125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -23.23946189880371
		 entropy bonus: 0.06270702183246613
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.052584648132324
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 443.508544921875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3784.344482421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.594154357910156
		 entropy bonus: 0.3148110806941986
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -23.200227737426758
		 entropy bonus: 0.06275992840528488
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.052584648132324
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 444.24365234375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3784.344482421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.8597412109375
		 entropy bonus: 0.319723904132843
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -23.18355369567871
		 entropy bonus: 0.06273698061704636
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.052584648132324
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 443.4920654296875 - Differentiable computation graph = True!
PPO iteration: 6/1000:
	 start solving instance: 25...
	 start solving instance: 147...
	 start solving instance: 116...
	 start solving instance: 38...
	 start solving instance: 57...
	 start solving instance: 146...
	 start solving instance: 10...
	 start solving instance: 99...
	 start solving instance: 36...
	 start solving instance: 22...
	 start solving instance: 77...
	 start solving instance: 137...
	 start solving instance: 78...
	 start solving instance: 138...
	 start solving instance: 125...
	 start solving instance: 44...
	 start solving instance: 113...
	 start solving instance: 64...
	 start solving instance: 83...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 6764.84228515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -36.28818893432617
		 entropy bonus: 0.3207438588142395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.3320426940918
		 entropy bonus: 0.08650583773851395
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.474918365478516
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 756.5386962890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6764.84228515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.86066436767578
		 entropy bonus: 0.3202061951160431
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.26044845581055
		 entropy bonus: 0.08661564439535141
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.474918365478516
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 756.03955078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6764.84228515625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.96034622192383
		 entropy bonus: 0.31865763664245605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.18475341796875
		 entropy bonus: 0.08673172444105148
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9.474918365478516
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 756.063720703125 - Differentiable computation graph = True!
PPO iteration: 7/1000:
	 start solving instance: 36...
	 start solving instance: 78...
	 start solving instance: 64...
	 start solving instance: 99...
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 147...
	 start solving instance: 83...
	 start solving instance: 137...
	 start solving instance: 38...
	 start solving instance: 47...
	 start solving instance: 125...
	 start solving instance: 116...
	 start solving instance: 146...
	 start solving instance: 113...
	 start solving instance: 138...
	 start solving instance: 10...
	 start solving instance: 77...
	 start solving instance: 25...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 5403.89306640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.50985336303711
		 entropy bonus: 0.32519468665122986
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.37242889404297
		 entropy bonus: 0.08656250685453415
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.385570526123047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 613.6160278320312 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5403.89306640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.06297302246094
		 entropy bonus: 0.3239765167236328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.284358978271484
		 entropy bonus: 0.08654824644327164
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.385570526123047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 613.0811767578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5403.89306640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.857196807861328
		 entropy bonus: 0.3220271170139313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.21455764770508
		 entropy bonus: 0.08641867339611053
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.385570526123047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 612.8058471679688 - Differentiable computation graph = True!
PPO iteration: 8/1000:
	 start solving instance: 64...
	 start solving instance: 116...
	 start solving instance: 25...
	 start solving instance: 113...
	 start solving instance: 125...
	 start solving instance: 22...
	 start solving instance: 78...
	 start solving instance: 137...
	 start solving instance: 57...
	 start solving instance: 36...
	 start solving instance: 147...
	 start solving instance: 38...
	 start solving instance: 77...
	 start solving instance: 47...
	 start solving instance: 44...
	 start solving instance: 10...
	 start solving instance: 83...
	 start solving instance: 138...
	 start solving instance: 146...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 5955.34912109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -36.21798324584961
		 entropy bonus: 0.3226107656955719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -29.675573348999023
		 entropy bonus: 0.08974403142929077
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.780030250549316
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 670.1672973632812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5955.34912109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.75739288330078
		 entropy bonus: 0.31761741638183594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -29.627588272094727
		 entropy bonus: 0.08766531199216843
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.780030250549316
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 669.659423828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5955.34912109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.369720458984375
		 entropy bonus: 0.3185575604438782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -29.578460693359375
		 entropy bonus: 0.08530077338218689
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.780030250549316
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 669.2227783203125 - Differentiable computation graph = True!
PPO iteration: 9/1000:
	 start solving instance: 146...
	 start solving instance: 116...
	 start solving instance: 47...
	 start solving instance: 138...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 36...
	 start solving instance: 64...
	 start solving instance: 147...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 22...
	 start solving instance: 125...
	 start solving instance: 83...
	 start solving instance: 77...
	 start solving instance: 57...
	 start solving instance: 113...
	 start solving instance: 78...
	 start solving instance: 99...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4007.293701171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.795169830322266
		 entropy bonus: 0.31490790843963623
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -25.366870880126953
		 entropy bonus: 0.05826780945062637
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.234723091125488
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 469.08880615234375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4007.293701171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.6414909362793
		 entropy bonus: 0.30799517035484314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -25.335901260375977
		 entropy bonus: 0.05776996538043022
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.234723091125488
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468.9049072265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4007.293701171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.910701751708984
		 entropy bonus: 0.31738486886024475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -25.30058479309082
		 entropy bonus: 0.05686086416244507
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8.234723091125488
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 468.1379699707031 - Differentiable computation graph = True!
PPO iteration: 10/1000:
	 start solving instance: 113...
	 start solving instance: 57...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 137...
	 start solving instance: 47...
	 start solving instance: 78...
	 start solving instance: 10...
	 start solving instance: 38...
	 start solving instance: 116...
	 start solving instance: 147...
	 start solving instance: 77...
	 start solving instance: 138...
	 start solving instance: 22...
	 start solving instance: 99...
	 start solving instance: 36...
	 start solving instance: 64...
	 start solving instance: 83...
	 start solving instance: 146...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4262.5546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.722774505615234
		 entropy bonus: 0.3233996331691742
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.824787139892578
		 entropy bonus: 0.053485043346881866
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10.786178588867188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 499.551513671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4262.5546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.4445915222168
		 entropy bonus: 0.3268371522426605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.709943771362305
		 entropy bonus: 0.05348462983965874
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10.786178588867188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 499.15814208984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4262.5546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.307735443115234
		 entropy bonus: 0.320460706949234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -26.650999069213867
		 entropy bonus: 0.05394934490323067
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10.786178588867188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 498.96295166015625 - Differentiable computation graph = True!
PPO iteration: 11/1000:
	 New training batch of size 20...
	 start solving instance: 57...
	 start solving instance: 75...
	 start solving instance: 103...
	 start solving instance: 34...
	 start solving instance: 95...
	 start solving instance: 33...
	 start solving instance: 82...
	 start solving instance: 20...
	 start solving instance: 80...
	 start solving instance: 112...
	 start solving instance: 56...
	 start solving instance: 15...
	 start solving instance: 47...
	 start solving instance: 87...
	 start solving instance: 22...
	 start solving instance: 30...
	 start solving instance: 58...
	 start solving instance: 14...
	 start solving instance: 50...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 23494.90625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.58906555175781
		 entropy bonus: 0.31687307357788086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.42902755737305
		 entropy bonus: 0.04719603434205055
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.52944278717041
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2472.001953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 23494.90625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.5134048461914
		 entropy bonus: 0.31628891825675964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.35767364501953
		 entropy bonus: 0.045563265681266785
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.52944278717041
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2471.85498046875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 23494.90625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.0240249633789
		 entropy bonus: 0.3194231688976288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.31563949584961
		 entropy bonus: 0.046314239501953125
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.52944278717041
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2471.3232421875 - Differentiable computation graph = True!
PPO iteration: 12/1000:
	 start solving instance: 103...
	 start solving instance: 50...
	 start solving instance: 15...
	 start solving instance: 56...
	 start solving instance: 34...
	 start solving instance: 58...
	 start solving instance: 75...
	 start solving instance: 47...
	 start solving instance: 33...
	 start solving instance: 95...
	 start solving instance: 87...
	 start solving instance: 22...
	 start solving instance: 112...
	 start solving instance: 20...
	 start solving instance: 14...
	 start solving instance: 83...
	 start solving instance: 30...
	 start solving instance: 57...
	 start solving instance: 82...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 23634.56640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -68.45704650878906
		 entropy bonus: 0.31657466292381287
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.235511779785156
		 entropy bonus: 0.04794011637568474
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.27120018005371
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2492.384033203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 23634.56640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -68.84983825683594
		 entropy bonus: 0.2973487377166748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.052894592285156
		 entropy bonus: 0.049550462514162064
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.27120018005371
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2492.595947265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 23634.56640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -68.78902435302734
		 entropy bonus: 0.29890894889831543
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.0066032409668
		 entropy bonus: 0.04782082512974739
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.27120018005371
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2492.48876953125 - Differentiable computation graph = True!
PPO iteration: 13/1000:
	 start solving instance: 50...
	 start solving instance: 34...
	 start solving instance: 75...
	 start solving instance: 30...
	 start solving instance: 58...
	 start solving instance: 83...
	 start solving instance: 56...
	 start solving instance: 14...
	 start solving instance: 22...
	 start solving instance: 82...
	 start solving instance: 15...
	 start solving instance: 87...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 103...
	 start solving instance: 20...
	 start solving instance: 47...
	 start solving instance: 80...
	 start solving instance: 95...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 35354.55859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -75.6688461303711
		 entropy bonus: 0.3071731626987457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -49.47788619995117
		 entropy bonus: 0.05682694911956787
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.028608322143555
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3685.5947265625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 35354.55859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -75.29986572265625
		 entropy bonus: 0.32263943552970886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -50.03928756713867
		 entropy bonus: 0.03755436837673187
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.028608322143555
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3685.78759765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 35354.55859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -75.30976867675781
		 entropy bonus: 0.32439136505126953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -50.01979446411133
		 entropy bonus: 0.03622470423579216
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.028608322143555
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3685.77783203125 - Differentiable computation graph = True!
PPO iteration: 14/1000:
	 start solving instance: 56...
	 start solving instance: 33...
	 start solving instance: 14...
	 start solving instance: 47...
	 start solving instance: 34...
	 start solving instance: 95...
	 start solving instance: 57...
	 start solving instance: 15...
	 start solving instance: 75...
	 start solving instance: 80...
	 start solving instance: 50...
	 start solving instance: 83...
	 start solving instance: 112...
	 start solving instance: 87...
	 start solving instance: 30...
	 start solving instance: 20...
	 start solving instance: 103...
	 start solving instance: 22...
	 start solving instance: 58...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 33333.33984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.73990631103516
		 entropy bonus: 0.3276892304420471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -54.496742248535156
		 entropy bonus: 0.05005940422415733
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.45307731628418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3482.98583984375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 33333.33984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.67094421386719
		 entropy bonus: 0.3266875147819519
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -53.95804977416992
		 entropy bonus: 0.05752253532409668
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.45307731628418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3482.37744140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 33333.33984375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.76067352294922
		 entropy bonus: 0.3289700448513031
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -53.75434494018555
		 entropy bonus: 0.06224697828292847
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.45307731628418
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3482.262939453125 - Differentiable computation graph = True!
PPO iteration: 15/1000:
	 start solving instance: 34...
	 start solving instance: 83...
	 start solving instance: 75...
	 start solving instance: 57...
	 start solving instance: 15...
	 start solving instance: 20...
	 start solving instance: 30...
	 start solving instance: 33...
	 start solving instance: 103...
	 start solving instance: 22...
	 start solving instance: 112...
	 start solving instance: 14...
	 start solving instance: 82...
	 start solving instance: 87...
	 start solving instance: 80...
	 start solving instance: 58...
	 start solving instance: 95...
	 start solving instance: 47...
	 start solving instance: 56...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 16731.99609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -71.27420806884766
		 entropy bonus: 0.32856932282447815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -43.20368576049805
		 entropy bonus: 0.07405128329992294
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.646770477294922
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1809.283935546875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 16731.99609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.8526840209961
		 entropy bonus: 0.32922476530075073
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -43.33930206298828
		 entropy bonus: 0.0728687047958374
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.646770477294922
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1808.998046875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 16731.99609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.81074523925781
		 entropy bonus: 0.32931825518608093
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -43.24819564819336
		 entropy bonus: 0.06823581457138062
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.646770477294922
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1808.8656005859375 - Differentiable computation graph = True!
PPO iteration: 16/1000:
	 start solving instance: 14...
	 start solving instance: 56...
	 start solving instance: 30...
	 start solving instance: 82...
	 start solving instance: 95...
	 start solving instance: 50...
	 start solving instance: 83...
	 start solving instance: 58...
	 start solving instance: 33...
	 start solving instance: 57...
	 start solving instance: 87...
	 start solving instance: 112...
	 start solving instance: 80...
	 start solving instance: 15...
	 start solving instance: 47...
	 start solving instance: 103...
	 start solving instance: 20...
	 start solving instance: 75...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 17045.087890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.65557098388672
		 entropy bonus: 0.3302253782749176
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.94544982910156
		 entropy bonus: 0.036619871854782104
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.839454650878906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1835.91259765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 17045.087890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.80289459228516
		 entropy bonus: 0.32952067255973816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.691097259521484
		 entropy bonus: 0.03604278340935707
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.839454650878906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1834.8056640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 17045.087890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.69359588623047
		 entropy bonus: 0.32930612564086914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.715911865234375
		 entropy bonus: 0.03472861647605896
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.839454650878906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1834.7213134765625 - Differentiable computation graph = True!
PPO iteration: 17/1000:
	 start solving instance: 82...
	 start solving instance: 20...
	 start solving instance: 14...
	 start solving instance: 33...
	 start solving instance: 87...
	 start solving instance: 83...
	 start solving instance: 112...
	 start solving instance: 80...
	 start solving instance: 47...
	 start solving instance: 34...
	 start solving instance: 58...
	 start solving instance: 95...
	 start solving instance: 15...
	 start solving instance: 30...
	 start solving instance: 56...
	 start solving instance: 50...
	 start solving instance: 103...
	 start solving instance: 75...
	 start solving instance: 22...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 15489.3095703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -71.00655364990234
		 entropy bonus: 0.3245753347873688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.32374954223633
		 entropy bonus: 0.04402808099985123
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.890277862548828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1671.11474609375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 15489.3095703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.85045623779297
		 entropy bonus: 0.32304295897483826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.481300354003906
		 entropy bonus: 0.04476137086749077
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.890277862548828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1671.1162109375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 15489.3095703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.55387878417969
		 entropy bonus: 0.32547125220298767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.472328186035156
		 entropy bonus: 0.04447432979941368
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.890277862548828
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1670.810546875 - Differentiable computation graph = True!
PPO iteration: 18/1000:
	 start solving instance: 30...
	 start solving instance: 56...
	 start solving instance: 83...
	 start solving instance: 82...
	 start solving instance: 14...
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 22...
	 start solving instance: 57...
	 start solving instance: 95...
	 start solving instance: 15...
	 start solving instance: 75...
	 start solving instance: 87...
	 start solving instance: 50...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 47...
	 start solving instance: 20...
	 start solving instance: 34...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 19115.251953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -73.62652587890625
		 entropy bonus: 0.32279714941978455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -43.08858871459961
		 entropy bonus: 0.04561518505215645
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.896013259887695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2048.099609375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 19115.251953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -72.91698455810547
		 entropy bonus: 0.3242831230163574
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -42.99652099609375
		 entropy bonus: 0.04377142712473869
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.896013259887695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2047.2979736328125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 19115.251953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -72.73252868652344
		 entropy bonus: 0.3229193091392517
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -42.99851608276367
		 entropy bonus: 0.04386119171977043
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.896013259887695
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2047.1156005859375 - Differentiable computation graph = True!
PPO iteration: 19/1000:
	 start solving instance: 103...
	 start solving instance: 57...
	 start solving instance: 75...
	 start solving instance: 83...
	 start solving instance: 58...
	 start solving instance: 14...
	 start solving instance: 34...
	 start solving instance: 95...
	 start solving instance: 47...
	 start solving instance: 80...
	 start solving instance: 15...
	 start solving instance: 33...
	 start solving instance: 82...
	 start solving instance: 56...
	 start solving instance: 30...
	 start solving instance: 22...
	 start solving instance: 112...
	 start solving instance: 87...
	 start solving instance: 20...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 16581.783203125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -72.09779357910156
		 entropy bonus: 0.3270306885242462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.68666458129883
		 entropy bonus: 0.03169747814536095
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.621335983276367
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1785.5482177734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 16581.783203125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -71.49040985107422
		 entropy bonus: 0.32718780636787415
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.544166564941406
		 entropy bonus: 0.03405767306685448
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.621335983276367
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1784.798095703125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 16581.783203125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -71.22782135009766
		 entropy bonus: 0.3275589048862457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.4646110534668
		 entropy bonus: 0.036540888249874115
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.621335983276367
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1784.4556884765625 - Differentiable computation graph = True!
PPO iteration: 20/1000:
	 start solving instance: 34...
	 start solving instance: 87...
	 start solving instance: 15...
	 start solving instance: 50...
	 start solving instance: 22...
	 start solving instance: 33...
	 start solving instance: 82...
	 start solving instance: 95...
	 start solving instance: 56...
	 start solving instance: 47...
	 start solving instance: 83...
	 start solving instance: 58...
	 start solving instance: 14...
	 start solving instance: 112...
	 start solving instance: 75...
	 start solving instance: 30...
	 start solving instance: 80...
	 start solving instance: 20...
	 start solving instance: 57...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 17114.0703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.95442199707031
		 entropy bonus: 0.31734946370124817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.61640548706055
		 entropy bonus: 0.06187298893928528
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.42641830444336
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1840.366455078125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 17114.0703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.61151123046875
		 entropy bonus: 0.3172178268432617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.496238708496094
		 entropy bonus: 0.06155027076601982
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.42641830444336
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1839.9034423828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 17114.0703125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.30257415771484
		 entropy bonus: 0.31672677397727966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.47283935546875
		 entropy bonus: 0.061833012849092484
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.42641830444336
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1839.571044921875 - Differentiable computation graph = True!
PPO iteration: 21/1000:
	 New training batch of size 20...
	 start solving instance: 45...
	 start solving instance: 148...
	 start solving instance: 53...
	 start solving instance: 120...
	 start solving instance: 134...
	 start solving instance: 1...
	 start solving instance: 35...
	 start solving instance: 9...
	 start solving instance: 111...
	 start solving instance: 55...
	 start solving instance: 109...
	 start solving instance: 44...
	 start solving instance: 10...
	 start solving instance: 20...
	 start solving instance: 54...
	 start solving instance: 37...
	 start solving instance: 146...
	 start solving instance: 61...
	 start solving instance: 66...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4872.68115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.264705657958984
		 entropy bonus: 0.32489216327667236
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.23518753051758
		 entropy bonus: 0.07853582501411438
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.55488395690918
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 575.2825927734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4872.68115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.771270751953125
		 entropy bonus: 0.324887216091156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.12153244018555
		 entropy bonus: 0.07450184971094131
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.55488395690918
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 574.6758422851562 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4872.68115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.69768142700195
		 entropy bonus: 0.3240697979927063
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.15157699584961
		 entropy bonus: 0.07316809147596359
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.55488395690918
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 574.632568359375 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 5282.02587890625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.470340728759766
		 entropy bonus: 0.3183669447898865
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.27778244018555
		 entropy bonus: 0.08298296481370926
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.455677032470703
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 621.3662
PPO iteration: 22/1000:
	 start solving instance: 120...
	 start solving instance: 111...
	 start solving instance: 44...
	 start solving instance: 134...
	 start solving instance: 66...
	 start solving instance: 54...
	 start solving instance: 9...
	 start solving instance: 55...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 35...
	 start solving instance: 37...
	 start solving instance: 126...
	 start solving instance: 45...
	 start solving instance: 146...
	 start solving instance: 109...
	 start solving instance: 10...
	 start solving instance: 148...
	 start solving instance: 20...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 4582.79052734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.51738357543945
		 entropy bonus: 0.3344782292842865
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -30.069944381713867
		 entropy bonus: 0.051714856177568436
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.553546905517578
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 546.38134765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4582.79052734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.302757263183594
		 entropy bonus: 0.33545002341270447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -30.02120018005371
		 entropy bonus: 0.052680082619190216
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.553546905517578
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 546.1177368164062 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4582.79052734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.189491271972656
		 entropy bonus: 0.3357184827327728
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -29.989648818969727
		 entropy bonus: 0.05212092027068138
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.553546905517578
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 545.9729614257812 - Differentiable computation graph = True!
PPO iteration: 23/1000:
	 start solving instance: 55...
	 start solving instance: 37...
	 start solving instance: 10...
	 start solving instance: 134...
	 start solving instance: 61...
	 start solving instance: 20...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 111...
	 start solving instance: 120...
	 start solving instance: 9...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 66...
	 start solving instance: 109...
	 start solving instance: 126...
	 start solving instance: 44...
	 start solving instance: 53...
	 start solving instance: 45...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 5135.80029296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -41.84724044799805
		 entropy bonus: 0.3301943242549896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.962684631347656
		 entropy bonus: 0.056214261800050735
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.25244140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 610.603759765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5135.80029296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -41.449764251708984
		 entropy bonus: 0.3301299512386322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.96903991699219
		 entropy bonus: 0.0511762760579586
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.25244140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 610.213134765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5135.80029296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -41.10844039916992
		 entropy bonus: 0.3299435079097748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.96322250366211
		 entropy bonus: 0.0500141866505146
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.25244140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 609.8660888671875 - Differentiable computation graph = True!
PPO iteration: 24/1000:
	 start solving instance: 44...
	 start solving instance: 148...
	 start solving instance: 134...
	 start solving instance: 126...
	 start solving instance: 9...
	 start solving instance: 1...
	 start solving instance: 10...
	 start solving instance: 111...
	 start solving instance: 109...
	 start solving instance: 45...
	 start solving instance: 61...
	 start solving instance: 37...
	 start solving instance: 20...
	 start solving instance: 146...
	 start solving instance: 53...
	 start solving instance: 35...
	 start solving instance: 66...
	 start solving instance: 54...
	 start solving instance: 55...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 7276.20166015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.689910888671875
		 entropy bonus: 0.3238336443901062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.9521598815918
		 entropy bonus: 0.07326283305883408
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.6450138092041
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 836.8675537109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7276.20166015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.198394775390625
		 entropy bonus: 0.323962539434433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.789920806884766
		 entropy bonus: 0.07553129643201828
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.6450138092041
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 836.2135620117188 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7276.20166015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.053619384765625
		 entropy bonus: 0.32396507263183594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.659420013427734
		 entropy bonus: 0.07786717265844345
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.6450138092041
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 835.9380493164062 - Differentiable computation graph = True!
PPO iteration: 25/1000:
	 start solving instance: 35...
	 start solving instance: 111...
	 start solving instance: 10...
	 start solving instance: 45...
	 start solving instance: 134...
	 start solving instance: 53...
	 start solving instance: 148...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 126...
	 start solving instance: 54...
	 start solving instance: 44...
	 start solving instance: 9...
	 start solving instance: 120...
	 start solving instance: 37...
	 start solving instance: 66...
	 start solving instance: 20...
	 start solving instance: 146...
	 start solving instance: 109...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 5685.06494140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -42.62638473510742
		 entropy bonus: 0.3306981027126312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.9138298034668
		 entropy bonus: 0.053717225790023804
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -23.274032592773438
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 669.2823486328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5685.06494140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -42.45375442504883
		 entropy bonus: 0.3306703567504883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.979557037353516
		 entropy bonus: 0.04915068298578262
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -23.274032592773438
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 669.1759033203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5685.06494140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -42.30762481689453
		 entropy bonus: 0.3305538594722748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.92970657348633
		 entropy bonus: 0.050088074058294296
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -23.274032592773438
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 668.9798583984375 - Differentiable computation graph = True!
PPO iteration: 26/1000:
	 start solving instance: 134...
	 start solving instance: 55...
	 start solving instance: 10...
	 start solving instance: 109...
	 start solving instance: 9...
	 start solving instance: 1...
	 start solving instance: 111...
	 start solving instance: 148...
	 start solving instance: 53...
	 start solving instance: 120...
	 start solving instance: 126...
	 start solving instance: 45...
	 start solving instance: 146...
	 start solving instance: 66...
	 start solving instance: 61...
	 start solving instance: 54...
	 start solving instance: 44...
	 start solving instance: 20...
	 start solving instance: 35...
	 start solving instance: 37...
	 Optimization epoch: 1/3
		 value loss (over batch): 5783.75146484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.43780517578125
		 entropy bonus: 0.3331318795681
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.2322998046875
		 entropy bonus: 0.04959632083773613
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.682090759277344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 672.6890869140625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5783.75146484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.11393737792969
		 entropy bonus: 0.3332161605358124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.13465118408203
		 entropy bonus: 0.05179017782211304
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.682090759277344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 672.2673950195312 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5783.75146484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.99996566772461
		 entropy bonus: 0.3332204520702362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.119911193847656
		 entropy bonus: 0.05330196022987366
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.682090759277344
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 672.1384887695312 - Differentiable computation graph = True!
PPO iteration: 27/1000:
	 start solving instance: 55...
	 start solving instance: 37...
	 start solving instance: 9...
	 start solving instance: 148...
	 start solving instance: 66...
	 start solving instance: 120...
	 start solving instance: 146...
	 start solving instance: 134...
	 start solving instance: 35...
	 start solving instance: 44...
	 start solving instance: 53...
	 start solving instance: 45...
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 1...
	 start solving instance: 111...
	 start solving instance: 109...
	 start solving instance: 126...
	 start solving instance: 54...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 4489.11181640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -40.13505935668945
		 entropy bonus: 0.32286572456359863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.27051544189453
		 entropy bonus: 0.07139457762241364
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -23.435745239257812
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 545.7130737304688 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4489.11181640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.63092041015625
		 entropy bonus: 0.3222082555294037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.2352294921875
		 entropy bonus: 0.07193054258823395
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -23.435745239257812
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 545.1736450195312 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4489.11181640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.58906936645508
		 entropy bonus: 0.3205527365207672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.15140151977539
		 entropy bonus: 0.07237547636032104
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -23.435745239257812
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 545.048095703125 - Differentiable computation graph = True!
PPO iteration: 28/1000:
	 start solving instance: 66...
	 start solving instance: 37...
	 start solving instance: 1...
	 start solving instance: 148...
	 start solving instance: 54...
	 start solving instance: 9...
	 start solving instance: 126...
	 start solving instance: 109...
	 start solving instance: 53...
	 start solving instance: 134...
	 start solving instance: 146...
	 start solving instance: 45...
	 start solving instance: 111...
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 35...
	 start solving instance: 44...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 5821.681640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.5438346862793
		 entropy bonus: 0.33216750621795654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.62656021118164
		 entropy bonus: 0.03224992752075195
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.91865348815918
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 681.2207641601562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5821.681640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -43.675113677978516
		 entropy bonus: 0.33571723103523254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.59526443481445
		 entropy bonus: 0.03214399889111519
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.91865348815918
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 680.3203735351562 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5821.681640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -43.667999267578125
		 entropy bonus: 0.335636705160141
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.46460723876953
		 entropy bonus: 0.031671296805143356
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.91865348815918
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 680.1827392578125 - Differentiable computation graph = True!
PPO iteration: 29/1000:
	 start solving instance: 66...
	 start solving instance: 148...
	 start solving instance: 55...
	 start solving instance: 134...
	 start solving instance: 146...
	 start solving instance: 37...
	 start solving instance: 54...
	 start solving instance: 109...
	 start solving instance: 111...
	 start solving instance: 120...
	 start solving instance: 126...
	 start solving instance: 53...
	 start solving instance: 61...
	 start solving instance: 35...
	 start solving instance: 10...
	 start solving instance: 45...
	 start solving instance: 44...
	 start solving instance: 1...
	 start solving instance: 9...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 7932.7001953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -45.514163970947266
		 entropy bonus: 0.3244195878505707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -45.12333679199219
		 entropy bonus: 0.10037446022033691
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -35.165565490722656
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 919.0306396484375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7932.7001953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -45.38860321044922
		 entropy bonus: 0.3244021534919739
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -44.91699981689453
		 entropy bonus: 0.10044653713703156
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -35.165565490722656
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 918.6986694335938 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7932.7001953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -45.336334228515625
		 entropy bonus: 0.3244205117225647
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -44.978267669677734
		 entropy bonus: 0.09654548019170761
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -35.165565490722656
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 918.7080688476562 - Differentiable computation graph = True!
PPO iteration: 30/1000:
	 start solving instance: 148...
	 start solving instance: 45...
	 start solving instance: 61...
	 start solving instance: 54...
	 start solving instance: 111...
	 start solving instance: 10...
	 start solving instance: 55...
	 start solving instance: 20...
	 start solving instance: 66...
	 start solving instance: 126...
	 start solving instance: 109...
	 start solving instance: 53...
	 start solving instance: 9...
	 start solving instance: 120...
	 start solving instance: 146...
	 start solving instance: 37...
	 start solving instance: 1...
	 start solving instance: 35...
	 start solving instance: 44...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 7844.9814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -45.11574172973633
		 entropy bonus: 0.3275608420372009
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -40.721920013427734
		 entropy bonus: 0.04836161062121391
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -27.765941619873047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 898.064208984375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7844.9814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -45.02607727050781
		 entropy bonus: 0.3275516927242279
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -40.72331619262695
		 entropy bonus: 0.04847922548651695
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -27.765941619873047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 897.9759521484375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7844.9814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.95978927612305
		 entropy bonus: 0.32753413915634155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -40.644718170166016
		 entropy bonus: 0.04839140176773071
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -27.765941619873047
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 897.8310546875 - Differentiable computation graph = True!
PPO iteration: 31/1000:
	 New training batch of size 20...
	 start solving instance: 87...
	 start solving instance: 86...
	 start solving instance: 96...
	 start solving instance: 68...
	 start solving instance: 147...
	 start solving instance: 23...
	 start solving instance: 106...
	 start solving instance: 115...
	 start solving instance: 73...
	 start solving instance: 43...
	 start solving instance: 29...
	 start solving instance: 39...
	 start solving instance: 113...
	 start solving instance: 72...
	 start solving instance: 4...
	 start solving instance: 13...
	 start solving instance: 102...
	 start solving instance: 126...
	 start solving instance: 19...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4675.9775390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.77584457397461
		 entropy bonus: 0.31352508068084717
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -35.20772171020508
		 entropy bonus: 0.08593481779098511
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.180015563964844
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 561.7213745117188 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4675.9775390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.638248443603516
		 entropy bonus: 0.31344491243362427
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -35.32962417602539
		 entropy bonus: 0.08961472660303116
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.180015563964844
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 561.705322265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4675.9775390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.34675979614258
		 entropy bonus: 0.31308186054229736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -35.11526870727539
		 entropy bonus: 0.08775721490383148
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.180015563964844
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 561.19970703125 - Differentiable computation graph = True!
PPO iteration: 32/1000:
	 start solving instance: 19...
	 start solving instance: 73...
	 start solving instance: 29...
	 start solving instance: 115...
	 start solving instance: 147...
	 start solving instance: 113...
	 start solving instance: 13...
	 start solving instance: 68...
	 start solving instance: 96...
	 start solving instance: 72...
	 start solving instance: 38...
	 start solving instance: 23...
	 start solving instance: 86...
	 start solving instance: 102...
	 start solving instance: 126...
	 start solving instance: 43...
	 start solving instance: 87...
	 start solving instance: 39...
	 start solving instance: 4...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4026.568115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.51044273376465
		 entropy bonus: 0.3203940689563751
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.599491119384766
		 entropy bonus: 0.08290084451436996
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.063568115234375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 486.78997802734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4026.568115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.992050170898438
		 entropy bonus: 0.3120476305484772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.5235595703125
		 entropy bonus: 0.08371999859809875
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.063568115234375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 487.1964416503906 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4026.568115234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.67840003967285
		 entropy bonus: 0.3213970363140106
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.50849914550781
		 entropy bonus: 0.08401292562484741
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.063568115234375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 486.86676025390625 - Differentiable computation graph = True!
PPO iteration: 33/1000:
	 start solving instance: 13...
	 start solving instance: 102...
	 start solving instance: 19...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 115...
	 start solving instance: 23...
	 start solving instance: 106...
	 start solving instance: 86...
	 start solving instance: 43...
	 start solving instance: 96...
	 start solving instance: 39...
	 start solving instance: 29...
	 start solving instance: 72...
	 start solving instance: 126...
	 start solving instance: 38...
	 start solving instance: 68...
	 start solving instance: 87...
	 start solving instance: 147...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 7059.54931640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.186927795410156
		 entropy bonus: 0.3270408809185028
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.41459274291992
		 entropy bonus: 0.07526805251836777
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.857044219970703
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 797.373291015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7059.54931640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.674560546875
		 entropy bonus: 0.3264519274234772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.3494758605957
		 entropy bonus: 0.07339973747730255
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.857044219970703
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 796.7960205078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7059.54931640625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.37154769897461
		 entropy bonus: 0.3260668218135834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.24222946166992
		 entropy bonus: 0.07552468776702881
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.857044219970703
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 796.3856201171875 - Differentiable computation graph = True!
PPO iteration: 34/1000:
	 start solving instance: 87...
	 start solving instance: 147...
	 start solving instance: 13...
	 start solving instance: 106...
	 start solving instance: 19...
	 start solving instance: 115...
	 start solving instance: 86...
	 start solving instance: 4...
	 start solving instance: 96...
	 start solving instance: 38...
	 start solving instance: 43...
	 start solving instance: 39...
	 start solving instance: 73...
	 start solving instance: 72...
	 start solving instance: 29...
	 start solving instance: 68...
	 start solving instance: 126...
	 start solving instance: 102...
	 start solving instance: 113...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 3990.572998046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.75593376159668
		 entropy bonus: 0.3229653239250183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.93399429321289
		 entropy bonus: 0.08530207723379135
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.706857681274414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 478.41326904296875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3990.572998046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.675689697265625
		 entropy bonus: 0.31777307391166687
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.89687728881836
		 entropy bonus: 0.0852700024843216
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.706857681274414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 478.29644775390625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3990.572998046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.450973510742188
		 entropy bonus: 0.32214102149009705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -32.83917999267578
		 entropy bonus: 0.08437992632389069
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.706857681274414
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 478.013671875 - Differentiable computation graph = True!
PPO iteration: 35/1000:
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 96...
	 start solving instance: 23...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 29...
	 start solving instance: 19...
	 start solving instance: 4...
	 start solving instance: 126...
	 start solving instance: 72...
	 start solving instance: 68...
	 start solving instance: 115...
	 start solving instance: 86...
	 start solving instance: 147...
	 start solving instance: 13...
	 start solving instance: 39...
	 start solving instance: 43...
	 start solving instance: 87...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4547.55810546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -30.865814208984375
		 entropy bonus: 0.31616806983947754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.09058380126953
		 entropy bonus: 0.0891909971833229
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.040327072143555
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535.7120361328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4547.55810546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -30.464160919189453
		 entropy bonus: 0.31560659408569336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.0450439453125
		 entropy bonus: 0.08882474899291992
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.040327072143555
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535.264892578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4547.55810546875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -30.23722267150879
		 entropy bonus: 0.31766682863235474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.03068161010742
		 entropy bonus: 0.08882385492324829
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17.040327072143555
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535.0233764648438 - Differentiable computation graph = True!
PPO iteration: 36/1000:
	 start solving instance: 147...
	 start solving instance: 72...
	 start solving instance: 19...
	 start solving instance: 43...
	 start solving instance: 4...
	 start solving instance: 29...
	 start solving instance: 113...
	 start solving instance: 23...
	 start solving instance: 39...
	 start solving instance: 68...
	 start solving instance: 38...
	 start solving instance: 86...
	 start solving instance: 102...
	 start solving instance: 13...
	 start solving instance: 126...
	 start solving instance: 115...
	 start solving instance: 87...
	 start solving instance: 73...
	 start solving instance: 96...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 5745.96923828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.865442276000977
		 entropy bonus: 0.32403045892715454
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.140140533447266
		 entropy bonus: 0.07268714904785156
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.34543514251709
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652.9082641601562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5745.96923828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.314619064331055
		 entropy bonus: 0.3237393796443939
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.107666015625
		 entropy bonus: 0.0728209912776947
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.34543514251709
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652.324951171875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5745.96923828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.228687286376953
		 entropy bonus: 0.3221431374549866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.01409912109375
		 entropy bonus: 0.07282537966966629
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.34543514251709
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652.1456298828125 - Differentiable computation graph = True!
PPO iteration: 37/1000:
	 start solving instance: 106...
	 start solving instance: 86...
	 start solving instance: 68...
	 start solving instance: 126...
	 start solving instance: 29...
	 start solving instance: 96...
	 start solving instance: 38...
	 start solving instance: 4...
	 start solving instance: 13...
	 start solving instance: 23...
	 start solving instance: 113...
	 start solving instance: 87...
	 start solving instance: 43...
	 start solving instance: 39...
	 start solving instance: 72...
	 start solving instance: 102...
	 start solving instance: 73...
	 start solving instance: 19...
	 start solving instance: 147...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 8409.1005859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.809417724609375
		 entropy bonus: 0.3139008581638336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -48.05622100830078
		 entropy bonus: 0.12817396223545074
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.854263305664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 942.5857543945312 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 8409.1005859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.28276443481445
		 entropy bonus: 0.3127504289150238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -47.75590896606445
		 entropy bonus: 0.12651239335536957
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.854263305664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 941.7590942382812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 8409.1005859375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.37236404418945
		 entropy bonus: 0.31228795647621155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -47.74702453613281
		 entropy bonus: 0.12703588604927063
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.854263305664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 941.8397827148438 - Differentiable computation graph = True!
PPO iteration: 38/1000:
	 start solving instance: 102...
	 start solving instance: 38...
	 start solving instance: 19...
	 start solving instance: 106...
	 start solving instance: 29...
	 start solving instance: 23...
	 start solving instance: 126...
	 start solving instance: 72...
	 start solving instance: 4...
	 start solving instance: 86...
	 start solving instance: 39...
	 start solving instance: 73...
	 start solving instance: 147...
	 start solving instance: 115...
	 start solving instance: 87...
	 start solving instance: 96...
	 start solving instance: 113...
	 start solving instance: 13...
	 start solving instance: 43...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 5648.966796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.41469192504883
		 entropy bonus: 0.3062755763530731
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.80836868286133
		 entropy bonus: 0.08409946411848068
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.957117080688477
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652.037841796875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5648.966796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.11648941040039
		 entropy bonus: 0.31755849719047546
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.63880157470703
		 entropy bonus: 0.08486141264438629
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.957117080688477
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 652.56884765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5648.966796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.366676330566406
		 entropy bonus: 0.29926466941833496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.64270782470703
		 entropy bonus: 0.08508208394050598
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.957117080688477
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 651.82470703125 - Differentiable computation graph = True!
PPO iteration: 39/1000:
	 start solving instance: 23...
	 start solving instance: 113...
	 start solving instance: 147...
	 start solving instance: 115...
	 start solving instance: 73...
	 start solving instance: 4...
	 start solving instance: 19...
	 start solving instance: 86...
	 start solving instance: 39...
	 start solving instance: 96...
	 start solving instance: 43...
	 start solving instance: 102...
	 start solving instance: 106...
	 start solving instance: 126...
	 start solving instance: 38...
	 start solving instance: 13...
	 start solving instance: 29...
	 start solving instance: 87...
	 start solving instance: 68...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 4452.84814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.83587646484375
		 entropy bonus: 0.30270859599113464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.988624572753906
		 entropy bonus: 0.07863321900367737
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.706412315368652
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 524.777587890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4452.84814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.629505157470703
		 entropy bonus: 0.3006291389465332
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.9887580871582
		 entropy bonus: 0.07870732247829437
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.706412315368652
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 524.5715942382812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4452.84814453125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.527647018432617
		 entropy bonus: 0.2975907027721405
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.95626449584961
		 entropy bonus: 0.07863928377628326
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15.706412315368652
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 524.4375 - Differentiable computation graph = True!
PPO iteration: 40/1000:
	 start solving instance: 38...
	 start solving instance: 68...
	 start solving instance: 23...
	 start solving instance: 13...
	 start solving instance: 113...
	 start solving instance: 43...
	 start solving instance: 115...
	 start solving instance: 86...
	 start solving instance: 96...
	 start solving instance: 102...
	 start solving instance: 29...
	 start solving instance: 72...
	 start solving instance: 73...
	 start solving instance: 106...
	 start solving instance: 39...
	 start solving instance: 147...
	 start solving instance: 4...
	 start solving instance: 87...
	 start solving instance: 126...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 3951.741455078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -30.09405517578125
		 entropy bonus: 0.29341909289360046
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.294660568237305
		 entropy bonus: 0.06284032016992569
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.683151245117188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 473.2104187011719 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3951.741455078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.323644638061523
		 entropy bonus: 0.3156800866127014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.253686904907227
		 entropy bonus: 0.06301020830869675
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.683151245117188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 472.39678955078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3951.741455078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -29.163166046142578
		 entropy bonus: 0.3157343566417694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.187753677368164
		 entropy bonus: 0.06324366480112076
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.683151245117188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 472.17034912109375 - Differentiable computation graph = True!
PPO iteration: 41/1000:
	 New training batch of size 20...
	 start solving instance: 69...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 34...
	 start solving instance: 45...
	 start solving instance: 90...
	 start solving instance: 91...
	 start solving instance: 23...
	 start solving instance: 37...
	 start solving instance: 58...
	 start solving instance: 85...
	 start solving instance: 67...
	 start solving instance: 150...
	 start solving instance: 124...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 57...
	 start solving instance: 79...
	 start solving instance: 40...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 6553.09716796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -41.54667282104492
		 entropy bonus: 0.3095491826534271
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.986968994140625
		 entropy bonus: 0.0895407572388649
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.805233001708984
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 754.6087036132812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6553.09716796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -41.44488525390625
		 entropy bonus: 0.3129768371582031
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.832271575927734
		 entropy bonus: 0.08957693725824356
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.805233001708984
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 754.3518676757812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6553.09716796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -40.6237678527832
		 entropy bonus: 0.3060153126716614
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.770748138427734
		 entropy bonus: 0.08926274627447128
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.805233001708984
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 753.469970703125 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 7391.796875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.531158447265625
		 entropy bonus: 0.31686580181121826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.10728073120117
		 entropy bonus: 0.08252089470624924
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.99044418334961
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 828.7686
PPO iteration: 42/1000:
	 start solving instance: 143...
	 start solving instance: 69...
	 start solving instance: 148...
	 start solving instance: 57...
	 start solving instance: 28...
	 start solving instance: 91...
	 start solving instance: 150...
	 start solving instance: 58...
	 start solving instance: 79...
	 start solving instance: 45...
	 start solving instance: 85...
	 start solving instance: 67...
	 start solving instance: 124...
	 start solving instance: 90...
	 start solving instance: 37...
	 start solving instance: 34...
	 start solving instance: 40...
	 start solving instance: 4...
	 start solving instance: 105...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 5856.37646484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.97190475463867
		 entropy bonus: 0.30517297983169556
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.78658676147461
		 entropy bonus: 0.0783359557390213
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.762466430664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 681.1202392578125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5856.37646484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.01003646850586
		 entropy bonus: 0.3219913840293884
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.68000030517578
		 entropy bonus: 0.078524649143219
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.762466430664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 681.0501098632812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5856.37646484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.519378662109375
		 entropy bonus: 0.3176369071006775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.613033294677734
		 entropy bonus: 0.07865405082702637
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.762466430664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 680.4928588867188 - Differentiable computation graph = True!
PPO iteration: 43/1000:
	 start solving instance: 58...
	 start solving instance: 67...
	 start solving instance: 90...
	 start solving instance: 143...
	 start solving instance: 69...
	 start solving instance: 34...
	 start solving instance: 40...
	 start solving instance: 28...
	 start solving instance: 150...
	 start solving instance: 37...
	 start solving instance: 124...
	 start solving instance: 23...
	 start solving instance: 4...
	 start solving instance: 85...
	 start solving instance: 45...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 148...
	 start solving instance: 57...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 4463.34326171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.02262496948242
		 entropy bonus: 0.3112536668777466
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.542261123657227
		 entropy bonus: 0.0845135822892189
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.505298614501953
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535.3649291992188 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4463.34326171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.51306915283203
		 entropy bonus: 0.32443681359291077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.48280143737793
		 entropy bonus: 0.0847281962633133
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.505298614501953
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535.7945556640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4463.34326171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.545894622802734
		 entropy bonus: 0.3245548903942108
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -31.4302978515625
		 entropy bonus: 0.08485125750303268
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.505298614501953
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 535.7748413085938 - Differentiable computation graph = True!
PPO iteration: 44/1000:
	 start solving instance: 45...
	 start solving instance: 28...
	 start solving instance: 90...
	 start solving instance: 85...
	 start solving instance: 4...
	 start solving instance: 37...
	 start solving instance: 91...
	 start solving instance: 143...
	 start solving instance: 67...
	 start solving instance: 40...
	 start solving instance: 58...
	 start solving instance: 148...
	 start solving instance: 23...
	 start solving instance: 105...
	 start solving instance: 34...
	 start solving instance: 69...
	 start solving instance: 79...
	 start solving instance: 124...
	 start solving instance: 57...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 7053.07421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.25764083862305
		 entropy bonus: 0.31503280997276306
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.04058837890625
		 entropy bonus: 0.07638672739267349
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.05095863342285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 801.6174926757812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7053.07421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.125885009765625
		 entropy bonus: 0.3113444745540619
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.834205627441406
		 entropy bonus: 0.07652134448289871
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.05095863342285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 801.2796630859375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7053.07421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.99778747558594
		 entropy bonus: 0.3139513432979584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.71583938598633
		 entropy bonus: 0.0762220025062561
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.05095863342285
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 801.032958984375 - Differentiable computation graph = True!
PPO iteration: 45/1000:
	 start solving instance: 57...
	 start solving instance: 79...
	 start solving instance: 67...
	 start solving instance: 85...
	 start solving instance: 148...
	 start solving instance: 69...
	 start solving instance: 143...
	 start solving instance: 40...
	 start solving instance: 4...
	 start solving instance: 45...
	 start solving instance: 34...
	 start solving instance: 105...
	 start solving instance: 91...
	 start solving instance: 58...
	 start solving instance: 23...
	 start solving instance: 124...
	 start solving instance: 37...
	 start solving instance: 90...
	 start solving instance: 28...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 6903.50927734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.46973419189453
		 entropy bonus: 0.3148277699947357
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.68722152709961
		 entropy bonus: 0.06199733167886734
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.56672477722168
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 780.0369262695312 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6903.50927734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.22529220581055
		 entropy bonus: 0.303438276052475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.626678466796875
		 entropy bonus: 0.06166020780801773
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.56672477722168
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 779.733154296875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6903.50927734375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.12421417236328
		 entropy bonus: 0.3019322454929352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -34.50881576538086
		 entropy bonus: 0.06169150024652481
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16.56672477722168
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 779.5143432617188 - Differentiable computation graph = True!
PPO iteration: 46/1000:
	 start solving instance: 67...
	 start solving instance: 58...
	 start solving instance: 57...
	 start solving instance: 105...
	 start solving instance: 28...
	 start solving instance: 124...
	 start solving instance: 23...
	 start solving instance: 91...
	 start solving instance: 150...
	 start solving instance: 4...
	 start solving instance: 143...
	 start solving instance: 148...
	 start solving instance: 85...
	 start solving instance: 90...
	 start solving instance: 40...
	 start solving instance: 69...
	 start solving instance: 79...
	 start solving instance: 37...
	 start solving instance: 45...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 6715.7236328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -40.84956741333008
		 entropy bonus: 0.318624883890152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.57318115234375
		 entropy bonus: 0.08818409591913223
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.988941192626953
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 773.943359375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6715.7236328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -40.72520065307617
		 entropy bonus: 0.32109376788139343
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.36918640136719
		 entropy bonus: 0.08755950629711151
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.988941192626953
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 773.6148681640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6715.7236328125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -40.33603286743164
		 entropy bonus: 0.3171721398830414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.296871185302734
		 entropy bonus: 0.08673938363790512
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -19.988941192626953
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 773.1538696289062 - Differentiable computation graph = True!
PPO iteration: 47/1000:
	 start solving instance: 34...
	 start solving instance: 23...
	 start solving instance: 79...
	 start solving instance: 58...
	 start solving instance: 40...
	 start solving instance: 4...
	 start solving instance: 45...
	 start solving instance: 57...
	 start solving instance: 91...
	 start solving instance: 124...
	 start solving instance: 69...
	 start solving instance: 90...
	 start solving instance: 143...
	 start solving instance: 67...
	 start solving instance: 150...
	 start solving instance: 37...
	 start solving instance: 148...
	 start solving instance: 85...
	 start solving instance: 105...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 4815.94873046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.49308395385742
		 entropy bonus: 0.3154635429382324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.934261322021484
		 entropy bonus: 0.08194151520729065
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.30196762084961
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 569.284423828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4815.94873046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -35.152992248535156
		 entropy bonus: 0.3095531463623047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.75299835205078
		 entropy bonus: 0.08140305429697037
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.30196762084961
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 568.7637329101562 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4815.94873046875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.840328216552734
		 entropy bonus: 0.312776654958725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.634883880615234
		 entropy bonus: 0.08111255615949631
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18.30196762084961
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 568.3326416015625 - Differentiable computation graph = True!
PPO iteration: 48/1000:
	 start solving instance: 85...
	 start solving instance: 148...
	 start solving instance: 150...
	 start solving instance: 69...
	 start solving instance: 91...
	 start solving instance: 4...
	 start solving instance: 67...
	 start solving instance: 23...
	 start solving instance: 45...
	 start solving instance: 124...
	 start solving instance: 28...
	 start solving instance: 37...
	 start solving instance: 105...
	 start solving instance: 57...
	 start solving instance: 40...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 58...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 6878.35791015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.53830337524414
		 entropy bonus: 0.31838175654411316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.42380905151367
		 entropy bonus: 0.08381645381450653
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.273733139038086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 786.0314331054688 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6878.35791015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.794551849365234
		 entropy bonus: 0.31687402725219727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.60471725463867
		 entropy bonus: 0.07797323912382126
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.273733139038086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 786.4693603515625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6878.35791015625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.4537467956543
		 entropy bonus: 0.31928104162216187
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -39.33516311645508
		 entropy bonus: 0.07977069914340973
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.273733139038086
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 785.8585205078125 - Differentiable computation graph = True!
PPO iteration: 49/1000:
	 start solving instance: 67...
	 start solving instance: 105...
	 start solving instance: 58...
	 start solving instance: 40...
	 start solving instance: 28...
	 start solving instance: 85...
	 start solving instance: 143...
	 start solving instance: 91...
	 start solving instance: 45...
	 start solving instance: 4...
	 start solving instance: 124...
	 start solving instance: 150...
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 23...
	 start solving instance: 37...
	 start solving instance: 90...
	 start solving instance: 57...
	 start solving instance: 69...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 6647.078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.6998176574707
		 entropy bonus: 0.3119785189628601
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.10728454589844
		 entropy bonus: 0.08634775131940842
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.01811981201172
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 759.4932250976562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6647.078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.419063568115234
		 entropy bonus: 0.31160038709640503
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -35.855525970458984
		 entropy bonus: 0.08441219478845596
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.01811981201172
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 758.9609375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6647.078125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.92221450805664
		 entropy bonus: 0.31174784898757935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -35.785186767578125
		 entropy bonus: 0.08568406105041504
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.01811981201172
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 758.3936157226562 - Differentiable computation graph = True!
PPO iteration: 50/1000:
	 start solving instance: 150...
	 start solving instance: 4...
	 start solving instance: 143...
	 start solving instance: 67...
	 start solving instance: 58...
	 start solving instance: 45...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 28...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 57...
	 start solving instance: 69...
	 start solving instance: 40...
	 start solving instance: 105...
	 start solving instance: 37...
	 start solving instance: 124...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 5427.0048828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.25071716308594
		 entropy bonus: 0.3234255015850067
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.61121368408203
		 entropy bonus: 0.08897726982831955
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.97249984741211
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 639.4937133789062 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5427.0048828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.830928802490234
		 entropy bonus: 0.322415292263031
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.422664642333984
		 entropy bonus: 0.08925368636846542
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.97249984741211
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 638.8854370117188 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5427.0048828125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.438720703125
		 entropy bonus: 0.3223056197166443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.364681243896484
		 entropy bonus: 0.08631999790668488
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.97249984741211
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 638.435546875 - Differentiable computation graph = True!
PPO iteration: 51/1000:
	 New training batch of size 20...
	 start solving instance: 79...
	 start solving instance: 77...
	 start solving instance: 64...
	 start solving instance: 107...
	 start solving instance: 138...
	 start solving instance: 121...
	 start solving instance: 50...
	 start solving instance: 59...
	 start solving instance: 42...
	 start solving instance: 54...
	 start solving instance: 142...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 26...
	 start solving instance: 10...
	 start solving instance: 129...
	 start solving instance: 115...
	 start solving instance: 69...
	 start solving instance: 80...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 9379.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -42.642364501953125
		 entropy bonus: 0.31799134612083435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -46.02357864379883
		 entropy bonus: 0.0869939848780632
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.36090660095215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1051.916015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9379.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -42.737762451171875
		 entropy bonus: 0.31649646162986755
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -45.648983001708984
		 entropy bonus: 0.08680886030197144
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.36090660095215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1051.636962890625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9379.296875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -42.31673049926758
		 entropy bonus: 0.315540075302124
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -45.62343978881836
		 entropy bonus: 0.09037399291992188
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.36090660095215
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1051.190185546875 - Differentiable computation graph = True!
PPO iteration: 52/1000:
	 start solving instance: 64...
	 start solving instance: 26...
	 start solving instance: 121...
	 start solving instance: 79...
	 start solving instance: 138...
	 start solving instance: 50...
	 start solving instance: 115...
	 start solving instance: 107...
	 start solving instance: 69...
	 start solving instance: 42...
	 start solving instance: 36...
	 start solving instance: 77...
	 start solving instance: 80...
	 start solving instance: 129...
	 start solving instance: 10...
	 start solving instance: 89...
	 start solving instance: 59...
	 start solving instance: 142...
	 start solving instance: 46...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 5392.97412109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -37.10295867919922
		 entropy bonus: 0.31715208292007446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -40.753047943115234
		 entropy bonus: 0.09538623690605164
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.165760040283203
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 641.2779541015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5392.97412109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.73786544799805
		 entropy bonus: 0.27673205733299255
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.17072296142578
		 entropy bonus: 0.08310120552778244
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.165760040283203
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 643.3358154296875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5392.97412109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.98287582397461
		 entropy bonus: 0.265733540058136
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -42.08335494995117
		 entropy bonus: 0.08047322928905487
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.165760040283203
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 644.4948120117188 - Differentiable computation graph = True!
PPO iteration: 53/1000:
	 start solving instance: 129...
	 start solving instance: 26...
	 start solving instance: 80...
	 start solving instance: 64...
	 start solving instance: 10...
	 start solving instance: 138...
	 start solving instance: 89...
	 start solving instance: 42...
	 start solving instance: 121...
	 start solving instance: 142...
	 start solving instance: 115...
	 start solving instance: 79...
	 start solving instance: 54...
	 start solving instance: 59...
	 start solving instance: 46...
	 start solving instance: 107...
	 start solving instance: 69...
	 start solving instance: 36...
	 start solving instance: 50...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 6820.03271484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.844051361083984
		 entropy bonus: 0.2870939373970032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.31821823120117
		 entropy bonus: 0.05219399929046631
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.25042724609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 786.382080078125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6820.03271484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.86220169067383
		 entropy bonus: 0.2834900915622711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.294708251953125
		 entropy bonus: 0.05308380350470543
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.25042724609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 786.376953125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6820.03271484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.92326354980469
		 entropy bonus: 0.3210581839084625
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.43049621582031
		 entropy bonus: 0.054885756224393845
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -24.25042724609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 787.5698852539062 - Differentiable computation graph = True!
PPO iteration: 54/1000:
	 start solving instance: 59...
	 start solving instance: 54...
	 start solving instance: 36...
	 start solving instance: 42...
	 start solving instance: 138...
	 start solving instance: 69...
	 start solving instance: 121...
	 start solving instance: 129...
	 start solving instance: 10...
	 start solving instance: 89...
	 start solving instance: 77...
	 start solving instance: 26...
	 start solving instance: 107...
	 start solving instance: 142...
	 start solving instance: 115...
	 start solving instance: 79...
	 start solving instance: 64...
	 start solving instance: 50...
	 start solving instance: 80...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4841.39990234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.23089599609375
		 entropy bonus: 0.29891905188560486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.974666595458984
		 entropy bonus: 0.048312149941921234
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.11703872680664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 576.4278564453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4841.39990234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.54107666015625
		 entropy bonus: 0.2890048027038574
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.0857048034668
		 entropy bonus: 0.04569045826792717
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.11703872680664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 576.850341796875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4841.39990234375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.948888778686523
		 entropy bonus: 0.3091566264629364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.88591003417969
		 entropy bonus: 0.04723268747329712
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.11703872680664
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 576.0562133789062 - Differentiable computation graph = True!
PPO iteration: 55/1000:
	 start solving instance: 79...
	 start solving instance: 64...
	 start solving instance: 69...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 54...
	 start solving instance: 138...
	 start solving instance: 59...
	 start solving instance: 142...
	 start solving instance: 46...
	 start solving instance: 115...
	 start solving instance: 80...
	 start solving instance: 26...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 50...
	 start solving instance: 77...
	 start solving instance: 121...
	 start solving instance: 129...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 7784.38037109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.543861389160156
		 entropy bonus: 0.31762439012527466
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -44.914955139160156
		 entropy bonus: 0.060550738126039505
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.739891052246094
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 879.5989379882812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7784.38037109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.15478515625
		 entropy bonus: 0.32456687092781067
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -44.82011032104492
		 entropy bonus: 0.06102921441197395
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.739891052246094
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 879.1142578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7784.38037109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.95092010498047
		 entropy bonus: 0.32539716362953186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -44.68930435180664
		 entropy bonus: 0.061202067881822586
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.739891052246094
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 878.779541015625 - Differentiable computation graph = True!
PPO iteration: 56/1000:
	 start solving instance: 69...
	 start solving instance: 138...
	 start solving instance: 46...
	 start solving instance: 89...
	 start solving instance: 77...
	 start solving instance: 59...
	 start solving instance: 80...
	 start solving instance: 54...
	 start solving instance: 36...
	 start solving instance: 64...
	 start solving instance: 142...
	 start solving instance: 26...
	 start solving instance: 121...
	 start solving instance: 115...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 10...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 5420.5947265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.34055709838867
		 entropy bonus: 0.32184097170829773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.847564697265625
		 entropy bonus: 0.07217281311750412
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.156187057495117
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 634.3643798828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5420.5947265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.2811279296875
		 entropy bonus: 0.32285580039024353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.8276481628418
		 entropy bonus: 0.07162361592054367
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.156187057495117
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 634.2850341796875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5420.5947265625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -34.47719955444336
		 entropy bonus: 0.3129664361476898
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -36.77010726928711
		 entropy bonus: 0.07145923376083374
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.156187057495117
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 634.424560546875 - Differentiable computation graph = True!
PPO iteration: 57/1000:
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 26...
	 start solving instance: 79...
	 start solving instance: 77...
	 start solving instance: 50...
	 start solving instance: 54...
	 start solving instance: 80...
	 start solving instance: 115...
	 start solving instance: 138...
	 start solving instance: 121...
	 start solving instance: 46...
	 start solving instance: 89...
	 start solving instance: 42...
	 start solving instance: 59...
	 start solving instance: 64...
	 start solving instance: 129...
	 start solving instance: 69...
	 start solving instance: 142...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4364.84375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -28.894256591796875
		 entropy bonus: 0.3082776665687561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.82209396362305
		 entropy bonus: 0.047720130532979965
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.41640281677246
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520.58154296875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4364.84375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -28.44187355041504
		 entropy bonus: 0.31633272767066956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.809608459472656
		 entropy bonus: 0.0479537658393383
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.41640281677246
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 520.1158447265625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4364.84375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -28.28167152404785
		 entropy bonus: 0.31713637709617615
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -33.78407669067383
		 entropy bonus: 0.04814376309514046
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -21.41640281677246
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 519.9299926757812 - Differentiable computation graph = True!
PPO iteration: 58/1000:
	 start solving instance: 69...
	 start solving instance: 115...
	 start solving instance: 138...
	 start solving instance: 36...
	 start solving instance: 59...
	 start solving instance: 64...
	 start solving instance: 107...
	 start solving instance: 10...
	 start solving instance: 79...
	 start solving instance: 54...
	 start solving instance: 77...
	 start solving instance: 42...
	 start solving instance: 129...
	 start solving instance: 142...
	 start solving instance: 46...
	 start solving instance: 89...
	 start solving instance: 121...
	 start solving instance: 26...
	 start solving instance: 50...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 5498.75390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -31.850065231323242
		 entropy bonus: 0.322526216506958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.1947135925293
		 entropy bonus: 0.04609989747405052
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.455886840820312
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 640.3392333984375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5498.75390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.31368637084961
		 entropy bonus: 0.27712884545326233
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.154720306396484
		 entropy bonus: 0.045891012996435165
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.455886840820312
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 640.7673950195312 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5498.75390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -32.418582916259766
		 entropy bonus: 0.26439687609672546
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.130855560302734
		 entropy bonus: 0.045850709080696106
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -20.455886840820312
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 640.8497314453125 - Differentiable computation graph = True!
PPO iteration: 59/1000:
	 start solving instance: 129...
	 start solving instance: 79...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 138...
	 start solving instance: 59...
	 start solving instance: 80...
	 start solving instance: 54...
	 start solving instance: 50...
	 start solving instance: 142...
	 start solving instance: 10...
	 start solving instance: 115...
	 start solving instance: 69...
	 start solving instance: 64...
	 start solving instance: 77...
	 start solving instance: 46...
	 start solving instance: 89...
	 start solving instance: 121...
	 start solving instance: 36...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 7878.03857421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.20635986328125
		 entropy bonus: 0.25626832246780396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -50.7984733581543
		 entropy bonus: 0.07949799299240112
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -29.902326583862305
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 907.677490234375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7878.03857421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.8391227722168
		 entropy bonus: 0.2584664821624756
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -51.12978744506836
		 entropy bonus: 0.07826753705739975
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -29.902326583862305
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 907.6414794921875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7878.03857421875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.4363899230957
		 entropy bonus: 0.2866551876068115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -50.8881950378418
		 entropy bonus: 0.07716641575098038
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -29.902326583862305
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 906.994384765625 - Differentiable computation graph = True!
PPO iteration: 60/1000:
	 start solving instance: 59...
	 start solving instance: 50...
	 start solving instance: 77...
	 start solving instance: 64...
	 start solving instance: 138...
	 start solving instance: 107...
	 start solving instance: 54...
	 start solving instance: 79...
	 start solving instance: 142...
	 start solving instance: 42...
	 start solving instance: 121...
	 start solving instance: 115...
	 start solving instance: 26...
	 start solving instance: 69...
	 start solving instance: 129...
	 start solving instance: 36...
	 start solving instance: 89...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4982.12744140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -33.99234390258789
		 entropy bonus: 0.2959783971309662
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.31378173828125
		 entropy bonus: 0.036101456731557846
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -27.028541564941406
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 596.51416015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4982.12744140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.63916778564453
		 entropy bonus: 0.28004440665245056
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.291805267333984
		 entropy bonus: 0.03653251379728317
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -27.028541564941406
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 601.140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4982.12744140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -38.74818801879883
		 entropy bonus: 0.27766671776771545
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.2943115234375
		 entropy bonus: 0.03659544140100479
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -27.028541564941406
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 601.2523803710938 - Differentiable computation graph = True!
PPO iteration: 61/1000:
	 New training batch of size 20...
	 start solving instance: 114...
	 start solving instance: 1...
	 start solving instance: 101...
	 start solving instance: 39...
	 start solving instance: 105...
	 start solving instance: 61...
	 start solving instance: 60...
	 start solving instance: 142...
	 start solving instance: 87...
	 start solving instance: 31...
	 start solving instance: 132...
	 start solving instance: 93...
	 start solving instance: 12...
	 start solving instance: 64...
	 start solving instance: 17...
	 start solving instance: 24...
	 start solving instance: 13...
	 start solving instance: 38...
	 start solving instance: 113...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 12061.3349609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -58.20858383178711
		 entropy bonus: 0.274151086807251
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -48.05893325805664
		 entropy bonus: 0.04644141346216202
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -29.597755432128906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1341.966796875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 12061.3349609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -56.56699752807617
		 entropy bonus: 0.27355167269706726
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -47.93494415283203
		 entropy bonus: 0.04579554870724678
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -29.597755432128906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1340.2012939453125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 12061.3349609375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -55.821136474609375
		 entropy bonus: 0.2989252507686615
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -47.93716049194336
		 entropy bonus: 0.04615920037031174
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -29.597755432128906
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1339.455078125 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 10786.65625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -39.16469192504883
		 entropy bonus: 0.3124542534351349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -54.303585052490234
		 entropy bonus: 0.10767390578985214
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -25.77947998046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1197.8713
PPO iteration: 62/1000:
	 start solving instance: 39...
	 start solving instance: 64...
	 start solving instance: 38...
	 start solving instance: 93...
	 start solving instance: 142...
	 start solving instance: 60...
	 start solving instance: 17...
	 start solving instance: 114...
	 start solving instance: 127...
	 start solving instance: 61...
	 start solving instance: 13...
	 start solving instance: 87...
	 start solving instance: 113...
	 start solving instance: 101...
	 start solving instance: 1...
	 start solving instance: 31...
	 start solving instance: 132...
	 start solving instance: 12...
	 start solving instance: 105...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 13058.6787109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -53.9176139831543
		 entropy bonus: 0.31169408559799194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -52.347347259521484
		 entropy bonus: 0.09736745804548264
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -28.349281311035156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1440.4412841796875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 13058.6787109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -58.115753173828125
		 entropy bonus: 0.22990036010742188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -52.304443359375
		 entropy bonus: 0.09670602530241013
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -28.349281311035156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1444.604736328125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 13058.6787109375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -57.58449935913086
		 entropy bonus: 0.22923579812049866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -52.423927307128906
		 entropy bonus: 0.09587810933589935
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -28.349281311035156
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1444.193115234375 - Differentiable computation graph = True!
PPO iteration: 63/1000:
	 start solving instance: 24...
	 start solving instance: 142...
	 start solving instance: 60...
	 start solving instance: 13...
	 start solving instance: 17...
	 start solving instance: 132...
	 start solving instance: 38...
	 start solving instance: 87...
	 start solving instance: 105...
	 start solving instance: 113...
	 start solving instance: 31...
	 start solving instance: 93...
	 start solving instance: 64...
	 start solving instance: 127...
	 start solving instance: 39...
	 start solving instance: 12...
	 start solving instance: 114...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 11460.001953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.708404541015625
		 entropy bonus: 0.24285145103931427
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -41.46399688720703
		 entropy bonus: 0.08617568016052246
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.295101165771484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1254.434814453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 11460.001953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.565895080566406
		 entropy bonus: 0.29014039039611816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -42.08611297607422
		 entropy bonus: 0.08449645340442657
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.295101165771484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1254.909912109375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 11460.001953125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -44.50161361694336
		 entropy bonus: 0.3241541087627411
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -42.92493438720703
		 entropy bonus: 0.07540353387594223
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -22.295101165771484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1255.6820068359375 - Differentiable computation graph = True!
PPO iteration: 64/1000:
	 start solving instance: 101...
	 start solving instance: 12...
	 start solving instance: 39...
	 start solving instance: 127...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 24...
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 113...
	 start solving instance: 105...
	 start solving instance: 17...
	 start solving instance: 114...
	 start solving instance: 87...
	 start solving instance: 38...
	 start solving instance: 132...
	 start solving instance: 13...
	 start solving instance: 1...
	 start solving instance: 60...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 7695.82275390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -40.32615280151367
		 entropy bonus: 0.3143753707408905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -37.79417419433594
		 entropy bonus: 0.09291153401136398
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -14.616231918334961
		 entropy bonus: 0.011361218988895416
		 -----------------
	 Multi-agent batch loss: 862.2769775390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7695.82275390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -43.08386993408203
		 entropy bonus: 0.2856629192829132
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.4289665222168
		 entropy bonus: 0.08875136822462082
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -14.578489303588867
		 entropy bonus: 0.00032189450575970113
		 -----------------
	 Multi-agent batch loss: 865.6361083984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7695.82275390625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -49.50775909423828
		 entropy bonus: 0.24198512732982635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -38.889686584472656
		 entropy bonus: 0.03167429938912392
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -14.578489303588867
		 entropy bonus: 1.0813819457944351e-11
		 -----------------
	 Multi-agent batch loss: 872.5308837890625 - Differentiable computation graph = True!
PPO iteration: 65/1000:
	 start solving instance: 24...
	 start solving instance: 60...
	 start solving instance: 93...
	 start solving instance: 113...
	 start solving instance: 101...
	 start solving instance: 105...
	 start solving instance: 132...
	 start solving instance: 31...
	 start solving instance: 17...
	 start solving instance: 114...
	 start solving instance: 64...
	 start solving instance: 127...
	 start solving instance: 12...
	 start solving instance: 142...
	 start solving instance: 13...
	 start solving instance: 61...
	 start solving instance: 38...
	 start solving instance: 87...
	 start solving instance: 1...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 16949.369140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -69.24578094482422
		 entropy bonus: 0.2644360661506653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -100.76399230957031
		 entropy bonus: 0.012262245640158653
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -97.10122680664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1962.020263671875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 16949.369140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.5637435913086
		 entropy bonus: 0.19274179637432098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -101.67803192138672
		 entropy bonus: 0.0053715999238193035
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -97.10122680664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1964.260009765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 16949.369140625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -70.59317016601562
		 entropy bonus: 0.17287781834602356
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -102.2210922241211
		 entropy bonus: 0.001970954006537795
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -97.10122680664062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1964.8349609375 - Differentiable computation graph = True!
PPO iteration: 66/1000:
	 start solving instance: 142...
	 start solving instance: 87...
	 start solving instance: 1...
	 start solving instance: 39...
	 start solving instance: 101...
	 start solving instance: 38...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 13...
	 start solving instance: 114...
	 start solving instance: 12...
	 start solving instance: 132...
	 start solving instance: 127...
	 start solving instance: 17...
	 start solving instance: 31...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 64...
	 start solving instance: 60...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 88412.1171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -168.4597625732422
		 entropy bonus: 0.21463680267333984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -285.7385559082031
		 entropy bonus: 0.00010116609337273985
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -379.2603454589844
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9674.6494140625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 88412.1171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -167.4388427734375
		 entropy bonus: 0.21624107658863068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -285.3783874511719
		 entropy bonus: 0.0032409001141786575
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -379.2603454589844
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9673.267578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 88412.1171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -166.99172973632812
		 entropy bonus: 0.21947865188121796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -285.36932373046875
		 entropy bonus: 0.00038438779301941395
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -379.2603454589844
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9672.8115234375 - Differentiable computation graph = True!
PPO iteration: 67/1000:
	 start solving instance: 12...
	 start solving instance: 113...
	 start solving instance: 93...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 13...
	 start solving instance: 64...
	 start solving instance: 105...
	 start solving instance: 132...
	 start solving instance: 60...
	 start solving instance: 24...
	 start solving instance: 17...
	 start solving instance: 38...
	 start solving instance: 101...
	 start solving instance: 39...
	 start solving instance: 87...
	 start solving instance: 31...
	 start solving instance: 114...
	 start solving instance: 127...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 123303.6484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -247.2159423828125
		 entropy bonus: 0.2026861011981964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -325.3334655761719
		 entropy bonus: 0.00011526839080033824
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -405.9109191894531
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13308.8046875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 123303.6484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -247.7301483154297
		 entropy bonus: 0.19639348983764648
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -325.2230529785156
		 entropy bonus: 3.346112134750001e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -405.9109191894531
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13309.2099609375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 123303.6484375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -247.2752685546875
		 entropy bonus: 0.19538514316082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -324.6922302246094
		 entropy bonus: 6.870629931654548e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -405.9109191894531
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13308.224609375 - Differentiable computation graph = True!
PPO iteration: 68/1000:
	 start solving instance: 38...
	 start solving instance: 60...
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 24...
	 start solving instance: 12...
	 start solving instance: 132...
	 start solving instance: 64...
	 start solving instance: 142...
	 start solving instance: 39...
	 start solving instance: 93...
	 start solving instance: 13...
	 start solving instance: 1...
	 start solving instance: 105...
	 start solving instance: 114...
	 start solving instance: 17...
	 start solving instance: 101...
	 start solving instance: 127...
	 start solving instance: 87...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 150802.171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -285.2856140136719
		 entropy bonus: 0.20052461326122284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -382.9371032714844
		 entropy bonus: 0.0030351050663739443
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -469.10455322265625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16217.5244140625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 150802.171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -284.2842712402344
		 entropy bonus: 0.19950087368488312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -384.0997314453125
		 entropy bonus: 0.0005358959315344691
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -469.10455322265625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16217.6865234375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 150802.171875
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -284.3252868652344
		 entropy bonus: 0.19685083627700806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -384.02349853515625
		 entropy bonus: 0.00048237733426503837
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -469.10455322265625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16217.6513671875 - Differentiable computation graph = True!
PPO iteration: 69/1000:
	 start solving instance: 101...
	 start solving instance: 105...
	 start solving instance: 31...
	 start solving instance: 114...
	 start solving instance: 61...
	 start solving instance: 12...
	 start solving instance: 38...
	 start solving instance: 64...
	 start solving instance: 24...
	 start solving instance: 13...
	 start solving instance: 60...
	 start solving instance: 87...
	 start solving instance: 132...
	 start solving instance: 1...
	 start solving instance: 17...
	 start solving instance: 127...
	 start solving instance: 142...
	 start solving instance: 39...
	 start solving instance: 93...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 147698.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -277.0892639160156
		 entropy bonus: 0.20463962852954865
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -363.5080261230469
		 entropy bonus: 0.00042230842518620193
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -439.0888366699219
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15849.546875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 147698.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -276.5657653808594
		 entropy bonus: 0.2057701200246811
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -363.4882507324219
		 entropy bonus: 0.0006286835414357483
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -439.0888366699219
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15849.00390625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 147698.8125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -276.4029541015625
		 entropy bonus: 0.20644442737102509
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -363.3637390136719
		 entropy bonus: 0.0016065262025222182
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -439.0888366699219
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15848.7158203125 - Differentiable computation graph = True!
PPO iteration: 70/1000:
	 start solving instance: 39...
	 start solving instance: 127...
	 start solving instance: 64...
	 start solving instance: 87...
	 start solving instance: 31...
	 start solving instance: 1...
	 start solving instance: 24...
	 start solving instance: 132...
	 start solving instance: 101...
	 start solving instance: 61...
	 start solving instance: 17...
	 start solving instance: 114...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 38...
	 start solving instance: 113...
	 start solving instance: 12...
	 start solving instance: 60...
	 start solving instance: 13...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 115365.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -249.6682891845703
		 entropy bonus: 0.1915179193019867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -309.7617492675781
		 entropy bonus: 0.005171290598809719
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -348.4455871582031
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12444.4501953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 115365.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -249.26158142089844
		 entropy bonus: 0.19134236872196198
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -310.882080078125
		 entropy bonus: 0.005233413074165583
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -348.4455871582031
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12445.1630859375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 115365.9375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -248.2448272705078
		 entropy bonus: 0.19246920943260193
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -309.2742919921875
		 entropy bonus: 0.0009119468159042299
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -348.4455871582031
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12442.5390625 - Differentiable computation graph = True!
PPO iteration: 71/1000:
	 New training batch of size 20...
	 start solving instance: 119...
	 start solving instance: 102...
	 start solving instance: 103...
	 start solving instance: 108...
	 start solving instance: 135...
	 start solving instance: 132...
	 start solving instance: 4...
	 start solving instance: 52...
	 start solving instance: 87...
	 start solving instance: 38...
	 start solving instance: 79...
	 start solving instance: 107...
	 start solving instance: 41...
	 start solving instance: 35...
	 start solving instance: 149...
	 start solving instance: 43...
	 start solving instance: 1...
	 start solving instance: 90...
	 start solving instance: 20...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 149305.0625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 335.3747253417969
		 entropy bonus: 0.20003096759319305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 418.0757751464844
		 entropy bonus: 0.0022434100974351168
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 575.7515258789062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13601.28515625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 149305.0625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 335.3980407714844
		 entropy bonus: 0.19866661727428436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 414.80670166015625
		 entropy bonus: 0.0005358729977160692
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 575.7515258789062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13604.5302734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 149305.0625
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 335.0005798339844
		 entropy bonus: 0.19818751513957977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 412.4895935058594
		 entropy bonus: 6.290615033321956e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 575.7515258789062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 13607.2451171875 - Differentiable computation graph = True!
PPO iteration: 72/1000:
	 start solving instance: 90...
	 start solving instance: 1...
	 start solving instance: 135...
	 start solving instance: 79...
	 start solving instance: 35...
	 start solving instance: 20...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 87...
	 start solving instance: 149...
	 start solving instance: 52...
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 41...
	 start solving instance: 4...
	 start solving instance: 132...
	 start solving instance: 103...
	 start solving instance: 108...
	 start solving instance: 107...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 707430.3125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 695.7103881835938
		 entropy bonus: 0.2037123739719391
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 887.3621215820312
		 entropy bonus: 1.2733052244584542e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 1147.78369140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 68012.1484375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 707430.3125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 695.4194946289062
		 entropy bonus: 0.2036352902650833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 887.3659057617188
		 entropy bonus: 2.9078330499032745e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 1147.78369140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 68012.4453125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 707430.3125
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 695.802490234375
		 entropy bonus: 0.20372100174427032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 887.3666381835938
		 entropy bonus: 7.373523658316117e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 1147.78369140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 68012.0625 - Differentiable computation graph = True!
PPO iteration: 73/1000:
	 start solving instance: 52...
	 start solving instance: 149...
	 start solving instance: 4...
	 start solving instance: 41...
	 start solving instance: 79...
	 start solving instance: 102...
	 start solving instance: 38...
	 start solving instance: 119...
	 start solving instance: 90...
	 start solving instance: 35...
	 start solving instance: 87...
	 start solving instance: 132...
	 start solving instance: 43...
	 start solving instance: 135...
	 start solving instance: 20...
	 start solving instance: 1...
	 start solving instance: 46...
	 start solving instance: 103...
	 start solving instance: 107...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 445175.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 577.9677734375
		 entropy bonus: 0.19906121492385864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 679.7079467773438
		 entropy bonus: 0.0001455366291338578
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 982.3120727539062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 42277.51953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 445175.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 577.6408081054688
		 entropy bonus: 0.1991318315267563
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 679.7340698242188
		 entropy bonus: 3.683211027838418e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 982.3120727539062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 42277.8203125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 445175.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 577.5728759765625
		 entropy bonus: 0.1991933137178421
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 679.7340698242188
		 entropy bonus: 6.302505045630014e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 982.3120727539062
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 42277.88671875 - Differentiable computation graph = True!
PPO iteration: 74/1000:
	 start solving instance: 46...
	 start solving instance: 149...
	 start solving instance: 38...
	 start solving instance: 41...
	 start solving instance: 79...
	 start solving instance: 52...
	 start solving instance: 103...
	 start solving instance: 108...
	 start solving instance: 119...
	 start solving instance: 87...
	 start solving instance: 43...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 20...
	 start solving instance: 90...
	 start solving instance: 4...
	 start solving instance: 102...
	 start solving instance: 135...
	 start solving instance: 132...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 313892.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 443.0270690917969
		 entropy bonus: 0.2141530066728592
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 568.3500366210938
		 entropy bonus: 2.3168182650135094e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 780.8900756835938
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 29596.912109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 313892.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 443.31915283203125
		 entropy bonus: 0.21419814229011536
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 566.6331176757812
		 entropy bonus: 2.4335972126365846e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 780.8900756835938
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 29598.337890625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 313892.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 443.43701171875
		 entropy bonus: 0.21433964371681213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 566.6331176757812
		 entropy bonus: 2.363987339215612e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 780.8900756835938
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 29598.21875 - Differentiable computation graph = True!
PPO iteration: 75/1000:
	 start solving instance: 4...
	 start solving instance: 41...
	 start solving instance: 20...
	 start solving instance: 108...
	 start solving instance: 103...
	 start solving instance: 52...
	 start solving instance: 102...
	 start solving instance: 43...
	 start solving instance: 135...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 119...
	 start solving instance: 149...
	 start solving instance: 132...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 46...
	 start solving instance: 38...
	 start solving instance: 87...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 285430.84375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 392.7561340332031
		 entropy bonus: 0.22054629027843475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 554.1685791015625
		 entropy bonus: 2.141834374924656e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 714.0846557617188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26882.052734375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 285430.84375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 393.5589599609375
		 entropy bonus: 0.22082233428955078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 554.1644897460938
		 entropy bonus: 3.489833397907205e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 714.0846557617188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26881.25390625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 285430.84375
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: 394.4769592285156
		 entropy bonus: 0.22115139663219452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: 553.68505859375
		 entropy bonus: 0.0019663055427372456
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: 714.0846557617188
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 26880.814453125 - Differentiable computation graph = True!
PPO iteration: 76/1000:
	 start solving instance: 52...
	 start solving instance: 107...
	 start solving instance: 149...
	 start solving instance: 135...
	 start solving instance: 108...
	 start solving instance: 4...
	 start solving instance: 41...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 43...
	 start solving instance: 102...
	 start solving instance: 1...
	 start solving instance: 20...
	 start solving instance: 38...
	 start solving instance: 35...
	 start solving instance: 103...
	 start solving instance: 46...
	 start solving instance: 87...
	 start solving instance: 79...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 4757399.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1758.3609619140625
		 entropy bonus: 0.21333849430084229
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2318.560546875
		 entropy bonus: 0.00014068807649891824
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2443.537841796875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 482260.34375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4757399.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1752.9500732421875
		 entropy bonus: 0.2131175547838211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2317.481201171875
		 entropy bonus: 5.005262155265144e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2443.537841796875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 482253.875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4757399.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1751.6015625
		 entropy bonus: 0.21292097866535187
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2315.466064453125
		 entropy bonus: 1.5403140878333943e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2443.537841796875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 482250.5 - Differentiable computation graph = True!
PPO iteration: 77/1000:
	 start solving instance: 41...
	 start solving instance: 38...
	 start solving instance: 52...
	 start solving instance: 1...
	 start solving instance: 87...
	 start solving instance: 79...
	 start solving instance: 35...
	 start solving instance: 4...
	 start solving instance: 20...
	 start solving instance: 149...
	 start solving instance: 43...
	 start solving instance: 107...
	 start solving instance: 108...
	 start solving instance: 132...
	 start solving instance: 102...
	 start solving instance: 90...
	 start solving instance: 119...
	 start solving instance: 135...
	 start solving instance: 103...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 158183344.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10162.9677734375
		 entropy bonus: 0.21474145352840424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13334.712890625
		 entropy bonus: 0.0003632713051047176
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13872.2373046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15855705.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 158183344.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10141.1884765625
		 entropy bonus: 0.2115112543106079
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13317.119140625
		 entropy bonus: 1.4703339999526388e-15
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13872.2373046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15855665.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 158183344.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10122.8740234375
		 entropy bonus: 0.21169738471508026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13306.9033203125
		 entropy bonus: 1.991794316286155e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13872.2373046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15855637.0 - Differentiable computation graph = True!
PPO iteration: 78/1000:
	 start solving instance: 46...
	 start solving instance: 108...
	 start solving instance: 43...
	 start solving instance: 87...
	 start solving instance: 119...
	 start solving instance: 102...
	 start solving instance: 103...
	 start solving instance: 135...
	 start solving instance: 35...
	 start solving instance: 20...
	 start solving instance: 52...
	 start solving instance: 132...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 90...
	 start solving instance: 41...
	 start solving instance: 79...
	 start solving instance: 38...
	 start solving instance: 4...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 103361768.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -8208.4033203125
		 entropy bonus: 0.19976118206977844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10403.115234375
		 entropy bonus: 1.3156752076692868e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10872.8173828125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10365661.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 103361768.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -8162.22216796875
		 entropy bonus: 0.19539737701416016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10403.0517578125
		 entropy bonus: 1.329244150838349e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10872.8173828125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10365615.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 103361768.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -8138.81103515625
		 entropy bonus: 0.19459275901317596
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10398.01953125
		 entropy bonus: 0.0001298089191550389
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10872.8173828125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 10365587.0 - Differentiable computation graph = True!
PPO iteration: 79/1000:
	 start solving instance: 87...
	 start solving instance: 79...
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 149...
	 start solving instance: 90...
	 start solving instance: 103...
	 start solving instance: 4...
	 start solving instance: 135...
	 start solving instance: 132...
	 start solving instance: 35...
	 start solving instance: 108...
	 start solving instance: 52...
	 start solving instance: 1...
	 start solving instance: 43...
	 start solving instance: 46...
	 start solving instance: 119...
	 start solving instance: 20...
	 start solving instance: 107...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 94153168.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7070.37841796875
		 entropy bonus: 0.21287892758846283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10333.8095703125
		 entropy bonus: 3.039288543060792e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10800.7705078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9443522.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 94153168.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7053.8056640625
		 entropy bonus: 0.21153919398784637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10333.8095703125
		 entropy bonus: 6.451132488448363e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10800.7705078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9443506.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 94153168.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7027.33203125
		 entropy bonus: 0.20980380475521088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10326.0537109375
		 entropy bonus: 9.141877477247817e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10800.7705078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9443471.0 - Differentiable computation graph = True!
PPO iteration: 80/1000:
	 start solving instance: 79...
	 start solving instance: 103...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 4...
	 start solving instance: 52...
	 start solving instance: 38...
	 start solving instance: 87...
	 start solving instance: 35...
	 start solving instance: 119...
	 start solving instance: 107...
	 start solving instance: 20...
	 start solving instance: 108...
	 start solving instance: 46...
	 start solving instance: 149...
	 start solving instance: 102...
	 start solving instance: 135...
	 start solving instance: 132...
	 start solving instance: 41...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 90559112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6842.65185546875
		 entropy bonus: 0.2055809050798416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9970.0068359375
		 entropy bonus: 2.286239947357771e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10352.4111328125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9083076.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 90559112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6634.3173828125
		 entropy bonus: 0.2194768488407135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9968.1591796875
		 entropy bonus: 4.2310439312132075e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10352.4111328125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9082866.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 90559112.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6590.7578125
		 entropy bonus: 0.22340738773345947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9962.0595703125
		 entropy bonus: 0.00025792562519200146
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10352.4111328125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 9082816.0 - Differentiable computation graph = True!
PPO iteration: 81/1000:
	 New training batch of size 20...
	 start solving instance: 149...
	 start solving instance: 33...
	 start solving instance: 81...
	 start solving instance: 75...
	 start solving instance: 83...
	 start solving instance: 10...
	 start solving instance: 26...
	 start solving instance: 37...
	 start solving instance: 52...
	 start solving instance: 60...
	 start solving instance: 112...
	 start solving instance: 53...
	 start solving instance: 66...
	 start solving instance: 76...
	 start solving instance: 90...
	 start solving instance: 84...
	 start solving instance: 137...
	 start solving instance: 68...
	 start solving instance: 102...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 68044520.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6727.37646484375
		 entropy bonus: 0.22676296532154083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9096.994140625
		 entropy bonus: 5.628856923053446e-36
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9772.490234375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6830049.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 68044520.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6725.99072265625
		 entropy bonus: 0.22520063817501068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9094.9013671875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9772.490234375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6830045.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 68044520.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6710.5673828125
		 entropy bonus: 0.22348140180110931
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9094.9013671875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9772.490234375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6830030.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 85044224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7155.28125
		 entropy bonus: 0.1873612403869629
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9365.5234375
		 entropy bonus: 7.430813347387734e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -11254.697265625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8532198.0000
PPO iteration: 82/1000:
	 start solving instance: 60...
	 start solving instance: 52...
	 start solving instance: 84...
	 start solving instance: 66...
	 start solving instance: 68...
	 start solving instance: 83...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 53...
	 start solving instance: 10...
	 start solving instance: 81...
	 start solving instance: 102...
	 start solving instance: 75...
	 start solving instance: 149...
	 start solving instance: 98...
	 start solving instance: 33...
	 start solving instance: 26...
	 start solving instance: 37...
	 start solving instance: 112...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 69139512.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7240.6376953125
		 entropy bonus: 0.21732018887996674
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8874.9287109375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10147.826171875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6940215.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 69139512.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7202.66259765625
		 entropy bonus: 0.21866686642169952
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8874.9287109375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10147.826171875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6940177.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 69139512.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7227.3134765625
		 entropy bonus: 0.2186879962682724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8874.9287109375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10147.826171875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6940202.0 - Differentiable computation graph = True!
PPO iteration: 83/1000:
	 start solving instance: 37...
	 start solving instance: 68...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 26...
	 start solving instance: 76...
	 start solving instance: 149...
	 start solving instance: 83...
	 start solving instance: 84...
	 start solving instance: 75...
	 start solving instance: 52...
	 start solving instance: 98...
	 start solving instance: 66...
	 start solving instance: 102...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 60...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 127731288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -9577.8818359375
		 entropy bonus: 0.21284662187099457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11980.4619140625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13799.578125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12808487.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 127731288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -9598.4892578125
		 entropy bonus: 0.21183013916015625
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11980.4619140625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13799.578125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12808507.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 127731288.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -9551.912109375
		 entropy bonus: 0.20790767669677734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11980.4619140625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13799.578125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12808461.0 - Differentiable computation graph = True!
PPO iteration: 84/1000:
	 start solving instance: 84...
	 start solving instance: 83...
	 start solving instance: 68...
	 start solving instance: 149...
	 start solving instance: 60...
	 start solving instance: 112...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 98...
	 start solving instance: 10...
	 start solving instance: 33...
	 start solving instance: 52...
	 start solving instance: 75...
	 start solving instance: 26...
	 start solving instance: 81...
	 start solving instance: 102...
	 start solving instance: 137...
	 start solving instance: 37...
	 start solving instance: 76...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 454315328.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -18470.509765625
		 entropy bonus: 0.20647697150707245
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -22561.94140625
		 entropy bonus: 6.350991365089495e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -26057.869140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45498624.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 454315328.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -18456.416015625
		 entropy bonus: 0.20098666846752167
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -22561.94140625
		 entropy bonus: 2.5885073824135336e-28
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -26057.869140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45498608.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 454315328.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -18544.40625
		 entropy bonus: 0.1993238776922226
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -22561.94140625
		 entropy bonus: 4.10668483812711e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -26057.869140625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 45498696.0 - Differentiable computation graph = True!
PPO iteration: 85/1000:
	 start solving instance: 53...
	 start solving instance: 149...
	 start solving instance: 10...
	 start solving instance: 98...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 66...
	 start solving instance: 60...
	 start solving instance: 112...
	 start solving instance: 83...
	 start solving instance: 137...
	 start solving instance: 84...
	 start solving instance: 26...
	 start solving instance: 81...
	 start solving instance: 102...
	 start solving instance: 76...
	 start solving instance: 90...
	 start solving instance: 37...
	 start solving instance: 75...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 38425064.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5091.703125
		 entropy bonus: 0.199652299284935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6738.1845703125
		 entropy bonus: 4.9430758306617334e-18
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7826.69677734375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3862163.25 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 38425064.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5077.609375
		 entropy bonus: 0.19729064404964447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6738.1845703125
		 entropy bonus: 1.020668518100917e-14
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7826.69677734375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3862149.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 38425064.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5076.63916015625
		 entropy bonus: 0.1944541186094284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737.11572265625
		 entropy bonus: 2.9594439420778385e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7826.69677734375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3862146.75 - Differentiable computation graph = True!
PPO iteration: 86/1000:
	 start solving instance: 102...
	 start solving instance: 84...
	 start solving instance: 81...
	 start solving instance: 52...
	 start solving instance: 90...
	 start solving instance: 98...
	 start solving instance: 75...
	 start solving instance: 83...
	 start solving instance: 66...
	 start solving instance: 37...
	 start solving instance: 76...
	 start solving instance: 60...
	 start solving instance: 149...
	 start solving instance: 137...
	 start solving instance: 112...
	 start solving instance: 10...
	 start solving instance: 26...
	 start solving instance: 33...
	 start solving instance: 68...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 13971501.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2999.5380859375
		 entropy bonus: 0.194813534617424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4007.546875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -4809.84716796875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1408967.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 13971501.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2991.406982421875
		 entropy bonus: 0.1911199986934662
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4007.546875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -4809.84716796875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1408958.875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 13971501.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2995.6767578125
		 entropy bonus: 0.18772269785404205
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4007.546630859375
		 entropy bonus: 7.229228344840521e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -4809.84716796875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1408963.125 - Differentiable computation graph = True!
PPO iteration: 87/1000:
	 start solving instance: 66...
	 start solving instance: 33...
	 start solving instance: 102...
	 start solving instance: 90...
	 start solving instance: 76...
	 start solving instance: 149...
	 start solving instance: 60...
	 start solving instance: 81...
	 start solving instance: 83...
	 start solving instance: 10...
	 start solving instance: 75...
	 start solving instance: 37...
	 start solving instance: 137...
	 start solving instance: 68...
	 start solving instance: 26...
	 start solving instance: 52...
	 start solving instance: 53...
	 start solving instance: 98...
	 start solving instance: 84...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 9212287.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2391.509521484375
		 entropy bonus: 0.18235285580158234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3172.03173828125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3717.329345703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 930509.5625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9212287.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2386.607421875
		 entropy bonus: 0.17842981219291687
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3170.998046875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3717.329345703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 930503.5625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9212287.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2383.6142578125
		 entropy bonus: 0.1740768998861313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3169.98681640625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3717.329345703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 930499.625 - Differentiable computation graph = True!
PPO iteration: 88/1000:
	 start solving instance: 83...
	 start solving instance: 26...
	 start solving instance: 68...
	 start solving instance: 137...
	 start solving instance: 66...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 60...
	 start solving instance: 84...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 76...
	 start solving instance: 37...
	 start solving instance: 112...
	 start solving instance: 75...
	 start solving instance: 102...
	 start solving instance: 98...
	 start solving instance: 149...
	 start solving instance: 10...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 7111282.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2212.664794921875
		 entropy bonus: 0.16366605460643768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2790.160888671875
		 entropy bonus: 4.1096192421319344e-11
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3424.95849609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 719556.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 7111282.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2214.59228515625
		 entropy bonus: 0.1603783369064331
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2789.5234375
		 entropy bonus: 7.527144134655828e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3424.95849609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 719557.3125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 7111282.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2219.299560546875
		 entropy bonus: 0.15762607753276825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2789.5234375
		 entropy bonus: 4.5921887847260104e-14
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3424.95849609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 719562.0625 - Differentiable computation graph = True!
PPO iteration: 89/1000:
	 start solving instance: 75...
	 start solving instance: 53...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 37...
	 start solving instance: 26...
	 start solving instance: 68...
	 start solving instance: 102...
	 start solving instance: 112...
	 start solving instance: 84...
	 start solving instance: 66...
	 start solving instance: 83...
	 start solving instance: 60...
	 start solving instance: 52...
	 start solving instance: 81...
	 start solving instance: 90...
	 start solving instance: 149...
	 start solving instance: 137...
	 start solving instance: 10...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 6203148.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1993.9840087890625
		 entropy bonus: 0.16189251840114594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2598.552734375
		 entropy bonus: 1.3860143226246024e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3207.656982421875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 628114.9375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 6203148.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1992.8125
		 entropy bonus: 0.1594752073287964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2598.552734375
		 entropy bonus: 2.0557996024541826e-23
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3207.656982421875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 628113.8125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 6203148.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1992.6998291015625
		 entropy bonus: 0.15678994357585907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2598.552734375
		 entropy bonus: 1.0895338587394163e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3207.656982421875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 628113.6875 - Differentiable computation graph = True!
PPO iteration: 90/1000:
	 start solving instance: 98...
	 start solving instance: 68...
	 start solving instance: 26...
	 start solving instance: 52...
	 start solving instance: 149...
	 start solving instance: 84...
	 start solving instance: 60...
	 start solving instance: 90...
	 start solving instance: 37...
	 start solving instance: 102...
	 start solving instance: 76...
	 start solving instance: 137...
	 start solving instance: 83...
	 start solving instance: 33...
	 start solving instance: 81...
	 start solving instance: 75...
	 start solving instance: 66...
	 start solving instance: 10...
	 start solving instance: 53...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 5892861.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1976.1015625
		 entropy bonus: 0.15642483532428741
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2558.866943359375
		 entropy bonus: 7.530644024876638e-18
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3037.819580078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 596858.875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5892861.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2003.9910888671875
		 entropy bonus: 0.18040180206298828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2555.692138671875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3037.819580078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 596883.625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5892861.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2003.6929931640625
		 entropy bonus: 0.1806790679693222
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -2549.282958984375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3037.819580078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 596876.9375 - Differentiable computation graph = True!
PPO iteration: 91/1000:
	 New training batch of size 20...
	 start solving instance: 31...
	 start solving instance: 107...
	 start solving instance: 96...
	 start solving instance: 76...
	 start solving instance: 27...
	 start solving instance: 58...
	 start solving instance: 142...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 62...
	 start solving instance: 131...
	 start solving instance: 104...
	 start solving instance: 20...
	 start solving instance: 103...
	 start solving instance: 144...
	 start solving instance: 44...
	 start solving instance: 10...
	 start solving instance: 61...
	 start solving instance: 143...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 68868584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5547.67822265625
		 entropy bonus: 0.158415749669075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8568.9189453125
		 entropy bonus: 3.576886326866133e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -11180.8359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6912156.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 68868584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5497.93896484375
		 entropy bonus: 0.15909229218959808
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8541.736328125
		 entropy bonus: 2.0745055735460483e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -11180.8359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6912079.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 68868584.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5479.8955078125
		 entropy bonus: 0.15322817862033844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8541.8154296875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -11180.8359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6912061.0 - Differentiable computation graph = True!
PPO iteration: 92/1000:
	 start solving instance: 116...
	 start solving instance: 10...
	 start solving instance: 44...
	 start solving instance: 96...
	 start solving instance: 58...
	 start solving instance: 91...
	 start solving instance: 31...
	 start solving instance: 144...
	 start solving instance: 143...
	 start solving instance: 61...
	 start solving instance: 104...
	 start solving instance: 131...
	 start solving instance: 38...
	 start solving instance: 142...
	 start solving instance: 107...
	 start solving instance: 62...
	 start solving instance: 76...
	 start solving instance: 20...
	 start solving instance: 27...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 62364628.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6282.68212890625
		 entropy bonus: 0.15203288197517395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8070.6142578125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10367.513671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6261183.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 62364628.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6255.78271484375
		 entropy bonus: 0.14999054372310638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8069.01708984375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10367.513671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6261155.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 62364628.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6228.56005859375
		 entropy bonus: 0.14682520925998688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8067.5439453125
		 entropy bonus: 5.638010777346723e-17
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10367.513671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6261126.5 - Differentiable computation graph = True!
PPO iteration: 93/1000:
	 start solving instance: 91...
	 start solving instance: 76...
	 start solving instance: 20...
	 start solving instance: 131...
	 start solving instance: 104...
	 start solving instance: 142...
	 start solving instance: 116...
	 start solving instance: 38...
	 start solving instance: 27...
	 start solving instance: 44...
	 start solving instance: 10...
	 start solving instance: 58...
	 start solving instance: 103...
	 start solving instance: 96...
	 start solving instance: 62...
	 start solving instance: 61...
	 start solving instance: 31...
	 start solving instance: 143...
	 start solving instance: 107...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 65378804.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6330.68798828125
		 entropy bonus: 0.1512395590543747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8237.7333984375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10282.51953125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6562731.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 65378804.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6276.7099609375
		 entropy bonus: 0.1474183350801468
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8235.8564453125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10282.51953125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6562675.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 65378804.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6265.5458984375
		 entropy bonus: 0.1426018923521042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8235.8564453125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -10282.51953125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6562664.5 - Differentiable computation graph = True!
PPO iteration: 94/1000:
	 start solving instance: 44...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 58...
	 start solving instance: 61...
	 start solving instance: 76...
	 start solving instance: 96...
	 start solving instance: 31...
	 start solving instance: 10...
	 start solving instance: 20...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 142...
	 start solving instance: 27...
	 start solving instance: 131...
	 start solving instance: 38...
	 start solving instance: 104...
	 start solving instance: 143...
	 start solving instance: 62...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 44867060.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5463.94677734375
		 entropy bonus: 0.1336291879415512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6731.21630859375
		 entropy bonus: 5.49091879004105e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8430.9599609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4507332.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 44867060.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5427.759765625
		 entropy bonus: 0.13015790283679962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6731.21630859375
		 entropy bonus: 6.702424567850243e-40
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8430.9599609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4507295.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 44867060.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5419.04443359375
		 entropy bonus: 0.12628328800201416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6729.72509765625
		 entropy bonus: 2.8037661476751544e-22
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8430.9599609375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4507285.5 - Differentiable computation graph = True!
PPO iteration: 95/1000:
	 start solving instance: 44...
	 start solving instance: 96...
	 start solving instance: 76...
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 61...
	 start solving instance: 107...
	 start solving instance: 58...
	 start solving instance: 103...
	 start solving instance: 62...
	 start solving instance: 142...
	 start solving instance: 10...
	 start solving instance: 143...
	 start solving instance: 144...
	 start solving instance: 31...
	 start solving instance: 131...
	 start solving instance: 27...
	 start solving instance: 20...
	 start solving instance: 116...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 9246900.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2477.851318359375
		 entropy bonus: 0.1206747516989708
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3058.77734375
		 entropy bonus: 2.5077861984328722e-26
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3849.37890625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 934076.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 9246900.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2458.704345703125
		 entropy bonus: 0.11530192941427231
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3058.77734375
		 entropy bonus: 2.2984984407181404e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3849.37890625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 934056.875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 9246900.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -2458.448974609375
		 entropy bonus: 0.11159121990203857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3058.106689453125
		 entropy bonus: 1.880770319493047e-17
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3849.37890625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 934055.9375 - Differentiable computation graph = True!
PPO iteration: 96/1000:
	 start solving instance: 131...
	 start solving instance: 144...
	 start solving instance: 38...
	 start solving instance: 91...
	 start solving instance: 62...
	 start solving instance: 27...
	 start solving instance: 96...
	 start solving instance: 58...
	 start solving instance: 107...
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 44...
	 start solving instance: 76...
	 start solving instance: 104...
	 start solving instance: 143...
	 start solving instance: 20...
	 start solving instance: 116...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 3913331.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1594.424560546875
		 entropy bonus: 0.11293118447065353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1959.408203125
		 entropy bonus: 2.3251655795523095e-14
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2400.921630859375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 397287.9375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3913331.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1586.418212890625
		 entropy bonus: 0.1112232580780983
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1959.408203125
		 entropy bonus: 9.771776270095511e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2400.921630859375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 397279.9375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3913331.75
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1572.287353515625
		 entropy bonus: 0.10789889097213745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1958.849853515625
		 entropy bonus: 1.504344981917427e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2400.921630859375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 397265.25 - Differentiable computation graph = True!
PPO iteration: 97/1000:
	 start solving instance: 62...
	 start solving instance: 20...
	 start solving instance: 142...
	 start solving instance: 10...
	 start solving instance: 131...
	 start solving instance: 96...
	 start solving instance: 143...
	 start solving instance: 38...
	 start solving instance: 116...
	 start solving instance: 58...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 31...
	 start solving instance: 61...
	 start solving instance: 76...
	 start solving instance: 44...
	 start solving instance: 103...
	 start solving instance: 91...
	 start solving instance: 144...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 2739015.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1325.5950927734375
		 entropy bonus: 0.09877011924982071
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1624.982421875
		 entropy bonus: 2.6365475136458372e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2006.9835205078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 278859.125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2739015.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1326.7320556640625
		 entropy bonus: 0.09491454809904099
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1624.35791015625
		 entropy bonus: 8.65551828610478e-06
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2006.9835205078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 278859.625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2739015.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1324.4459228515625
		 entropy bonus: 0.09122075885534286
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1624.35791015625
		 entropy bonus: 3.093061806680453e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2006.9835205078125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 278857.34375 - Differentiable computation graph = True!
PPO iteration: 98/1000:
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 96...
	 start solving instance: 27...
	 start solving instance: 10...
	 start solving instance: 62...
	 start solving instance: 58...
	 start solving instance: 76...
	 start solving instance: 142...
	 start solving instance: 61...
	 start solving instance: 144...
	 start solving instance: 107...
	 start solving instance: 20...
	 start solving instance: 103...
	 start solving instance: 131...
	 start solving instance: 143...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 44...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 2816536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1387.201171875
		 entropy bonus: 0.08492306619882584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1643.7869873046875
		 entropy bonus: 5.8669115787779447e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2008.8314208984375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 286693.40625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2816536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1386.85888671875
		 entropy bonus: 0.08201871067285538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1643.4375
		 entropy bonus: 2.2555635137422314e-09
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2008.8314208984375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 286692.71875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2816536.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1389.6226806640625
		 entropy bonus: 0.07939061522483826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1643.4375
		 entropy bonus: 5.77162484471927e-10
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2008.8314208984375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 286695.5 - Differentiable computation graph = True!
PPO iteration: 99/1000:
	 start solving instance: 76...
	 start solving instance: 27...
	 start solving instance: 61...
	 start solving instance: 38...
	 start solving instance: 116...
	 start solving instance: 104...
	 start solving instance: 62...
	 start solving instance: 142...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 91...
	 start solving instance: 107...
	 start solving instance: 20...
	 start solving instance: 144...
	 start solving instance: 131...
	 start solving instance: 10...
	 start solving instance: 58...
	 start solving instance: 96...
	 start solving instance: 44...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 3077920.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1479.9593505859375
		 entropy bonus: 0.07996045798063278
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1721.786376953125
		 entropy bonus: 7.992517225829943e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2141.88720703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 313135.6875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3077920.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1472.2822265625
		 entropy bonus: 0.07751183956861496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1721.7864990234375
		 entropy bonus: 1.8587600791875047e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2141.88720703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 313128.03125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3077920.5
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1475.9879150390625
		 entropy bonus: 0.07541240006685257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1721.7864990234375
		 entropy bonus: 1.0215617685105371e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2141.88720703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 313131.71875 - Differentiable computation graph = True!
PPO iteration: 100/1000:
	 start solving instance: 144...
	 start solving instance: 38...
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 44...
	 start solving instance: 96...
	 start solving instance: 142...
	 start solving instance: 10...
	 start solving instance: 61...
	 start solving instance: 27...
	 start solving instance: 20...
	 start solving instance: 76...
	 start solving instance: 131...
	 start solving instance: 116...
	 start solving instance: 107...
	 start solving instance: 31...
	 start solving instance: 58...
	 start solving instance: 91...
	 start solving instance: 104...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 2761993.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1348.7298583984375
		 entropy bonus: 0.07298141717910767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1625.7664794921875
		 entropy bonus: 0.0010160778183490038
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2029.744873046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 281203.5625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2761993.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1349.164306640625
		 entropy bonus: 0.0708322748541832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1618.0369873046875
		 entropy bonus: 3.425230476854224e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2029.744873046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 281196.28125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2761993.25
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1350.1197509765625
		 entropy bonus: 0.06893615424633026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1613.3128662109375
		 entropy bonus: 1.5607411086657609e-15
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -2029.744873046875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 281192.53125 - Differentiable computation graph = True!
PPO iteration: 101/1000:
	 New training batch of size 20...
	 start solving instance: 150...
	 start solving instance: 148...
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 95...
	 start solving instance: 125...
	 start solving instance: 140...
	 start solving instance: 92...
	 start solving instance: 51...
	 start solving instance: 114...
	 start solving instance: 2...
	 start solving instance: 121...
	 start solving instance: 118...
	 start solving instance: 13...
	 start solving instance: 133...
	 start solving instance: 91...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 75...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 40345628.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5654.2119140625
		 entropy bonus: 0.0660158172249794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6278.556640625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8120.31103515625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4054615.75 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 40345628.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5650.1748046875
		 entropy bonus: 0.06491302698850632
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276.990234375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8120.31103515625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4054610.25 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 40345628.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5642.419921875
		 entropy bonus: 0.0638975277543068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6273.546875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8120.31103515625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4054599.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 147414800.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10847.0625
		 entropy bonus: 0.06222417578101158
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11818.1123046875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16620.041015625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14780765.0000
PPO iteration: 102/1000:
	 start solving instance: 118...
	 start solving instance: 13...
	 start solving instance: 107...
	 start solving instance: 92...
	 start solving instance: 145...
	 start solving instance: 95...
	 start solving instance: 65...
	 start solving instance: 51...
	 start solving instance: 56...
	 start solving instance: 125...
	 start solving instance: 133...
	 start solving instance: 140...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 91...
	 start solving instance: 121...
	 start solving instance: 75...
	 start solving instance: 2...
	 start solving instance: 114...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 159128144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11485.083984375
		 entropy bonus: 0.06287842988967896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12322.4501953125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16088.6298828125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15952711.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 159128144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11500.109375
		 entropy bonus: 0.06334298104047775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12319.1494140625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16088.6298828125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15952723.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 159128144.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11489.0537109375
		 entropy bonus: 0.0610247366130352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12319.1494140625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -16088.6298828125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15952712.0 - Differentiable computation graph = True!
PPO iteration: 103/1000:
	 start solving instance: 148...
	 start solving instance: 56...
	 start solving instance: 145...
	 start solving instance: 107...
	 start solving instance: 13...
	 start solving instance: 95...
	 start solving instance: 133...
	 start solving instance: 125...
	 start solving instance: 35...
	 start solving instance: 51...
	 start solving instance: 121...
	 start solving instance: 91...
	 start solving instance: 2...
	 start solving instance: 150...
	 start solving instance: 75...
	 start solving instance: 114...
	 start solving instance: 92...
	 start solving instance: 118...
	 start solving instance: 65...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 199628336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -13257.4404296875
		 entropy bonus: 0.059123922139406204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13702.0068359375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18034.69921875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20007828.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 199628336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -13256.8515625
		 entropy bonus: 0.059481292963027954
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13702.0068359375
		 entropy bonus: 3.465250203178327e-24
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18034.69921875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20007826.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 199628336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -13245.923828125
		 entropy bonus: 0.059291042387485504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13689.6640625
		 entropy bonus: 3.783505853677006e-44
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -18034.69921875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20007804.0 - Differentiable computation graph = True!
PPO iteration: 104/1000:
	 start solving instance: 13...
	 start solving instance: 145...
	 start solving instance: 133...
	 start solving instance: 35...
	 start solving instance: 140...
	 start solving instance: 121...
	 start solving instance: 118...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 107...
	 start solving instance: 148...
	 start solving instance: 65...
	 start solving instance: 95...
	 start solving instance: 91...
	 start solving instance: 92...
	 start solving instance: 125...
	 start solving instance: 75...
	 start solving instance: 114...
	 start solving instance: 2...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 120603664.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10357.2568359375
		 entropy bonus: 0.05988987907767296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10704.6123046875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13600.232421875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12095029.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 120603664.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10395.9375
		 entropy bonus: 0.06112796068191528
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10701.7294921875
		 entropy bonus: 5.213881261136563e-40
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13600.232421875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12095065.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 120603664.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10342.462890625
		 entropy bonus: 0.06117290258407593
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10698.8671875
		 entropy bonus: 3.5367629102031796e-18
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13600.232421875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12095008.0 - Differentiable computation graph = True!
PPO iteration: 105/1000:
	 start solving instance: 114...
	 start solving instance: 75...
	 start solving instance: 56...
	 start solving instance: 133...
	 start solving instance: 107...
	 start solving instance: 150...
	 start solving instance: 2...
	 start solving instance: 148...
	 start solving instance: 35...
	 start solving instance: 95...
	 start solving instance: 121...
	 start solving instance: 65...
	 start solving instance: 145...
	 start solving instance: 13...
	 start solving instance: 92...
	 start solving instance: 51...
	 start solving instance: 125...
	 start solving instance: 91...
	 start solving instance: 118...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 122926544.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10632.3896484375
		 entropy bonus: 0.060303956270217896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10752.392578125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13282.0263671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12327321.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 122926544.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10636.1484375
		 entropy bonus: 0.06065509468317032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10752.392578125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13282.0263671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12327325.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 122926544.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10671.1376953125
		 entropy bonus: 0.06072952225804329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10752.392578125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13282.0263671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 12327360.0 - Differentiable computation graph = True!
PPO iteration: 106/1000:
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 121...
	 start solving instance: 13...
	 start solving instance: 35...
	 start solving instance: 118...
	 start solving instance: 75...
	 start solving instance: 145...
	 start solving instance: 150...
	 start solving instance: 95...
	 start solving instance: 56...
	 start solving instance: 125...
	 start solving instance: 92...
	 start solving instance: 140...
	 start solving instance: 65...
	 start solving instance: 2...
	 start solving instance: 148...
	 start solving instance: 114...
	 start solving instance: 91...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 117028224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10414.6376953125
		 entropy bonus: 0.06260509788990021
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10495.8212890625
		 entropy bonus: 2.4412760089289817e-17
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13099.3603515625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11736833.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 117028224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10356.390625
		 entropy bonus: 0.060514044016599655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10495.8212890625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13099.3603515625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11736774.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 117028224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -10363.70703125
		 entropy bonus: 0.059766318649053574
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10495.8212890625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -13099.3603515625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 11736782.0 - Differentiable computation graph = True!
PPO iteration: 107/1000:
	 start solving instance: 114...
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 65...
	 start solving instance: 145...
	 start solving instance: 140...
	 start solving instance: 51...
	 start solving instance: 148...
	 start solving instance: 118...
	 start solving instance: 133...
	 start solving instance: 91...
	 start solving instance: 13...
	 start solving instance: 2...
	 start solving instance: 121...
	 start solving instance: 125...
	 start solving instance: 56...
	 start solving instance: 107...
	 start solving instance: 150...
	 start solving instance: 35...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 67609048.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -8007.1689453125
		 entropy bonus: 0.05588097125291824
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8008.17919921875
		 entropy bonus: 5.013263567298087e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9477.0791015625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6786397.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 67609048.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -8029.1875
		 entropy bonus: 0.05562981963157654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8004.07666015625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9477.0791015625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6786415.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 67609048.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -8005.33203125
		 entropy bonus: 0.054592669010162354
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -8004.07666015625
		 entropy bonus: 7.911010859476761e-34
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9477.0791015625
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6786391.5 - Differentiable computation graph = True!
PPO iteration: 108/1000:
	 start solving instance: 2...
	 start solving instance: 140...
	 start solving instance: 107...
	 start solving instance: 13...
	 start solving instance: 125...
	 start solving instance: 56...
	 start solving instance: 148...
	 start solving instance: 75...
	 start solving instance: 51...
	 start solving instance: 145...
	 start solving instance: 91...
	 start solving instance: 133...
	 start solving instance: 121...
	 start solving instance: 35...
	 start solving instance: 65...
	 start solving instance: 92...
	 start solving instance: 118...
	 start solving instance: 114...
	 start solving instance: 95...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 42926516.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6407.01025390625
		 entropy bonus: 0.053749930113554
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6317.2978515625
		 entropy bonus: 8.29171388133259e-18
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7423.3701171875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4312799.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 42926516.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6407.48828125
		 entropy bonus: 0.05277148634195328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315.9169921875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7423.3701171875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4312798.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 42926516.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6399.18701171875
		 entropy bonus: 0.0530482642352581
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315.9169921875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7423.3701171875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4312790.0 - Differentiable computation graph = True!
PPO iteration: 109/1000:
	 start solving instance: 92...
	 start solving instance: 51...
	 start solving instance: 133...
	 start solving instance: 56...
	 start solving instance: 145...
	 start solving instance: 118...
	 start solving instance: 35...
	 start solving instance: 107...
	 start solving instance: 140...
	 start solving instance: 13...
	 start solving instance: 75...
	 start solving instance: 65...
	 start solving instance: 121...
	 start solving instance: 148...
	 start solving instance: 114...
	 start solving instance: 125...
	 start solving instance: 150...
	 start solving instance: 95...
	 start solving instance: 2...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 63607336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7810.61083984375
		 entropy bonus: 0.052378714084625244
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7699.33740234375
		 entropy bonus: 2.469839283399377e-16
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9311.28125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6385554.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 63607336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7779.86572265625
		 entropy bonus: 0.05158478021621704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7694.9462890625
		 entropy bonus: 7.31182877421525e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9311.28125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6385519.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 63607336.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7790.40625
		 entropy bonus: 0.051085274666547775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7694.9462890625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9311.28125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 6385530.0 - Differentiable computation graph = True!
PPO iteration: 110/1000:
	 start solving instance: 133...
	 start solving instance: 91...
	 start solving instance: 92...
	 start solving instance: 140...
	 start solving instance: 65...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 56...
	 start solving instance: 95...
	 start solving instance: 150...
	 start solving instance: 2...
	 start solving instance: 125...
	 start solving instance: 51...
	 start solving instance: 118...
	 start solving instance: 121...
	 start solving instance: 107...
	 start solving instance: 145...
	 start solving instance: 114...
	 start solving instance: 13...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 57794764.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7267.96240234375
		 entropy bonus: 0.051005519926548004
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7427.8876953125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9174.546875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5803347.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 57794764.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7261.93896484375
		 entropy bonus: 0.05148094892501831
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7425.96435546875
		 entropy bonus: 1.4937576796694198e-14
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9174.546875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5803339.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 57794764.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -7268.39306640625
		 entropy bonus: 0.05108340457081795
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7423.91748046875
		 entropy bonus: 0.00017013218894135207
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9174.546875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5803343.5 - Differentiable computation graph = True!
PPO iteration: 111/1000:
	 New training batch of size 20...
	 start solving instance: 98...
	 start solving instance: 113...
	 start solving instance: 128...
	 start solving instance: 91...
	 start solving instance: 63...
	 start solving instance: 139...
	 start solving instance: 125...
	 start solving instance: 20...
	 start solving instance: 78...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 137...
	 start solving instance: 95...
	 start solving instance: 105...
	 start solving instance: 79...
	 start solving instance: 143...
	 start solving instance: 112...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 45659224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6632.37255859375
		 entropy bonus: 0.04801972582936287
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6499.11962890625
		 entropy bonus: 2.7575593776418827e-05
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8127.88720703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4587182.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 45659224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6621.46044921875
		 entropy bonus: 0.049127839505672455
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6455.44677734375
		 entropy bonus: 6.652328741224324e-29
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8127.88720703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4587127.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 45659224.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6606.63623046875
		 entropy bonus: 0.049653615802526474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6427.9443359375
		 entropy bonus: 0.0003810623602475971
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8127.88720703125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4587085.0 - Differentiable computation graph = True!
PPO iteration: 112/1000:
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 19...
	 start solving instance: 125...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 139...
	 start solving instance: 79...
	 start solving instance: 143...
	 start solving instance: 20...
	 start solving instance: 95...
	 start solving instance: 105...
	 start solving instance: 112...
	 start solving instance: 137...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 74993280.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -9247.2490234375
		 entropy bonus: 0.045269161462783813
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7734.23046875
		 entropy bonus: 4.3465800620215433e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7403.1787109375
		 entropy bonus: 1.3527675548540415e-19
		 -----------------
	 Multi-agent batch loss: 7523712.5 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 74993280.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -9237.984375
		 entropy bonus: 0.044812239706516266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7687.19287109375
		 entropy bonus: 1.1431897588650141e-21
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7403.1787109375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7523656.5 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 74993280.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -9222.6640625
		 entropy bonus: 0.04346510022878647
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7667.49462890625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7403.1787109375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 7523621.0 - Differentiable computation graph = True!
PPO iteration: 113/1000:
	 start solving instance: 20...
	 start solving instance: 98...
	 start solving instance: 112...
	 start solving instance: 95...
	 start solving instance: 40...
	 start solving instance: 132...
	 start solving instance: 103...
	 start solving instance: 128...
	 start solving instance: 19...
	 start solving instance: 137...
	 start solving instance: 143...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 139...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 105...
	 start solving instance: 125...
	 start solving instance: 63...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 233891152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -16495.458984375
		 entropy bonus: 0.04683553799986839
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12683.5888671875
		 entropy bonus: 0.0002676106814760715
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9143.5693359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23427440.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 233891152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -16437.06640625
		 entropy bonus: 0.04864458367228508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12597.5390625
		 entropy bonus: 0.0003085182688664645
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9143.5693359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23427296.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 233891152.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -16472.365234375
		 entropy bonus: 0.05027158930897713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12549.1767578125
		 entropy bonus: 0.00012230954598635435
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -9143.5693359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 23427280.0 - Differentiable computation graph = True!
PPO iteration: 114/1000:
	 start solving instance: 112...
	 start solving instance: 63...
	 start solving instance: 143...
	 start solving instance: 125...
	 start solving instance: 79...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 91...
	 start solving instance: 19...
	 start solving instance: 40...
	 start solving instance: 128...
	 start solving instance: 25...
	 start solving instance: 105...
	 start solving instance: 139...
	 start solving instance: 113...
	 start solving instance: 78...
	 start solving instance: 137...
	 start solving instance: 20...
	 start solving instance: 132...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 216778192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -16325.5673828125
		 entropy bonus: 0.046840425580739975
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10568.1005859375
		 entropy bonus: 1.8581236815862212e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6367.27294921875
		 entropy bonus: 5.802206004545951e-08
		 -----------------
	 Multi-agent batch loss: 21711082.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 216778192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -16308.1630859375
		 entropy bonus: 0.049511998891830444
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -10155.625
		 entropy bonus: 0.0008323437650687993
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6346.33544921875
		 entropy bonus: 8.165319087538592e-09
		 -----------------
	 Multi-agent batch loss: 21710630.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 216778192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -16268.7412109375
		 entropy bonus: 0.054892707616090775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9991.6865234375
		 entropy bonus: 0.0019658112432807684
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6338.3359375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 21710418.0 - Differentiable computation graph = True!
PPO iteration: 115/1000:
	 start solving instance: 128...
	 start solving instance: 25...
	 start solving instance: 98...
	 start solving instance: 137...
	 start solving instance: 125...
	 start solving instance: 139...
	 start solving instance: 20...
	 start solving instance: 113...
	 start solving instance: 112...
	 start solving instance: 105...
	 start solving instance: 91...
	 start solving instance: 40...
	 start solving instance: 143...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 78...
	 start solving instance: 132...
	 start solving instance: 19...
	 start solving instance: 63...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 156793264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11505.7548828125
		 entropy bonus: 0.060836005955934525
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9403.5771484375
		 entropy bonus: 8.510192550659212e-12
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6248.11767578125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15706485.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 156793264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11367.9287109375
		 entropy bonus: 0.08273408561944962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9360.0478515625
		 entropy bonus: 4.112163948537147e-20
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6248.11767578125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15706303.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 156793264.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11390.427734375
		 entropy bonus: 0.11193450540304184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -9328.5703125
		 entropy bonus: 1.401298464324817e-44
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6248.11767578125
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 15706294.0 - Differentiable computation graph = True!
PPO iteration: 116/1000:
	 start solving instance: 91...
	 start solving instance: 40...
	 start solving instance: 113...
	 start solving instance: 143...
	 start solving instance: 139...
	 start solving instance: 19...
	 start solving instance: 63...
	 start solving instance: 105...
	 start solving instance: 95...
	 start solving instance: 137...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 20...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 132...
	 start solving instance: 79...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 148899552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11250.0517578125
		 entropy bonus: 0.16938742995262146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11244.0234375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -12601.3271484375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14925050.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 148899552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11446.33984375
		 entropy bonus: 0.1888243407011032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11228.40234375
		 entropy bonus: 2.7787171674731326e-08
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -12601.3271484375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14925231.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 148899552.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11623.4150390625
		 entropy bonus: 0.18937712907791138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -11218.142578125
		 entropy bonus: 9.556810031307724e-17
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -12601.3271484375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 14925397.0 - Differentiable computation graph = True!
PPO iteration: 117/1000:
	 start solving instance: 78...
	 start solving instance: 91...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 139...
	 start solving instance: 19...
	 start solving instance: 143...
	 start solving instance: 112...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 128...
	 start solving instance: 40...
	 start solving instance: 113...
	 start solving instance: 125...
	 start solving instance: 105...
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 79...
	 start solving instance: 132...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 163150208.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11441.1162109375
		 entropy bonus: 0.18063469231128693
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12229.1142578125
		 entropy bonus: 1.5745811765555118e-07
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15022.8583984375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16353714.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 163150208.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11470.55078125
		 entropy bonus: 0.17729927599430084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12220.5732421875
		 entropy bonus: 1.311185724882022e-13
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15022.8583984375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16353735.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 163150208.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -11456.982421875
		 entropy bonus: 0.1747262328863144
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -12218.7353515625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -15022.8583984375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 16353720.0 - Differentiable computation graph = True!
PPO iteration: 118/1000:
	 start solving instance: 137...
	 start solving instance: 63...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 19...
	 start solving instance: 105...
	 start solving instance: 98...
	 start solving instance: 143...
	 start solving instance: 79...
	 start solving instance: 91...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 132...
	 start solving instance: 139...
	 start solving instance: 113...
	 start solving instance: 78...
	 start solving instance: 125...
	 start solving instance: 103...
	 start solving instance: 20...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 202790304.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -12516.310546875
		 entropy bonus: 0.1681579351425171
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13817.4716796875
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17552.763671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20322916.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 202790304.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -12469.4853515625
		 entropy bonus: 0.16739754378795624
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13802.5986328125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17552.763671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20322856.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 202790304.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -12375.13671875
		 entropy bonus: 0.1654716581106186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -13724.1298828125
		 entropy bonus: 1.1210387714598537e-44
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -17552.763671875
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 20322682.0 - Differentiable computation graph = True!
PPO iteration: 119/1000:
	 start solving instance: 125...
	 start solving instance: 63...
	 start solving instance: 113...
	 start solving instance: 19...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 105...
	 start solving instance: 98...
	 start solving instance: 137...
	 start solving instance: 132...
	 start solving instance: 79...
	 start solving instance: 139...
	 start solving instance: 20...
	 start solving instance: 91...
	 start solving instance: 112...
	 start solving instance: 143...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 2993000192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -47806.3515625
		 entropy bonus: 0.16853468120098114
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -48649.1953125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -62583.77734375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 299459072.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2993000192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -47196.12890625
		 entropy bonus: 0.16689743101596832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -48616.20703125
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -62583.77734375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 299458432.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2993000192.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -49064.06640625
		 entropy bonus: 0.17081640660762787
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -48587.75
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -62583.77734375
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 299460256.0 - Differentiable computation graph = True!
PPO iteration: 120/1000:
	 start solving instance: 139...
	 start solving instance: 40...
	 start solving instance: 128...
	 start solving instance: 113...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 95...
	 start solving instance: 20...
	 start solving instance: 125...
	 start solving instance: 105...
	 start solving instance: 19...
	 start solving instance: 143...
	 start solving instance: 98...
	 start solving instance: 91...
	 start solving instance: 103...
	 start solving instance: 63...
	 start solving instance: 112...
	 start solving instance: 78...
	 start solving instance: 137...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 82325364736.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -265269.5
		 entropy bonus: 0.1554083675146103
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -252679.40625
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -300750.25
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8233355264.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 82325364736.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -314936.8125
		 entropy bonus: 0.15318648517131805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -252515.234375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -300750.25
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8233404928.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 82325364736.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -312700.65625
		 entropy bonus: 0.193970188498497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -252471.609375
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -300750.25
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 8233402880.0 - Differentiable computation graph = True!
PPO iteration: 121/1000:
	 New training batch of size 20...
	 start solving instance: 77...
	 start solving instance: 66...
	 start solving instance: 114...
	 start solving instance: 40...
	 start solving instance: 107...
	 start solving instance: 21...
	 start solving instance: 47...
	 start solving instance: 124...
	 start solving instance: 97...
	 start solving instance: 14...
	 start solving instance: 49...
	 start solving instance: 74...
	 start solving instance: 98...
	 start solving instance: 4...
	 start solving instance: 86...
	 start solving instance: 11...
	 start solving instance: 139...
	 start solving instance: 120...
	 start solving instance: 132...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 3509836805308416.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -56432012.0
		 entropy bonus: 0.20023027062416077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -55023680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -62697888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 350983888568320.0 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3509836805308416.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -56432012.0
		 entropy bonus: 0.20023027062416077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -55023680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -62697888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 350983888568320.0 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3509836805308416.0
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -56392180.0
		 entropy bonus: 0.20023027062416077
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -55023680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -62697888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 350983888568320.0 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 1.1095994408024146e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -982669248.0
		 entropy bonus: 0.21742065250873566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -985066688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -1158398336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 110959947516215296.0000
PPO iteration: 122/1000:
	 start solving instance: 81...
	 start solving instance: 139...
	 start solving instance: 132...
	 start solving instance: 4...
	 start solving instance: 66...
	 start solving instance: 97...
	 start solving instance: 21...
	 start solving instance: 124...
	 start solving instance: 107...
	 start solving instance: 77...
	 start solving instance: 11...
	 start solving instance: 47...
	 start solving instance: 120...
	 start solving instance: 114...
	 start solving instance: 74...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 14...
	 start solving instance: 98...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.3150366601020703e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1081578368.0
		 entropy bonus: 0.21954818069934845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1094281344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -1168570624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.3150366944618086e+17 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.3150366601020703e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1081578368.0
		 entropy bonus: 0.21954818069934845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1094281344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -1168570624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.3150366944618086e+17 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.3150366601020703e+18
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -1081578368.0
		 entropy bonus: 0.21954818069934845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -1094281344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -1168570624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.3150366944618086e+17 - Differentiable computation graph = True!
PPO iteration: 123/1000:
	 start solving instance: 77...
	 start solving instance: 40...
	 start solving instance: 47...
	 start solving instance: 107...
	 start solving instance: 11...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 139...
	 start solving instance: 21...
	 start solving instance: 66...
	 start solving instance: 132...
	 start solving instance: 81...
	 start solving instance: 120...
	 start solving instance: 114...
	 start solving instance: 4...
	 start solving instance: 86...
	 start solving instance: 74...
	 start solving instance: 98...
	 start solving instance: 97...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 1.043132959598995e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -3114681088.0
		 entropy bonus: 0.20164521038532257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3058255616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3484323328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.0431330008306811e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 1.043132959598995e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -3114681088.0
		 entropy bonus: 0.20164521038532257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3058255616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3484323328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.0431330008306811e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 1.043132959598995e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -3114681088.0
		 entropy bonus: 0.20164521038532257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -3058255616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -3484323328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 1.0431330008306811e+18 - Differentiable computation graph = True!
PPO iteration: 124/1000:
	 start solving instance: 66...
	 start solving instance: 21...
	 start solving instance: 40...
	 start solving instance: 14...
	 start solving instance: 114...
	 start solving instance: 47...
	 start solving instance: 86...
	 start solving instance: 139...
	 start solving instance: 98...
	 start solving instance: 97...
	 start solving instance: 49...
	 start solving instance: 107...
	 start solving instance: 4...
	 start solving instance: 124...
	 start solving instance: 11...
	 start solving instance: 120...
	 start solving instance: 81...
	 start solving instance: 74...
	 start solving instance: 77...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.1078288815349563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -4475935232.0
		 entropy bonus: 0.1983812004327774
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4308684800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -4935793664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.1078289365105377e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.1078288815349563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -4475935232.0
		 entropy bonus: 0.1983812004327774
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4308684800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -4935793664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.1078289365105377e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.1078288815349563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -4475935232.0
		 entropy bonus: 0.1983812004327774
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4308684800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -4935793664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.1078289365105377e+18 - Differentiable computation graph = True!
PPO iteration: 125/1000:
	 start solving instance: 86...
	 start solving instance: 107...
	 start solving instance: 4...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 98...
	 start solving instance: 114...
	 start solving instance: 77...
	 start solving instance: 49...
	 start solving instance: 139...
	 start solving instance: 97...
	 start solving instance: 81...
	 start solving instance: 74...
	 start solving instance: 66...
	 start solving instance: 14...
	 start solving instance: 21...
	 start solving instance: 11...
	 start solving instance: 132...
	 start solving instance: 120...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.141943976616421e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5296589824.0
		 entropy bonus: 0.20647087693214417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5311725056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5955637760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.141944086567584e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.141943976616421e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5296589824.0
		 entropy bonus: 0.20647087693214417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5311725056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5955637760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.141944086567584e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.141943976616421e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5296589824.0
		 entropy bonus: 0.20647087693214417
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5311725056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5955637760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.141944086567584e+18 - Differentiable computation graph = True!
PPO iteration: 126/1000:
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 97...
	 start solving instance: 14...
	 start solving instance: 77...
	 start solving instance: 21...
	 start solving instance: 11...
	 start solving instance: 81...
	 start solving instance: 120...
	 start solving instance: 47...
	 start solving instance: 74...
	 start solving instance: 66...
	 start solving instance: 4...
	 start solving instance: 114...
	 start solving instance: 98...
	 start solving instance: 139...
	 start solving instance: 124...
	 start solving instance: 132...
	 start solving instance: 49...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.827916746753311e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5690400256.0
		 entropy bonus: 0.22272244095802307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5965882880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6591235072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8279167467533107e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.827916746753311e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5690400256.0
		 entropy bonus: 0.22272244095802307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5965882880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6591235072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8279167467533107e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.827916746753311e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5690400256.0
		 entropy bonus: 0.22272244095802307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5965882880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6591235072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8279167467533107e+18 - Differentiable computation graph = True!
PPO iteration: 127/1000:
	 start solving instance: 66...
	 start solving instance: 107...
	 start solving instance: 81...
	 start solving instance: 132...
	 start solving instance: 98...
	 start solving instance: 40...
	 start solving instance: 74...
	 start solving instance: 21...
	 start solving instance: 114...
	 start solving instance: 4...
	 start solving instance: 11...
	 start solving instance: 77...
	 start solving instance: 14...
	 start solving instance: 86...
	 start solving instance: 124...
	 start solving instance: 97...
	 start solving instance: 139...
	 start solving instance: 47...
	 start solving instance: 120...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.63655356491099e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5719027712.0
		 entropy bonus: 0.21156048774719238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718577152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373298176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6365536198865715e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.63655356491099e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5719027712.0
		 entropy bonus: 0.21156048774719238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718577152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373298176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6365536198865715e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.63655356491099e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5719027712.0
		 entropy bonus: 0.21156048774719238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718577152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373298176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6365536198865715e+18 - Differentiable computation graph = True!
PPO iteration: 128/1000:
	 start solving instance: 74...
	 start solving instance: 66...
	 start solving instance: 114...
	 start solving instance: 47...
	 start solving instance: 49...
	 start solving instance: 97...
	 start solving instance: 98...
	 start solving instance: 139...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 107...
	 start solving instance: 124...
	 start solving instance: 132...
	 start solving instance: 21...
	 start solving instance: 120...
	 start solving instance: 86...
	 start solving instance: 40...
	 start solving instance: 77...
	 start solving instance: 81...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.844514974286217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5712057856.0
		 entropy bonus: 0.2226063758134842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5929589248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6405046784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844514974286217e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.844514974286217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5712057856.0
		 entropy bonus: 0.2226063758134842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5929589248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6405046784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844514974286217e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.844514974286217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5712057856.0
		 entropy bonus: 0.2226063758134842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5929589248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6405046784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844514974286217e+18 - Differentiable computation graph = True!
PPO iteration: 129/1000:
	 start solving instance: 74...
	 start solving instance: 120...
	 start solving instance: 98...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 114...
	 start solving instance: 107...
	 start solving instance: 4...
	 start solving instance: 11...
	 start solving instance: 86...
	 start solving instance: 132...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 21...
	 start solving instance: 40...
	 start solving instance: 97...
	 start solving instance: 66...
	 start solving instance: 47...
	 start solving instance: 77...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.755418028650319e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5820648960.0
		 entropy bonus: 0.20268535614013672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5763649536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6363752960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7554179736747377e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.755418028650319e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5820648960.0
		 entropy bonus: 0.20268535614013672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5763649536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6363752960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7554179736747377e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.755418028650319e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5820648960.0
		 entropy bonus: 0.20268535614013672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5763649536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6363752960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7554179736747377e+18 - Differentiable computation graph = True!
PPO iteration: 130/1000:
	 start solving instance: 97...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 98...
	 start solving instance: 11...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 74...
	 start solving instance: 77...
	 start solving instance: 107...
	 start solving instance: 47...
	 start solving instance: 132...
	 start solving instance: 114...
	 start solving instance: 14...
	 start solving instance: 21...
	 start solving instance: 4...
	 start solving instance: 120...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.926846844778735e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5842195968.0
		 entropy bonus: 0.22820352017879486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6000121856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6477797376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.926846954729898e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.926846844778735e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5842195968.0
		 entropy bonus: 0.22820352017879486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6000121856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6477797376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.926846954729898e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.926846844778735e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5842195968.0
		 entropy bonus: 0.22820352017879486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6000121856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6477797376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.926846954729898e+18 - Differentiable computation graph = True!
PPO iteration: 131/1000:
	 New training batch of size 20...
	 start solving instance: 10...
	 start solving instance: 47...
	 start solving instance: 40...
	 start solving instance: 82...
	 start solving instance: 74...
	 start solving instance: 109...
	 start solving instance: 104...
	 start solving instance: 17...
	 start solving instance: 92...
	 start solving instance: 108...
	 start solving instance: 52...
	 start solving instance: 79...
	 start solving instance: 114...
	 start solving instance: 118...
	 start solving instance: 78...
	 start solving instance: 33...
	 start solving instance: 98...
	 start solving instance: 129...
	 start solving instance: 3...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.692229095402032e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5978516992.0
		 entropy bonus: 0.215840145945549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5660978688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6065926656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.692229040426451e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.692229095402032e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5978516992.0
		 entropy bonus: 0.215840145945549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5660978688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6065926656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.692229040426451e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.692229095402032e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5978516992.0
		 entropy bonus: 0.215840145945549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5660978688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6065926656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.692229040426451e+18 - Differentiable computation graph = True!
PPO iteration: 132/1000:
	 start solving instance: 17...
	 start solving instance: 10...
	 start solving instance: 98...
	 start solving instance: 52...
	 start solving instance: 109...
	 start solving instance: 79...
	 start solving instance: 104...
	 start solving instance: 47...
	 start solving instance: 90...
	 start solving instance: 3...
	 start solving instance: 108...
	 start solving instance: 40...
	 start solving instance: 118...
	 start solving instance: 129...
	 start solving instance: 82...
	 start solving instance: 92...
	 start solving instance: 78...
	 start solving instance: 33...
	 start solving instance: 74...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.041002540020951e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6122580992.0
		 entropy bonus: 0.23233428597450256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6093303296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6494786048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0410026499721134e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.041002540020951e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6122580992.0
		 entropy bonus: 0.23233428597450256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6093303296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6494786048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0410026499721134e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.041002540020951e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6122580992.0
		 entropy bonus: 0.23233428597450256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6093303296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6494786048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0410026499721134e+18 - Differentiable computation graph = True!
PPO iteration: 133/1000:
	 start solving instance: 129...
	 start solving instance: 90...
	 start solving instance: 3...
	 start solving instance: 98...
	 start solving instance: 47...
	 start solving instance: 92...
	 start solving instance: 17...
	 start solving instance: 109...
	 start solving instance: 108...
	 start solving instance: 79...
	 start solving instance: 74...
	 start solving instance: 40...
	 start solving instance: 78...
	 start solving instance: 118...
	 start solving instance: 104...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 114...
	 start solving instance: 82...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.855964408768574e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6011061760.0
		 entropy bonus: 0.21698425710201263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5846394880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6184494080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8559644637441556e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.855964408768574e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6011061760.0
		 entropy bonus: 0.21698425710201263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5846394880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6184494080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8559644637441556e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.855964408768574e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6011061760.0
		 entropy bonus: 0.21698425710201263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5846394880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6184494080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8559644637441556e+18 - Differentiable computation graph = True!
PPO iteration: 134/1000:
	 start solving instance: 90...
	 start solving instance: 47...
	 start solving instance: 82...
	 start solving instance: 52...
	 start solving instance: 40...
	 start solving instance: 109...
	 start solving instance: 108...
	 start solving instance: 114...
	 start solving instance: 118...
	 start solving instance: 92...
	 start solving instance: 33...
	 start solving instance: 10...
	 start solving instance: 98...
	 start solving instance: 17...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 78...
	 start solving instance: 79...
	 start solving instance: 104...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7177214923943444e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982704640.0
		 entropy bonus: 0.2159603089094162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5751539200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6081372160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7177214923943444e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7177214923943444e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982704640.0
		 entropy bonus: 0.2159603089094162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5751539200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6081372160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7177214923943444e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7177214923943444e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982704640.0
		 entropy bonus: 0.2159603089094162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5751539200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6081372160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7177214923943444e+18 - Differentiable computation graph = True!
PPO iteration: 135/1000:
	 start solving instance: 98...
	 start solving instance: 108...
	 start solving instance: 90...
	 start solving instance: 3...
	 start solving instance: 92...
	 start solving instance: 79...
	 start solving instance: 47...
	 start solving instance: 118...
	 start solving instance: 109...
	 start solving instance: 104...
	 start solving instance: 129...
	 start solving instance: 52...
	 start solving instance: 82...
	 start solving instance: 40...
	 start solving instance: 10...
	 start solving instance: 33...
	 start solving instance: 17...
	 start solving instance: 114...
	 start solving instance: 78...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.696833850099158e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5950198784.0
		 entropy bonus: 0.21420077979564667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5739485696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6245088256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.696833795123577e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.696833850099158e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5950198784.0
		 entropy bonus: 0.21420077979564667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5739485696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6245088256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.696833795123577e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.696833850099158e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5950198784.0
		 entropy bonus: 0.21420077979564667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5739485696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6245088256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.696833795123577e+18 - Differentiable computation graph = True!
PPO iteration: 136/1000:
	 start solving instance: 118...
	 start solving instance: 33...
	 start solving instance: 98...
	 start solving instance: 82...
	 start solving instance: 92...
	 start solving instance: 78...
	 start solving instance: 74...
	 start solving instance: 129...
	 start solving instance: 109...
	 start solving instance: 52...
	 start solving instance: 114...
	 start solving instance: 108...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 10...
	 start solving instance: 40...
	 start solving instance: 3...
	 start solving instance: 17...
	 start solving instance: 79...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.945803744655547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6032722432.0
		 entropy bonus: 0.21118421852588654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5978338816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6487639040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.945803909582291e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.945803744655547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6032722432.0
		 entropy bonus: 0.21118421852588654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5978338816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6487639040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.945803909582291e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.945803744655547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6032722432.0
		 entropy bonus: 0.21118421852588654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5978338816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6487639040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.945803909582291e+18 - Differentiable computation graph = True!
PPO iteration: 137/1000:
	 start solving instance: 47...
	 start solving instance: 108...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 17...
	 start solving instance: 74...
	 start solving instance: 92...
	 start solving instance: 33...
	 start solving instance: 10...
	 start solving instance: 78...
	 start solving instance: 79...
	 start solving instance: 82...
	 start solving instance: 98...
	 start solving instance: 3...
	 start solving instance: 114...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 40...
	 start solving instance: 109...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.971584213694336e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6028043776.0
		 entropy bonus: 0.21969051659107208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6005040128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6319918592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971584158718755e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.971584213694336e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6028043776.0
		 entropy bonus: 0.21969051659107208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6005040128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6319918592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971584158718755e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.971584213694336e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6028043776.0
		 entropy bonus: 0.21969051659107208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6005040128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6319918592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971584158718755e+18 - Differentiable computation graph = True!
PPO iteration: 138/1000:
	 start solving instance: 92...
	 start solving instance: 47...
	 start solving instance: 79...
	 start solving instance: 17...
	 start solving instance: 33...
	 start solving instance: 108...
	 start solving instance: 3...
	 start solving instance: 52...
	 start solving instance: 118...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 40...
	 start solving instance: 82...
	 start solving instance: 109...
	 start solving instance: 78...
	 start solving instance: 114...
	 start solving instance: 74...
	 start solving instance: 98...
	 start solving instance: 129...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.092185685903226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069645312.0
		 entropy bonus: 0.21726834774017334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6088515072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6503221248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.092185740878807e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.092185685903226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069645312.0
		 entropy bonus: 0.21726834774017334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6088515072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6503221248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.092185740878807e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.092185685903226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069645312.0
		 entropy bonus: 0.21726834774017334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6088515072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6503221248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.092185740878807e+18 - Differentiable computation graph = True!
PPO iteration: 139/1000:
	 start solving instance: 92...
	 start solving instance: 98...
	 start solving instance: 40...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 109...
	 start solving instance: 10...
	 start solving instance: 114...
	 start solving instance: 82...
	 start solving instance: 74...
	 start solving instance: 118...
	 start solving instance: 17...
	 start solving instance: 47...
	 start solving instance: 78...
	 start solving instance: 79...
	 start solving instance: 129...
	 start solving instance: 108...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0088171958480404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6073585664.0
		 entropy bonus: 0.21676576137542725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6000401920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6371557376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0088171958480404e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0088171958480404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6073585664.0
		 entropy bonus: 0.21676576137542725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6000401920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6371557376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0088171958480404e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0088171958480404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6073585664.0
		 entropy bonus: 0.21676576137542725
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6000401920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6371557376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0088171958480404e+18 - Differentiable computation graph = True!
PPO iteration: 140/1000:
	 start solving instance: 90...
	 start solving instance: 82...
	 start solving instance: 129...
	 start solving instance: 47...
	 start solving instance: 33...
	 start solving instance: 92...
	 start solving instance: 98...
	 start solving instance: 108...
	 start solving instance: 78...
	 start solving instance: 40...
	 start solving instance: 52...
	 start solving instance: 74...
	 start solving instance: 3...
	 start solving instance: 114...
	 start solving instance: 104...
	 start solving instance: 17...
	 start solving instance: 79...
	 start solving instance: 118...
	 start solving instance: 10...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.945728098255556e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5995853824.0
		 entropy bonus: 0.22343027591705322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5907958784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6253881344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9457280432799744e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.945728098255556e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5995853824.0
		 entropy bonus: 0.22343027591705322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5907958784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6253881344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9457280432799744e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.945728098255556e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5995853824.0
		 entropy bonus: 0.22343027591705322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5907958784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6253881344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9457280432799744e+18 - Differentiable computation graph = True!
PPO iteration: 141/1000:
	 New training batch of size 20...
	 start solving instance: 115...
	 start solving instance: 108...
	 start solving instance: 144...
	 start solving instance: 80...
	 start solving instance: 74...
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 73...
	 start solving instance: 29...
	 start solving instance: 14...
	 start solving instance: 59...
	 start solving instance: 99...
	 start solving instance: 21...
	 start solving instance: 126...
	 start solving instance: 119...
	 start solving instance: 56...
	 start solving instance: 114...
	 start solving instance: 105...
	 start solving instance: 113...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.145109578594596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140307968.0
		 entropy bonus: 0.2194264680147171
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6135882240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6631997952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.145109633570177e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.145109578594596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140307968.0
		 entropy bonus: 0.2194264680147171
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6135882240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6631997952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.145109633570177e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.145109578594596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140307968.0
		 entropy bonus: 0.2194264680147171
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6135882240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6631997952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.145109633570177e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.0215536106400645e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5208887296.0
		 entropy bonus: 0.21488800644874573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5079784960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6007795712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3021553610640064512.0000
PPO iteration: 142/1000:
	 start solving instance: 114...
	 start solving instance: 74...
	 start solving instance: 126...
	 start solving instance: 56...
	 start solving instance: 14...
	 start solving instance: 10...
	 start solving instance: 108...
	 start solving instance: 29...
	 start solving instance: 105...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 59...
	 start solving instance: 99...
	 start solving instance: 73...
	 start solving instance: 115...
	 start solving instance: 80...
	 start solving instance: 21...
	 start solving instance: 113...
	 start solving instance: 144...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.230417167356527e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6153950720.0
		 entropy bonus: 0.21223540604114532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6134722560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6511319040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2304171673565266e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.230417167356527e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6153950720.0
		 entropy bonus: 0.21223540604114532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6134722560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6511319040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2304171673565266e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.230417167356527e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6153950720.0
		 entropy bonus: 0.21223540604114532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6134722560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6511319040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2304171673565266e+18 - Differentiable computation graph = True!
PPO iteration: 143/1000:
	 start solving instance: 74...
	 start solving instance: 108...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 115...
	 start solving instance: 144...
	 start solving instance: 99...
	 start solving instance: 10...
	 start solving instance: 29...
	 start solving instance: 59...
	 start solving instance: 21...
	 start solving instance: 114...
	 start solving instance: 119...
	 start solving instance: 56...
	 start solving instance: 126...
	 start solving instance: 80...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.971966843740802e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009445888.0
		 entropy bonus: 0.2029791921377182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877236736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6580077056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971966788765221e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.971966843740802e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009445888.0
		 entropy bonus: 0.2029791921377182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877236736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6580077056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971966788765221e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.971966843740802e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009445888.0
		 entropy bonus: 0.2029791921377182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877236736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6580077056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971966788765221e+18 - Differentiable computation graph = True!
PPO iteration: 144/1000:
	 start solving instance: 126...
	 start solving instance: 99...
	 start solving instance: 119...
	 start solving instance: 114...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 113...
	 start solving instance: 104...
	 start solving instance: 108...
	 start solving instance: 144...
	 start solving instance: 73...
	 start solving instance: 91...
	 start solving instance: 59...
	 start solving instance: 29...
	 start solving instance: 14...
	 start solving instance: 74...
	 start solving instance: 105...
	 start solving instance: 56...
	 start solving instance: 21...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.025434334980945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6018029056.0
		 entropy bonus: 0.19728568196296692
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5951257088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6474149376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.025434389956526e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.025434334980945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6018029056.0
		 entropy bonus: 0.19728568196296692
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5951257088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6474149376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.025434389956526e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.025434334980945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6018029056.0
		 entropy bonus: 0.19728568196296692
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5951257088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6474149376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.025434389956526e+18 - Differentiable computation graph = True!
PPO iteration: 145/1000:
	 start solving instance: 21...
	 start solving instance: 74...
	 start solving instance: 56...
	 start solving instance: 114...
	 start solving instance: 108...
	 start solving instance: 119...
	 start solving instance: 14...
	 start solving instance: 126...
	 start solving instance: 99...
	 start solving instance: 144...
	 start solving instance: 73...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 113...
	 start solving instance: 105...
	 start solving instance: 115...
	 start solving instance: 29...
	 start solving instance: 59...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.176816415307098e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981006336.0
		 entropy bonus: 0.2227035015821457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6159426048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6577167872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1768165252582605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.176816415307098e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981006336.0
		 entropy bonus: 0.2227035015821457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6159426048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6577167872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1768165252582605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.176816415307098e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981006336.0
		 entropy bonus: 0.2227035015821457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6159426048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6577167872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1768165252582605e+18 - Differentiable computation graph = True!
PPO iteration: 146/1000:
	 start solving instance: 29...
	 start solving instance: 104...
	 start solving instance: 105...
	 start solving instance: 99...
	 start solving instance: 59...
	 start solving instance: 113...
	 start solving instance: 126...
	 start solving instance: 80...
	 start solving instance: 73...
	 start solving instance: 56...
	 start solving instance: 10...
	 start solving instance: 91...
	 start solving instance: 14...
	 start solving instance: 74...
	 start solving instance: 119...
	 start solving instance: 144...
	 start solving instance: 115...
	 start solving instance: 21...
	 start solving instance: 114...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.083131867355467e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6093381120.0
		 entropy bonus: 0.21523597836494446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6035875328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6498946560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0831318123798856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.083131867355467e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6093381120.0
		 entropy bonus: 0.21523597836494446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6035875328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6498946560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0831318123798856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.083131867355467e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6093381120.0
		 entropy bonus: 0.21523597836494446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6035875328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6498946560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0831318123798856e+18 - Differentiable computation graph = True!
PPO iteration: 147/1000:
	 start solving instance: 108...
	 start solving instance: 14...
	 start solving instance: 56...
	 start solving instance: 119...
	 start solving instance: 29...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 114...
	 start solving instance: 126...
	 start solving instance: 105...
	 start solving instance: 91...
	 start solving instance: 10...
	 start solving instance: 99...
	 start solving instance: 59...
	 start solving instance: 104...
	 start solving instance: 21...
	 start solving instance: 115...
	 start solving instance: 144...
	 start solving instance: 74...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.161676579997273e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6094461952.0
		 entropy bonus: 0.19773243367671967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6013670400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6777484288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.161676525021692e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.161676579997273e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6094461952.0
		 entropy bonus: 0.19773243367671967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6013670400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6777484288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.161676525021692e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.161676579997273e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6094461952.0
		 entropy bonus: 0.19773243367671967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6013670400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6777484288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.161676525021692e+18 - Differentiable computation graph = True!
PPO iteration: 148/1000:
	 start solving instance: 115...
	 start solving instance: 113...
	 start solving instance: 126...
	 start solving instance: 56...
	 start solving instance: 29...
	 start solving instance: 80...
	 start solving instance: 99...
	 start solving instance: 114...
	 start solving instance: 59...
	 start solving instance: 104...
	 start solving instance: 91...
	 start solving instance: 108...
	 start solving instance: 144...
	 start solving instance: 21...
	 start solving instance: 74...
	 start solving instance: 14...
	 start solving instance: 105...
	 start solving instance: 10...
	 start solving instance: 73...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.991972237905861e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063141888.0
		 entropy bonus: 0.19979993999004364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5890522624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6554202624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.991972402832605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.991972237905861e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063141888.0
		 entropy bonus: 0.19979993999004364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5890522624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6554202624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.991972402832605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.991972237905861e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063141888.0
		 entropy bonus: 0.19979993999004364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5890522624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6554202624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.991972402832605e+18 - Differentiable computation graph = True!
PPO iteration: 149/1000:
	 start solving instance: 126...
	 start solving instance: 73...
	 start solving instance: 80...
	 start solving instance: 119...
	 start solving instance: 91...
	 start solving instance: 114...
	 start solving instance: 144...
	 start solving instance: 56...
	 start solving instance: 113...
	 start solving instance: 115...
	 start solving instance: 21...
	 start solving instance: 29...
	 start solving instance: 14...
	 start solving instance: 105...
	 start solving instance: 104...
	 start solving instance: 108...
	 start solving instance: 99...
	 start solving instance: 74...
	 start solving instance: 59...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.055990642726142e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6049926656.0
		 entropy bonus: 0.21028633415699005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5999237632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6550473728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.055990642726142e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.055990642726142e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6049926656.0
		 entropy bonus: 0.21028633415699005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5999237632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6550473728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.055990642726142e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.055990642726142e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6049926656.0
		 entropy bonus: 0.21028633415699005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5999237632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6550473728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.055990642726142e+18 - Differentiable computation graph = True!
PPO iteration: 150/1000:
	 start solving instance: 56...
	 start solving instance: 29...
	 start solving instance: 99...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 74...
	 start solving instance: 105...
	 start solving instance: 91...
	 start solving instance: 114...
	 start solving instance: 144...
	 start solving instance: 80...
	 start solving instance: 108...
	 start solving instance: 10...
	 start solving instance: 115...
	 start solving instance: 14...
	 start solving instance: 59...
	 start solving instance: 119...
	 start solving instance: 21...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.378204724269154e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6183141376.0
		 entropy bonus: 0.21557311713695526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294920704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7208062464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3782047242691543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.378204724269154e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6183141376.0
		 entropy bonus: 0.21557311713695526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294920704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7208062464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3782047242691543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.378204724269154e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6183141376.0
		 entropy bonus: 0.21557311713695526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294920704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7208062464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3782047242691543e+18 - Differentiable computation graph = True!
PPO iteration: 151/1000:
	 New training batch of size 20...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 58...
	 start solving instance: 28...
	 start solving instance: 102...
	 start solving instance: 140...
	 start solving instance: 105...
	 start solving instance: 121...
	 start solving instance: 39...
	 start solving instance: 72...
	 start solving instance: 135...
	 start solving instance: 131...
	 start solving instance: 43...
	 start solving instance: 46...
	 start solving instance: 99...
	 start solving instance: 10...
	 start solving instance: 9...
	 start solving instance: 83...
	 start solving instance: 34...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.662382852266053e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5780605440.0
		 entropy bonus: 0.20339198410511017
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865510400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836377600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6623827972904714e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.662382852266053e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5780605440.0
		 entropy bonus: 0.20339198410511017
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865510400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836377600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6623827972904714e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.662382852266053e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5780605440.0
		 entropy bonus: 0.20339198410511017
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865510400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836377600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6623827972904714e+18 - Differentiable computation graph = True!
PPO iteration: 152/1000:
	 start solving instance: 58...
	 start solving instance: 102...
	 start solving instance: 5...
	 start solving instance: 10...
	 start solving instance: 121...
	 start solving instance: 135...
	 start solving instance: 9...
	 start solving instance: 129...
	 start solving instance: 99...
	 start solving instance: 131...
	 start solving instance: 28...
	 start solving instance: 39...
	 start solving instance: 105...
	 start solving instance: 83...
	 start solving instance: 34...
	 start solving instance: 140...
	 start solving instance: 43...
	 start solving instance: 46...
	 start solving instance: 72...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5919465980744434e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5697627648.0
		 entropy bonus: 0.22215138375759125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723395584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400634368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.591946708025606e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5919465980744434e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5697627648.0
		 entropy bonus: 0.22215138375759125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723395584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400634368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.591946708025606e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5919465980744434e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5697627648.0
		 entropy bonus: 0.22215138375759125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723395584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400634368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.591946708025606e+18 - Differentiable computation graph = True!
PPO iteration: 153/1000:
	 start solving instance: 39...
	 start solving instance: 95...
	 start solving instance: 46...
	 start solving instance: 10...
	 start solving instance: 102...
	 start solving instance: 105...
	 start solving instance: 34...
	 start solving instance: 121...
	 start solving instance: 72...
	 start solving instance: 9...
	 start solving instance: 135...
	 start solving instance: 28...
	 start solving instance: 99...
	 start solving instance: 129...
	 start solving instance: 5...
	 start solving instance: 58...
	 start solving instance: 131...
	 start solving instance: 43...
	 start solving instance: 140...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2831346836647182e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5755149824.0
		 entropy bonus: 0.21042267978191376
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5401993728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6028320256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2831348485914624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2831346836647182e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5755149824.0
		 entropy bonus: 0.21042267978191376
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5401993728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6028320256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2831348485914624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2831346836647182e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5755149824.0
		 entropy bonus: 0.21042267978191376
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5401993728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6028320256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2831348485914624e+18 - Differentiable computation graph = True!
PPO iteration: 154/1000:
	 start solving instance: 34...
	 start solving instance: 39...
	 start solving instance: 83...
	 start solving instance: 140...
	 start solving instance: 43...
	 start solving instance: 121...
	 start solving instance: 95...
	 start solving instance: 129...
	 start solving instance: 58...
	 start solving instance: 102...
	 start solving instance: 131...
	 start solving instance: 99...
	 start solving instance: 46...
	 start solving instance: 5...
	 start solving instance: 72...
	 start solving instance: 105...
	 start solving instance: 28...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4833493739152867e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5678075392.0
		 entropy bonus: 0.22057104110717773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5727480320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6168208384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4833493189397053e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4833493739152867e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5678075392.0
		 entropy bonus: 0.22057104110717773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5727480320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6168208384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4833493189397053e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4833493739152867e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5678075392.0
		 entropy bonus: 0.22057104110717773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5727480320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6168208384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4833493189397053e+18 - Differentiable computation graph = True!
PPO iteration: 155/1000:
	 start solving instance: 121...
	 start solving instance: 140...
	 start solving instance: 34...
	 start solving instance: 46...
	 start solving instance: 10...
	 start solving instance: 99...
	 start solving instance: 102...
	 start solving instance: 95...
	 start solving instance: 131...
	 start solving instance: 5...
	 start solving instance: 43...
	 start solving instance: 83...
	 start solving instance: 9...
	 start solving instance: 28...
	 start solving instance: 135...
	 start solving instance: 105...
	 start solving instance: 58...
	 start solving instance: 129...
	 start solving instance: 39...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2581157363793265e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5675648000.0
		 entropy bonus: 0.2146453857421875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5370877440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5968265216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2581157363793265e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2581157363793265e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5675648000.0
		 entropy bonus: 0.2146453857421875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5370877440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5968265216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2581157363793265e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2581157363793265e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5675648000.0
		 entropy bonus: 0.2146453857421875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5370877440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5968265216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2581157363793265e+18 - Differentiable computation graph = True!
PPO iteration: 156/1000:
	 start solving instance: 28...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 95...
	 start solving instance: 135...
	 start solving instance: 5...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 99...
	 start solving instance: 34...
	 start solving instance: 121...
	 start solving instance: 105...
	 start solving instance: 102...
	 start solving instance: 72...
	 start solving instance: 39...
	 start solving instance: 10...
	 start solving instance: 140...
	 start solving instance: 129...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4237760747037786e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5747069440.0
		 entropy bonus: 0.2151275873184204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5511702016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6376484864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.42377612967936e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4237760747037786e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5747069440.0
		 entropy bonus: 0.2151275873184204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5511702016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6376484864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.42377612967936e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4237760747037786e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5747069440.0
		 entropy bonus: 0.2151275873184204
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5511702016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6376484864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.42377612967936e+18 - Differentiable computation graph = True!
PPO iteration: 157/1000:
	 start solving instance: 129...
	 start solving instance: 135...
	 start solving instance: 39...
	 start solving instance: 140...
	 start solving instance: 34...
	 start solving instance: 5...
	 start solving instance: 121...
	 start solving instance: 102...
	 start solving instance: 105...
	 start solving instance: 83...
	 start solving instance: 10...
	 start solving instance: 46...
	 start solving instance: 72...
	 start solving instance: 43...
	 start solving instance: 99...
	 start solving instance: 28...
	 start solving instance: 131...
	 start solving instance: 9...
	 start solving instance: 58...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.286761092915449e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5576027136.0
		 entropy bonus: 0.22437699139118195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5546364416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6017804800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2867610379398676e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.286761092915449e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5576027136.0
		 entropy bonus: 0.22437699139118195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5546364416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6017804800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2867610379398676e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.286761092915449e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5576027136.0
		 entropy bonus: 0.22437699139118195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5546364416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6017804800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2867610379398676e+18 - Differentiable computation graph = True!
PPO iteration: 158/1000:
	 start solving instance: 99...
	 start solving instance: 34...
	 start solving instance: 83...
	 start solving instance: 102...
	 start solving instance: 72...
	 start solving instance: 43...
	 start solving instance: 129...
	 start solving instance: 39...
	 start solving instance: 121...
	 start solving instance: 95...
	 start solving instance: 135...
	 start solving instance: 140...
	 start solving instance: 131...
	 start solving instance: 5...
	 start solving instance: 58...
	 start solving instance: 46...
	 start solving instance: 10...
	 start solving instance: 105...
	 start solving instance: 28...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5779504747598316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5628144128.0
		 entropy bonus: 0.21521888673305511
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5768539648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6669494784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5779504747598316e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5779504747598316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5628144128.0
		 entropy bonus: 0.21521888673305511
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5768539648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6669494784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5779504747598316e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5779504747598316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5628144128.0
		 entropy bonus: 0.21521888673305511
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5768539648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6669494784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5779504747598316e+18 - Differentiable computation graph = True!
PPO iteration: 159/1000:
	 start solving instance: 58...
	 start solving instance: 140...
	 start solving instance: 34...
	 start solving instance: 99...
	 start solving instance: 105...
	 start solving instance: 43...
	 start solving instance: 102...
	 start solving instance: 129...
	 start solving instance: 135...
	 start solving instance: 131...
	 start solving instance: 10...
	 start solving instance: 9...
	 start solving instance: 95...
	 start solving instance: 5...
	 start solving instance: 39...
	 start solving instance: 72...
	 start solving instance: 28...
	 start solving instance: 121...
	 start solving instance: 46...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4862316336963387e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711657472.0
		 entropy bonus: 0.21611319482326508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5658052096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6266447872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.48623168867192e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4862316336963387e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711657472.0
		 entropy bonus: 0.21611319482326508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5658052096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6266447872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.48623168867192e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4862316336963387e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711657472.0
		 entropy bonus: 0.21611319482326508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5658052096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6266447872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.48623168867192e+18 - Differentiable computation graph = True!
PPO iteration: 160/1000:
	 start solving instance: 9...
	 start solving instance: 46...
	 start solving instance: 140...
	 start solving instance: 43...
	 start solving instance: 95...
	 start solving instance: 34...
	 start solving instance: 5...
	 start solving instance: 28...
	 start solving instance: 102...
	 start solving instance: 39...
	 start solving instance: 129...
	 start solving instance: 72...
	 start solving instance: 99...
	 start solving instance: 10...
	 start solving instance: 83...
	 start solving instance: 131...
	 start solving instance: 135...
	 start solving instance: 121...
	 start solving instance: 105...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2896022309616222e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682277376.0
		 entropy bonus: 0.2139481157064438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5405443584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6036770816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.289602175986041e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2896022309616222e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682277376.0
		 entropy bonus: 0.2139481157064438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5405443584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6036770816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.289602175986041e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2896022309616222e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682277376.0
		 entropy bonus: 0.2139481157064438
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5405443584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6036770816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.289602175986041e+18 - Differentiable computation graph = True!
PPO iteration: 161/1000:
	 New training batch of size 20...
	 start solving instance: 111...
	 start solving instance: 62...
	 start solving instance: 77...
	 start solving instance: 20...
	 start solving instance: 60...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 39...
	 start solving instance: 14...
	 start solving instance: 30...
	 start solving instance: 38...
	 start solving instance: 127...
	 start solving instance: 101...
	 start solving instance: 69...
	 start solving instance: 9...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 82...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.299499482929693e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6159157248.0
		 entropy bonus: 0.2016068547964096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6112733184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6999511552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2994994829296927e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.299499482929693e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6159157248.0
		 entropy bonus: 0.2016068547964096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6112733184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6999511552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2994994829296927e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.299499482929693e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6159157248.0
		 entropy bonus: 0.2016068547964096
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6112733184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6999511552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2994994829296927e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.2696225653686534e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5393363456.0
		 entropy bonus: 0.20163242518901825
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5379704832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6226263040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3269622675319816192.0000
PPO iteration: 162/1000:
	 start solving instance: 14...
	 start solving instance: 44...
	 start solving instance: 150...
	 start solving instance: 9...
	 start solving instance: 107...
	 start solving instance: 39...
	 start solving instance: 69...
	 start solving instance: 77...
	 start solving instance: 82...
	 start solving instance: 62...
	 start solving instance: 101...
	 start solving instance: 60...
	 start solving instance: 20...
	 start solving instance: 111...
	 start solving instance: 51...
	 start solving instance: 127...
	 start solving instance: 103...
	 start solving instance: 38...
	 start solving instance: 30...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2606814448133865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193456640.0
		 entropy bonus: 0.19348616898059845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6085291520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7111844352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.260681499788968e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2606814448133865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193456640.0
		 entropy bonus: 0.19348616898059845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6085291520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7111844352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.260681499788968e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2606814448133865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193456640.0
		 entropy bonus: 0.19348616898059845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6085291520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7111844352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.260681499788968e+18 - Differentiable computation graph = True!
PPO iteration: 163/1000:
	 start solving instance: 60...
	 start solving instance: 82...
	 start solving instance: 39...
	 start solving instance: 69...
	 start solving instance: 51...
	 start solving instance: 38...
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 44...
	 start solving instance: 20...
	 start solving instance: 101...
	 start solving instance: 111...
	 start solving instance: 85...
	 start solving instance: 9...
	 start solving instance: 14...
	 start solving instance: 30...
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 127...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.156727018453677e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060524032.0
		 entropy bonus: 0.1881212443113327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6049338368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6982717440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.156727073429258e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.156727018453677e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060524032.0
		 entropy bonus: 0.1881212443113327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6049338368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6982717440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.156727073429258e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.156727018453677e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060524032.0
		 entropy bonus: 0.1881212443113327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6049338368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6982717440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.156727073429258e+18 - Differentiable computation graph = True!
PPO iteration: 164/1000:
	 start solving instance: 38...
	 start solving instance: 82...
	 start solving instance: 60...
	 start solving instance: 101...
	 start solving instance: 127...
	 start solving instance: 39...
	 start solving instance: 111...
	 start solving instance: 62...
	 start solving instance: 20...
	 start solving instance: 150...
	 start solving instance: 14...
	 start solving instance: 44...
	 start solving instance: 9...
	 start solving instance: 69...
	 start solving instance: 30...
	 start solving instance: 51...
	 start solving instance: 77...
	 start solving instance: 107...
	 start solving instance: 103...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.175929769130459e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132043264.0
		 entropy bonus: 0.20333583652973175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6054862336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6961665536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.175929769130459e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.175929769130459e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132043264.0
		 entropy bonus: 0.20333583652973175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6054862336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6961665536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.175929769130459e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.175929769130459e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132043264.0
		 entropy bonus: 0.20333583652973175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6054862336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6961665536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.175929769130459e+18 - Differentiable computation graph = True!
PPO iteration: 165/1000:
	 start solving instance: 62...
	 start solving instance: 111...
	 start solving instance: 107...
	 start solving instance: 30...
	 start solving instance: 69...
	 start solving instance: 38...
	 start solving instance: 44...
	 start solving instance: 9...
	 start solving instance: 150...
	 start solving instance: 60...
	 start solving instance: 85...
	 start solving instance: 101...
	 start solving instance: 77...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 39...
	 start solving instance: 51...
	 start solving instance: 103...
	 start solving instance: 82...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.139307235832496e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106689536.0
		 entropy bonus: 0.20072226226329803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6075697152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7071592448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.139307235832496e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.139307235832496e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106689536.0
		 entropy bonus: 0.20072226226329803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6075697152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7071592448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.139307235832496e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.139307235832496e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106689536.0
		 entropy bonus: 0.20072226226329803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6075697152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7071592448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.139307235832496e+18 - Differentiable computation graph = True!
PPO iteration: 166/1000:
	 start solving instance: 150...
	 start solving instance: 127...
	 start solving instance: 39...
	 start solving instance: 38...
	 start solving instance: 14...
	 start solving instance: 9...
	 start solving instance: 101...
	 start solving instance: 111...
	 start solving instance: 77...
	 start solving instance: 30...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 60...
	 start solving instance: 62...
	 start solving instance: 20...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 69...
	 start solving instance: 82...
	 start solving instance: 51...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.238976645476437e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107731968.0
		 entropy bonus: 0.20964853465557098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114065920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6870471168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.238976590500856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.238976645476437e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107731968.0
		 entropy bonus: 0.20964853465557098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114065920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6870471168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.238976590500856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.238976645476437e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107731968.0
		 entropy bonus: 0.20964853465557098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114065920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6870471168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.238976590500856e+18 - Differentiable computation graph = True!
PPO iteration: 167/1000:
	 start solving instance: 101...
	 start solving instance: 127...
	 start solving instance: 103...
	 start solving instance: 14...
	 start solving instance: 38...
	 start solving instance: 51...
	 start solving instance: 20...
	 start solving instance: 69...
	 start solving instance: 150...
	 start solving instance: 85...
	 start solving instance: 82...
	 start solving instance: 9...
	 start solving instance: 111...
	 start solving instance: 39...
	 start solving instance: 107...
	 start solving instance: 30...
	 start solving instance: 44...
	 start solving instance: 77...
	 start solving instance: 62...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2330423613190046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149297664.0
		 entropy bonus: 0.18979452550411224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6182551040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6936115200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2330425262457487e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2330423613190046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149297664.0
		 entropy bonus: 0.18979452550411224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6182551040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6936115200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2330425262457487e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2330423613190046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149297664.0
		 entropy bonus: 0.18979452550411224
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6182551040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6936115200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2330425262457487e+18 - Differentiable computation graph = True!
PPO iteration: 168/1000:
	 start solving instance: 62...
	 start solving instance: 101...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 111...
	 start solving instance: 85...
	 start solving instance: 39...
	 start solving instance: 9...
	 start solving instance: 103...
	 start solving instance: 30...
	 start solving instance: 107...
	 start solving instance: 38...
	 start solving instance: 69...
	 start solving instance: 14...
	 start solving instance: 44...
	 start solving instance: 60...
	 start solving instance: 20...
	 start solving instance: 77...
	 start solving instance: 82...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.980777450316497e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5960507904.0
		 entropy bonus: 0.19601097702980042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5824802304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707575808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.980777450316497e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.980777450316497e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5960507904.0
		 entropy bonus: 0.19601097702980042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5824802304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707575808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.980777450316497e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.980777450316497e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5960507904.0
		 entropy bonus: 0.19601097702980042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5824802304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707575808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.980777450316497e+18 - Differentiable computation graph = True!
PPO iteration: 169/1000:
	 start solving instance: 103...
	 start solving instance: 38...
	 start solving instance: 111...
	 start solving instance: 85...
	 start solving instance: 30...
	 start solving instance: 69...
	 start solving instance: 107...
	 start solving instance: 101...
	 start solving instance: 150...
	 start solving instance: 9...
	 start solving instance: 39...
	 start solving instance: 44...
	 start solving instance: 51...
	 start solving instance: 60...
	 start solving instance: 77...
	 start solving instance: 62...
	 start solving instance: 14...
	 start solving instance: 82...
	 start solving instance: 127...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.039786040355979e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6071991808.0
		 entropy bonus: 0.2053258866071701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6051528192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6985212416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0397860403559793e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.039786040355979e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6071991808.0
		 entropy bonus: 0.2053258866071701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6051528192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6985212416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0397860403559793e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.039786040355979e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6071991808.0
		 entropy bonus: 0.2053258866071701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6051528192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6985212416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0397860403559793e+18 - Differentiable computation graph = True!
PPO iteration: 170/1000:
	 start solving instance: 69...
	 start solving instance: 44...
	 start solving instance: 20...
	 start solving instance: 9...
	 start solving instance: 30...
	 start solving instance: 14...
	 start solving instance: 62...
	 start solving instance: 127...
	 start solving instance: 82...
	 start solving instance: 51...
	 start solving instance: 77...
	 start solving instance: 85...
	 start solving instance: 107...
	 start solving instance: 101...
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 39...
	 start solving instance: 60...
	 start solving instance: 111...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.169064418526626e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079093248.0
		 entropy bonus: 0.20164985954761505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114987520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6769266688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.169064418526626e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.169064418526626e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079093248.0
		 entropy bonus: 0.20164985954761505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114987520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6769266688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.169064418526626e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.169064418526626e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079093248.0
		 entropy bonus: 0.20164985954761505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114987520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6769266688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.169064418526626e+18 - Differentiable computation graph = True!
PPO iteration: 171/1000:
	 New training batch of size 20...
	 start solving instance: 52...
	 start solving instance: 135...
	 start solving instance: 145...
	 start solving instance: 57...
	 start solving instance: 130...
	 start solving instance: 73...
	 start solving instance: 35...
	 start solving instance: 115...
	 start solving instance: 61...
	 start solving instance: 47...
	 start solving instance: 140...
	 start solving instance: 51...
	 start solving instance: 125...
	 start solving instance: 129...
	 start solving instance: 49...
	 start solving instance: 62...
	 start solving instance: 11...
	 start solving instance: 55...
	 start solving instance: 43...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6292378543444197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5700572160.0
		 entropy bonus: 0.2088909149169922
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5730662912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6467328000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.629238019271164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6292378543444197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5700572160.0
		 entropy bonus: 0.2088909149169922
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5730662912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6467328000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.629238019271164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6292378543444197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5700572160.0
		 entropy bonus: 0.2088909149169922
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5730662912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6467328000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.629238019271164e+18 - Differentiable computation graph = True!
PPO iteration: 172/1000:
	 start solving instance: 11...
	 start solving instance: 52...
	 start solving instance: 130...
	 start solving instance: 115...
	 start solving instance: 55...
	 start solving instance: 135...
	 start solving instance: 129...
	 start solving instance: 125...
	 start solving instance: 140...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 73...
	 start solving instance: 51...
	 start solving instance: 62...
	 start solving instance: 110...
	 start solving instance: 145...
	 start solving instance: 47...
	 start solving instance: 61...
	 start solving instance: 49...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5700467453747266e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5669932032.0
		 entropy bonus: 0.19756203889846802
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5626156032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6537525760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5700469103014707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5700467453747266e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5669932032.0
		 entropy bonus: 0.19756203889846802
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5626156032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6537525760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5700469103014707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5700467453747266e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5669932032.0
		 entropy bonus: 0.19756203889846802
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5626156032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6537525760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5700469103014707e+18 - Differentiable computation graph = True!
PPO iteration: 173/1000:
	 start solving instance: 35...
	 start solving instance: 62...
	 start solving instance: 140...
	 start solving instance: 11...
	 start solving instance: 55...
	 start solving instance: 115...
	 start solving instance: 145...
	 start solving instance: 51...
	 start solving instance: 57...
	 start solving instance: 47...
	 start solving instance: 129...
	 start solving instance: 52...
	 start solving instance: 61...
	 start solving instance: 125...
	 start solving instance: 135...
	 start solving instance: 73...
	 start solving instance: 43...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.447952356277643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5645983232.0
		 entropy bonus: 0.20169317722320557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417741312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6183035392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4479524662288056e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.447952356277643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5645983232.0
		 entropy bonus: 0.20169317722320557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417741312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6183035392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4479524662288056e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.447952356277643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5645983232.0
		 entropy bonus: 0.20169317722320557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417741312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6183035392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4479524662288056e+18 - Differentiable computation graph = True!
PPO iteration: 174/1000:
	 start solving instance: 73...
	 start solving instance: 62...
	 start solving instance: 43...
	 start solving instance: 140...
	 start solving instance: 52...
	 start solving instance: 145...
	 start solving instance: 129...
	 start solving instance: 110...
	 start solving instance: 51...
	 start solving instance: 47...
	 start solving instance: 49...
	 start solving instance: 55...
	 start solving instance: 61...
	 start solving instance: 130...
	 start solving instance: 135...
	 start solving instance: 115...
	 start solving instance: 125...
	 start solving instance: 57...
	 start solving instance: 35...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.44283588886895e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5665531392.0
		 entropy bonus: 0.20107905566692352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518372864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419288576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.44283588886895e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.44283588886895e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5665531392.0
		 entropy bonus: 0.20107905566692352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518372864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419288576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.44283588886895e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.44283588886895e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5665531392.0
		 entropy bonus: 0.20107905566692352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518372864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419288576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.44283588886895e+18 - Differentiable computation graph = True!
PPO iteration: 175/1000:
	 start solving instance: 61...
	 start solving instance: 110...
	 start solving instance: 43...
	 start solving instance: 52...
	 start solving instance: 129...
	 start solving instance: 47...
	 start solving instance: 55...
	 start solving instance: 115...
	 start solving instance: 62...
	 start solving instance: 51...
	 start solving instance: 49...
	 start solving instance: 11...
	 start solving instance: 35...
	 start solving instance: 73...
	 start solving instance: 57...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 125...
	 start solving instance: 135...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.454876640704725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5647816192.0
		 entropy bonus: 0.19681109488010406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5448852480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6284903936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.454876640704725e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.454876640704725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5647816192.0
		 entropy bonus: 0.19681109488010406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5448852480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6284903936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.454876640704725e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.454876640704725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5647816192.0
		 entropy bonus: 0.19681109488010406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5448852480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6284903936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.454876640704725e+18 - Differentiable computation graph = True!
PPO iteration: 176/1000:
	 start solving instance: 47...
	 start solving instance: 110...
	 start solving instance: 57...
	 start solving instance: 49...
	 start solving instance: 35...
	 start solving instance: 52...
	 start solving instance: 62...
	 start solving instance: 145...
	 start solving instance: 135...
	 start solving instance: 125...
	 start solving instance: 140...
	 start solving instance: 55...
	 start solving instance: 73...
	 start solving instance: 11...
	 start solving instance: 51...
	 start solving instance: 61...
	 start solving instance: 129...
	 start solving instance: 43...
	 start solving instance: 115...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5809550002338922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5590226432.0
		 entropy bonus: 0.20336632430553436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5611347456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6366743552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5809551651606364e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5809550002338922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5590226432.0
		 entropy bonus: 0.20336632430553436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5611347456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6366743552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5809551651606364e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5809550002338922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5590226432.0
		 entropy bonus: 0.20336632430553436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5611347456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6366743552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5809551651606364e+18 - Differentiable computation graph = True!
PPO iteration: 177/1000:
	 start solving instance: 51...
	 start solving instance: 125...
	 start solving instance: 135...
	 start solving instance: 52...
	 start solving instance: 129...
	 start solving instance: 55...
	 start solving instance: 47...
	 start solving instance: 110...
	 start solving instance: 115...
	 start solving instance: 73...
	 start solving instance: 43...
	 start solving instance: 140...
	 start solving instance: 49...
	 start solving instance: 145...
	 start solving instance: 11...
	 start solving instance: 61...
	 start solving instance: 62...
	 start solving instance: 57...
	 start solving instance: 35...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7554360606410146e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682064896.0
		 entropy bonus: 0.2115527242422104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5745780736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6673315328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.755436115616596e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7554360606410146e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682064896.0
		 entropy bonus: 0.2115527242422104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5745780736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6673315328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.755436115616596e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7554360606410146e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682064896.0
		 entropy bonus: 0.2115527242422104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5745780736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6673315328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.755436115616596e+18 - Differentiable computation graph = True!
PPO iteration: 178/1000:
	 start solving instance: 57...
	 start solving instance: 49...
	 start solving instance: 43...
	 start solving instance: 11...
	 start solving instance: 73...
	 start solving instance: 62...
	 start solving instance: 135...
	 start solving instance: 35...
	 start solving instance: 52...
	 start solving instance: 140...
	 start solving instance: 125...
	 start solving instance: 47...
	 start solving instance: 145...
	 start solving instance: 55...
	 start solving instance: 61...
	 start solving instance: 130...
	 start solving instance: 51...
	 start solving instance: 129...
	 start solving instance: 110...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.231503156940636e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5549181440.0
		 entropy bonus: 0.19318392872810364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266122752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6065612288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.231503156940636e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.231503156940636e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5549181440.0
		 entropy bonus: 0.19318392872810364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266122752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6065612288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.231503156940636e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.231503156940636e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5549181440.0
		 entropy bonus: 0.19318392872810364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266122752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6065612288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.231503156940636e+18 - Differentiable computation graph = True!
PPO iteration: 179/1000:
	 start solving instance: 11...
	 start solving instance: 61...
	 start solving instance: 55...
	 start solving instance: 47...
	 start solving instance: 135...
	 start solving instance: 57...
	 start solving instance: 145...
	 start solving instance: 125...
	 start solving instance: 73...
	 start solving instance: 62...
	 start solving instance: 52...
	 start solving instance: 51...
	 start solving instance: 49...
	 start solving instance: 43...
	 start solving instance: 110...
	 start solving instance: 129...
	 start solving instance: 35...
	 start solving instance: 115...
	 start solving instance: 140...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7868359137070416e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5693535232.0
		 entropy bonus: 0.2094573974609375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5781809152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6580045824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.786835968682623e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7868359137070416e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5693535232.0
		 entropy bonus: 0.2094573974609375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5781809152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6580045824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.786835968682623e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7868359137070416e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5693535232.0
		 entropy bonus: 0.2094573974609375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5781809152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6580045824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.786835968682623e+18 - Differentiable computation graph = True!
PPO iteration: 180/1000:
	 start solving instance: 129...
	 start solving instance: 47...
	 start solving instance: 125...
	 start solving instance: 43...
	 start solving instance: 73...
	 start solving instance: 51...
	 start solving instance: 110...
	 start solving instance: 61...
	 start solving instance: 57...
	 start solving instance: 35...
	 start solving instance: 62...
	 start solving instance: 135...
	 start solving instance: 140...
	 start solving instance: 130...
	 start solving instance: 55...
	 start solving instance: 115...
	 start solving instance: 145...
	 start solving instance: 11...
	 start solving instance: 49...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7695863354858406e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711194112.0
		 entropy bonus: 0.20144830644130707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5788751360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6680324608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.769586280510259e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7695863354858406e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711194112.0
		 entropy bonus: 0.20144830644130707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5788751360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6680324608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.769586280510259e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7695863354858406e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711194112.0
		 entropy bonus: 0.20144830644130707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5788751360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6680324608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.769586280510259e+18 - Differentiable computation graph = True!
PPO iteration: 181/1000:
	 New training batch of size 20...
	 start solving instance: 27...
	 start solving instance: 148...
	 start solving instance: 126...
	 start solving instance: 149...
	 start solving instance: 90...
	 start solving instance: 11...
	 start solving instance: 122...
	 start solving instance: 18...
	 start solving instance: 124...
	 start solving instance: 83...
	 start solving instance: 24...
	 start solving instance: 113...
	 start solving instance: 37...
	 start solving instance: 87...
	 start solving instance: 100...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 5...
	 start solving instance: 115...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.709992913262189e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6575846912.0
		 entropy bonus: 0.21790266036987305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6554617344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6884947968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.709992803311026e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.709992913262189e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6575846912.0
		 entropy bonus: 0.21790266036987305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6554617344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6884947968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.709992803311026e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.709992913262189e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6575846912.0
		 entropy bonus: 0.21790266036987305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6554617344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6884947968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.709992803311026e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.7796689690130645e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5057164800.0
		 entropy bonus: 0.19504569470882416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4941721088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859560960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2779669023988645888.0000
PPO iteration: 182/1000:
	 start solving instance: 126...
	 start solving instance: 115...
	 start solving instance: 87...
	 start solving instance: 14...
	 start solving instance: 149...
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 100...
	 start solving instance: 124...
	 start solving instance: 37...
	 start solving instance: 11...
	 start solving instance: 90...
	 start solving instance: 24...
	 start solving instance: 18...
	 start solving instance: 44...
	 start solving instance: 122...
	 start solving instance: 148...
	 start solving instance: 5...
	 start solving instance: 27...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.733523781510549e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6656158720.0
		 entropy bonus: 0.23174898326396942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6696041984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7321399296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.733524001412874e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.733523781510549e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6656158720.0
		 entropy bonus: 0.23174898326396942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6696041984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7321399296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.733524001412874e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.733523781510549e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6656158720.0
		 entropy bonus: 0.23174898326396942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6696041984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7321399296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.733524001412874e+18 - Differentiable computation graph = True!
PPO iteration: 183/1000:
	 start solving instance: 18...
	 start solving instance: 113...
	 start solving instance: 14...
	 start solving instance: 5...
	 start solving instance: 90...
	 start solving instance: 24...
	 start solving instance: 115...
	 start solving instance: 124...
	 start solving instance: 87...
	 start solving instance: 122...
	 start solving instance: 148...
	 start solving instance: 149...
	 start solving instance: 44...
	 start solving instance: 37...
	 start solving instance: 100...
	 start solving instance: 126...
	 start solving instance: 83...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.851076527877941e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6526258688.0
		 entropy bonus: 0.22502771019935608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6757545472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7098402304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.851076637829104e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.851076527877941e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6526258688.0
		 entropy bonus: 0.22502771019935608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6757545472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7098402304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.851076637829104e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.851076527877941e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6526258688.0
		 entropy bonus: 0.22502771019935608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6757545472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7098402304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.851076637829104e+18 - Differentiable computation graph = True!
PPO iteration: 184/1000:
	 start solving instance: 44...
	 start solving instance: 126...
	 start solving instance: 11...
	 start solving instance: 113...
	 start solving instance: 87...
	 start solving instance: 100...
	 start solving instance: 148...
	 start solving instance: 18...
	 start solving instance: 90...
	 start solving instance: 122...
	 start solving instance: 149...
	 start solving instance: 124...
	 start solving instance: 37...
	 start solving instance: 83...
	 start solving instance: 104...
	 start solving instance: 115...
	 start solving instance: 27...
	 start solving instance: 14...
	 start solving instance: 5...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.862696166760278e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6544183808.0
		 entropy bonus: 0.2277195006608963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6822699520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7319978496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.86269627671144e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.862696166760278e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6544183808.0
		 entropy bonus: 0.2277195006608963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6822699520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7319978496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.86269627671144e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.862696166760278e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6544183808.0
		 entropy bonus: 0.2277195006608963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6822699520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7319978496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.86269627671144e+18 - Differentiable computation graph = True!
PPO iteration: 185/1000:
	 start solving instance: 113...
	 start solving instance: 44...
	 start solving instance: 122...
	 start solving instance: 27...
	 start solving instance: 124...
	 start solving instance: 149...
	 start solving instance: 83...
	 start solving instance: 115...
	 start solving instance: 100...
	 start solving instance: 87...
	 start solving instance: 18...
	 start solving instance: 90...
	 start solving instance: 24...
	 start solving instance: 148...
	 start solving instance: 37...
	 start solving instance: 126...
	 start solving instance: 5...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.574888003073632e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6548551168.0
		 entropy bonus: 0.2252485752105713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6464323072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7253773824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5748881130247946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.574888003073632e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6548551168.0
		 entropy bonus: 0.2252485752105713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6464323072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7253773824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5748881130247946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.574888003073632e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6548551168.0
		 entropy bonus: 0.2252485752105713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6464323072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7253773824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5748881130247946e+18 - Differentiable computation graph = True!
PPO iteration: 186/1000:
	 start solving instance: 44...
	 start solving instance: 149...
	 start solving instance: 18...
	 start solving instance: 115...
	 start solving instance: 126...
	 start solving instance: 87...
	 start solving instance: 83...
	 start solving instance: 100...
	 start solving instance: 104...
	 start solving instance: 122...
	 start solving instance: 5...
	 start solving instance: 24...
	 start solving instance: 90...
	 start solving instance: 37...
	 start solving instance: 27...
	 start solving instance: 148...
	 start solving instance: 11...
	 start solving instance: 124...
	 start solving instance: 14...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.71430255903842e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6493294592.0
		 entropy bonus: 0.2474335879087448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6625774080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172013056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714302888891908e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.71430255903842e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6493294592.0
		 entropy bonus: 0.2474335879087448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6625774080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172013056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714302888891908e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.71430255903842e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6493294592.0
		 entropy bonus: 0.2474335879087448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6625774080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172013056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.714302888891908e+18 - Differentiable computation graph = True!
PPO iteration: 187/1000:
	 start solving instance: 148...
	 start solving instance: 5...
	 start solving instance: 27...
	 start solving instance: 115...
	 start solving instance: 37...
	 start solving instance: 149...
	 start solving instance: 11...
	 start solving instance: 122...
	 start solving instance: 126...
	 start solving instance: 124...
	 start solving instance: 90...
	 start solving instance: 83...
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 14...
	 start solving instance: 24...
	 start solving instance: 100...
	 start solving instance: 18...
	 start solving instance: 44...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.602862657516811e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6425372160.0
		 entropy bonus: 0.21754777431488037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6499708928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6961828864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6028627124923924e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.602862657516811e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6425372160.0
		 entropy bonus: 0.21754777431488037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6499708928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6961828864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6028627124923924e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.602862657516811e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6425372160.0
		 entropy bonus: 0.21754777431488037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6499708928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6961828864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.6028627124923924e+18 - Differentiable computation graph = True!
PPO iteration: 188/1000:
	 start solving instance: 44...
	 start solving instance: 104...
	 start solving instance: 124...
	 start solving instance: 100...
	 start solving instance: 122...
	 start solving instance: 83...
	 start solving instance: 149...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 18...
	 start solving instance: 11...
	 start solving instance: 126...
	 start solving instance: 24...
	 start solving instance: 5...
	 start solving instance: 14...
	 start solving instance: 87...
	 start solving instance: 113...
	 start solving instance: 115...
	 start solving instance: 27...
	 start solving instance: 37...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.9144607343913206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6570155520.0
		 entropy bonus: 0.24155616760253906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6828582400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6826149376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.914460734391321e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.9144607343913206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6570155520.0
		 entropy bonus: 0.24155616760253906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6828582400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6826149376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.914460734391321e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.9144607343913206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6570155520.0
		 entropy bonus: 0.24155616760253906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6828582400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6826149376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.914460734391321e+18 - Differentiable computation graph = True!
PPO iteration: 189/1000:
	 start solving instance: 87...
	 start solving instance: 104...
	 start solving instance: 37...
	 start solving instance: 149...
	 start solving instance: 44...
	 start solving instance: 24...
	 start solving instance: 5...
	 start solving instance: 18...
	 start solving instance: 113...
	 start solving instance: 90...
	 start solving instance: 124...
	 start solving instance: 100...
	 start solving instance: 83...
	 start solving instance: 122...
	 start solving instance: 11...
	 start solving instance: 27...
	 start solving instance: 148...
	 start solving instance: 14...
	 start solving instance: 126...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.573689535399356e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6504470528.0
		 entropy bonus: 0.2141759693622589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6265887744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6959478784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.573689645350519e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.573689535399356e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6504470528.0
		 entropy bonus: 0.2141759693622589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6265887744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6959478784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.573689645350519e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.573689535399356e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6504470528.0
		 entropy bonus: 0.2141759693622589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6265887744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6959478784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.573689645350519e+18 - Differentiable computation graph = True!
PPO iteration: 190/1000:
	 start solving instance: 87...
	 start solving instance: 44...
	 start solving instance: 126...
	 start solving instance: 100...
	 start solving instance: 115...
	 start solving instance: 18...
	 start solving instance: 27...
	 start solving instance: 24...
	 start solving instance: 122...
	 start solving instance: 83...
	 start solving instance: 5...
	 start solving instance: 149...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 37...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 11...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.665122723341953e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6478428672.0
		 entropy bonus: 0.23314447700977325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6633426944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6708190208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.665122833293115e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.665122723341953e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6478428672.0
		 entropy bonus: 0.23314447700977325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6633426944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6708190208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.665122833293115e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.665122723341953e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6478428672.0
		 entropy bonus: 0.23314447700977325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6633426944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6708190208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.665122833293115e+18 - Differentiable computation graph = True!
PPO iteration: 191/1000:
	 New training batch of size 20...
	 start solving instance: 139...
	 start solving instance: 52...
	 start solving instance: 2...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 69...
	 start solving instance: 60...
	 start solving instance: 127...
	 start solving instance: 101...
	 start solving instance: 31...
	 start solving instance: 95...
	 start solving instance: 133...
	 start solving instance: 78...
	 start solving instance: 147...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 119...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1876970743737614e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5448819712.0
		 entropy bonus: 0.19512023031711578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5177017856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6078598656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1876972393005056e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1876970743737614e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5448819712.0
		 entropy bonus: 0.19512023031711578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5177017856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6078598656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1876972393005056e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1876970743737614e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5448819712.0
		 entropy bonus: 0.19512023031711578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5177017856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6078598656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1876972393005056e+18 - Differentiable computation graph = True!
PPO iteration: 192/1000:
	 start solving instance: 119...
	 start solving instance: 50...
	 start solving instance: 26...
	 start solving instance: 60...
	 start solving instance: 43...
	 start solving instance: 78...
	 start solving instance: 69...
	 start solving instance: 19...
	 start solving instance: 52...
	 start solving instance: 2...
	 start solving instance: 147...
	 start solving instance: 140...
	 start solving instance: 31...
	 start solving instance: 101...
	 start solving instance: 57...
	 start solving instance: 133...
	 start solving instance: 127...
	 start solving instance: 139...
	 start solving instance: 95...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.320564258497469e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5455438848.0
		 entropy bonus: 0.20173433423042297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5365496320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6583482368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.320564423424213e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.320564258497469e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5455438848.0
		 entropy bonus: 0.20173433423042297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5365496320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6583482368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.320564423424213e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.320564258497469e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5455438848.0
		 entropy bonus: 0.20173433423042297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5365496320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6583482368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.320564423424213e+18 - Differentiable computation graph = True!
PPO iteration: 193/1000:
	 start solving instance: 119...
	 start solving instance: 101...
	 start solving instance: 133...
	 start solving instance: 2...
	 start solving instance: 43...
	 start solving instance: 19...
	 start solving instance: 60...
	 start solving instance: 78...
	 start solving instance: 95...
	 start solving instance: 127...
	 start solving instance: 50...
	 start solving instance: 139...
	 start solving instance: 69...
	 start solving instance: 31...
	 start solving instance: 57...
	 start solving instance: 144...
	 start solving instance: 52...
	 start solving instance: 147...
	 start solving instance: 140...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0707893015272227e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5353637376.0
		 entropy bonus: 0.1879018396139145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5076262400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5734274560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.070789466453967e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0707893015272227e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5353637376.0
		 entropy bonus: 0.1879018396139145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5076262400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5734274560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.070789466453967e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0707893015272227e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5353637376.0
		 entropy bonus: 0.1879018396139145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5076262400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5734274560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.070789466453967e+18 - Differentiable computation graph = True!
PPO iteration: 194/1000:
	 start solving instance: 127...
	 start solving instance: 101...
	 start solving instance: 57...
	 start solving instance: 52...
	 start solving instance: 69...
	 start solving instance: 19...
	 start solving instance: 60...
	 start solving instance: 119...
	 start solving instance: 2...
	 start solving instance: 26...
	 start solving instance: 95...
	 start solving instance: 140...
	 start solving instance: 78...
	 start solving instance: 43...
	 start solving instance: 133...
	 start solving instance: 147...
	 start solving instance: 50...
	 start solving instance: 144...
	 start solving instance: 31...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1849696258299003e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5477788160.0
		 entropy bonus: 0.18870198726654053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5257143808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6124943872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1849696258299003e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1849696258299003e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5477788160.0
		 entropy bonus: 0.18870198726654053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5257143808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6124943872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1849696258299003e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1849696258299003e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5477788160.0
		 entropy bonus: 0.18870198726654053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5257143808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6124943872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1849696258299003e+18 - Differentiable computation graph = True!
PPO iteration: 195/1000:
	 start solving instance: 95...
	 start solving instance: 31...
	 start solving instance: 50...
	 start solving instance: 43...
	 start solving instance: 119...
	 start solving instance: 140...
	 start solving instance: 147...
	 start solving instance: 52...
	 start solving instance: 139...
	 start solving instance: 26...
	 start solving instance: 101...
	 start solving instance: 2...
	 start solving instance: 57...
	 start solving instance: 60...
	 start solving instance: 127...
	 start solving instance: 19...
	 start solving instance: 78...
	 start solving instance: 133...
	 start solving instance: 69...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.319335224399941e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5549064192.0
		 entropy bonus: 0.1882522851228714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5327858176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6429440000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3193351694243594e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.319335224399941e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5549064192.0
		 entropy bonus: 0.1882522851228714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5327858176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6429440000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3193351694243594e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.319335224399941e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5549064192.0
		 entropy bonus: 0.1882522851228714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5327858176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6429440000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3193351694243594e+18 - Differentiable computation graph = True!
PPO iteration: 196/1000:
	 start solving instance: 144...
	 start solving instance: 147...
	 start solving instance: 26...
	 start solving instance: 101...
	 start solving instance: 60...
	 start solving instance: 31...
	 start solving instance: 139...
	 start solving instance: 140...
	 start solving instance: 127...
	 start solving instance: 119...
	 start solving instance: 52...
	 start solving instance: 78...
	 start solving instance: 50...
	 start solving instance: 69...
	 start solving instance: 19...
	 start solving instance: 43...
	 start solving instance: 133...
	 start solving instance: 95...
	 start solving instance: 2...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.168525110022557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5392689664.0
		 entropy bonus: 0.19406674802303314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5181556224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6074234368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1685250550469755e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.168525110022557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5392689664.0
		 entropy bonus: 0.19406674802303314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5181556224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6074234368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1685250550469755e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.168525110022557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5392689664.0
		 entropy bonus: 0.19406674802303314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5181556224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6074234368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1685250550469755e+18 - Differentiable computation graph = True!
PPO iteration: 197/1000:
	 start solving instance: 50...
	 start solving instance: 140...
	 start solving instance: 26...
	 start solving instance: 147...
	 start solving instance: 101...
	 start solving instance: 31...
	 start solving instance: 57...
	 start solving instance: 60...
	 start solving instance: 95...
	 start solving instance: 69...
	 start solving instance: 2...
	 start solving instance: 133...
	 start solving instance: 19...
	 start solving instance: 52...
	 start solving instance: 127...
	 start solving instance: 119...
	 start solving instance: 43...
	 start solving instance: 139...
	 start solving instance: 144...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.125134422948656e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5552217088.0
		 entropy bonus: 0.19203142821788788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5067186176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428622848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1251344779242373e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.125134422948656e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5552217088.0
		 entropy bonus: 0.19203142821788788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5067186176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428622848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1251344779242373e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.125134422948656e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5552217088.0
		 entropy bonus: 0.19203142821788788
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5067186176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428622848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1251344779242373e+18 - Differentiable computation graph = True!
PPO iteration: 198/1000:
	 start solving instance: 101...
	 start solving instance: 50...
	 start solving instance: 133...
	 start solving instance: 31...
	 start solving instance: 2...
	 start solving instance: 69...
	 start solving instance: 19...
	 start solving instance: 139...
	 start solving instance: 57...
	 start solving instance: 147...
	 start solving instance: 60...
	 start solving instance: 140...
	 start solving instance: 52...
	 start solving instance: 95...
	 start solving instance: 43...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 78...
	 start solving instance: 127...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4007215148925714e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5474827776.0
		 entropy bonus: 0.19374866783618927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5502225920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6418576896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.400721569868153e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4007215148925714e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5474827776.0
		 entropy bonus: 0.19374866783618927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5502225920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6418576896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.400721569868153e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4007215148925714e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5474827776.0
		 entropy bonus: 0.19374866783618927
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5502225920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6418576896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.400721569868153e+18 - Differentiable computation graph = True!
PPO iteration: 199/1000:
	 start solving instance: 78...
	 start solving instance: 31...
	 start solving instance: 26...
	 start solving instance: 2...
	 start solving instance: 19...
	 start solving instance: 69...
	 start solving instance: 101...
	 start solving instance: 147...
	 start solving instance: 133...
	 start solving instance: 127...
	 start solving instance: 60...
	 start solving instance: 139...
	 start solving instance: 43...
	 start solving instance: 119...
	 start solving instance: 57...
	 start solving instance: 144...
	 start solving instance: 50...
	 start solving instance: 140...
	 start solving instance: 52...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0462178554743357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5426077184.0
		 entropy bonus: 0.1969202756881714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5114070528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5886699008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.046217855474336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0462178554743357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5426077184.0
		 entropy bonus: 0.1969202756881714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5114070528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5886699008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.046217855474336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0462178554743357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5426077184.0
		 entropy bonus: 0.1969202756881714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5114070528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5886699008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.046217855474336e+18 - Differentiable computation graph = True!
PPO iteration: 200/1000:
	 start solving instance: 133...
	 start solving instance: 52...
	 start solving instance: 119...
	 start solving instance: 127...
	 start solving instance: 60...
	 start solving instance: 147...
	 start solving instance: 140...
	 start solving instance: 2...
	 start solving instance: 19...
	 start solving instance: 31...
	 start solving instance: 78...
	 start solving instance: 139...
	 start solving instance: 101...
	 start solving instance: 69...
	 start solving instance: 26...
	 start solving instance: 43...
	 start solving instance: 50...
	 start solving instance: 144...
	 start solving instance: 57...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3761461105978245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5673178624.0
		 entropy bonus: 0.18585382401943207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5334529536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774471168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3761461105978245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3761461105978245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5673178624.0
		 entropy bonus: 0.18585382401943207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5334529536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774471168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3761461105978245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3761461105978245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5673178624.0
		 entropy bonus: 0.18585382401943207
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5334529536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774471168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3761461105978245e+18 - Differentiable computation graph = True!
PPO iteration: 201/1000:
	 New training batch of size 20...
	 start solving instance: 41...
	 start solving instance: 104...
	 start solving instance: 53...
	 start solving instance: 79...
	 start solving instance: 25...
	 start solving instance: 28...
	 start solving instance: 96...
	 start solving instance: 90...
	 start solving instance: 59...
	 start solving instance: 84...
	 start solving instance: 132...
	 start solving instance: 14...
	 start solving instance: 26...
	 start solving instance: 109...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 113...
	 start solving instance: 112...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.508138411369955e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312986112.0
		 entropy bonus: 0.24421802163124084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6686751232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7020380160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5081384113699553e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.508138411369955e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312986112.0
		 entropy bonus: 0.24421802163124084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6686751232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7020380160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5081384113699553e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.508138411369955e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312986112.0
		 entropy bonus: 0.24421802163124084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6686751232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7020380160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5081384113699553e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.8412994544801415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5127629824.0
		 entropy bonus: 0.19794651865959167
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4925000192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5803466752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2841299399504560128.0000
PPO iteration: 202/1000:
	 start solving instance: 25...
	 start solving instance: 28...
	 start solving instance: 96...
	 start solving instance: 59...
	 start solving instance: 113...
	 start solving instance: 14...
	 start solving instance: 84...
	 start solving instance: 117...
	 start solving instance: 90...
	 start solving instance: 41...
	 start solving instance: 135...
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 124...
	 start solving instance: 134...
	 start solving instance: 112...
	 start solving instance: 79...
	 start solving instance: 26...
	 start solving instance: 104...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.564071887288874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6292771328.0
		 entropy bonus: 0.25323888659477234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6697200640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037977600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.564071942264455e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.564071887288874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6292771328.0
		 entropy bonus: 0.25323888659477234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6697200640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037977600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.564071942264455e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.564071887288874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6292771328.0
		 entropy bonus: 0.25323888659477234
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6697200640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037977600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.564071942264455e+18 - Differentiable computation graph = True!
PPO iteration: 203/1000:
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 14...
	 start solving instance: 59...
	 start solving instance: 104...
	 start solving instance: 109...
	 start solving instance: 25...
	 start solving instance: 113...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 41...
	 start solving instance: 134...
	 start solving instance: 26...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 84...
	 start solving instance: 79...
	 start solving instance: 124...
	 start solving instance: 96...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.37400063160919e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6200907264.0
		 entropy bonus: 0.2414831668138504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6490924032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6614960128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.374000741560353e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.37400063160919e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6200907264.0
		 entropy bonus: 0.2414831668138504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6490924032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6614960128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.374000741560353e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.37400063160919e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6200907264.0
		 entropy bonus: 0.2414831668138504
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6490924032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6614960128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.374000741560353e+18 - Differentiable computation graph = True!
PPO iteration: 204/1000:
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 84...
	 start solving instance: 14...
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 117...
	 start solving instance: 90...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 132...
	 start solving instance: 26...
	 start solving instance: 41...
	 start solving instance: 112...
	 start solving instance: 59...
	 start solving instance: 124...
	 start solving instance: 96...
	 start solving instance: 25...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.108991501231456e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212764672.0
		 entropy bonus: 0.24012552201747894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6175224832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6656637952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.108991501231456e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.108991501231456e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212764672.0
		 entropy bonus: 0.24012552201747894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6175224832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6656637952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.108991501231456e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.108991501231456e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212764672.0
		 entropy bonus: 0.24012552201747894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6175224832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6656637952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.108991501231456e+18 - Differentiable computation graph = True!
PPO iteration: 205/1000:
	 start solving instance: 135...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 112...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 59...
	 start solving instance: 79...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 41...
	 start solving instance: 26...
	 start solving instance: 124...
	 start solving instance: 113...
	 start solving instance: 117...
	 start solving instance: 84...
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 96...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.562631966861138e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6260380160.0
		 entropy bonus: 0.25000935792922974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6708296192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7061229568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5626321317878825e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.562631966861138e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6260380160.0
		 entropy bonus: 0.25000935792922974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6708296192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7061229568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5626321317878825e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.562631966861138e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6260380160.0
		 entropy bonus: 0.25000935792922974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6708296192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7061229568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5626321317878825e+18 - Differentiable computation graph = True!
PPO iteration: 206/1000:
	 start solving instance: 113...
	 start solving instance: 59...
	 start solving instance: 109...
	 start solving instance: 134...
	 start solving instance: 28...
	 start solving instance: 96...
	 start solving instance: 84...
	 start solving instance: 14...
	 start solving instance: 135...
	 start solving instance: 112...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 41...
	 start solving instance: 117...
	 start solving instance: 104...
	 start solving instance: 53...
	 start solving instance: 124...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.638197882600974e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6338950144.0
		 entropy bonus: 0.25406011939048767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6797005824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6821737472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.638197992552137e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.638197882600974e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6338950144.0
		 entropy bonus: 0.25406011939048767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6797005824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6821737472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.638197992552137e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.638197882600974e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6338950144.0
		 entropy bonus: 0.25406011939048767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6797005824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6821737472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.638197992552137e+18 - Differentiable computation graph = True!
PPO iteration: 207/1000:
	 start solving instance: 41...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 28...
	 start solving instance: 90...
	 start solving instance: 59...
	 start solving instance: 26...
	 start solving instance: 132...
	 start solving instance: 109...
	 start solving instance: 113...
	 start solving instance: 79...
	 start solving instance: 53...
	 start solving instance: 117...
	 start solving instance: 124...
	 start solving instance: 25...
	 start solving instance: 134...
	 start solving instance: 112...
	 start solving instance: 84...
	 start solving instance: 135...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.296631516799802e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6204702208.0
		 entropy bonus: 0.24926672875881195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6436367872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6794744320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.296631681726546e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.296631516799802e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6204702208.0
		 entropy bonus: 0.24926672875881195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6436367872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6794744320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.296631681726546e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.296631516799802e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6204702208.0
		 entropy bonus: 0.24926672875881195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6436367872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6794744320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.296631681726546e+18 - Differentiable computation graph = True!
PPO iteration: 208/1000:
	 start solving instance: 112...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 25...
	 start solving instance: 109...
	 start solving instance: 96...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 14...
	 start solving instance: 124...
	 start solving instance: 26...
	 start solving instance: 113...
	 start solving instance: 84...
	 start solving instance: 104...
	 start solving instance: 41...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 135...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.364474462866139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6249604096.0
		 entropy bonus: 0.2483384907245636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6470726144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6719998976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3644745728173015e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.364474462866139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6249604096.0
		 entropy bonus: 0.2483384907245636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6470726144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6719998976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3644745728173015e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.364474462866139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6249604096.0
		 entropy bonus: 0.2483384907245636
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6470726144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6719998976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3644745728173015e+18 - Differentiable computation graph = True!
PPO iteration: 209/1000:
	 start solving instance: 135...
	 start solving instance: 25...
	 start solving instance: 84...
	 start solving instance: 112...
	 start solving instance: 90...
	 start solving instance: 14...
	 start solving instance: 59...
	 start solving instance: 113...
	 start solving instance: 104...
	 start solving instance: 41...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 26...
	 start solving instance: 79...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 96...
	 start solving instance: 28...
	 start solving instance: 53...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.542531135086789e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266507264.0
		 entropy bonus: 0.2398209422826767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6661384192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6888793600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5425311350867886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.542531135086789e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266507264.0
		 entropy bonus: 0.2398209422826767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6661384192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6888793600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5425311350867886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.542531135086789e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266507264.0
		 entropy bonus: 0.2398209422826767
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6661384192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6888793600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5425311350867886e+18 - Differentiable computation graph = True!
PPO iteration: 210/1000:
	 start solving instance: 117...
	 start solving instance: 112...
	 start solving instance: 59...
	 start solving instance: 84...
	 start solving instance: 96...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 113...
	 start solving instance: 41...
	 start solving instance: 109...
	 start solving instance: 124...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 25...
	 start solving instance: 28...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.197736163341815e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6249280000.0
		 entropy bonus: 0.2358921766281128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6331871232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6526732800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1977361083662336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.197736163341815e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6249280000.0
		 entropy bonus: 0.2358921766281128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6331871232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6526732800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1977361083662336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.197736163341815e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6249280000.0
		 entropy bonus: 0.2358921766281128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6331871232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6526732800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1977361083662336e+18 - Differentiable computation graph = True!
PPO iteration: 211/1000:
	 New training batch of size 20...
	 start solving instance: 148...
	 start solving instance: 82...
	 start solving instance: 39...
	 start solving instance: 115...
	 start solving instance: 3...
	 start solving instance: 97...
	 start solving instance: 100...
	 start solving instance: 102...
	 start solving instance: 40...
	 start solving instance: 13...
	 start solving instance: 116...
	 start solving instance: 50...
	 start solving instance: 15...
	 start solving instance: 30...
	 start solving instance: 73...
	 start solving instance: 10...
	 start solving instance: 44...
	 start solving instance: 90...
	 start solving instance: 53...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.895961231351664e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6394862080.0
		 entropy bonus: 0.23063412308692932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6634188288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7315296768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.895961451253989e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.895961231351664e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6394862080.0
		 entropy bonus: 0.23063412308692932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6634188288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7315296768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.895961451253989e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.895961231351664e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6394862080.0
		 entropy bonus: 0.23063412308692932
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6634188288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7315296768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.895961451253989e+18 - Differentiable computation graph = True!
PPO iteration: 212/1000:
	 start solving instance: 100...
	 start solving instance: 30...
	 start solving instance: 58...
	 start solving instance: 3...
	 start solving instance: 50...
	 start solving instance: 115...
	 start solving instance: 15...
	 start solving instance: 116...
	 start solving instance: 73...
	 start solving instance: 97...
	 start solving instance: 39...
	 start solving instance: 90...
	 start solving instance: 13...
	 start solving instance: 44...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 102...
	 start solving instance: 82...
	 start solving instance: 53...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.052902882272503e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6550324224.0
		 entropy bonus: 0.21787695586681366
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6781721600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7563433984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.052902992223666e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.052902882272503e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6550324224.0
		 entropy bonus: 0.21787695586681366
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6781721600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7563433984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.052902992223666e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.052902882272503e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6550324224.0
		 entropy bonus: 0.21787695586681366
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6781721600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7563433984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.052902992223666e+18 - Differentiable computation graph = True!
PPO iteration: 213/1000:
	 start solving instance: 3...
	 start solving instance: 116...
	 start solving instance: 15...
	 start solving instance: 58...
	 start solving instance: 102...
	 start solving instance: 44...
	 start solving instance: 50...
	 start solving instance: 90...
	 start solving instance: 82...
	 start solving instance: 39...
	 start solving instance: 115...
	 start solving instance: 10...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 73...
	 start solving instance: 13...
	 start solving instance: 97...
	 start solving instance: 53...
	 start solving instance: 100...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.21907603282015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6490243072.0
		 entropy bonus: 0.21566270291805267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6863355392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7474622976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.21907603282015e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.21907603282015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6490243072.0
		 entropy bonus: 0.21566270291805267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6863355392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7474622976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.21907603282015e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.21907603282015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6490243072.0
		 entropy bonus: 0.21566270291805267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6863355392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7474622976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.21907603282015e+18 - Differentiable computation graph = True!
PPO iteration: 214/1000:
	 start solving instance: 115...
	 start solving instance: 82...
	 start solving instance: 39...
	 start solving instance: 53...
	 start solving instance: 3...
	 start solving instance: 44...
	 start solving instance: 97...
	 start solving instance: 15...
	 start solving instance: 102...
	 start solving instance: 148...
	 start solving instance: 116...
	 start solving instance: 100...
	 start solving instance: 90...
	 start solving instance: 58...
	 start solving instance: 73...
	 start solving instance: 50...
	 start solving instance: 30...
	 start solving instance: 10...
	 start solving instance: 40...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.174613102006842e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6528989696.0
		 entropy bonus: 0.23293732106685638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6896623616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7807868928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.17461343186033e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.174613102006842e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6528989696.0
		 entropy bonus: 0.23293732106685638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6896623616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7807868928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.17461343186033e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.174613102006842e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6528989696.0
		 entropy bonus: 0.23293732106685638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6896623616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7807868928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.17461343186033e+18 - Differentiable computation graph = True!
PPO iteration: 215/1000:
	 start solving instance: 90...
	 start solving instance: 30...
	 start solving instance: 44...
	 start solving instance: 40...
	 start solving instance: 116...
	 start solving instance: 3...
	 start solving instance: 39...
	 start solving instance: 82...
	 start solving instance: 13...
	 start solving instance: 115...
	 start solving instance: 100...
	 start solving instance: 58...
	 start solving instance: 53...
	 start solving instance: 50...
	 start solving instance: 73...
	 start solving instance: 102...
	 start solving instance: 148...
	 start solving instance: 97...
	 start solving instance: 10...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.96985984765914e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6447706624.0
		 entropy bonus: 0.21446838974952698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6670199808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7693167616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.969860177512628e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.96985984765914e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6447706624.0
		 entropy bonus: 0.21446838974952698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6670199808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7693167616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.969860177512628e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.96985984765914e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6447706624.0
		 entropy bonus: 0.21446838974952698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6670199808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7693167616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.969860177512628e+18 - Differentiable computation graph = True!
PPO iteration: 216/1000:
	 start solving instance: 148...
	 start solving instance: 100...
	 start solving instance: 10...
	 start solving instance: 82...
	 start solving instance: 40...
	 start solving instance: 30...
	 start solving instance: 3...
	 start solving instance: 58...
	 start solving instance: 44...
	 start solving instance: 97...
	 start solving instance: 15...
	 start solving instance: 115...
	 start solving instance: 116...
	 start solving instance: 53...
	 start solving instance: 50...
	 start solving instance: 73...
	 start solving instance: 13...
	 start solving instance: 90...
	 start solving instance: 102...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.750283857155064e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6436892160.0
		 entropy bonus: 0.20713983476161957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6498835968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7356129280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.750283857155064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.750283857155064e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6436892160.0
		 entropy bonus: 0.20713983476161957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6498835968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7356129280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.750283857155064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.750283857155064e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6436892160.0
		 entropy bonus: 0.20713983476161957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6498835968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7356129280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.750283857155064e+18 - Differentiable computation graph = True!
PPO iteration: 217/1000:
	 start solving instance: 40...
	 start solving instance: 30...
	 start solving instance: 97...
	 start solving instance: 58...
	 start solving instance: 73...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 115...
	 start solving instance: 3...
	 start solving instance: 50...
	 start solving instance: 10...
	 start solving instance: 53...
	 start solving instance: 90...
	 start solving instance: 39...
	 start solving instance: 82...
	 start solving instance: 102...
	 start solving instance: 100...
	 start solving instance: 13...
	 start solving instance: 148...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7867300287879315e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6423208960.0
		 entropy bonus: 0.20440936088562012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6421688320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7268514816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.786729918836769e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7867300287879315e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6423208960.0
		 entropy bonus: 0.20440936088562012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6421688320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7268514816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.786729918836769e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7867300287879315e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6423208960.0
		 entropy bonus: 0.20440936088562012
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6421688320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7268514816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.786729918836769e+18 - Differentiable computation graph = True!
PPO iteration: 218/1000:
	 start solving instance: 102...
	 start solving instance: 50...
	 start solving instance: 39...
	 start solving instance: 97...
	 start solving instance: 10...
	 start solving instance: 82...
	 start solving instance: 115...
	 start solving instance: 100...
	 start solving instance: 53...
	 start solving instance: 30...
	 start solving instance: 13...
	 start solving instance: 148...
	 start solving instance: 40...
	 start solving instance: 73...
	 start solving instance: 116...
	 start solving instance: 58...
	 start solving instance: 15...
	 start solving instance: 3...
	 start solving instance: 44...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.723369131921061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6371250688.0
		 entropy bonus: 0.21818971633911133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6451408896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089015296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.723369461774549e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.723369131921061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6371250688.0
		 entropy bonus: 0.21818971633911133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6451408896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089015296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.723369461774549e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.723369131921061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6371250688.0
		 entropy bonus: 0.21818971633911133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6451408896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089015296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.723369461774549e+18 - Differentiable computation graph = True!
PPO iteration: 219/1000:
	 start solving instance: 50...
	 start solving instance: 10...
	 start solving instance: 148...
	 start solving instance: 13...
	 start solving instance: 115...
	 start solving instance: 116...
	 start solving instance: 58...
	 start solving instance: 73...
	 start solving instance: 100...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 44...
	 start solving instance: 90...
	 start solving instance: 82...
	 start solving instance: 53...
	 start solving instance: 30...
	 start solving instance: 40...
	 start solving instance: 39...
	 start solving instance: 15...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.769034488650505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6391531008.0
		 entropy bonus: 0.22070932388305664
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6497629696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7543952384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.769034378699342e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.769034488650505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6391531008.0
		 entropy bonus: 0.22070932388305664
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6497629696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7543952384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.769034378699342e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.769034488650505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6391531008.0
		 entropy bonus: 0.22070932388305664
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6497629696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7543952384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.769034378699342e+18 - Differentiable computation graph = True!
PPO iteration: 220/1000:
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 40...
	 start solving instance: 148...
	 start solving instance: 100...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 53...
	 start solving instance: 10...
	 start solving instance: 44...
	 start solving instance: 50...
	 start solving instance: 58...
	 start solving instance: 73...
	 start solving instance: 15...
	 start solving instance: 102...
	 start solving instance: 13...
	 start solving instance: 3...
	 start solving instance: 115...
	 start solving instance: 82...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.711861203420106e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6368987648.0
		 entropy bonus: 0.22521395981311798
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6496712192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7085815296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711861423322431e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.711861203420106e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6368987648.0
		 entropy bonus: 0.22521395981311798
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6496712192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7085815296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711861423322431e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.711861203420106e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6368987648.0
		 entropy bonus: 0.22521395981311798
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6496712192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7085815296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.711861423322431e+18 - Differentiable computation graph = True!
PPO iteration: 221/1000:
	 New training batch of size 20...
	 start solving instance: 65...
	 start solving instance: 140...
	 start solving instance: 103...
	 start solving instance: 95...
	 start solving instance: 54...
	 start solving instance: 111...
	 start solving instance: 37...
	 start solving instance: 130...
	 start solving instance: 83...
	 start solving instance: 97...
	 start solving instance: 5...
	 start solving instance: 26...
	 start solving instance: 138...
	 start solving instance: 64...
	 start solving instance: 57...
	 start solving instance: 31...
	 start solving instance: 10...
	 start solving instance: 74...
	 start solving instance: 125...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.984555812074186e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5970386432.0
		 entropy bonus: 0.2055535763502121
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5908800512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988693504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.984555922025349e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.984555812074186e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5970386432.0
		 entropy bonus: 0.2055535763502121
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5908800512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988693504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.984555922025349e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.984555812074186e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5970386432.0
		 entropy bonus: 0.2055535763502121
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5908800512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988693504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.984555922025349e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.2525799152358e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5345529344.0
		 entropy bonus: 0.20617090165615082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5395031040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6129329152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3252579970211381248.0000
PPO iteration: 222/1000:
	 start solving instance: 83...
	 start solving instance: 5...
	 start solving instance: 31...
	 start solving instance: 54...
	 start solving instance: 65...
	 start solving instance: 97...
	 start solving instance: 95...
	 start solving instance: 74...
	 start solving instance: 103...
	 start solving instance: 10...
	 start solving instance: 125...
	 start solving instance: 111...
	 start solving instance: 37...
	 start solving instance: 14...
	 start solving instance: 130...
	 start solving instance: 64...
	 start solving instance: 140...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.06264796573e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5997766144.0
		 entropy bonus: 0.20747628808021545
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156071424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6957140480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0626479107544187e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.06264796573e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5997766144.0
		 entropy bonus: 0.20747628808021545
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156071424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6957140480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0626479107544187e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.06264796573e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5997766144.0
		 entropy bonus: 0.20747628808021545
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156071424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6957140480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0626479107544187e+18 - Differentiable computation graph = True!
PPO iteration: 223/1000:
	 start solving instance: 138...
	 start solving instance: 95...
	 start solving instance: 140...
	 start solving instance: 64...
	 start solving instance: 5...
	 start solving instance: 130...
	 start solving instance: 57...
	 start solving instance: 83...
	 start solving instance: 54...
	 start solving instance: 26...
	 start solving instance: 37...
	 start solving instance: 31...
	 start solving instance: 74...
	 start solving instance: 65...
	 start solving instance: 10...
	 start solving instance: 14...
	 start solving instance: 111...
	 start solving instance: 125...
	 start solving instance: 103...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.951154408040956e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5961169920.0
		 entropy bonus: 0.1998630166053772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6039016960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6797224960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.951154408040956e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.951154408040956e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5961169920.0
		 entropy bonus: 0.1998630166053772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6039016960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6797224960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.951154408040956e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.951154408040956e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5961169920.0
		 entropy bonus: 0.1998630166053772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6039016960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6797224960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.951154408040956e+18 - Differentiable computation graph = True!
PPO iteration: 224/1000:
	 start solving instance: 103...
	 start solving instance: 57...
	 start solving instance: 54...
	 start solving instance: 14...
	 start solving instance: 111...
	 start solving instance: 37...
	 start solving instance: 5...
	 start solving instance: 65...
	 start solving instance: 74...
	 start solving instance: 138...
	 start solving instance: 97...
	 start solving instance: 125...
	 start solving instance: 130...
	 start solving instance: 140...
	 start solving instance: 95...
	 start solving instance: 31...
	 start solving instance: 26...
	 start solving instance: 83...
	 start solving instance: 64...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.870243986180827e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967952384.0
		 entropy bonus: 0.1946769803762436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5933877760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841483264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8702440961319895e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.870243986180827e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967952384.0
		 entropy bonus: 0.1946769803762436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5933877760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841483264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8702440961319895e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.870243986180827e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967952384.0
		 entropy bonus: 0.1946769803762436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5933877760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841483264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8702440961319895e+18 - Differentiable computation graph = True!
PPO iteration: 225/1000:
	 start solving instance: 111...
	 start solving instance: 140...
	 start solving instance: 26...
	 start solving instance: 138...
	 start solving instance: 57...
	 start solving instance: 10...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 31...
	 start solving instance: 95...
	 start solving instance: 14...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 65...
	 start solving instance: 97...
	 start solving instance: 125...
	 start solving instance: 5...
	 start solving instance: 130...
	 start solving instance: 54...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.98452942379512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969260032.0
		 entropy bonus: 0.2000233232975006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5997987840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6924034048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9845295337462825e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.98452942379512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969260032.0
		 entropy bonus: 0.2000233232975006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5997987840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6924034048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9845295337462825e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.98452942379512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969260032.0
		 entropy bonus: 0.2000233232975006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5997987840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6924034048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9845295337462825e+18 - Differentiable computation graph = True!
PPO iteration: 226/1000:
	 start solving instance: 5...
	 start solving instance: 37...
	 start solving instance: 14...
	 start solving instance: 130...
	 start solving instance: 83...
	 start solving instance: 97...
	 start solving instance: 138...
	 start solving instance: 140...
	 start solving instance: 31...
	 start solving instance: 125...
	 start solving instance: 10...
	 start solving instance: 74...
	 start solving instance: 65...
	 start solving instance: 95...
	 start solving instance: 64...
	 start solving instance: 103...
	 start solving instance: 57...
	 start solving instance: 54...
	 start solving instance: 111...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.835239054389648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5983196672.0
		 entropy bonus: 0.19257967174053192
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5754304000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6718708736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.835239219316392e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.835239054389648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5983196672.0
		 entropy bonus: 0.19257967174053192
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5754304000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6718708736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.835239219316392e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.835239054389648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5983196672.0
		 entropy bonus: 0.19257967174053192
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5754304000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6718708736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.835239219316392e+18 - Differentiable computation graph = True!
PPO iteration: 227/1000:
	 start solving instance: 138...
	 start solving instance: 5...
	 start solving instance: 83...
	 start solving instance: 14...
	 start solving instance: 140...
	 start solving instance: 64...
	 start solving instance: 97...
	 start solving instance: 31...
	 start solving instance: 37...
	 start solving instance: 57...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 125...
	 start solving instance: 10...
	 start solving instance: 54...
	 start solving instance: 65...
	 start solving instance: 111...
	 start solving instance: 95...
	 start solving instance: 130...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.89687767624277e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6015696384.0
		 entropy bonus: 0.19138650596141815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6007632896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6797408768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8968778411695145e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.89687767624277e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6015696384.0
		 entropy bonus: 0.19138650596141815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6007632896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6797408768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8968778411695145e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.89687767624277e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6015696384.0
		 entropy bonus: 0.19138650596141815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6007632896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6797408768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8968778411695145e+18 - Differentiable computation graph = True!
PPO iteration: 228/1000:
	 start solving instance: 83...
	 start solving instance: 111...
	 start solving instance: 54...
	 start solving instance: 130...
	 start solving instance: 140...
	 start solving instance: 65...
	 start solving instance: 125...
	 start solving instance: 95...
	 start solving instance: 74...
	 start solving instance: 138...
	 start solving instance: 57...
	 start solving instance: 37...
	 start solving instance: 97...
	 start solving instance: 14...
	 start solving instance: 31...
	 start solving instance: 26...
	 start solving instance: 64...
	 start solving instance: 10...
	 start solving instance: 103...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0189995531305484e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6046371328.0
		 entropy bonus: 0.2019919902086258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5982973440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7163604992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.018999498154967e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0189995531305484e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6046371328.0
		 entropy bonus: 0.2019919902086258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5982973440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7163604992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.018999498154967e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0189995531305484e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6046371328.0
		 entropy bonus: 0.2019919902086258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5982973440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7163604992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.018999498154967e+18 - Differentiable computation graph = True!
PPO iteration: 229/1000:
	 start solving instance: 125...
	 start solving instance: 5...
	 start solving instance: 65...
	 start solving instance: 83...
	 start solving instance: 140...
	 start solving instance: 64...
	 start solving instance: 14...
	 start solving instance: 10...
	 start solving instance: 74...
	 start solving instance: 26...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 138...
	 start solving instance: 37...
	 start solving instance: 111...
	 start solving instance: 57...
	 start solving instance: 95...
	 start solving instance: 130...
	 start solving instance: 54...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.916461737552065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5947273216.0
		 entropy bonus: 0.19367246329784393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5950330368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6850718208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9164617925276467e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.916461737552065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5947273216.0
		 entropy bonus: 0.19367246329784393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5950330368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6850718208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9164617925276467e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.916461737552065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5947273216.0
		 entropy bonus: 0.19367246329784393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5950330368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6850718208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9164617925276467e+18 - Differentiable computation graph = True!
PPO iteration: 230/1000:
	 start solving instance: 65...
	 start solving instance: 138...
	 start solving instance: 103...
	 start solving instance: 10...
	 start solving instance: 95...
	 start solving instance: 5...
	 start solving instance: 74...
	 start solving instance: 26...
	 start solving instance: 83...
	 start solving instance: 64...
	 start solving instance: 57...
	 start solving instance: 31...
	 start solving instance: 130...
	 start solving instance: 125...
	 start solving instance: 97...
	 start solving instance: 111...
	 start solving instance: 54...
	 start solving instance: 140...
	 start solving instance: 14...
	 start solving instance: 37...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.084189157736736e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5919246848.0
		 entropy bonus: 0.20685230195522308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032497152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6937428992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.084189267687899e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.084189157736736e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5919246848.0
		 entropy bonus: 0.20685230195522308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032497152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6937428992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.084189267687899e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.084189157736736e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5919246848.0
		 entropy bonus: 0.20685230195522308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032497152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6937428992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.084189267687899e+18 - Differentiable computation graph = True!
PPO iteration: 231/1000:
	 New training batch of size 20...
	 start solving instance: 146...
	 start solving instance: 9...
	 start solving instance: 78...
	 start solving instance: 96...
	 start solving instance: 129...
	 start solving instance: 58...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 1...
	 start solving instance: 37...
	 start solving instance: 46...
	 start solving instance: 55...
	 start solving instance: 93...
	 start solving instance: 35...
	 start solving instance: 89...
	 start solving instance: 131...
	 start solving instance: 105...
	 start solving instance: 3...
	 start solving instance: 126...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.135490171265509e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6125846528.0
		 entropy bonus: 0.23290804028511047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6178891776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6793762304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.135490281216672e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.135490171265509e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6125846528.0
		 entropy bonus: 0.23290804028511047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6178891776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6793762304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.135490281216672e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.135490171265509e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6125846528.0
		 entropy bonus: 0.23290804028511047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6178891776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6793762304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.135490281216672e+18 - Differentiable computation graph = True!
PPO iteration: 232/1000:
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 146...
	 start solving instance: 55...
	 start solving instance: 58...
	 start solving instance: 131...
	 start solving instance: 129...
	 start solving instance: 46...
	 start solving instance: 11...
	 start solving instance: 96...
	 start solving instance: 3...
	 start solving instance: 1...
	 start solving instance: 78...
	 start solving instance: 105...
	 start solving instance: 9...
	 start solving instance: 33...
	 start solving instance: 35...
	 start solving instance: 93...
	 start solving instance: 126...
	 start solving instance: 37...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.922655506453653e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6093821440.0
		 entropy bonus: 0.2264307737350464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5993925632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6653250048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.922655616404816e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.922655506453653e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6093821440.0
		 entropy bonus: 0.2264307737350464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5993925632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6653250048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.922655616404816e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.922655506453653e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6093821440.0
		 entropy bonus: 0.2264307737350464
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5993925632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6653250048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.922655616404816e+18 - Differentiable computation graph = True!
PPO iteration: 233/1000:
	 start solving instance: 129...
	 start solving instance: 96...
	 start solving instance: 131...
	 start solving instance: 93...
	 start solving instance: 78...
	 start solving instance: 126...
	 start solving instance: 1...
	 start solving instance: 3...
	 start solving instance: 117...
	 start solving instance: 46...
	 start solving instance: 37...
	 start solving instance: 146...
	 start solving instance: 9...
	 start solving instance: 35...
	 start solving instance: 105...
	 start solving instance: 55...
	 start solving instance: 58...
	 start solving instance: 89...
	 start solving instance: 11...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.206022962578037e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167980544.0
		 entropy bonus: 0.22759468853473663
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6254960128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6924516352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2060231275047813e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.206022962578037e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167980544.0
		 entropy bonus: 0.22759468853473663
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6254960128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6924516352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2060231275047813e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.206022962578037e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167980544.0
		 entropy bonus: 0.22759468853473663
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6254960128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6924516352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2060231275047813e+18 - Differentiable computation graph = True!
PPO iteration: 234/1000:
	 start solving instance: 55...
	 start solving instance: 131...
	 start solving instance: 129...
	 start solving instance: 11...
	 start solving instance: 105...
	 start solving instance: 146...
	 start solving instance: 89...
	 start solving instance: 96...
	 start solving instance: 9...
	 start solving instance: 117...
	 start solving instance: 33...
	 start solving instance: 37...
	 start solving instance: 3...
	 start solving instance: 93...
	 start solving instance: 1...
	 start solving instance: 35...
	 start solving instance: 78...
	 start solving instance: 46...
	 start solving instance: 58...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.210788245972818e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212921856.0
		 entropy bonus: 0.22069230675697327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6219273728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6869307904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2107884108995625e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.210788245972818e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212921856.0
		 entropy bonus: 0.22069230675697327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6219273728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6869307904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2107884108995625e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.210788245972818e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212921856.0
		 entropy bonus: 0.22069230675697327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6219273728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6869307904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2107884108995625e+18 - Differentiable computation graph = True!
PPO iteration: 235/1000:
	 start solving instance: 46...
	 start solving instance: 131...
	 start solving instance: 96...
	 start solving instance: 37...
	 start solving instance: 1...
	 start solving instance: 9...
	 start solving instance: 33...
	 start solving instance: 89...
	 start solving instance: 146...
	 start solving instance: 129...
	 start solving instance: 58...
	 start solving instance: 117...
	 start solving instance: 93...
	 start solving instance: 78...
	 start solving instance: 35...
	 start solving instance: 126...
	 start solving instance: 55...
	 start solving instance: 105...
	 start solving instance: 11...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.320832207531803e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6121772544.0
		 entropy bonus: 0.21755798161029816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6347765248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7315689472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3208322075318026e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.320832207531803e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6121772544.0
		 entropy bonus: 0.21755798161029816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6347765248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7315689472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3208322075318026e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.320832207531803e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6121772544.0
		 entropy bonus: 0.21755798161029816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6347765248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7315689472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3208322075318026e+18 - Differentiable computation graph = True!
PPO iteration: 236/1000:
	 start solving instance: 9...
	 start solving instance: 35...
	 start solving instance: 126...
	 start solving instance: 129...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 117...
	 start solving instance: 146...
	 start solving instance: 33...
	 start solving instance: 58...
	 start solving instance: 37...
	 start solving instance: 131...
	 start solving instance: 78...
	 start solving instance: 3...
	 start solving instance: 93...
	 start solving instance: 55...
	 start solving instance: 96...
	 start solving instance: 11...
	 start solving instance: 89...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2987575324832694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201285632.0
		 entropy bonus: 0.2237672656774521
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6342152192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7012058624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.298757587458851e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2987575324832694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201285632.0
		 entropy bonus: 0.2237672656774521
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6342152192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7012058624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.298757587458851e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2987575324832694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201285632.0
		 entropy bonus: 0.2237672656774521
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6342152192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7012058624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.298757587458851e+18 - Differentiable computation graph = True!
PPO iteration: 237/1000:
	 start solving instance: 11...
	 start solving instance: 78...
	 start solving instance: 46...
	 start solving instance: 131...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 93...
	 start solving instance: 1...
	 start solving instance: 9...
	 start solving instance: 96...
	 start solving instance: 105...
	 start solving instance: 55...
	 start solving instance: 33...
	 start solving instance: 146...
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 37...
	 start solving instance: 35...
	 start solving instance: 126...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.223216685608547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6119718912.0
		 entropy bonus: 0.23365893959999084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6308298240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6667359744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2232167405841285e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.223216685608547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6119718912.0
		 entropy bonus: 0.23365893959999084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6308298240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6667359744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2232167405841285e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.223216685608547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6119718912.0
		 entropy bonus: 0.23365893959999084
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6308298240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6667359744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2232167405841285e+18 - Differentiable computation graph = True!
PPO iteration: 238/1000:
	 start solving instance: 58...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 46...
	 start solving instance: 117...
	 start solving instance: 3...
	 start solving instance: 105...
	 start solving instance: 126...
	 start solving instance: 78...
	 start solving instance: 35...
	 start solving instance: 93...
	 start solving instance: 131...
	 start solving instance: 96...
	 start solving instance: 89...
	 start solving instance: 9...
	 start solving instance: 11...
	 start solving instance: 33...
	 start solving instance: 37...
	 start solving instance: 55...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.425882187277428e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212501504.0
		 entropy bonus: 0.2307327836751938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6489891840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7178939392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.425882297228591e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.425882187277428e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212501504.0
		 entropy bonus: 0.2307327836751938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6489891840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7178939392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.425882297228591e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.425882187277428e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212501504.0
		 entropy bonus: 0.2307327836751938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6489891840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7178939392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.425882297228591e+18 - Differentiable computation graph = True!
PPO iteration: 239/1000:
	 start solving instance: 1...
	 start solving instance: 58...
	 start solving instance: 117...
	 start solving instance: 131...
	 start solving instance: 126...
	 start solving instance: 89...
	 start solving instance: 55...
	 start solving instance: 146...
	 start solving instance: 78...
	 start solving instance: 37...
	 start solving instance: 105...
	 start solving instance: 96...
	 start solving instance: 3...
	 start solving instance: 93...
	 start solving instance: 35...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 129...
	 start solving instance: 9...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.193464780570231e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083750400.0
		 entropy bonus: 0.23274122178554535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6186379264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967746048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.193464780570231e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.193464780570231e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083750400.0
		 entropy bonus: 0.23274122178554535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6186379264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967746048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.193464780570231e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.193464780570231e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083750400.0
		 entropy bonus: 0.23274122178554535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6186379264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967746048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.193464780570231e+18 - Differentiable computation graph = True!
PPO iteration: 240/1000:
	 start solving instance: 78...
	 start solving instance: 58...
	 start solving instance: 35...
	 start solving instance: 105...
	 start solving instance: 33...
	 start solving instance: 146...
	 start solving instance: 89...
	 start solving instance: 3...
	 start solving instance: 126...
	 start solving instance: 96...
	 start solving instance: 37...
	 start solving instance: 46...
	 start solving instance: 93...
	 start solving instance: 129...
	 start solving instance: 131...
	 start solving instance: 11...
	 start solving instance: 1...
	 start solving instance: 117...
	 start solving instance: 9...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.203035369583044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6074078208.0
		 entropy bonus: 0.23792922496795654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294972416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6890671616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.203035479534207e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.203035369583044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6074078208.0
		 entropy bonus: 0.23792922496795654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294972416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6890671616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.203035479534207e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.203035369583044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6074078208.0
		 entropy bonus: 0.23792922496795654
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294972416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6890671616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.203035479534207e+18 - Differentiable computation graph = True!
PPO iteration: 241/1000:
	 New training batch of size 20...
	 start solving instance: 77...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 61...
	 start solving instance: 103...
	 start solving instance: 33...
	 start solving instance: 120...
	 start solving instance: 56...
	 start solving instance: 110...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 130...
	 start solving instance: 31...
	 start solving instance: 20...
	 start solving instance: 97...
	 start solving instance: 138...
	 start solving instance: 47...
	 start solving instance: 19...
	 start solving instance: 30...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.117425195221149e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5874640384.0
		 entropy bonus: 0.2362356036901474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6066191872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7230985216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.117425305172312e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.117425195221149e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5874640384.0
		 entropy bonus: 0.2362356036901474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6066191872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7230985216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.117425305172312e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.117425195221149e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5874640384.0
		 entropy bonus: 0.2362356036901474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6066191872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7230985216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.117425305172312e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.7784007923015877e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5080530432.0
		 entropy bonus: 0.202315092086792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4942082560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5795247104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2778400737326006272.0000
PPO iteration: 242/1000:
	 start solving instance: 20...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 99...
	 start solving instance: 142...
	 start solving instance: 77...
	 start solving instance: 97...
	 start solving instance: 133...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 61...
	 start solving instance: 56...
	 start solving instance: 138...
	 start solving instance: 120...
	 start solving instance: 33...
	 start solving instance: 10...
	 start solving instance: 30...
	 start solving instance: 19...
	 start solving instance: 47...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.157226636537338e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5905393664.0
		 entropy bonus: 0.22913046181201935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6015689728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6957027840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1572268014640824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.157226636537338e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5905393664.0
		 entropy bonus: 0.22913046181201935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6015689728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6957027840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1572268014640824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.157226636537338e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5905393664.0
		 entropy bonus: 0.22913046181201935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6015689728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6957027840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1572268014640824e+18 - Differentiable computation graph = True!
PPO iteration: 243/1000:
	 start solving instance: 56...
	 start solving instance: 47...
	 start solving instance: 130...
	 start solving instance: 77...
	 start solving instance: 137...
	 start solving instance: 138...
	 start solving instance: 61...
	 start solving instance: 33...
	 start solving instance: 19...
	 start solving instance: 103...
	 start solving instance: 120...
	 start solving instance: 31...
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 10...
	 start solving instance: 142...
	 start solving instance: 20...
	 start solving instance: 110...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.534617729999359e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016295424.0
		 entropy bonus: 0.2399362176656723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6298067968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7251831808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.534617675023778e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.534617729999359e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016295424.0
		 entropy bonus: 0.2399362176656723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6298067968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7251831808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.534617675023778e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.534617729999359e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016295424.0
		 entropy bonus: 0.2399362176656723
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6298067968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7251831808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.534617675023778e+18 - Differentiable computation graph = True!
PPO iteration: 244/1000:
	 start solving instance: 142...
	 start solving instance: 103...
	 start solving instance: 47...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 138...
	 start solving instance: 133...
	 start solving instance: 97...
	 start solving instance: 99...
	 start solving instance: 20...
	 start solving instance: 31...
	 start solving instance: 120...
	 start solving instance: 33...
	 start solving instance: 77...
	 start solving instance: 110...
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 30...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.407305718423827e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985338880.0
		 entropy bonus: 0.23846431076526642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6211976704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7501878784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4073057733994086e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.407305718423827e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985338880.0
		 entropy bonus: 0.23846431076526642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6211976704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7501878784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4073057733994086e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.407305718423827e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985338880.0
		 entropy bonus: 0.23846431076526642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6211976704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7501878784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4073057733994086e+18 - Differentiable computation graph = True!
PPO iteration: 245/1000:
	 start solving instance: 56...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 19...
	 start solving instance: 110...
	 start solving instance: 133...
	 start solving instance: 103...
	 start solving instance: 97...
	 start solving instance: 47...
	 start solving instance: 20...
	 start solving instance: 99...
	 start solving instance: 33...
	 start solving instance: 137...
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 120...
	 start solving instance: 30...
	 start solving instance: 31...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5559003168712425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6011581952.0
		 entropy bonus: 0.2445562183856964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6364106240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7357464576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.555900371846824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5559003168712425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6011581952.0
		 entropy bonus: 0.2445562183856964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6364106240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7357464576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.555900371846824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5559003168712425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6011581952.0
		 entropy bonus: 0.2445562183856964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6364106240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7357464576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.555900371846824e+18 - Differentiable computation graph = True!
PPO iteration: 246/1000:
	 start solving instance: 77...
	 start solving instance: 130...
	 start solving instance: 56...
	 start solving instance: 47...
	 start solving instance: 61...
	 start solving instance: 137...
	 start solving instance: 133...
	 start solving instance: 30...
	 start solving instance: 20...
	 start solving instance: 10...
	 start solving instance: 138...
	 start solving instance: 120...
	 start solving instance: 99...
	 start solving instance: 110...
	 start solving instance: 33...
	 start solving instance: 19...
	 start solving instance: 31...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3706761482514465e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5980655616.0
		 entropy bonus: 0.2403283566236496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6265098752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7232658432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370676093275865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3706761482514465e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5980655616.0
		 entropy bonus: 0.2403283566236496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6265098752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7232658432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370676093275865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3706761482514465e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5980655616.0
		 entropy bonus: 0.2403283566236496
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6265098752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7232658432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.370676093275865e+18 - Differentiable computation graph = True!
PPO iteration: 247/1000:
	 start solving instance: 137...
	 start solving instance: 47...
	 start solving instance: 61...
	 start solving instance: 77...
	 start solving instance: 10...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 20...
	 start solving instance: 120...
	 start solving instance: 30...
	 start solving instance: 31...
	 start solving instance: 19...
	 start solving instance: 33...
	 start solving instance: 99...
	 start solving instance: 103...
	 start solving instance: 133...
	 start solving instance: 138...
	 start solving instance: 110...
	 start solving instance: 97...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.648233345130011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021988352.0
		 entropy bonus: 0.23757348954677582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6470727168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7580290048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.648233235178848e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.648233345130011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021988352.0
		 entropy bonus: 0.23757348954677582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6470727168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7580290048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.648233235178848e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.648233345130011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021988352.0
		 entropy bonus: 0.23757348954677582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6470727168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7580290048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.648233235178848e+18 - Differentiable computation graph = True!
PPO iteration: 248/1000:
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 130...
	 start solving instance: 47...
	 start solving instance: 56...
	 start solving instance: 133...
	 start solving instance: 30...
	 start solving instance: 77...
	 start solving instance: 61...
	 start solving instance: 33...
	 start solving instance: 99...
	 start solving instance: 10...
	 start solving instance: 19...
	 start solving instance: 31...
	 start solving instance: 110...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 20...
	 start solving instance: 120...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3808470706130256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027847168.0
		 entropy bonus: 0.222279891371727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140103680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7195494912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380847125588607e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3808470706130256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027847168.0
		 entropy bonus: 0.222279891371727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140103680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7195494912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380847125588607e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3808470706130256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027847168.0
		 entropy bonus: 0.222279891371727
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140103680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7195494912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380847125588607e+18 - Differentiable computation graph = True!
PPO iteration: 249/1000:
	 start solving instance: 33...
	 start solving instance: 10...
	 start solving instance: 31...
	 start solving instance: 103...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 130...
	 start solving instance: 47...
	 start solving instance: 133...
	 start solving instance: 99...
	 start solving instance: 20...
	 start solving instance: 56...
	 start solving instance: 137...
	 start solving instance: 61...
	 start solving instance: 120...
	 start solving instance: 30...
	 start solving instance: 19...
	 start solving instance: 110...
	 start solving instance: 77...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6271614246860095e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6046111232.0
		 entropy bonus: 0.24816563725471497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6403104768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7217489408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.627161644588335e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6271614246860095e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6046111232.0
		 entropy bonus: 0.24816563725471497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6403104768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7217489408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.627161644588335e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6271614246860095e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6046111232.0
		 entropy bonus: 0.24816563725471497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6403104768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7217489408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.627161644588335e+18 - Differentiable computation graph = True!
PPO iteration: 250/1000:
	 start solving instance: 120...
	 start solving instance: 97...
	 start solving instance: 137...
	 start solving instance: 142...
	 start solving instance: 20...
	 start solving instance: 10...
	 start solving instance: 33...
	 start solving instance: 77...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 30...
	 start solving instance: 19...
	 start solving instance: 133...
	 start solving instance: 99...
	 start solving instance: 31...
	 start solving instance: 47...
	 start solving instance: 138...
	 start solving instance: 61...
	 start solving instance: 103...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.185996017985074e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894905344.0
		 entropy bonus: 0.23209357261657715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6068950016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7224104448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1859960729606554e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.185996017985074e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894905344.0
		 entropy bonus: 0.23209357261657715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6068950016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7224104448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1859960729606554e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.185996017985074e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894905344.0
		 entropy bonus: 0.23209357261657715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6068950016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7224104448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1859960729606554e+18 - Differentiable computation graph = True!
PPO iteration: 251/1000:
	 New training batch of size 20...
	 start solving instance: 79...
	 start solving instance: 5...
	 start solving instance: 23...
	 start solving instance: 45...
	 start solving instance: 36...
	 start solving instance: 95...
	 start solving instance: 59...
	 start solving instance: 122...
	 start solving instance: 81...
	 start solving instance: 65...
	 start solving instance: 147...
	 start solving instance: 66...
	 start solving instance: 131...
	 start solving instance: 76...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 145...
	 start solving instance: 9...
	 start solving instance: 43...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.274499667146624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6052179968.0
		 entropy bonus: 0.21687515079975128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294284800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7350530048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.274499612171043e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.274499667146624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6052179968.0
		 entropy bonus: 0.21687515079975128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294284800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7350530048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.274499612171043e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.274499667146624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6052179968.0
		 entropy bonus: 0.21687515079975128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6294284800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7350530048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.274499612171043e+18 - Differentiable computation graph = True!
PPO iteration: 252/1000:
	 start solving instance: 66...
	 start solving instance: 65...
	 start solving instance: 23...
	 start solving instance: 36...
	 start solving instance: 76...
	 start solving instance: 5...
	 start solving instance: 95...
	 start solving instance: 9...
	 start solving instance: 81...
	 start solving instance: 45...
	 start solving instance: 79...
	 start solving instance: 131...
	 start solving instance: 122...
	 start solving instance: 43...
	 start solving instance: 108...
	 start solving instance: 59...
	 start solving instance: 147...
	 start solving instance: 112...
	 start solving instance: 145...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.339117525706369e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048901120.0
		 entropy bonus: 0.21280832588672638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6318505472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7237185024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3391176356575314e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.339117525706369e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048901120.0
		 entropy bonus: 0.21280832588672638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6318505472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7237185024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3391176356575314e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.339117525706369e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048901120.0
		 entropy bonus: 0.21280832588672638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6318505472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7237185024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3391176356575314e+18 - Differentiable computation graph = True!
PPO iteration: 253/1000:
	 start solving instance: 117...
	 start solving instance: 65...
	 start solving instance: 76...
	 start solving instance: 23...
	 start solving instance: 131...
	 start solving instance: 95...
	 start solving instance: 122...
	 start solving instance: 79...
	 start solving instance: 81...
	 start solving instance: 66...
	 start solving instance: 9...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 5...
	 start solving instance: 145...
	 start solving instance: 108...
	 start solving instance: 45...
	 start solving instance: 59...
	 start solving instance: 43...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1668244934385205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5973478912.0
		 entropy bonus: 0.2181965410709381
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188080640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7445105664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.166824438462939e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1668244934385205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5973478912.0
		 entropy bonus: 0.2181965410709381
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188080640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7445105664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.166824438462939e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1668244934385205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5973478912.0
		 entropy bonus: 0.2181965410709381
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188080640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7445105664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.166824438462939e+18 - Differentiable computation graph = True!
PPO iteration: 254/1000:
	 start solving instance: 9...
	 start solving instance: 45...
	 start solving instance: 117...
	 start solving instance: 5...
	 start solving instance: 23...
	 start solving instance: 59...
	 start solving instance: 65...
	 start solving instance: 131...
	 start solving instance: 112...
	 start solving instance: 43...
	 start solving instance: 36...
	 start solving instance: 81...
	 start solving instance: 76...
	 start solving instance: 66...
	 start solving instance: 145...
	 start solving instance: 122...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 79...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.211513044037848e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969710080.0
		 entropy bonus: 0.21273589134216309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6230867456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914084352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.211512989062267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.211513044037848e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969710080.0
		 entropy bonus: 0.21273589134216309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6230867456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914084352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.211512989062267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.211513044037848e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969710080.0
		 entropy bonus: 0.21273589134216309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6230867456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914084352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.211512989062267e+18 - Differentiable computation graph = True!
PPO iteration: 255/1000:
	 start solving instance: 59...
	 start solving instance: 43...
	 start solving instance: 95...
	 start solving instance: 76...
	 start solving instance: 5...
	 start solving instance: 145...
	 start solving instance: 36...
	 start solving instance: 108...
	 start solving instance: 45...
	 start solving instance: 66...
	 start solving instance: 79...
	 start solving instance: 131...
	 start solving instance: 117...
	 start solving instance: 9...
	 start solving instance: 112...
	 start solving instance: 23...
	 start solving instance: 122...
	 start solving instance: 147...
	 start solving instance: 81...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.200481423974046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113439744.0
		 entropy bonus: 0.20835573971271515
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6233605632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6949628928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2004815889007903e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.200481423974046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113439744.0
		 entropy bonus: 0.20835573971271515
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6233605632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6949628928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2004815889007903e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.200481423974046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113439744.0
		 entropy bonus: 0.20835573971271515
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6233605632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6949628928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2004815889007903e+18 - Differentiable computation graph = True!
PPO iteration: 256/1000:
	 start solving instance: 117...
	 start solving instance: 112...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 76...
	 start solving instance: 131...
	 start solving instance: 66...
	 start solving instance: 45...
	 start solving instance: 81...
	 start solving instance: 23...
	 start solving instance: 65...
	 start solving instance: 122...
	 start solving instance: 43...
	 start solving instance: 59...
	 start solving instance: 147...
	 start solving instance: 5...
	 start solving instance: 95...
	 start solving instance: 9...
	 start solving instance: 108...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.095124460581945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5976913408.0
		 entropy bonus: 0.2128286361694336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6141910528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6907092992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0951244605819453e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.095124460581945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5976913408.0
		 entropy bonus: 0.2128286361694336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6141910528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6907092992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0951244605819453e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.095124460581945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5976913408.0
		 entropy bonus: 0.2128286361694336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6141910528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6907092992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0951244605819453e+18 - Differentiable computation graph = True!
PPO iteration: 257/1000:
	 start solving instance: 9...
	 start solving instance: 45...
	 start solving instance: 131...
	 start solving instance: 108...
	 start solving instance: 59...
	 start solving instance: 117...
	 start solving instance: 81...
	 start solving instance: 112...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 76...
	 start solving instance: 23...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 95...
	 start solving instance: 36...
	 start solving instance: 5...
	 start solving instance: 122...
	 start solving instance: 65...
	 start solving instance: 43...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0106230337455e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5989313024.0
		 entropy bonus: 0.21251197159290314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6036570112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6643778560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0106231436966625e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0106230337455e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5989313024.0
		 entropy bonus: 0.21251197159290314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6036570112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6643778560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0106231436966625e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0106230337455e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5989313024.0
		 entropy bonus: 0.21251197159290314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6036570112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6643778560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0106231436966625e+18 - Differentiable computation graph = True!
PPO iteration: 258/1000:
	 start solving instance: 45...
	 start solving instance: 145...
	 start solving instance: 112...
	 start solving instance: 76...
	 start solving instance: 43...
	 start solving instance: 81...
	 start solving instance: 131...
	 start solving instance: 5...
	 start solving instance: 36...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 79...
	 start solving instance: 108...
	 start solving instance: 147...
	 start solving instance: 9...
	 start solving instance: 59...
	 start solving instance: 66...
	 start solving instance: 95...
	 start solving instance: 117...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0822935996904505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031314944.0
		 entropy bonus: 0.20557069778442383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5995476480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6941401600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0822937096416133e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0822935996904505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031314944.0
		 entropy bonus: 0.20557069778442383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5995476480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6941401600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0822937096416133e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0822935996904505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031314944.0
		 entropy bonus: 0.20557069778442383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5995476480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6941401600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0822937096416133e+18 - Differentiable computation graph = True!
PPO iteration: 259/1000:
	 start solving instance: 147...
	 start solving instance: 23...
	 start solving instance: 5...
	 start solving instance: 65...
	 start solving instance: 117...
	 start solving instance: 145...
	 start solving instance: 76...
	 start solving instance: 36...
	 start solving instance: 131...
	 start solving instance: 9...
	 start solving instance: 108...
	 start solving instance: 79...
	 start solving instance: 81...
	 start solving instance: 59...
	 start solving instance: 122...
	 start solving instance: 112...
	 start solving instance: 66...
	 start solving instance: 43...
	 start solving instance: 95...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.296101552195214e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6053099008.0
		 entropy bonus: 0.225942924618721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6307847680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7007278080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.296101717121958e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.296101552195214e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6053099008.0
		 entropy bonus: 0.225942924618721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6307847680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7007278080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.296101717121958e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.296101552195214e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6053099008.0
		 entropy bonus: 0.225942924618721
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6307847680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7007278080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.296101717121958e+18 - Differentiable computation graph = True!
PPO iteration: 260/1000:
	 start solving instance: 9...
	 start solving instance: 65...
	 start solving instance: 59...
	 start solving instance: 122...
	 start solving instance: 66...
	 start solving instance: 5...
	 start solving instance: 81...
	 start solving instance: 95...
	 start solving instance: 145...
	 start solving instance: 79...
	 start solving instance: 108...
	 start solving instance: 76...
	 start solving instance: 45...
	 start solving instance: 112...
	 start solving instance: 147...
	 start solving instance: 117...
	 start solving instance: 23...
	 start solving instance: 43...
	 start solving instance: 131...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.328680081726217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6038771200.0
		 entropy bonus: 0.22186584770679474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6377559552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7838222848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328680246652961e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.328680081726217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6038771200.0
		 entropy bonus: 0.22186584770679474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6377559552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7838222848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328680246652961e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.328680081726217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6038771200.0
		 entropy bonus: 0.22186584770679474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6377559552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7838222848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328680246652961e+18 - Differentiable computation graph = True!
PPO iteration: 261/1000:
	 New training batch of size 20...
	 start solving instance: 62...
	 start solving instance: 91...
	 start solving instance: 46...
	 start solving instance: 113...
	 start solving instance: 100...
	 start solving instance: 4...
	 start solving instance: 80...
	 start solving instance: 12...
	 start solving instance: 81...
	 start solving instance: 136...
	 start solving instance: 31...
	 start solving instance: 89...
	 start solving instance: 33...
	 start solving instance: 131...
	 start solving instance: 82...
	 start solving instance: 74...
	 start solving instance: 118...
	 start solving instance: 5...
	 start solving instance: 137...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6779372034595488e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5835423744.0
		 entropy bonus: 0.20976486802101135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5738115584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726237696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6779373134107116e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6779372034595488e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5835423744.0
		 entropy bonus: 0.20976486802101135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5738115584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726237696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6779373134107116e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6779372034595488e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5835423744.0
		 entropy bonus: 0.20976486802101135
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5738115584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726237696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6779373134107116e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.799189918354925e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5223046144.0
		 entropy bonus: 0.19712917506694794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4930666496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5635063296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2799190028306087936.0000
PPO iteration: 262/1000:
	 start solving instance: 80...
	 start solving instance: 136...
	 start solving instance: 12...
	 start solving instance: 62...
	 start solving instance: 118...
	 start solving instance: 82...
	 start solving instance: 100...
	 start solving instance: 89...
	 start solving instance: 81...
	 start solving instance: 91...
	 start solving instance: 4...
	 start solving instance: 33...
	 start solving instance: 46...
	 start solving instance: 5...
	 start solving instance: 137...
	 start solving instance: 31...
	 start solving instance: 131...
	 start solving instance: 113...
	 start solving instance: 74...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.853645318843269e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5778195456.0
		 entropy bonus: 0.2105896919965744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5804072960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624792576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.853645318843269e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.853645318843269e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5778195456.0
		 entropy bonus: 0.2105896919965744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5804072960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624792576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.853645318843269e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.853645318843269e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5778195456.0
		 entropy bonus: 0.2105896919965744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5804072960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624792576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.853645318843269e+18 - Differentiable computation graph = True!
PPO iteration: 263/1000:
	 start solving instance: 131...
	 start solving instance: 81...
	 start solving instance: 5...
	 start solving instance: 118...
	 start solving instance: 91...
	 start solving instance: 100...
	 start solving instance: 136...
	 start solving instance: 80...
	 start solving instance: 89...
	 start solving instance: 113...
	 start solving instance: 12...
	 start solving instance: 62...
	 start solving instance: 137...
	 start solving instance: 31...
	 start solving instance: 33...
	 start solving instance: 74...
	 start solving instance: 46...
	 start solving instance: 4...
	 start solving instance: 82...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6800711356267364e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5710640640.0
		 entropy bonus: 0.2153533697128296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5675456512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6535473664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.680071190602318e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6800711356267364e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5710640640.0
		 entropy bonus: 0.2153533697128296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5675456512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6535473664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.680071190602318e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6800711356267364e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5710640640.0
		 entropy bonus: 0.2153533697128296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5675456512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6535473664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.680071190602318e+18 - Differentiable computation graph = True!
PPO iteration: 264/1000:
	 start solving instance: 4...
	 start solving instance: 5...
	 start solving instance: 118...
	 start solving instance: 137...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 81...
	 start solving instance: 131...
	 start solving instance: 89...
	 start solving instance: 100...
	 start solving instance: 105...
	 start solving instance: 82...
	 start solving instance: 62...
	 start solving instance: 31...
	 start solving instance: 113...
	 start solving instance: 136...
	 start solving instance: 33...
	 start solving instance: 12...
	 start solving instance: 80...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.997792172854005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5853577216.0
		 entropy bonus: 0.21431724727153778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5973356032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967237120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9977921178784236e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.997792172854005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5853577216.0
		 entropy bonus: 0.21431724727153778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5973356032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967237120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9977921178784236e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.997792172854005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5853577216.0
		 entropy bonus: 0.21431724727153778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5973356032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967237120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9977921178784236e+18 - Differentiable computation graph = True!
PPO iteration: 265/1000:
	 start solving instance: 100...
	 start solving instance: 74...
	 start solving instance: 91...
	 start solving instance: 136...
	 start solving instance: 82...
	 start solving instance: 80...
	 start solving instance: 5...
	 start solving instance: 12...
	 start solving instance: 89...
	 start solving instance: 4...
	 start solving instance: 118...
	 start solving instance: 131...
	 start solving instance: 46...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 105...
	 start solving instance: 137...
	 start solving instance: 33...
	 start solving instance: 113...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.777602215056979e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5822948352.0
		 entropy bonus: 0.20664897561073303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5830829568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6796913152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.77760227003256e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.777602215056979e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5822948352.0
		 entropy bonus: 0.20664897561073303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5830829568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6796913152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.77760227003256e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.777602215056979e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5822948352.0
		 entropy bonus: 0.20664897561073303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5830829568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6796913152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.77760227003256e+18 - Differentiable computation graph = True!
PPO iteration: 266/1000:
	 start solving instance: 33...
	 start solving instance: 5...
	 start solving instance: 62...
	 start solving instance: 100...
	 start solving instance: 137...
	 start solving instance: 4...
	 start solving instance: 80...
	 start solving instance: 74...
	 start solving instance: 131...
	 start solving instance: 12...
	 start solving instance: 91...
	 start solving instance: 105...
	 start solving instance: 31...
	 start solving instance: 82...
	 start solving instance: 46...
	 start solving instance: 113...
	 start solving instance: 81...
	 start solving instance: 89...
	 start solving instance: 136...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.961994713081525e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785882624.0
		 entropy bonus: 0.21297502517700195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5907095552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6912994816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9619947680571064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.961994713081525e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785882624.0
		 entropy bonus: 0.21297502517700195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5907095552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6912994816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9619947680571064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.961994713081525e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785882624.0
		 entropy bonus: 0.21297502517700195
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5907095552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6912994816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9619947680571064e+18 - Differentiable computation graph = True!
PPO iteration: 267/1000:
	 start solving instance: 62...
	 start solving instance: 5...
	 start solving instance: 136...
	 start solving instance: 33...
	 start solving instance: 91...
	 start solving instance: 100...
	 start solving instance: 74...
	 start solving instance: 31...
	 start solving instance: 4...
	 start solving instance: 82...
	 start solving instance: 46...
	 start solving instance: 12...
	 start solving instance: 80...
	 start solving instance: 118...
	 start solving instance: 113...
	 start solving instance: 105...
	 start solving instance: 137...
	 start solving instance: 81...
	 start solving instance: 89...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.618906623187511e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5739349504.0
		 entropy bonus: 0.21682147681713104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5667839488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6524466688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6189067331386737e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.618906623187511e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5739349504.0
		 entropy bonus: 0.21682147681713104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5667839488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6524466688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6189067331386737e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.618906623187511e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5739349504.0
		 entropy bonus: 0.21682147681713104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5667839488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6524466688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6189067331386737e+18 - Differentiable computation graph = True!
PPO iteration: 268/1000:
	 start solving instance: 118...
	 start solving instance: 91...
	 start solving instance: 33...
	 start solving instance: 137...
	 start solving instance: 82...
	 start solving instance: 12...
	 start solving instance: 113...
	 start solving instance: 4...
	 start solving instance: 80...
	 start solving instance: 74...
	 start solving instance: 31...
	 start solving instance: 89...
	 start solving instance: 81...
	 start solving instance: 136...
	 start solving instance: 105...
	 start solving instance: 131...
	 start solving instance: 46...
	 start solving instance: 62...
	 start solving instance: 5...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.718194282394288e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5867773952.0
		 entropy bonus: 0.2126832753419876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5751779328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6708310528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.718194282394288e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.718194282394288e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5867773952.0
		 entropy bonus: 0.2126832753419876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5751779328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6708310528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.718194282394288e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.718194282394288e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5867773952.0
		 entropy bonus: 0.2126832753419876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5751779328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6708310528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.718194282394288e+18 - Differentiable computation graph = True!
PPO iteration: 269/1000:
	 start solving instance: 5...
	 start solving instance: 137...
	 start solving instance: 31...
	 start solving instance: 136...
	 start solving instance: 46...
	 start solving instance: 131...
	 start solving instance: 89...
	 start solving instance: 4...
	 start solving instance: 74...
	 start solving instance: 113...
	 start solving instance: 33...
	 start solving instance: 91...
	 start solving instance: 82...
	 start solving instance: 81...
	 start solving instance: 100...
	 start solving instance: 62...
	 start solving instance: 118...
	 start solving instance: 105...
	 start solving instance: 12...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.913592452008221e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802692096.0
		 entropy bonus: 0.2059372216463089
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5870154752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696366592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.913592616934965e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.913592452008221e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802692096.0
		 entropy bonus: 0.2059372216463089
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5870154752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696366592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.913592616934965e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.913592452008221e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802692096.0
		 entropy bonus: 0.2059372216463089
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5870154752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696366592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.913592616934965e+18 - Differentiable computation graph = True!
PPO iteration: 270/1000:
	 start solving instance: 118...
	 start solving instance: 5...
	 start solving instance: 100...
	 start solving instance: 74...
	 start solving instance: 12...
	 start solving instance: 89...
	 start solving instance: 137...
	 start solving instance: 31...
	 start solving instance: 82...
	 start solving instance: 4...
	 start solving instance: 131...
	 start solving instance: 33...
	 start solving instance: 91...
	 start solving instance: 62...
	 start solving instance: 46...
	 start solving instance: 105...
	 start solving instance: 81...
	 start solving instance: 113...
	 start solving instance: 136...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6115829961372205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738120192.0
		 entropy bonus: 0.2150500863790512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5622655488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6665537536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6115831610639647e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6115829961372205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738120192.0
		 entropy bonus: 0.2150500863790512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5622655488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6665537536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6115831610639647e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6115829961372205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738120192.0
		 entropy bonus: 0.2150500863790512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5622655488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6665537536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6115831610639647e+18 - Differentiable computation graph = True!
PPO iteration: 271/1000:
	 New training batch of size 20...
	 start solving instance: 86...
	 start solving instance: 54...
	 start solving instance: 93...
	 start solving instance: 65...
	 start solving instance: 67...
	 start solving instance: 73...
	 start solving instance: 42...
	 start solving instance: 148...
	 start solving instance: 99...
	 start solving instance: 9...
	 start solving instance: 144...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 14...
	 start solving instance: 107...
	 start solving instance: 79...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 27...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0424204702161306e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6088955904.0
		 entropy bonus: 0.21611927449703217
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198810112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6487054336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0424204702161306e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0424204702161306e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6088955904.0
		 entropy bonus: 0.21611927449703217
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198810112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6487054336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0424204702161306e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0424204702161306e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6088955904.0
		 entropy bonus: 0.21611927449703217
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198810112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6487054336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0424204702161306e+18 - Differentiable computation graph = True!
PPO iteration: 272/1000:
	 start solving instance: 9...
	 start solving instance: 148...
	 start solving instance: 27...
	 start solving instance: 144...
	 start solving instance: 92...
	 start solving instance: 65...
	 start solving instance: 137...
	 start solving instance: 93...
	 start solving instance: 54...
	 start solving instance: 86...
	 start solving instance: 67...
	 start solving instance: 73...
	 start solving instance: 90...
	 start solving instance: 112...
	 start solving instance: 14...
	 start solving instance: 42...
	 start solving instance: 99...
	 start solving instance: 79...
	 start solving instance: 107...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.985338664353163e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044969984.0
		 entropy bonus: 0.20802120864391327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6094553088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926809600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9853387743043256e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.985338664353163e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044969984.0
		 entropy bonus: 0.20802120864391327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6094553088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926809600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9853387743043256e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.985338664353163e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044969984.0
		 entropy bonus: 0.20802120864391327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6094553088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926809600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9853387743043256e+18 - Differentiable computation graph = True!
PPO iteration: 273/1000:
	 start solving instance: 42...
	 start solving instance: 79...
	 start solving instance: 146...
	 start solving instance: 73...
	 start solving instance: 99...
	 start solving instance: 86...
	 start solving instance: 14...
	 start solving instance: 9...
	 start solving instance: 67...
	 start solving instance: 92...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 93...
	 start solving instance: 144...
	 start solving instance: 148...
	 start solving instance: 112...
	 start solving instance: 65...
	 start solving instance: 27...
	 start solving instance: 54...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8686294633066004e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6078355968.0
		 entropy bonus: 0.21053428947925568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5788765184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6857200128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8686294633066004e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8686294633066004e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6078355968.0
		 entropy bonus: 0.21053428947925568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5788765184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6857200128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8686294633066004e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8686294633066004e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6078355968.0
		 entropy bonus: 0.21053428947925568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5788765184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6857200128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8686294633066004e+18 - Differentiable computation graph = True!
PPO iteration: 274/1000:
	 start solving instance: 65...
	 start solving instance: 148...
	 start solving instance: 73...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 144...
	 start solving instance: 99...
	 start solving instance: 90...
	 start solving instance: 54...
	 start solving instance: 67...
	 start solving instance: 27...
	 start solving instance: 107...
	 start solving instance: 86...
	 start solving instance: 146...
	 start solving instance: 137...
	 start solving instance: 14...
	 start solving instance: 93...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.891941308838707e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044092928.0
		 entropy bonus: 0.19987767934799194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938525696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6656972288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.891941308838707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.891941308838707e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044092928.0
		 entropy bonus: 0.19987767934799194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938525696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6656972288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.891941308838707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.891941308838707e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044092928.0
		 entropy bonus: 0.19987767934799194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938525696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6656972288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.891941308838707e+18 - Differentiable computation graph = True!
PPO iteration: 275/1000:
	 start solving instance: 107...
	 start solving instance: 79...
	 start solving instance: 9...
	 start solving instance: 148...
	 start solving instance: 86...
	 start solving instance: 112...
	 start solving instance: 73...
	 start solving instance: 67...
	 start solving instance: 146...
	 start solving instance: 99...
	 start solving instance: 65...
	 start solving instance: 90...
	 start solving instance: 42...
	 start solving instance: 144...
	 start solving instance: 54...
	 start solving instance: 14...
	 start solving instance: 137...
	 start solving instance: 92...
	 start solving instance: 93...
	 start solving instance: 27...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.772726540694769e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060523008.0
		 entropy bonus: 0.20874814689159393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5724595712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6496618496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7727264857191875e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.772726540694769e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060523008.0
		 entropy bonus: 0.20874814689159393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5724595712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6496618496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7727264857191875e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.772726540694769e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060523008.0
		 entropy bonus: 0.20874814689159393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5724595712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6496618496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7727264857191875e+18 - Differentiable computation graph = True!
PPO iteration: 276/1000:
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 137...
	 start solving instance: 144...
	 start solving instance: 73...
	 start solving instance: 86...
	 start solving instance: 93...
	 start solving instance: 90...
	 start solving instance: 107...
	 start solving instance: 27...
	 start solving instance: 148...
	 start solving instance: 99...
	 start solving instance: 112...
	 start solving instance: 9...
	 start solving instance: 67...
	 start solving instance: 146...
	 start solving instance: 79...
	 start solving instance: 14...
	 start solving instance: 65...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.742801792428566e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959953920.0
		 entropy bonus: 0.2082062065601349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5790408704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5919939072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.742801902379729e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.742801792428566e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959953920.0
		 entropy bonus: 0.2082062065601349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5790408704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5919939072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.742801902379729e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.742801792428566e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959953920.0
		 entropy bonus: 0.2082062065601349
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5790408704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5919939072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.742801902379729e+18 - Differentiable computation graph = True!
PPO iteration: 277/1000:
	 start solving instance: 79...
	 start solving instance: 137...
	 start solving instance: 93...
	 start solving instance: 112...
	 start solving instance: 86...
	 start solving instance: 99...
	 start solving instance: 107...
	 start solving instance: 73...
	 start solving instance: 144...
	 start solving instance: 9...
	 start solving instance: 54...
	 start solving instance: 67...
	 start solving instance: 42...
	 start solving instance: 65...
	 start solving instance: 14...
	 start solving instance: 90...
	 start solving instance: 146...
	 start solving instance: 148...
	 start solving instance: 27...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.921349726444506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031417344.0
		 entropy bonus: 0.21468840539455414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5989232128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6291632640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.921349671468925e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.921349726444506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031417344.0
		 entropy bonus: 0.21468840539455414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5989232128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6291632640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.921349671468925e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.921349726444506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031417344.0
		 entropy bonus: 0.21468840539455414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5989232128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6291632640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.921349671468925e+18 - Differentiable computation graph = True!
PPO iteration: 278/1000:
	 start solving instance: 144...
	 start solving instance: 93...
	 start solving instance: 112...
	 start solving instance: 67...
	 start solving instance: 86...
	 start solving instance: 73...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 14...
	 start solving instance: 9...
	 start solving instance: 27...
	 start solving instance: 92...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 146...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 79...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.773011534108688e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048640512.0
		 entropy bonus: 0.2020036280155182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5826049536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6292166656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7730115341086884e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.773011534108688e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048640512.0
		 entropy bonus: 0.2020036280155182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5826049536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6292166656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7730115341086884e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.773011534108688e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048640512.0
		 entropy bonus: 0.2020036280155182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5826049536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6292166656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7730115341086884e+18 - Differentiable computation graph = True!
PPO iteration: 279/1000:
	 start solving instance: 99...
	 start solving instance: 93...
	 start solving instance: 90...
	 start solving instance: 86...
	 start solving instance: 79...
	 start solving instance: 137...
	 start solving instance: 9...
	 start solving instance: 54...
	 start solving instance: 14...
	 start solving instance: 92...
	 start solving instance: 144...
	 start solving instance: 107...
	 start solving instance: 73...
	 start solving instance: 27...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 65...
	 start solving instance: 67...
	 start solving instance: 42...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.019632871828147e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6052495360.0
		 entropy bonus: 0.20178022980690002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6095808512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6729908736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.019632816852566e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.019632871828147e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6052495360.0
		 entropy bonus: 0.20178022980690002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6095808512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6729908736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.019632816852566e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.019632871828147e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6052495360.0
		 entropy bonus: 0.20178022980690002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6095808512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6729908736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.019632816852566e+18 - Differentiable computation graph = True!
PPO iteration: 280/1000:
	 start solving instance: 86...
	 start solving instance: 90...
	 start solving instance: 144...
	 start solving instance: 137...
	 start solving instance: 112...
	 start solving instance: 79...
	 start solving instance: 99...
	 start solving instance: 14...
	 start solving instance: 54...
	 start solving instance: 93...
	 start solving instance: 146...
	 start solving instance: 148...
	 start solving instance: 107...
	 start solving instance: 9...
	 start solving instance: 65...
	 start solving instance: 67...
	 start solving instance: 92...
	 start solving instance: 42...
	 start solving instance: 27...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0174624358749176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099369984.0
		 entropy bonus: 0.21342508494853973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6078630400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6417819648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.017462380899336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0174624358749176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099369984.0
		 entropy bonus: 0.21342508494853973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6078630400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6417819648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.017462380899336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0174624358749176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099369984.0
		 entropy bonus: 0.21342508494853973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6078630400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6417819648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.017462380899336e+18 - Differentiable computation graph = True!
PPO iteration: 281/1000:
	 New training batch of size 20...
	 start solving instance: 64...
	 start solving instance: 124...
	 start solving instance: 27...
	 start solving instance: 43...
	 start solving instance: 46...
	 start solving instance: 26...
	 start solving instance: 145...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 38...
	 start solving instance: 25...
	 start solving instance: 32...
	 start solving instance: 61...
	 start solving instance: 59...
	 start solving instance: 69...
	 start solving instance: 100...
	 start solving instance: 89...
	 start solving instance: 13...
	 start solving instance: 126...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.522164221498517e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6211929088.0
		 entropy bonus: 0.2272280752658844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6508987904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7188195328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.52216433144968e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.522164221498517e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6211929088.0
		 entropy bonus: 0.2272280752658844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6508987904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7188195328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.52216433144968e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.522164221498517e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6211929088.0
		 entropy bonus: 0.2272280752658844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6508987904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7188195328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.52216433144968e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9282514728325743e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5258542592.0
		 entropy bonus: 0.1983669251203537
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5067554304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5867355648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2928251527808155648.0000
PPO iteration: 282/1000:
	 start solving instance: 43...
	 start solving instance: 25...
	 start solving instance: 89...
	 start solving instance: 13...
	 start solving instance: 38...
	 start solving instance: 126...
	 start solving instance: 1...
	 start solving instance: 27...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 46...
	 start solving instance: 59...
	 start solving instance: 124...
	 start solving instance: 26...
	 start solving instance: 32...
	 start solving instance: 66...
	 start solving instance: 61...
	 start solving instance: 64...
	 start solving instance: 100...
	 start solving instance: 69...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.346835217724054e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6068996608.0
		 entropy bonus: 0.2317243069410324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6261575168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7143866368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346835382650798e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.346835217724054e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6068996608.0
		 entropy bonus: 0.2317243069410324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6261575168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7143866368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346835382650798e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.346835217724054e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6068996608.0
		 entropy bonus: 0.2317243069410324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6261575168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7143866368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346835382650798e+18 - Differentiable computation graph = True!
PPO iteration: 283/1000:
	 start solving instance: 59...
	 start solving instance: 69...
	 start solving instance: 89...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 43...
	 start solving instance: 46...
	 start solving instance: 27...
	 start solving instance: 126...
	 start solving instance: 61...
	 start solving instance: 124...
	 start solving instance: 100...
	 start solving instance: 38...
	 start solving instance: 13...
	 start solving instance: 66...
	 start solving instance: 145...
	 start solving instance: 26...
	 start solving instance: 64...
	 start solving instance: 32...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.241386774964522e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6196054528.0
		 entropy bonus: 0.2141316682100296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6204155392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7054416384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.241386719988941e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.241386774964522e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6196054528.0
		 entropy bonus: 0.2141316682100296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6204155392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7054416384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.241386719988941e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.241386774964522e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6196054528.0
		 entropy bonus: 0.2141316682100296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6204155392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7054416384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.241386719988941e+18 - Differentiable computation graph = True!
PPO iteration: 284/1000:
	 start solving instance: 89...
	 start solving instance: 1...
	 start solving instance: 26...
	 start solving instance: 124...
	 start solving instance: 61...
	 start solving instance: 66...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 38...
	 start solving instance: 59...
	 start solving instance: 27...
	 start solving instance: 64...
	 start solving instance: 69...
	 start solving instance: 25...
	 start solving instance: 43...
	 start solving instance: 100...
	 start solving instance: 13...
	 start solving instance: 46...
	 start solving instance: 126...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.166793707112943e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212413440.0
		 entropy bonus: 0.22463420033454895
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6148618240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6739351552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1667936521373614e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.166793707112943e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212413440.0
		 entropy bonus: 0.22463420033454895
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6148618240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6739351552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1667936521373614e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.166793707112943e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6212413440.0
		 entropy bonus: 0.22463420033454895
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6148618240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6739351552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1667936521373614e+18 - Differentiable computation graph = True!
PPO iteration: 285/1000:
	 start solving instance: 61...
	 start solving instance: 64...
	 start solving instance: 145...
	 start solving instance: 32...
	 start solving instance: 25...
	 start solving instance: 46...
	 start solving instance: 124...
	 start solving instance: 43...
	 start solving instance: 89...
	 start solving instance: 13...
	 start solving instance: 130...
	 start solving instance: 1...
	 start solving instance: 69...
	 start solving instance: 26...
	 start solving instance: 59...
	 start solving instance: 126...
	 start solving instance: 27...
	 start solving instance: 66...
	 start solving instance: 100...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.480131651187245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6098999296.0
		 entropy bonus: 0.23053018748760223
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6464920576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395527168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480131651187245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.480131651187245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6098999296.0
		 entropy bonus: 0.23053018748760223
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6464920576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395527168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480131651187245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.480131651187245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6098999296.0
		 entropy bonus: 0.23053018748760223
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6464920576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395527168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.480131651187245e+18 - Differentiable computation graph = True!
PPO iteration: 286/1000:
	 start solving instance: 69...
	 start solving instance: 100...
	 start solving instance: 25...
	 start solving instance: 89...
	 start solving instance: 61...
	 start solving instance: 38...
	 start solving instance: 130...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 126...
	 start solving instance: 59...
	 start solving instance: 13...
	 start solving instance: 145...
	 start solving instance: 27...
	 start solving instance: 1...
	 start solving instance: 124...
	 start solving instance: 32...
	 start solving instance: 66...
	 start solving instance: 64...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.852144373570837e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6229565440.0
		 entropy bonus: 0.23374556005001068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6765146112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7556632576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.852144263619674e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.852144373570837e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6229565440.0
		 entropy bonus: 0.23374556005001068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6765146112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7556632576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.852144263619674e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.852144373570837e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6229565440.0
		 entropy bonus: 0.23374556005001068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6765146112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7556632576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.852144263619674e+18 - Differentiable computation graph = True!
PPO iteration: 287/1000:
	 start solving instance: 69...
	 start solving instance: 66...
	 start solving instance: 26...
	 start solving instance: 32...
	 start solving instance: 59...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 124...
	 start solving instance: 126...
	 start solving instance: 100...
	 start solving instance: 145...
	 start solving instance: 25...
	 start solving instance: 46...
	 start solving instance: 38...
	 start solving instance: 43...
	 start solving instance: 61...
	 start solving instance: 13...
	 start solving instance: 27...
	 start solving instance: 89...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.642309176479554e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6085061632.0
		 entropy bonus: 0.24054966866970062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6565645824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7510203392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.642309066528391e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.642309176479554e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6085061632.0
		 entropy bonus: 0.24054966866970062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6565645824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7510203392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.642309066528391e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.642309176479554e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6085061632.0
		 entropy bonus: 0.24054966866970062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6565645824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7510203392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.642309066528391e+18 - Differentiable computation graph = True!
PPO iteration: 288/1000:
	 start solving instance: 46...
	 start solving instance: 100...
	 start solving instance: 126...
	 start solving instance: 38...
	 start solving instance: 32...
	 start solving instance: 130...
	 start solving instance: 61...
	 start solving instance: 64...
	 start solving instance: 69...
	 start solving instance: 43...
	 start solving instance: 13...
	 start solving instance: 124...
	 start solving instance: 145...
	 start solving instance: 66...
	 start solving instance: 59...
	 start solving instance: 1...
	 start solving instance: 26...
	 start solving instance: 27...
	 start solving instance: 89...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.418892371957331e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6075987456.0
		 entropy bonus: 0.2326975166797638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6332931584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7245041152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.418892426932912e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.418892371957331e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6075987456.0
		 entropy bonus: 0.2326975166797638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6332931584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7245041152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.418892426932912e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.418892371957331e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6075987456.0
		 entropy bonus: 0.2326975166797638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6332931584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7245041152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.418892426932912e+18 - Differentiable computation graph = True!
PPO iteration: 289/1000:
	 start solving instance: 38...
	 start solving instance: 46...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 43...
	 start solving instance: 66...
	 start solving instance: 27...
	 start solving instance: 59...
	 start solving instance: 32...
	 start solving instance: 100...
	 start solving instance: 26...
	 start solving instance: 69...
	 start solving instance: 64...
	 start solving instance: 1...
	 start solving instance: 89...
	 start solving instance: 13...
	 start solving instance: 126...
	 start solving instance: 124...
	 start solving instance: 61...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.551814971467078e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6208595968.0
		 entropy bonus: 0.22601218521595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6498576384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7189963264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.551815136393822e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.551814971467078e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6208595968.0
		 entropy bonus: 0.22601218521595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6498576384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7189963264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.551815136393822e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.551814971467078e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6208595968.0
		 entropy bonus: 0.22601218521595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6498576384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7189963264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.551815136393822e+18 - Differentiable computation graph = True!
PPO iteration: 290/1000:
	 start solving instance: 38...
	 start solving instance: 89...
	 start solving instance: 25...
	 start solving instance: 61...
	 start solving instance: 26...
	 start solving instance: 43...
	 start solving instance: 27...
	 start solving instance: 13...
	 start solving instance: 145...
	 start solving instance: 100...
	 start solving instance: 124...
	 start solving instance: 69...
	 start solving instance: 59...
	 start solving instance: 66...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 126...
	 start solving instance: 32...
	 start solving instance: 64...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.675901015926715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6272794624.0
		 entropy bonus: 0.22174707055091858
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6640094208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7341920256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.675901345780204e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.675901015926715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6272794624.0
		 entropy bonus: 0.22174707055091858
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6640094208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7341920256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.675901345780204e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.675901015926715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6272794624.0
		 entropy bonus: 0.22174707055091858
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6640094208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7341920256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.675901345780204e+18 - Differentiable computation graph = True!
PPO iteration: 291/1000:
	 New training batch of size 20...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 10...
	 start solving instance: 34...
	 start solving instance: 129...
	 start solving instance: 50...
	 start solving instance: 43...
	 start solving instance: 13...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 61...
	 start solving instance: 89...
	 start solving instance: 136...
	 start solving instance: 73...
	 start solving instance: 143...
	 start solving instance: 99...
	 start solving instance: 12...
	 start solving instance: 96...
	 start solving instance: 83...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.242588321271356e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6224522240.0
		 entropy bonus: 0.2127474844455719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6187673088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7402915328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2425884861981e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.242588321271356e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6224522240.0
		 entropy bonus: 0.2127474844455719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6187673088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7402915328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2425884861981e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.242588321271356e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6224522240.0
		 entropy bonus: 0.2127474844455719
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6187673088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7402915328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2425884861981e+18 - Differentiable computation graph = True!
PPO iteration: 292/1000:
	 start solving instance: 144...
	 start solving instance: 32...
	 start solving instance: 12...
	 start solving instance: 96...
	 start solving instance: 136...
	 start solving instance: 50...
	 start solving instance: 26...
	 start solving instance: 10...
	 start solving instance: 61...
	 start solving instance: 18...
	 start solving instance: 43...
	 start solving instance: 99...
	 start solving instance: 73...
	 start solving instance: 83...
	 start solving instance: 131...
	 start solving instance: 129...
	 start solving instance: 34...
	 start solving instance: 143...
	 start solving instance: 13...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9194462519145005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6089266688.0
		 entropy bonus: 0.2135024517774582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5833267712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7048294912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9194464168412447e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9194462519145005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6089266688.0
		 entropy bonus: 0.2135024517774582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5833267712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7048294912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9194464168412447e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9194462519145005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6089266688.0
		 entropy bonus: 0.2135024517774582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5833267712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7048294912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9194464168412447e+18 - Differentiable computation graph = True!
PPO iteration: 293/1000:
	 start solving instance: 18...
	 start solving instance: 99...
	 start solving instance: 131...
	 start solving instance: 10...
	 start solving instance: 50...
	 start solving instance: 143...
	 start solving instance: 73...
	 start solving instance: 61...
	 start solving instance: 89...
	 start solving instance: 144...
	 start solving instance: 43...
	 start solving instance: 96...
	 start solving instance: 13...
	 start solving instance: 12...
	 start solving instance: 136...
	 start solving instance: 34...
	 start solving instance: 129...
	 start solving instance: 83...
	 start solving instance: 26...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2994233967250506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6145488384.0
		 entropy bonus: 0.2211025506258011
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161579520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7298444800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.299423341749469e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2994233967250506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6145488384.0
		 entropy bonus: 0.2211025506258011
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161579520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7298444800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.299423341749469e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2994233967250506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6145488384.0
		 entropy bonus: 0.2211025506258011
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161579520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7298444800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.299423341749469e+18 - Differentiable computation graph = True!
PPO iteration: 294/1000:
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 12...
	 start solving instance: 136...
	 start solving instance: 61...
	 start solving instance: 129...
	 start solving instance: 73...
	 start solving instance: 83...
	 start solving instance: 10...
	 start solving instance: 143...
	 start solving instance: 96...
	 start solving instance: 32...
	 start solving instance: 89...
	 start solving instance: 99...
	 start solving instance: 131...
	 start solving instance: 34...
	 start solving instance: 50...
	 start solving instance: 13...
	 start solving instance: 43...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.256019075706965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106230784.0
		 entropy bonus: 0.22379861772060394
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6089250816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7363652096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.256019020731384e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.256019075706965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106230784.0
		 entropy bonus: 0.22379861772060394
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6089250816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7363652096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.256019020731384e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.256019075706965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106230784.0
		 entropy bonus: 0.22379861772060394
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6089250816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7363652096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.256019020731384e+18 - Differentiable computation graph = True!
PPO iteration: 295/1000:
	 start solving instance: 26...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 96...
	 start solving instance: 73...
	 start solving instance: 129...
	 start solving instance: 143...
	 start solving instance: 43...
	 start solving instance: 61...
	 start solving instance: 50...
	 start solving instance: 34...
	 start solving instance: 12...
	 start solving instance: 144...
	 start solving instance: 13...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 10...
	 start solving instance: 136...
	 start solving instance: 83...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0275247264876724e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6095087104.0
		 entropy bonus: 0.2065640538930893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5946078720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6783144448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.027524836438835e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0275247264876724e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6095087104.0
		 entropy bonus: 0.2065640538930893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5946078720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6783144448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.027524836438835e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0275247264876724e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6095087104.0
		 entropy bonus: 0.2065640538930893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5946078720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6783144448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.027524836438835e+18 - Differentiable computation graph = True!
PPO iteration: 296/1000:
	 start solving instance: 89...
	 start solving instance: 96...
	 start solving instance: 136...
	 start solving instance: 99...
	 start solving instance: 10...
	 start solving instance: 34...
	 start solving instance: 18...
	 start solving instance: 73...
	 start solving instance: 50...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 61...
	 start solving instance: 26...
	 start solving instance: 131...
	 start solving instance: 143...
	 start solving instance: 13...
	 start solving instance: 32...
	 start solving instance: 144...
	 start solving instance: 83...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.423092506375435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6151764480.0
		 entropy bonus: 0.21067817509174347
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6322451456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7508193792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4230925613510164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.423092506375435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6151764480.0
		 entropy bonus: 0.21067817509174347
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6322451456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7508193792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4230925613510164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.423092506375435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6151764480.0
		 entropy bonus: 0.21067817509174347
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6322451456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7508193792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4230925613510164e+18 - Differentiable computation graph = True!
PPO iteration: 297/1000:
	 start solving instance: 26...
	 start solving instance: 73...
	 start solving instance: 61...
	 start solving instance: 129...
	 start solving instance: 83...
	 start solving instance: 131...
	 start solving instance: 10...
	 start solving instance: 136...
	 start solving instance: 144...
	 start solving instance: 43...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 89...
	 start solving instance: 99...
	 start solving instance: 143...
	 start solving instance: 96...
	 start solving instance: 18...
	 start solving instance: 32...
	 start solving instance: 50...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.185912455101363e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6164514304.0
		 entropy bonus: 0.20602436363697052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6137490432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7072119296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1859125100769444e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.185912455101363e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6164514304.0
		 entropy bonus: 0.20602436363697052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6137490432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7072119296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1859125100769444e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.185912455101363e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6164514304.0
		 entropy bonus: 0.20602436363697052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6137490432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7072119296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1859125100769444e+18 - Differentiable computation graph = True!
PPO iteration: 298/1000:
	 start solving instance: 32...
	 start solving instance: 13...
	 start solving instance: 18...
	 start solving instance: 73...
	 start solving instance: 43...
	 start solving instance: 89...
	 start solving instance: 129...
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 143...
	 start solving instance: 34...
	 start solving instance: 50...
	 start solving instance: 83...
	 start solving instance: 99...
	 start solving instance: 12...
	 start solving instance: 136...
	 start solving instance: 61...
	 start solving instance: 96...
	 start solving instance: 10...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.330294164795792e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6171197952.0
		 entropy bonus: 0.20924797654151917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6255455232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7166407680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.330294329722536e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.330294164795792e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6171197952.0
		 entropy bonus: 0.20924797654151917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6255455232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7166407680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.330294329722536e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.330294164795792e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6171197952.0
		 entropy bonus: 0.20924797654151917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6255455232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7166407680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.330294329722536e+18 - Differentiable computation graph = True!
PPO iteration: 299/1000:
	 start solving instance: 61...
	 start solving instance: 99...
	 start solving instance: 32...
	 start solving instance: 18...
	 start solving instance: 43...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 73...
	 start solving instance: 10...
	 start solving instance: 89...
	 start solving instance: 50...
	 start solving instance: 83...
	 start solving instance: 144...
	 start solving instance: 12...
	 start solving instance: 96...
	 start solving instance: 26...
	 start solving instance: 143...
	 start solving instance: 136...
	 start solving instance: 129...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2254530922594435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6170443264.0
		 entropy bonus: 0.20780491828918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6143568896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7053114368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.225453147235025e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2254530922594435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6170443264.0
		 entropy bonus: 0.20780491828918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6143568896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7053114368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.225453147235025e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2254530922594435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6170443264.0
		 entropy bonus: 0.20780491828918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6143568896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7053114368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.225453147235025e+18 - Differentiable computation graph = True!
PPO iteration: 300/1000:
	 start solving instance: 34...
	 start solving instance: 136...
	 start solving instance: 13...
	 start solving instance: 131...
	 start solving instance: 96...
	 start solving instance: 32...
	 start solving instance: 10...
	 start solving instance: 26...
	 start solving instance: 143...
	 start solving instance: 73...
	 start solving instance: 18...
	 start solving instance: 43...
	 start solving instance: 129...
	 start solving instance: 50...
	 start solving instance: 83...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 12...
	 start solving instance: 61...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.352066694049012e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6223181824.0
		 entropy bonus: 0.21622686088085175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6215689216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7126547456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3520668589757563e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.352066694049012e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6223181824.0
		 entropy bonus: 0.21622686088085175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6215689216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7126547456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3520668589757563e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.352066694049012e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6223181824.0
		 entropy bonus: 0.21622686088085175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6215689216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7126547456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3520668589757563e+18 - Differentiable computation graph = True!
PPO iteration: 301/1000:
	 New training batch of size 20...
	 start solving instance: 55...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 101...
	 start solving instance: 39...
	 start solving instance: 13...
	 start solving instance: 64...
	 start solving instance: 78...
	 start solving instance: 31...
	 start solving instance: 46...
	 start solving instance: 83...
	 start solving instance: 63...
	 start solving instance: 38...
	 start solving instance: 30...
	 start solving instance: 131...
	 start solving instance: 98...
	 start solving instance: 50...
	 start solving instance: 143...
	 start solving instance: 144...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9622594754814935e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5932358656.0
		 entropy bonus: 0.19889716804027557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5773087744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687470080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9622594754814935e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9622594754814935e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5932358656.0
		 entropy bonus: 0.19889716804027557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5773087744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687470080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9622594754814935e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9622594754814935e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5932358656.0
		 entropy bonus: 0.19889716804027557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5773087744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687470080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9622594754814935e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9594307638660694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5233586176.0
		 entropy bonus: 0.2027403861284256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5080427008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6044223488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2959430928792813568.0000
PPO iteration: 302/1000:
	 start solving instance: 50...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 13...
	 start solving instance: 83...
	 start solving instance: 35...
	 start solving instance: 131...
	 start solving instance: 30...
	 start solving instance: 78...
	 start solving instance: 39...
	 start solving instance: 55...
	 start solving instance: 101...
	 start solving instance: 31...
	 start solving instance: 63...
	 start solving instance: 46...
	 start solving instance: 98...
	 start solving instance: 64...
	 start solving instance: 38...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.040062677481528e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998351872.0
		 entropy bonus: 0.19803887605667114
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5837484544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6740948480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.040062842408272e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.040062677481528e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998351872.0
		 entropy bonus: 0.19803887605667114
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5837484544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6740948480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.040062842408272e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.040062677481528e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998351872.0
		 entropy bonus: 0.19803887605667114
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5837484544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6740948480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.040062842408272e+18 - Differentiable computation graph = True!
PPO iteration: 303/1000:
	 start solving instance: 31...
	 start solving instance: 46...
	 start solving instance: 101...
	 start solving instance: 13...
	 start solving instance: 78...
	 start solving instance: 97...
	 start solving instance: 38...
	 start solving instance: 55...
	 start solving instance: 63...
	 start solving instance: 62...
	 start solving instance: 64...
	 start solving instance: 30...
	 start solving instance: 50...
	 start solving instance: 98...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 144...
	 start solving instance: 35...
	 start solving instance: 39...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.964546899471919e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886648320.0
		 entropy bonus: 0.19498606026172638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810676224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7171778560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9645470094230815e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.964546899471919e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886648320.0
		 entropy bonus: 0.19498606026172638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810676224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7171778560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9645470094230815e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.964546899471919e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886648320.0
		 entropy bonus: 0.19498606026172638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810676224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7171778560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9645470094230815e+18 - Differentiable computation graph = True!
PPO iteration: 304/1000:
	 start solving instance: 63...
	 start solving instance: 83...
	 start solving instance: 55...
	 start solving instance: 64...
	 start solving instance: 35...
	 start solving instance: 97...
	 start solving instance: 13...
	 start solving instance: 38...
	 start solving instance: 31...
	 start solving instance: 78...
	 start solving instance: 39...
	 start solving instance: 30...
	 start solving instance: 143...
	 start solving instance: 131...
	 start solving instance: 98...
	 start solving instance: 46...
	 start solving instance: 144...
	 start solving instance: 101...
	 start solving instance: 50...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.873196394803731e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5872812544.0
		 entropy bonus: 0.2026687115430832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5703560704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840402944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.873196559730475e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.873196394803731e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5872812544.0
		 entropy bonus: 0.2026687115430832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5703560704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840402944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.873196559730475e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.873196394803731e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5872812544.0
		 entropy bonus: 0.2026687115430832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5703560704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840402944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.873196559730475e+18 - Differentiable computation graph = True!
PPO iteration: 305/1000:
	 start solving instance: 46...
	 start solving instance: 101...
	 start solving instance: 83...
	 start solving instance: 62...
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 78...
	 start solving instance: 144...
	 start solving instance: 98...
	 start solving instance: 31...
	 start solving instance: 50...
	 start solving instance: 64...
	 start solving instance: 55...
	 start solving instance: 39...
	 start solving instance: 38...
	 start solving instance: 35...
	 start solving instance: 13...
	 start solving instance: 143...
	 start solving instance: 131...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9009894099260015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5917125120.0
		 entropy bonus: 0.1951657086610794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5752811520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6900007424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.900989464901583e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9009894099260015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5917125120.0
		 entropy bonus: 0.1951657086610794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5752811520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6900007424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.900989464901583e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9009894099260015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5917125120.0
		 entropy bonus: 0.1951657086610794
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5752811520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6900007424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.900989464901583e+18 - Differentiable computation graph = True!
PPO iteration: 306/1000:
	 start solving instance: 78...
	 start solving instance: 46...
	 start solving instance: 39...
	 start solving instance: 97...
	 start solving instance: 83...
	 start solving instance: 55...
	 start solving instance: 50...
	 start solving instance: 13...
	 start solving instance: 35...
	 start solving instance: 64...
	 start solving instance: 143...
	 start solving instance: 101...
	 start solving instance: 63...
	 start solving instance: 144...
	 start solving instance: 131...
	 start solving instance: 38...
	 start solving instance: 31...
	 start solving instance: 98...
	 start solving instance: 62...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.985943835553091e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5994385920.0
		 entropy bonus: 0.19598530232906342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5814289920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7143887872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9859437805775094e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.985943835553091e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5994385920.0
		 entropy bonus: 0.19598530232906342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5814289920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7143887872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9859437805775094e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.985943835553091e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5994385920.0
		 entropy bonus: 0.19598530232906342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5814289920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7143887872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9859437805775094e+18 - Differentiable computation graph = True!
PPO iteration: 307/1000:
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 31...
	 start solving instance: 55...
	 start solving instance: 97...
	 start solving instance: 35...
	 start solving instance: 78...
	 start solving instance: 38...
	 start solving instance: 46...
	 start solving instance: 144...
	 start solving instance: 30...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 39...
	 start solving instance: 50...
	 start solving instance: 64...
	 start solving instance: 13...
	 start solving instance: 83...
	 start solving instance: 101...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.078164713625826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5923653120.0
		 entropy bonus: 0.18907558917999268
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5845197824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6694653440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0781647686014075e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.078164713625826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5923653120.0
		 entropy bonus: 0.18907558917999268
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5845197824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6694653440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0781647686014075e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.078164713625826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5923653120.0
		 entropy bonus: 0.18907558917999268
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5845197824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6694653440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0781647686014075e+18 - Differentiable computation graph = True!
PPO iteration: 308/1000:
	 start solving instance: 13...
	 start solving instance: 46...
	 start solving instance: 35...
	 start solving instance: 131...
	 start solving instance: 64...
	 start solving instance: 98...
	 start solving instance: 39...
	 start solving instance: 55...
	 start solving instance: 63...
	 start solving instance: 62...
	 start solving instance: 101...
	 start solving instance: 38...
	 start solving instance: 31...
	 start solving instance: 83...
	 start solving instance: 50...
	 start solving instance: 97...
	 start solving instance: 144...
	 start solving instance: 30...
	 start solving instance: 143...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.108266703166426e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021699072.0
		 entropy bonus: 0.18500222265720367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5947524608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926281216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.108266648190845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.108266703166426e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021699072.0
		 entropy bonus: 0.18500222265720367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5947524608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926281216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.108266648190845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.108266703166426e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021699072.0
		 entropy bonus: 0.18500222265720367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5947524608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926281216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.108266648190845e+18 - Differentiable computation graph = True!
PPO iteration: 309/1000:
	 start solving instance: 62...
	 start solving instance: 131...
	 start solving instance: 83...
	 start solving instance: 13...
	 start solving instance: 63...
	 start solving instance: 46...
	 start solving instance: 78...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 144...
	 start solving instance: 64...
	 start solving instance: 101...
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 35...
	 start solving instance: 98...
	 start solving instance: 55...
	 start solving instance: 39...
	 start solving instance: 143...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.149062102994125e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5995480576.0
		 entropy bonus: 0.18660111725330353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004214272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7070736384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.149062102994125e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.149062102994125e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5995480576.0
		 entropy bonus: 0.18660111725330353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004214272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7070736384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.149062102994125e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.149062102994125e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5995480576.0
		 entropy bonus: 0.18660111725330353
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004214272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7070736384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.149062102994125e+18 - Differentiable computation graph = True!
PPO iteration: 310/1000:
	 start solving instance: 131...
	 start solving instance: 46...
	 start solving instance: 98...
	 start solving instance: 83...
	 start solving instance: 64...
	 start solving instance: 35...
	 start solving instance: 55...
	 start solving instance: 50...
	 start solving instance: 13...
	 start solving instance: 78...
	 start solving instance: 38...
	 start solving instance: 62...
	 start solving instance: 31...
	 start solving instance: 30...
	 start solving instance: 144...
	 start solving instance: 97...
	 start solving instance: 63...
	 start solving instance: 143...
	 start solving instance: 101...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.996983811905264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5914705408.0
		 entropy bonus: 0.19650384783744812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920996352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696350208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.996983976832008e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.996983811905264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5914705408.0
		 entropy bonus: 0.19650384783744812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920996352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696350208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.996983976832008e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.996983811905264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5914705408.0
		 entropy bonus: 0.19650384783744812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920996352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696350208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.996983976832008e+18 - Differentiable computation graph = True!
PPO iteration: 311/1000:
	 New training batch of size 20...
	 start solving instance: 34...
	 start solving instance: 87...
	 start solving instance: 125...
	 start solving instance: 13...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 86...
	 start solving instance: 69...
	 start solving instance: 100...
	 start solving instance: 78...
	 start solving instance: 14...
	 start solving instance: 135...
	 start solving instance: 108...
	 start solving instance: 65...
	 start solving instance: 46...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 89...
	 start solving instance: 28...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.627134156797641e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6253381120.0
		 entropy bonus: 0.19669635593891144
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6490301440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7710118400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.627134156797641e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.627134156797641e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6253381120.0
		 entropy bonus: 0.19669635593891144
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6490301440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7710118400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.627134156797641e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.627134156797641e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6253381120.0
		 entropy bonus: 0.19669635593891144
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6490301440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7710118400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.627134156797641e+18 - Differentiable computation graph = True!
PPO iteration: 312/1000:
	 start solving instance: 69...
	 start solving instance: 100...
	 start solving instance: 98...
	 start solving instance: 112...
	 start solving instance: 89...
	 start solving instance: 125...
	 start solving instance: 14...
	 start solving instance: 135...
	 start solving instance: 46...
	 start solving instance: 87...
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 108...
	 start solving instance: 85...
	 start solving instance: 28...
	 start solving instance: 34...
	 start solving instance: 86...
	 start solving instance: 13...
	 start solving instance: 128...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.775365036798588e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288276480.0
		 entropy bonus: 0.2017631083726883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6619047424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7646134272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.775365366652076e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.775365036798588e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288276480.0
		 entropy bonus: 0.2017631083726883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6619047424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7646134272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.775365366652076e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.775365036798588e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288276480.0
		 entropy bonus: 0.2017631083726883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6619047424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7646134272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.775365366652076e+18 - Differentiable computation graph = True!
PPO iteration: 313/1000:
	 start solving instance: 78...
	 start solving instance: 89...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 86...
	 start solving instance: 69...
	 start solving instance: 100...
	 start solving instance: 112...
	 start solving instance: 135...
	 start solving instance: 13...
	 start solving instance: 87...
	 start solving instance: 98...
	 start solving instance: 14...
	 start solving instance: 128...
	 start solving instance: 125...
	 start solving instance: 65...
	 start solving instance: 34...
	 start solving instance: 39...
	 start solving instance: 28...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.724293601297695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244338176.0
		 entropy bonus: 0.20479123294353485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6553310720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7715622912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.724293601297695e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.724293601297695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244338176.0
		 entropy bonus: 0.20479123294353485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6553310720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7715622912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.724293601297695e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.724293601297695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244338176.0
		 entropy bonus: 0.20479123294353485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6553310720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7715622912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.724293601297695e+18 - Differentiable computation graph = True!
PPO iteration: 314/1000:
	 start solving instance: 128...
	 start solving instance: 78...
	 start solving instance: 112...
	 start solving instance: 28...
	 start solving instance: 34...
	 start solving instance: 39...
	 start solving instance: 69...
	 start solving instance: 98...
	 start solving instance: 108...
	 start solving instance: 87...
	 start solving instance: 46...
	 start solving instance: 100...
	 start solving instance: 14...
	 start solving instance: 86...
	 start solving instance: 13...
	 start solving instance: 125...
	 start solving instance: 135...
	 start solving instance: 89...
	 start solving instance: 85...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.455895336278504e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231012864.0
		 entropy bonus: 0.21078519523143768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6409678336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7187822592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4558953912540856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.455895336278504e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231012864.0
		 entropy bonus: 0.21078519523143768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6409678336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7187822592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4558953912540856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.455895336278504e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231012864.0
		 entropy bonus: 0.21078519523143768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6409678336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7187822592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4558953912540856e+18 - Differentiable computation graph = True!
PPO iteration: 315/1000:
	 start solving instance: 14...
	 start solving instance: 86...
	 start solving instance: 85...
	 start solving instance: 87...
	 start solving instance: 46...
	 start solving instance: 98...
	 start solving instance: 112...
	 start solving instance: 28...
	 start solving instance: 135...
	 start solving instance: 78...
	 start solving instance: 89...
	 start solving instance: 39...
	 start solving instance: 69...
	 start solving instance: 65...
	 start solving instance: 125...
	 start solving instance: 34...
	 start solving instance: 13...
	 start solving instance: 128...
	 start solving instance: 100...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.726145618683521e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6299689984.0
		 entropy bonus: 0.20038624107837677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6552104448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395317248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.726145728634683e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.726145618683521e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6299689984.0
		 entropy bonus: 0.20038624107837677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6552104448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395317248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.726145728634683e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.726145618683521e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6299689984.0
		 entropy bonus: 0.20038624107837677
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6552104448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395317248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.726145728634683e+18 - Differentiable computation graph = True!
PPO iteration: 316/1000:
	 start solving instance: 108...
	 start solving instance: 100...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 34...
	 start solving instance: 78...
	 start solving instance: 14...
	 start solving instance: 135...
	 start solving instance: 125...
	 start solving instance: 39...
	 start solving instance: 87...
	 start solving instance: 69...
	 start solving instance: 86...
	 start solving instance: 89...
	 start solving instance: 65...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 28...
	 start solving instance: 13...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.461638305412704e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6227052544.0
		 entropy bonus: 0.2109251469373703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6420886528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7316465152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4616384153638666e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.461638305412704e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6227052544.0
		 entropy bonus: 0.2109251469373703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6420886528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7316465152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4616384153638666e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.461638305412704e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6227052544.0
		 entropy bonus: 0.2109251469373703
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6420886528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7316465152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4616384153638666e+18 - Differentiable computation graph = True!
PPO iteration: 317/1000:
	 start solving instance: 89...
	 start solving instance: 100...
	 start solving instance: 98...
	 start solving instance: 108...
	 start solving instance: 125...
	 start solving instance: 34...
	 start solving instance: 13...
	 start solving instance: 87...
	 start solving instance: 28...
	 start solving instance: 128...
	 start solving instance: 85...
	 start solving instance: 135...
	 start solving instance: 65...
	 start solving instance: 69...
	 start solving instance: 86...
	 start solving instance: 39...
	 start solving instance: 112...
	 start solving instance: 46...
	 start solving instance: 78...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.552917561727412e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6278148608.0
		 entropy bonus: 0.2098519653081894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6565769216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7637234688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5529176716785746e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.552917561727412e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6278148608.0
		 entropy bonus: 0.2098519653081894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6565769216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7637234688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5529176716785746e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.552917561727412e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6278148608.0
		 entropy bonus: 0.2098519653081894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6565769216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7637234688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5529176716785746e+18 - Differentiable computation graph = True!
PPO iteration: 318/1000:
	 start solving instance: 13...
	 start solving instance: 14...
	 start solving instance: 100...
	 start solving instance: 78...
	 start solving instance: 46...
	 start solving instance: 65...
	 start solving instance: 87...
	 start solving instance: 39...
	 start solving instance: 69...
	 start solving instance: 125...
	 start solving instance: 98...
	 start solving instance: 34...
	 start solving instance: 89...
	 start solving instance: 128...
	 start solving instance: 85...
	 start solving instance: 86...
	 start solving instance: 28...
	 start solving instance: 108...
	 start solving instance: 135...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.488041977642117e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266123776.0
		 entropy bonus: 0.19048479199409485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6331222016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7283569152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4880420875932795e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.488041977642117e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266123776.0
		 entropy bonus: 0.19048479199409485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6331222016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7283569152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4880420875932795e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.488041977642117e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266123776.0
		 entropy bonus: 0.19048479199409485
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6331222016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7283569152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4880420875932795e+18 - Differentiable computation graph = True!
PPO iteration: 319/1000:
	 start solving instance: 65...
	 start solving instance: 69...
	 start solving instance: 78...
	 start solving instance: 14...
	 start solving instance: 112...
	 start solving instance: 100...
	 start solving instance: 13...
	 start solving instance: 28...
	 start solving instance: 89...
	 start solving instance: 108...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 34...
	 start solving instance: 128...
	 start solving instance: 135...
	 start solving instance: 87...
	 start solving instance: 39...
	 start solving instance: 46...
	 start solving instance: 86...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.751727735824659e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6181766656.0
		 entropy bonus: 0.20476284623146057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6662501376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7860685312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751728065678148e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.751727735824659e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6181766656.0
		 entropy bonus: 0.20476284623146057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6662501376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7860685312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751728065678148e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.751727735824659e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6181766656.0
		 entropy bonus: 0.20476284623146057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6662501376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7860685312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751728065678148e+18 - Differentiable computation graph = True!
PPO iteration: 320/1000:
	 start solving instance: 135...
	 start solving instance: 125...
	 start solving instance: 69...
	 start solving instance: 98...
	 start solving instance: 65...
	 start solving instance: 86...
	 start solving instance: 112...
	 start solving instance: 39...
	 start solving instance: 14...
	 start solving instance: 78...
	 start solving instance: 46...
	 start solving instance: 87...
	 start solving instance: 100...
	 start solving instance: 34...
	 start solving instance: 85...
	 start solving instance: 28...
	 start solving instance: 89...
	 start solving instance: 13...
	 start solving instance: 128...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.632113625057513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6287683072.0
		 entropy bonus: 0.1947426050901413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6526822912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7679623168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.632113844959838e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.632113625057513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6287683072.0
		 entropy bonus: 0.1947426050901413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6526822912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7679623168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.632113844959838e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.632113625057513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6287683072.0
		 entropy bonus: 0.1947426050901413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6526822912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7679623168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.632113844959838e+18 - Differentiable computation graph = True!
PPO iteration: 321/1000:
	 New training batch of size 20...
	 start solving instance: 25...
	 start solving instance: 129...
	 start solving instance: 32...
	 start solving instance: 101...
	 start solving instance: 11...
	 start solving instance: 64...
	 start solving instance: 106...
	 start solving instance: 3...
	 start solving instance: 12...
	 start solving instance: 76...
	 start solving instance: 118...
	 start solving instance: 43...
	 start solving instance: 81...
	 start solving instance: 116...
	 start solving instance: 10...
	 start solving instance: 34...
	 start solving instance: 44...
	 start solving instance: 134...
	 start solving instance: 68...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.921268802388702e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886617600.0
		 entropy bonus: 0.22321854531764984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5992315392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6541471232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9212688573642834e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.921268802388702e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886617600.0
		 entropy bonus: 0.22321854531764984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5992315392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6541471232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9212688573642834e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.921268802388702e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886617600.0
		 entropy bonus: 0.22321854531764984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5992315392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6541471232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9212688573642834e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.8404981304058184e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5197770240.0
		 entropy bonus: 0.18666501343250275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4906094592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5684307968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2840498130405818368.0000
PPO iteration: 322/1000:
	 start solving instance: 11...
	 start solving instance: 25...
	 start solving instance: 106...
	 start solving instance: 43...
	 start solving instance: 81...
	 start solving instance: 116...
	 start solving instance: 12...
	 start solving instance: 76...
	 start solving instance: 101...
	 start solving instance: 34...
	 start solving instance: 64...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 134...
	 start solving instance: 3...
	 start solving instance: 129...
	 start solving instance: 32...
	 start solving instance: 22...
	 start solving instance: 118...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.103344409511199e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059637760.0
		 entropy bonus: 0.21783152222633362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6024401408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6857780224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1033444095111987e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.103344409511199e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059637760.0
		 entropy bonus: 0.21783152222633362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6024401408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6857780224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1033444095111987e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.103344409511199e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059637760.0
		 entropy bonus: 0.21783152222633362
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6024401408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6857780224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1033444095111987e+18 - Differentiable computation graph = True!
PPO iteration: 323/1000:
	 start solving instance: 12...
	 start solving instance: 10...
	 start solving instance: 101...
	 start solving instance: 134...
	 start solving instance: 64...
	 start solving instance: 68...
	 start solving instance: 11...
	 start solving instance: 116...
	 start solving instance: 118...
	 start solving instance: 81...
	 start solving instance: 129...
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 25...
	 start solving instance: 34...
	 start solving instance: 32...
	 start solving instance: 76...
	 start solving instance: 43...
	 start solving instance: 106...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.010846454508264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5941382656.0
		 entropy bonus: 0.22529159486293793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6102502912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6793792512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.010846619435008e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.010846454508264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5941382656.0
		 entropy bonus: 0.22529159486293793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6102502912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6793792512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.010846619435008e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.010846454508264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5941382656.0
		 entropy bonus: 0.22529159486293793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6102502912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6793792512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.010846619435008e+18 - Differentiable computation graph = True!
PPO iteration: 324/1000:
	 start solving instance: 76...
	 start solving instance: 25...
	 start solving instance: 64...
	 start solving instance: 134...
	 start solving instance: 10...
	 start solving instance: 68...
	 start solving instance: 118...
	 start solving instance: 43...
	 start solving instance: 32...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 12...
	 start solving instance: 44...
	 start solving instance: 106...
	 start solving instance: 34...
	 start solving instance: 101...
	 start solving instance: 116...
	 start solving instance: 11...
	 start solving instance: 81...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.164666372015522e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885455872.0
		 entropy bonus: 0.23130932450294495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6172722176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6813483008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.164666372015522e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.164666372015522e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885455872.0
		 entropy bonus: 0.23130932450294495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6172722176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6813483008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.164666372015522e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.164666372015522e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885455872.0
		 entropy bonus: 0.23130932450294495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6172722176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6813483008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.164666372015522e+18 - Differentiable computation graph = True!
PPO iteration: 325/1000:
	 start solving instance: 118...
	 start solving instance: 12...
	 start solving instance: 81...
	 start solving instance: 43...
	 start solving instance: 22...
	 start solving instance: 68...
	 start solving instance: 32...
	 start solving instance: 44...
	 start solving instance: 76...
	 start solving instance: 134...
	 start solving instance: 10...
	 start solving instance: 101...
	 start solving instance: 106...
	 start solving instance: 64...
	 start solving instance: 129...
	 start solving instance: 11...
	 start solving instance: 3...
	 start solving instance: 34...
	 start solving instance: 25...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.061018929302287e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6050756096.0
		 entropy bonus: 0.21998277306556702
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6022833152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6720328704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0610189842778685e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.061018929302287e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6050756096.0
		 entropy bonus: 0.21998277306556702
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6022833152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6720328704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0610189842778685e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.061018929302287e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6050756096.0
		 entropy bonus: 0.21998277306556702
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6022833152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6720328704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0610189842778685e+18 - Differentiable computation graph = True!
PPO iteration: 326/1000:
	 start solving instance: 64...
	 start solving instance: 43...
	 start solving instance: 68...
	 start solving instance: 11...
	 start solving instance: 32...
	 start solving instance: 12...
	 start solving instance: 81...
	 start solving instance: 129...
	 start solving instance: 25...
	 start solving instance: 118...
	 start solving instance: 22...
	 start solving instance: 106...
	 start solving instance: 101...
	 start solving instance: 10...
	 start solving instance: 134...
	 start solving instance: 44...
	 start solving instance: 34...
	 start solving instance: 76...
	 start solving instance: 116...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.886725665481189e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022592000.0
		 entropy bonus: 0.22095969319343567
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850830336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6542955008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.886725775432352e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.886725665481189e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022592000.0
		 entropy bonus: 0.22095969319343567
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850830336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6542955008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.886725775432352e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.886725665481189e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022592000.0
		 entropy bonus: 0.22095969319343567
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850830336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6542955008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.886725775432352e+18 - Differentiable computation graph = True!
PPO iteration: 327/1000:
	 start solving instance: 12...
	 start solving instance: 10...
	 start solving instance: 68...
	 start solving instance: 22...
	 start solving instance: 64...
	 start solving instance: 3...
	 start solving instance: 101...
	 start solving instance: 43...
	 start solving instance: 106...
	 start solving instance: 34...
	 start solving instance: 32...
	 start solving instance: 44...
	 start solving instance: 81...
	 start solving instance: 118...
	 start solving instance: 11...
	 start solving instance: 134...
	 start solving instance: 25...
	 start solving instance: 116...
	 start solving instance: 76...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.864549395558249e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985330688.0
		 entropy bonus: 0.21493621170520782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5835736064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6683636224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8645494505338307e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.864549395558249e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985330688.0
		 entropy bonus: 0.21493621170520782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5835736064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6683636224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8645494505338307e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.864549395558249e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985330688.0
		 entropy bonus: 0.21493621170520782
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5835736064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6683636224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8645494505338307e+18 - Differentiable computation graph = True!
PPO iteration: 328/1000:
	 start solving instance: 118...
	 start solving instance: 3...
	 start solving instance: 76...
	 start solving instance: 81...
	 start solving instance: 32...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 22...
	 start solving instance: 34...
	 start solving instance: 64...
	 start solving instance: 12...
	 start solving instance: 101...
	 start solving instance: 25...
	 start solving instance: 11...
	 start solving instance: 134...
	 start solving instance: 129...
	 start solving instance: 116...
	 start solving instance: 106...
	 start solving instance: 43...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.864899919865184e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885385728.0
		 entropy bonus: 0.20495262742042542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5930128384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6574581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.864899919865184e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.864899919865184e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885385728.0
		 entropy bonus: 0.20495262742042542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5930128384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6574581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.864899919865184e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.864899919865184e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885385728.0
		 entropy bonus: 0.20495262742042542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5930128384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6574581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.864899919865184e+18 - Differentiable computation graph = True!
PPO iteration: 329/1000:
	 start solving instance: 76...
	 start solving instance: 68...
	 start solving instance: 3...
	 start solving instance: 81...
	 start solving instance: 22...
	 start solving instance: 32...
	 start solving instance: 129...
	 start solving instance: 118...
	 start solving instance: 134...
	 start solving instance: 11...
	 start solving instance: 25...
	 start solving instance: 44...
	 start solving instance: 64...
	 start solving instance: 10...
	 start solving instance: 101...
	 start solving instance: 116...
	 start solving instance: 12...
	 start solving instance: 43...
	 start solving instance: 34...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9982165843423265e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6008115712.0
		 entropy bonus: 0.2171068638563156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5966910464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741396992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.998216529366745e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9982165843423265e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6008115712.0
		 entropy bonus: 0.2171068638563156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5966910464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741396992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.998216529366745e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9982165843423265e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6008115712.0
		 entropy bonus: 0.2171068638563156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5966910464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741396992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.998216529366745e+18 - Differentiable computation graph = True!
PPO iteration: 330/1000:
	 start solving instance: 25...
	 start solving instance: 12...
	 start solving instance: 43...
	 start solving instance: 22...
	 start solving instance: 81...
	 start solving instance: 134...
	 start solving instance: 11...
	 start solving instance: 101...
	 start solving instance: 116...
	 start solving instance: 44...
	 start solving instance: 118...
	 start solving instance: 129...
	 start solving instance: 32...
	 start solving instance: 106...
	 start solving instance: 76...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 64...
	 start solving instance: 3...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.930653354034096e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5963636224.0
		 entropy bonus: 0.22539977729320526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5951617536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6650798592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9306534639852585e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.930653354034096e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5963636224.0
		 entropy bonus: 0.22539977729320526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5951617536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6650798592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9306534639852585e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.930653354034096e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5963636224.0
		 entropy bonus: 0.22539977729320526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5951617536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6650798592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9306534639852585e+18 - Differentiable computation graph = True!
PPO iteration: 331/1000:
	 New training batch of size 20...
	 start solving instance: 42...
	 start solving instance: 91...
	 start solving instance: 72...
	 start solving instance: 131...
	 start solving instance: 99...
	 start solving instance: 47...
	 start solving instance: 84...
	 start solving instance: 85...
	 start solving instance: 18...
	 start solving instance: 32...
	 start solving instance: 106...
	 start solving instance: 116...
	 start solving instance: 137...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 147...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6041942779985658e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5780223488.0
		 entropy bonus: 0.20771442353725433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5746150912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6304029184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.60419444292531e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6041942779985658e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5780223488.0
		 entropy bonus: 0.20771442353725433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5746150912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6304029184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.60419444292531e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6041942779985658e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5780223488.0
		 entropy bonus: 0.20771442353725433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5746150912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6304029184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.60419444292531e+18 - Differentiable computation graph = True!
PPO iteration: 332/1000:
	 start solving instance: 85...
	 start solving instance: 107...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 137...
	 start solving instance: 65...
	 start solving instance: 32...
	 start solving instance: 72...
	 start solving instance: 84...
	 start solving instance: 91...
	 start solving instance: 116...
	 start solving instance: 42...
	 start solving instance: 147...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 106...
	 start solving instance: 131...
	 start solving instance: 39...
	 start solving instance: 144...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6238377129357607e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715492352.0
		 entropy bonus: 0.19713690876960754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5777264640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6536742400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.623837767911342e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6238377129357607e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715492352.0
		 entropy bonus: 0.19713690876960754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5777264640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6536742400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.623837767911342e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6238377129357607e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715492352.0
		 entropy bonus: 0.19713690876960754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5777264640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6536742400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.623837767911342e+18 - Differentiable computation graph = True!
PPO iteration: 333/1000:
	 start solving instance: 42...
	 start solving instance: 106...
	 start solving instance: 99...
	 start solving instance: 144...
	 start solving instance: 83...
	 start solving instance: 91...
	 start solving instance: 39...
	 start solving instance: 85...
	 start solving instance: 116...
	 start solving instance: 72...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 147...
	 start solving instance: 107...
	 start solving instance: 47...
	 start solving instance: 137...
	 start solving instance: 84...
	 start solving instance: 37...
	 start solving instance: 65...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5669755894960226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5707696640.0
		 entropy bonus: 0.20862971246242523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5688537088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6697065984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5669756994471854e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5669755894960226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5707696640.0
		 entropy bonus: 0.20862971246242523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5688537088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6697065984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5669756994471854e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5669755894960226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5707696640.0
		 entropy bonus: 0.20862971246242523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5688537088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6697065984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5669756994471854e+18 - Differentiable computation graph = True!
PPO iteration: 334/1000:
	 start solving instance: 39...
	 start solving instance: 147...
	 start solving instance: 99...
	 start solving instance: 37...
	 start solving instance: 47...
	 start solving instance: 131...
	 start solving instance: 65...
	 start solving instance: 106...
	 start solving instance: 83...
	 start solving instance: 85...
	 start solving instance: 32...
	 start solving instance: 18...
	 start solving instance: 42...
	 start solving instance: 72...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 84...
	 start solving instance: 144...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.703350875419312e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5744311808.0
		 entropy bonus: 0.20170266926288605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5833325056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6787901952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.703350875419312e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.703350875419312e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5744311808.0
		 entropy bonus: 0.20170266926288605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5833325056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6787901952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.703350875419312e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.703350875419312e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5744311808.0
		 entropy bonus: 0.20170266926288605
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5833325056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6787901952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.703350875419312e+18 - Differentiable computation graph = True!
PPO iteration: 335/1000:
	 start solving instance: 116...
	 start solving instance: 39...
	 start solving instance: 106...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 18...
	 start solving instance: 65...
	 start solving instance: 37...
	 start solving instance: 42...
	 start solving instance: 137...
	 start solving instance: 85...
	 start solving instance: 84...
	 start solving instance: 144...
	 start solving instance: 32...
	 start solving instance: 47...
	 start solving instance: 83...
	 start solving instance: 91...
	 start solving instance: 131...
	 start solving instance: 147...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6674592974514946e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5764360192.0
		 entropy bonus: 0.18836431205272675
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5740750336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001401344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.667459242475913e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6674592974514946e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5764360192.0
		 entropy bonus: 0.18836431205272675
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5740750336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001401344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.667459242475913e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6674592974514946e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5764360192.0
		 entropy bonus: 0.18836431205272675
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5740750336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001401344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.667459242475913e+18 - Differentiable computation graph = True!
PPO iteration: 336/1000:
	 start solving instance: 37...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 85...
	 start solving instance: 72...
	 start solving instance: 147...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 106...
	 start solving instance: 39...
	 start solving instance: 131...
	 start solving instance: 91...
	 start solving instance: 83...
	 start solving instance: 32...
	 start solving instance: 84...
	 start solving instance: 144...
	 start solving instance: 137...
	 start solving instance: 116...
	 start solving instance: 18...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.713305853697196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5685553152.0
		 entropy bonus: 0.21286128461360931
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5814776320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6781864448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.713305853697196e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.713305853697196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5685553152.0
		 entropy bonus: 0.21286128461360931
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5814776320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6781864448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.713305853697196e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.713305853697196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5685553152.0
		 entropy bonus: 0.21286128461360931
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5814776320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6781864448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.713305853697196e+18 - Differentiable computation graph = True!
PPO iteration: 337/1000:
	 start solving instance: 18...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 91...
	 start solving instance: 84...
	 start solving instance: 72...
	 start solving instance: 39...
	 start solving instance: 42...
	 start solving instance: 32...
	 start solving instance: 85...
	 start solving instance: 106...
	 start solving instance: 116...
	 start solving instance: 83...
	 start solving instance: 147...
	 start solving instance: 144...
	 start solving instance: 131...
	 start solving instance: 65...
	 start solving instance: 37...
	 start solving instance: 137...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.603198560268452e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5735781888.0
		 entropy bonus: 0.1965727061033249
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5670641152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6547423232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.603198560268452e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.603198560268452e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5735781888.0
		 entropy bonus: 0.1965727061033249
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5670641152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6547423232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.603198560268452e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.603198560268452e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5735781888.0
		 entropy bonus: 0.1965727061033249
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5670641152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6547423232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.603198560268452e+18 - Differentiable computation graph = True!
PPO iteration: 338/1000:
	 start solving instance: 116...
	 start solving instance: 65...
	 start solving instance: 72...
	 start solving instance: 91...
	 start solving instance: 99...
	 start solving instance: 137...
	 start solving instance: 147...
	 start solving instance: 84...
	 start solving instance: 85...
	 start solving instance: 39...
	 start solving instance: 47...
	 start solving instance: 106...
	 start solving instance: 32...
	 start solving instance: 144...
	 start solving instance: 42...
	 start solving instance: 83...
	 start solving instance: 37...
	 start solving instance: 107...
	 start solving instance: 131...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.586670261675072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5726489600.0
		 entropy bonus: 0.19872525334358215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5725050368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6201727488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.586670426601816e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.586670261675072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5726489600.0
		 entropy bonus: 0.19872525334358215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5725050368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6201727488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.586670426601816e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.586670261675072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5726489600.0
		 entropy bonus: 0.19872525334358215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5725050368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6201727488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.586670426601816e+18 - Differentiable computation graph = True!
PPO iteration: 339/1000:
	 start solving instance: 18...
	 start solving instance: 116...
	 start solving instance: 106...
	 start solving instance: 107...
	 start solving instance: 144...
	 start solving instance: 137...
	 start solving instance: 91...
	 start solving instance: 47...
	 start solving instance: 42...
	 start solving instance: 84...
	 start solving instance: 37...
	 start solving instance: 83...
	 start solving instance: 99...
	 start solving instance: 72...
	 start solving instance: 131...
	 start solving instance: 39...
	 start solving instance: 65...
	 start solving instance: 85...
	 start solving instance: 147...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4309294973540893e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5634512384.0
		 entropy bonus: 0.20753715932369232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5573752320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204042752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4309295523296707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4309294973540893e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5634512384.0
		 entropy bonus: 0.20753715932369232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5573752320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204042752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4309295523296707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4309294973540893e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5634512384.0
		 entropy bonus: 0.20753715932369232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5573752320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204042752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4309295523296707e+18 - Differentiable computation graph = True!
PPO iteration: 340/1000:
	 start solving instance: 131...
	 start solving instance: 37...
	 start solving instance: 91...
	 start solving instance: 39...
	 start solving instance: 32...
	 start solving instance: 106...
	 start solving instance: 137...
	 start solving instance: 83...
	 start solving instance: 84...
	 start solving instance: 99...
	 start solving instance: 42...
	 start solving instance: 72...
	 start solving instance: 144...
	 start solving instance: 147...
	 start solving instance: 116...
	 start solving instance: 107...
	 start solving instance: 18...
	 start solving instance: 65...
	 start solving instance: 85...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5689261231236973e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5759508480.0
		 entropy bonus: 0.21175329387187958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5642150912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6335760896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.56892623307486e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5689261231236973e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5759508480.0
		 entropy bonus: 0.21175329387187958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5642150912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6335760896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.56892623307486e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5689261231236973e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5759508480.0
		 entropy bonus: 0.21175329387187958
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5642150912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6335760896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.56892623307486e+18 - Differentiable computation graph = True!
PPO iteration: 341/1000:
	 New training batch of size 20...
	 start solving instance: 108...
	 start solving instance: 25...
	 start solving instance: 112...
	 start solving instance: 39...
	 start solving instance: 1...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 120...
	 start solving instance: 55...
	 start solving instance: 133...
	 start solving instance: 23...
	 start solving instance: 44...
	 start solving instance: 95...
	 start solving instance: 150...
	 start solving instance: 91...
	 start solving instance: 96...
	 start solving instance: 148...
	 start solving instance: 11...
	 start solving instance: 98...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6541439917368017e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5726368768.0
		 entropy bonus: 0.20374689996242523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5602572800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6639680000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.654144156663546e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6541439917368017e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5726368768.0
		 entropy bonus: 0.20374689996242523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5602572800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6639680000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.654144156663546e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6541439917368017e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5726368768.0
		 entropy bonus: 0.20374689996242523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5602572800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6639680000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.654144156663546e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9509168055275487e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5113233408.0
		 entropy bonus: 0.22969989478588104
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5037059072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6038198784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2950916860503130112.0000
PPO iteration: 342/1000:
	 start solving instance: 55...
	 start solving instance: 25...
	 start solving instance: 97...
	 start solving instance: 1...
	 start solving instance: 112...
	 start solving instance: 148...
	 start solving instance: 11...
	 start solving instance: 150...
	 start solving instance: 108...
	 start solving instance: 98...
	 start solving instance: 62...
	 start solving instance: 96...
	 start solving instance: 23...
	 start solving instance: 101...
	 start solving instance: 39...
	 start solving instance: 120...
	 start solving instance: 95...
	 start solving instance: 133...
	 start solving instance: 91...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.538780153117986e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5592206848.0
		 entropy bonus: 0.2206941395998001
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5466774016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6505824768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5387800981424046e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.538780153117986e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5592206848.0
		 entropy bonus: 0.2206941395998001
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5466774016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6505824768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5387800981424046e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.538780153117986e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5592206848.0
		 entropy bonus: 0.2206941395998001
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5466774016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6505824768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5387800981424046e+18 - Differentiable computation graph = True!
PPO iteration: 343/1000:
	 start solving instance: 97...
	 start solving instance: 55...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 101...
	 start solving instance: 112...
	 start solving instance: 108...
	 start solving instance: 133...
	 start solving instance: 150...
	 start solving instance: 120...
	 start solving instance: 96...
	 start solving instance: 62...
	 start solving instance: 44...
	 start solving instance: 11...
	 start solving instance: 39...
	 start solving instance: 98...
	 start solving instance: 148...
	 start solving instance: 23...
	 start solving instance: 91...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.653970268899613e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738273792.0
		 entropy bonus: 0.21371245384216309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5687374336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6852793344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.653970433826357e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.653970268899613e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738273792.0
		 entropy bonus: 0.21371245384216309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5687374336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6852793344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.653970433826357e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.653970268899613e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738273792.0
		 entropy bonus: 0.21371245384216309
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5687374336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6852793344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.653970433826357e+18 - Differentiable computation graph = True!
PPO iteration: 344/1000:
	 start solving instance: 98...
	 start solving instance: 39...
	 start solving instance: 101...
	 start solving instance: 108...
	 start solving instance: 120...
	 start solving instance: 25...
	 start solving instance: 148...
	 start solving instance: 96...
	 start solving instance: 1...
	 start solving instance: 23...
	 start solving instance: 133...
	 start solving instance: 55...
	 start solving instance: 91...
	 start solving instance: 97...
	 start solving instance: 112...
	 start solving instance: 62...
	 start solving instance: 150...
	 start solving instance: 44...
	 start solving instance: 11...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.699114677019817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5720832512.0
		 entropy bonus: 0.2116578072309494
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5699788800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6803828224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.699114731995398e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.699114677019817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5720832512.0
		 entropy bonus: 0.2116578072309494
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5699788800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6803828224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.699114731995398e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.699114677019817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5720832512.0
		 entropy bonus: 0.2116578072309494
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5699788800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6803828224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.699114731995398e+18 - Differentiable computation graph = True!
PPO iteration: 345/1000:
	 start solving instance: 39...
	 start solving instance: 44...
	 start solving instance: 133...
	 start solving instance: 91...
	 start solving instance: 95...
	 start solving instance: 148...
	 start solving instance: 25...
	 start solving instance: 96...
	 start solving instance: 108...
	 start solving instance: 55...
	 start solving instance: 97...
	 start solving instance: 1...
	 start solving instance: 101...
	 start solving instance: 150...
	 start solving instance: 11...
	 start solving instance: 112...
	 start solving instance: 62...
	 start solving instance: 120...
	 start solving instance: 98...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6452649955378594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5681679360.0
		 entropy bonus: 0.21178583800792694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5610948096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662065152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.645265050513441e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6452649955378594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5681679360.0
		 entropy bonus: 0.21178583800792694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5610948096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662065152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.645265050513441e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6452649955378594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5681679360.0
		 entropy bonus: 0.21178583800792694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5610948096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662065152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.645265050513441e+18 - Differentiable computation graph = True!
PPO iteration: 346/1000:
	 start solving instance: 39...
	 start solving instance: 44...
	 start solving instance: 108...
	 start solving instance: 133...
	 start solving instance: 98...
	 start solving instance: 148...
	 start solving instance: 150...
	 start solving instance: 1...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 11...
	 start solving instance: 101...
	 start solving instance: 120...
	 start solving instance: 91...
	 start solving instance: 112...
	 start solving instance: 23...
	 start solving instance: 95...
	 start solving instance: 96...
	 start solving instance: 55...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.644494457789114e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5687026688.0
		 entropy bonus: 0.20893494784832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593458176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6731099648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6444945677402767e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.644494457789114e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5687026688.0
		 entropy bonus: 0.20893494784832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593458176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6731099648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6444945677402767e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.644494457789114e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5687026688.0
		 entropy bonus: 0.20893494784832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593458176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6731099648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6444945677402767e+18 - Differentiable computation graph = True!
PPO iteration: 347/1000:
	 start solving instance: 101...
	 start solving instance: 98...
	 start solving instance: 148...
	 start solving instance: 133...
	 start solving instance: 112...
	 start solving instance: 62...
	 start solving instance: 91...
	 start solving instance: 23...
	 start solving instance: 55...
	 start solving instance: 150...
	 start solving instance: 96...
	 start solving instance: 95...
	 start solving instance: 108...
	 start solving instance: 120...
	 start solving instance: 97...
	 start solving instance: 11...
	 start solving instance: 39...
	 start solving instance: 1...
	 start solving instance: 44...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5913069022094033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5734211584.0
		 entropy bonus: 0.21116428077220917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5585067520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6758880256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5913070671361475e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5913069022094033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5734211584.0
		 entropy bonus: 0.21116428077220917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5585067520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6758880256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5913070671361475e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5913069022094033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5734211584.0
		 entropy bonus: 0.21116428077220917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5585067520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6758880256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5913070671361475e+18 - Differentiable computation graph = True!
PPO iteration: 348/1000:
	 start solving instance: 25...
	 start solving instance: 108...
	 start solving instance: 133...
	 start solving instance: 96...
	 start solving instance: 97...
	 start solving instance: 95...
	 start solving instance: 101...
	 start solving instance: 62...
	 start solving instance: 148...
	 start solving instance: 91...
	 start solving instance: 11...
	 start solving instance: 55...
	 start solving instance: 150...
	 start solving instance: 120...
	 start solving instance: 39...
	 start solving instance: 1...
	 start solving instance: 23...
	 start solving instance: 98...
	 start solving instance: 112...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5749595832299553e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702265344.0
		 entropy bonus: 0.2091173231601715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5662467584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6682133504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.574959528254374e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5749595832299553e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702265344.0
		 entropy bonus: 0.2091173231601715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5662467584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6682133504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.574959528254374e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5749595832299553e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702265344.0
		 entropy bonus: 0.2091173231601715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5662467584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6682133504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.574959528254374e+18 - Differentiable computation graph = True!
PPO iteration: 349/1000:
	 start solving instance: 25...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 23...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 1...
	 start solving instance: 150...
	 start solving instance: 112...
	 start solving instance: 101...
	 start solving instance: 55...
	 start solving instance: 11...
	 start solving instance: 44...
	 start solving instance: 39...
	 start solving instance: 133...
	 start solving instance: 96...
	 start solving instance: 98...
	 start solving instance: 91...
	 start solving instance: 95...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.497263253760141e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5667810816.0
		 entropy bonus: 0.21784766018390656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5629303808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6753053184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4972633637113037e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.497263253760141e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5667810816.0
		 entropy bonus: 0.21784766018390656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5629303808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6753053184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4972633637113037e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.497263253760141e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5667810816.0
		 entropy bonus: 0.21784766018390656
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5629303808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6753053184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4972633637113037e+18 - Differentiable computation graph = True!
PPO iteration: 350/1000:
	 start solving instance: 112...
	 start solving instance: 11...
	 start solving instance: 108...
	 start solving instance: 62...
	 start solving instance: 98...
	 start solving instance: 91...
	 start solving instance: 120...
	 start solving instance: 96...
	 start solving instance: 133...
	 start solving instance: 55...
	 start solving instance: 101...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 150...
	 start solving instance: 39...
	 start solving instance: 23...
	 start solving instance: 148...
	 start solving instance: 44...
	 start solving instance: 1...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6474387300259725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5614468608.0
		 entropy bonus: 0.21424071490764618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5674089472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509998080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.647438785001554e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6474387300259725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5614468608.0
		 entropy bonus: 0.21424071490764618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5674089472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509998080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.647438785001554e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6474387300259725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5614468608.0
		 entropy bonus: 0.21424071490764618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5674089472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509998080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.647438785001554e+18 - Differentiable computation graph = True!
PPO iteration: 351/1000:
	 New training batch of size 20...
	 start solving instance: 36...
	 start solving instance: 20...
	 start solving instance: 5...
	 start solving instance: 56...
	 start solving instance: 7...
	 start solving instance: 134...
	 start solving instance: 23...
	 start solving instance: 53...
	 start solving instance: 133...
	 start solving instance: 14...
	 start solving instance: 50...
	 start solving instance: 105...
	 start solving instance: 149...
	 start solving instance: 46...
	 start solving instance: 60...
	 start solving instance: 1...
	 start solving instance: 98...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.168890255884786e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6238097408.0
		 entropy bonus: 0.20631535351276398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6151035904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7244843520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.16889042081153e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.168890255884786e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6238097408.0
		 entropy bonus: 0.20631535351276398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6151035904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7244843520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.16889042081153e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.168890255884786e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6238097408.0
		 entropy bonus: 0.20631535351276398
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6151035904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7244843520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.16889042081153e+18 - Differentiable computation graph = True!
PPO iteration: 352/1000:
	 start solving instance: 60...
	 start solving instance: 98...
	 start solving instance: 1...
	 start solving instance: 105...
	 start solving instance: 46...
	 start solving instance: 14...
	 start solving instance: 56...
	 start solving instance: 23...
	 start solving instance: 149...
	 start solving instance: 36...
	 start solving instance: 18...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 133...
	 start solving instance: 89...
	 start solving instance: 7...
	 start solving instance: 53...
	 start solving instance: 20...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.106079114831803e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187763712.0
		 entropy bonus: 0.22528456151485443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6108618240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7061122560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1060791698073846e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.106079114831803e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187763712.0
		 entropy bonus: 0.22528456151485443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6108618240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7061122560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1060791698073846e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.106079114831803e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187763712.0
		 entropy bonus: 0.22528456151485443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6108618240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7061122560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1060791698073846e+18 - Differentiable computation graph = True!
PPO iteration: 353/1000:
	 start solving instance: 89...
	 start solving instance: 46...
	 start solving instance: 53...
	 start solving instance: 134...
	 start solving instance: 60...
	 start solving instance: 50...
	 start solving instance: 5...
	 start solving instance: 149...
	 start solving instance: 7...
	 start solving instance: 20...
	 start solving instance: 105...
	 start solving instance: 109...
	 start solving instance: 23...
	 start solving instance: 56...
	 start solving instance: 98...
	 start solving instance: 133...
	 start solving instance: 36...
	 start solving instance: 18...
	 start solving instance: 14...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.186433623612929e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6204339200.0
		 entropy bonus: 0.22518658638000488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6281160192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6902502912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.18643367858851e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.186433623612929e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6204339200.0
		 entropy bonus: 0.22518658638000488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6281160192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6902502912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.18643367858851e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.186433623612929e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6204339200.0
		 entropy bonus: 0.22518658638000488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6281160192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6902502912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.18643367858851e+18 - Differentiable computation graph = True!
PPO iteration: 354/1000:
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 105...
	 start solving instance: 53...
	 start solving instance: 18...
	 start solving instance: 23...
	 start solving instance: 36...
	 start solving instance: 14...
	 start solving instance: 109...
	 start solving instance: 89...
	 start solving instance: 20...
	 start solving instance: 7...
	 start solving instance: 50...
	 start solving instance: 56...
	 start solving instance: 133...
	 start solving instance: 134...
	 start solving instance: 60...
	 start solving instance: 149...
	 start solving instance: 46...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.316050211560279e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6285116928.0
		 entropy bonus: 0.21211586892604828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6370944000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7112014848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.316050156584698e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.316050211560279e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6285116928.0
		 entropy bonus: 0.21211586892604828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6370944000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7112014848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.316050156584698e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.316050211560279e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6285116928.0
		 entropy bonus: 0.21211586892604828
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6370944000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7112014848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.316050156584698e+18 - Differentiable computation graph = True!
PPO iteration: 355/1000:
	 start solving instance: 89...
	 start solving instance: 46...
	 start solving instance: 20...
	 start solving instance: 149...
	 start solving instance: 109...
	 start solving instance: 56...
	 start solving instance: 98...
	 start solving instance: 133...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 105...
	 start solving instance: 7...
	 start solving instance: 50...
	 start solving instance: 23...
	 start solving instance: 18...
	 start solving instance: 1...
	 start solving instance: 14...
	 start solving instance: 53...
	 start solving instance: 36...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.148207122752366e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6220872192.0
		 entropy bonus: 0.22280216217041016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6172133376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7062192128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.148207232703529e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.148207122752366e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6220872192.0
		 entropy bonus: 0.22280216217041016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6172133376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7062192128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.148207232703529e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.148207122752366e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6220872192.0
		 entropy bonus: 0.22280216217041016
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6172133376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7062192128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.148207232703529e+18 - Differentiable computation graph = True!
PPO iteration: 356/1000:
	 start solving instance: 149...
	 start solving instance: 133...
	 start solving instance: 36...
	 start solving instance: 98...
	 start solving instance: 89...
	 start solving instance: 105...
	 start solving instance: 53...
	 start solving instance: 60...
	 start solving instance: 23...
	 start solving instance: 14...
	 start solving instance: 46...
	 start solving instance: 56...
	 start solving instance: 20...
	 start solving instance: 134...
	 start solving instance: 50...
	 start solving instance: 1...
	 start solving instance: 109...
	 start solving instance: 18...
	 start solving instance: 7...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.261265505390061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6154194432.0
		 entropy bonus: 0.23142504692077637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359626752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7144579072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.261265615341224e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.261265505390061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6154194432.0
		 entropy bonus: 0.23142504692077637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359626752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7144579072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.261265615341224e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.261265505390061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6154194432.0
		 entropy bonus: 0.23142504692077637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359626752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7144579072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.261265615341224e+18 - Differentiable computation graph = True!
PPO iteration: 357/1000:
	 start solving instance: 105...
	 start solving instance: 60...
	 start solving instance: 23...
	 start solving instance: 46...
	 start solving instance: 98...
	 start solving instance: 134...
	 start solving instance: 18...
	 start solving instance: 109...
	 start solving instance: 50...
	 start solving instance: 7...
	 start solving instance: 133...
	 start solving instance: 20...
	 start solving instance: 56...
	 start solving instance: 5...
	 start solving instance: 36...
	 start solving instance: 149...
	 start solving instance: 1...
	 start solving instance: 14...
	 start solving instance: 53...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2189158359253385e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6271864320.0
		 entropy bonus: 0.22727227210998535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6279622144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001658368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2189160008520827e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2189158359253385e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6271864320.0
		 entropy bonus: 0.22727227210998535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6279622144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001658368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2189160008520827e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2189158359253385e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6271864320.0
		 entropy bonus: 0.22727227210998535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6279622144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001658368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2189160008520827e+18 - Differentiable computation graph = True!
PPO iteration: 358/1000:
	 start solving instance: 149...
	 start solving instance: 98...
	 start solving instance: 7...
	 start solving instance: 53...
	 start solving instance: 134...
	 start solving instance: 46...
	 start solving instance: 56...
	 start solving instance: 1...
	 start solving instance: 109...
	 start solving instance: 18...
	 start solving instance: 105...
	 start solving instance: 60...
	 start solving instance: 133...
	 start solving instance: 5...
	 start solving instance: 23...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 89...
	 start solving instance: 50...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.313974773411689e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6241764864.0
		 entropy bonus: 0.22481480240821838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359925248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7042941952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3139748283872707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.313974773411689e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6241764864.0
		 entropy bonus: 0.22481480240821838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359925248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7042941952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3139748283872707e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.313974773411689e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6241764864.0
		 entropy bonus: 0.22481480240821838
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359925248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7042941952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3139748283872707e+18 - Differentiable computation graph = True!
PPO iteration: 359/1000:
	 start solving instance: 133...
	 start solving instance: 60...
	 start solving instance: 18...
	 start solving instance: 56...
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 1...
	 start solving instance: 50...
	 start solving instance: 36...
	 start solving instance: 14...
	 start solving instance: 109...
	 start solving instance: 134...
	 start solving instance: 89...
	 start solving instance: 7...
	 start solving instance: 46...
	 start solving instance: 20...
	 start solving instance: 149...
	 start solving instance: 53...
	 start solving instance: 105...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.213310085842285e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187103232.0
		 entropy bonus: 0.22995653748512268
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6316238336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7175438336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.213310140817867e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.213310085842285e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187103232.0
		 entropy bonus: 0.22995653748512268
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6316238336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7175438336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.213310140817867e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.213310085842285e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187103232.0
		 entropy bonus: 0.22995653748512268
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6316238336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7175438336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.213310140817867e+18 - Differentiable computation graph = True!
PPO iteration: 360/1000:
	 start solving instance: 7...
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 134...
	 start solving instance: 18...
	 start solving instance: 20...
	 start solving instance: 36...
	 start solving instance: 89...
	 start solving instance: 98...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 56...
	 start solving instance: 23...
	 start solving instance: 14...
	 start solving instance: 5...
	 start solving instance: 105...
	 start solving instance: 133...
	 start solving instance: 53...
	 start solving instance: 60...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.260739059222682e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6141172224.0
		 entropy bonus: 0.22928181290626526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6383475712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7032158208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.260739224149426e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.260739059222682e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6141172224.0
		 entropy bonus: 0.22928181290626526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6383475712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7032158208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.260739224149426e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.260739059222682e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6141172224.0
		 entropy bonus: 0.22928181290626526
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6383475712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7032158208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.260739224149426e+18 - Differentiable computation graph = True!
PPO iteration: 361/1000:
	 New training batch of size 20...
	 start solving instance: 90...
	 start solving instance: 107...
	 start solving instance: 89...
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 140...
	 start solving instance: 87...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 97...
	 start solving instance: 83...
	 start solving instance: 36...
	 start solving instance: 58...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 95...
	 start solving instance: 23...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.857351220835333e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6517200896.0
		 entropy bonus: 0.23158633708953857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6793073664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7101188096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.857351550688821e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.857351220835333e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6517200896.0
		 entropy bonus: 0.23158633708953857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6793073664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7101188096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.857351550688821e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.857351220835333e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6517200896.0
		 entropy bonus: 0.23158633708953857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6793073664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7101188096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.857351550688821e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.076639143191642e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5183240704.0
		 entropy bonus: 0.21545778214931488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5154490368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5998828032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3076639143191642112.0000
PPO iteration: 362/1000:
	 start solving instance: 90...
	 start solving instance: 87...
	 start solving instance: 36...
	 start solving instance: 13...
	 start solving instance: 107...
	 start solving instance: 26...
	 start solving instance: 83...
	 start solving instance: 89...
	 start solving instance: 95...
	 start solving instance: 134...
	 start solving instance: 58...
	 start solving instance: 108...
	 start solving instance: 57...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 126...
	 start solving instance: 97...
	 start solving instance: 104...
	 start solving instance: 69...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.276620073371435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6634608640.0
		 entropy bonus: 0.22847075760364532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7131160064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7814164480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.276620073371435e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.276620073371435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6634608640.0
		 entropy bonus: 0.22847075760364532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7131160064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7814164480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.276620073371435e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.276620073371435e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6634608640.0
		 entropy bonus: 0.22847075760364532
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7131160064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7814164480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.276620073371435e+18 - Differentiable computation graph = True!
PPO iteration: 363/1000:
	 start solving instance: 13...
	 start solving instance: 97...
	 start solving instance: 89...
	 start solving instance: 87...
	 start solving instance: 69...
	 start solving instance: 36...
	 start solving instance: 107...
	 start solving instance: 57...
	 start solving instance: 146...
	 start solving instance: 26...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 95...
	 start solving instance: 134...
	 start solving instance: 126...
	 start solving instance: 23...
	 start solving instance: 83...
	 start solving instance: 108...
	 start solving instance: 58...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.083527799543274e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6641309184.0
		 entropy bonus: 0.22366996109485626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6910847488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7981618688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.083527689592111e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.083527799543274e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6641309184.0
		 entropy bonus: 0.22366996109485626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6910847488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7981618688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.083527689592111e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.083527799543274e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6641309184.0
		 entropy bonus: 0.22366996109485626
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6910847488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7981618688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.083527689592111e+18 - Differentiable computation graph = True!
PPO iteration: 364/1000:
	 start solving instance: 58...
	 start solving instance: 57...
	 start solving instance: 104...
	 start solving instance: 69...
	 start solving instance: 23...
	 start solving instance: 97...
	 start solving instance: 36...
	 start solving instance: 26...
	 start solving instance: 87...
	 start solving instance: 146...
	 start solving instance: 95...
	 start solving instance: 134...
	 start solving instance: 107...
	 start solving instance: 108...
	 start solving instance: 140...
	 start solving instance: 90...
	 start solving instance: 83...
	 start solving instance: 126...
	 start solving instance: 13...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.154128320772073e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6624292352.0
		 entropy bonus: 0.22324705123901367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7022030336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7715845120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.154128430723236e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.154128320772073e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6624292352.0
		 entropy bonus: 0.22324705123901367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7022030336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7715845120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.154128430723236e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.154128320772073e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6624292352.0
		 entropy bonus: 0.22324705123901367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7022030336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7715845120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.154128430723236e+18 - Differentiable computation graph = True!
PPO iteration: 365/1000:
	 start solving instance: 97...
	 start solving instance: 13...
	 start solving instance: 36...
	 start solving instance: 23...
	 start solving instance: 134...
	 start solving instance: 107...
	 start solving instance: 146...
	 start solving instance: 95...
	 start solving instance: 57...
	 start solving instance: 26...
	 start solving instance: 89...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 83...
	 start solving instance: 69...
	 start solving instance: 90...
	 start solving instance: 140...
	 start solving instance: 108...
	 start solving instance: 58...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.031050748377432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6599132672.0
		 entropy bonus: 0.2198510617017746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6790139904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7369269760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.031050748377432e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.031050748377432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6599132672.0
		 entropy bonus: 0.2198510617017746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6790139904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7369269760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.031050748377432e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.031050748377432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6599132672.0
		 entropy bonus: 0.2198510617017746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6790139904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7369269760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.031050748377432e+18 - Differentiable computation graph = True!
PPO iteration: 366/1000:
	 start solving instance: 58...
	 start solving instance: 140...
	 start solving instance: 26...
	 start solving instance: 89...
	 start solving instance: 23...
	 start solving instance: 90...
	 start solving instance: 107...
	 start solving instance: 104...
	 start solving instance: 69...
	 start solving instance: 13...
	 start solving instance: 146...
	 start solving instance: 83...
	 start solving instance: 108...
	 start solving instance: 97...
	 start solving instance: 95...
	 start solving instance: 57...
	 start solving instance: 87...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0946649727233425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6665790464.0
		 entropy bonus: 0.21511144936084747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6807028736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7672829952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.094665192625668e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0946649727233425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6665790464.0
		 entropy bonus: 0.21511144936084747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6807028736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7672829952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.094665192625668e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0946649727233425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6665790464.0
		 entropy bonus: 0.21511144936084747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6807028736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7672829952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.094665192625668e+18 - Differentiable computation graph = True!
PPO iteration: 367/1000:
	 start solving instance: 87...
	 start solving instance: 83...
	 start solving instance: 90...
	 start solving instance: 36...
	 start solving instance: 108...
	 start solving instance: 57...
	 start solving instance: 126...
	 start solving instance: 89...
	 start solving instance: 107...
	 start solving instance: 146...
	 start solving instance: 97...
	 start solving instance: 23...
	 start solving instance: 95...
	 start solving instance: 69...
	 start solving instance: 58...
	 start solving instance: 13...
	 start solving instance: 26...
	 start solving instance: 134...
	 start solving instance: 104...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.099701615587859e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6666481664.0
		 entropy bonus: 0.22592134773731232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6871891456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7669582848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.099701505636696e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.099701615587859e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6666481664.0
		 entropy bonus: 0.22592134773731232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6871891456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7669582848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.099701505636696e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.099701615587859e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6666481664.0
		 entropy bonus: 0.22592134773731232
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6871891456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7669582848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.099701505636696e+18 - Differentiable computation graph = True!
PPO iteration: 368/1000:
	 start solving instance: 134...
	 start solving instance: 89...
	 start solving instance: 97...
	 start solving instance: 90...
	 start solving instance: 69...
	 start solving instance: 23...
	 start solving instance: 83...
	 start solving instance: 107...
	 start solving instance: 36...
	 start solving instance: 104...
	 start solving instance: 26...
	 start solving instance: 13...
	 start solving instance: 146...
	 start solving instance: 140...
	 start solving instance: 108...
	 start solving instance: 95...
	 start solving instance: 126...
	 start solving instance: 87...
	 start solving instance: 57...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.275556185920399e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6601568768.0
		 entropy bonus: 0.227292999625206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7148291072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7594671616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.275556295871562e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.275556185920399e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6601568768.0
		 entropy bonus: 0.227292999625206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7148291072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7594671616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.275556295871562e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.275556185920399e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6601568768.0
		 entropy bonus: 0.227292999625206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7148291072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7594671616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.275556295871562e+18 - Differentiable computation graph = True!
PPO iteration: 369/1000:
	 start solving instance: 126...
	 start solving instance: 146...
	 start solving instance: 89...
	 start solving instance: 97...
	 start solving instance: 108...
	 start solving instance: 95...
	 start solving instance: 107...
	 start solving instance: 140...
	 start solving instance: 13...
	 start solving instance: 36...
	 start solving instance: 104...
	 start solving instance: 58...
	 start solving instance: 134...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 90...
	 start solving instance: 87...
	 start solving instance: 23...
	 start solving instance: 69...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7134088759873634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6460236800.0
		 entropy bonus: 0.2245398610830307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6667534336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089168384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713408985938526e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7134088759873634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6460236800.0
		 entropy bonus: 0.2245398610830307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6667534336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089168384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713408985938526e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7134088759873634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6460236800.0
		 entropy bonus: 0.2245398610830307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6667534336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089168384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.713408985938526e+18 - Differentiable computation graph = True!
PPO iteration: 370/1000:
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 95...
	 start solving instance: 58...
	 start solving instance: 83...
	 start solving instance: 146...
	 start solving instance: 23...
	 start solving instance: 26...
	 start solving instance: 126...
	 start solving instance: 89...
	 start solving instance: 69...
	 start solving instance: 134...
	 start solving instance: 107...
	 start solving instance: 87...
	 start solving instance: 97...
	 start solving instance: 57...
	 start solving instance: 140...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.050761913230898e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6552929792.0
		 entropy bonus: 0.23197968304157257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6898454528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7580587520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.050762243084386e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.050761913230898e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6552929792.0
		 entropy bonus: 0.23197968304157257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6898454528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7580587520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.050762243084386e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.050761913230898e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6552929792.0
		 entropy bonus: 0.23197968304157257
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6898454528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7580587520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.050762243084386e+18 - Differentiable computation graph = True!
PPO iteration: 371/1000:
	 New training batch of size 20...
	 start solving instance: 53...
	 start solving instance: 144...
	 start solving instance: 52...
	 start solving instance: 89...
	 start solving instance: 130...
	 start solving instance: 7...
	 start solving instance: 31...
	 start solving instance: 112...
	 start solving instance: 27...
	 start solving instance: 40...
	 start solving instance: 50...
	 start solving instance: 3...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 101...
	 start solving instance: 72...
	 start solving instance: 18...
	 start solving instance: 67...
	 start solving instance: 147...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.319135333186011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530206208.0
		 entropy bonus: 0.1999853104352951
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5380196864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6231443456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.319135333186011e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.319135333186011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530206208.0
		 entropy bonus: 0.1999853104352951
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5380196864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6231443456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.319135333186011e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.319135333186011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530206208.0
		 entropy bonus: 0.1999853104352951
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5380196864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6231443456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.319135333186011e+18 - Differentiable computation graph = True!
PPO iteration: 372/1000:
	 start solving instance: 49...
	 start solving instance: 50...
	 start solving instance: 27...
	 start solving instance: 67...
	 start solving instance: 139...
	 start solving instance: 144...
	 start solving instance: 112...
	 start solving instance: 89...
	 start solving instance: 7...
	 start solving instance: 147...
	 start solving instance: 72...
	 start solving instance: 3...
	 start solving instance: 31...
	 start solving instance: 101...
	 start solving instance: 18...
	 start solving instance: 52...
	 start solving instance: 53...
	 start solving instance: 130...
	 start solving instance: 145...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.435672350711664e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5624232960.0
		 entropy bonus: 0.19468344748020172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518743040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6279631360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4356722957360824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.435672350711664e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5624232960.0
		 entropy bonus: 0.19468344748020172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518743040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6279631360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4356722957360824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.435672350711664e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5624232960.0
		 entropy bonus: 0.19468344748020172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518743040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6279631360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4356722957360824e+18 - Differentiable computation graph = True!
PPO iteration: 373/1000:
	 start solving instance: 18...
	 start solving instance: 7...
	 start solving instance: 144...
	 start solving instance: 112...
	 start solving instance: 31...
	 start solving instance: 52...
	 start solving instance: 3...
	 start solving instance: 101...
	 start solving instance: 72...
	 start solving instance: 27...
	 start solving instance: 53...
	 start solving instance: 67...
	 start solving instance: 40...
	 start solving instance: 145...
	 start solving instance: 147...
	 start solving instance: 139...
	 start solving instance: 130...
	 start solving instance: 50...
	 start solving instance: 89...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4502998136029446e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5717434880.0
		 entropy bonus: 0.1959436982870102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5494268416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6440188416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4502999235541074e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4502998136029446e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5717434880.0
		 entropy bonus: 0.1959436982870102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5494268416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6440188416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4502999235541074e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4502998136029446e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5717434880.0
		 entropy bonus: 0.1959436982870102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5494268416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6440188416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4502999235541074e+18 - Differentiable computation graph = True!
PPO iteration: 374/1000:
	 start solving instance: 145...
	 start solving instance: 101...
	 start solving instance: 49...
	 start solving instance: 53...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 72...
	 start solving instance: 3...
	 start solving instance: 18...
	 start solving instance: 27...
	 start solving instance: 112...
	 start solving instance: 40...
	 start solving instance: 130...
	 start solving instance: 50...
	 start solving instance: 147...
	 start solving instance: 7...
	 start solving instance: 139...
	 start solving instance: 67...
	 start solving instance: 31...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.375769637816474e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5634139136.0
		 entropy bonus: 0.2005910724401474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5420742656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204766720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.375769802743218e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.375769637816474e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5634139136.0
		 entropy bonus: 0.2005910724401474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5420742656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204766720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.375769802743218e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.375769637816474e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5634139136.0
		 entropy bonus: 0.2005910724401474
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5420742656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204766720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.375769802743218e+18 - Differentiable computation graph = True!
PPO iteration: 375/1000:
	 start solving instance: 53...
	 start solving instance: 67...
	 start solving instance: 72...
	 start solving instance: 112...
	 start solving instance: 139...
	 start solving instance: 147...
	 start solving instance: 40...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 50...
	 start solving instance: 101...
	 start solving instance: 49...
	 start solving instance: 145...
	 start solving instance: 52...
	 start solving instance: 31...
	 start solving instance: 27...
	 start solving instance: 144...
	 start solving instance: 3...
	 start solving instance: 89...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5148525810743247e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5729396224.0
		 entropy bonus: 0.20413093268871307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5589983744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6385359872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5148525260987433e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5148525810743247e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5729396224.0
		 entropy bonus: 0.20413093268871307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5589983744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6385359872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5148525260987433e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5148525810743247e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5729396224.0
		 entropy bonus: 0.20413093268871307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5589983744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6385359872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5148525260987433e+18 - Differentiable computation graph = True!
PPO iteration: 376/1000:
	 start solving instance: 18...
	 start solving instance: 67...
	 start solving instance: 7...
	 start solving instance: 72...
	 start solving instance: 31...
	 start solving instance: 130...
	 start solving instance: 139...
	 start solving instance: 40...
	 start solving instance: 52...
	 start solving instance: 101...
	 start solving instance: 112...
	 start solving instance: 145...
	 start solving instance: 49...
	 start solving instance: 147...
	 start solving instance: 27...
	 start solving instance: 144...
	 start solving instance: 50...
	 start solving instance: 89...
	 start solving instance: 53...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.411801953272647e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5565471232.0
		 entropy bonus: 0.19914628565311432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5482439680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6067357696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4118018982970655e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.411801953272647e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5565471232.0
		 entropy bonus: 0.19914628565311432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5482439680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6067357696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4118018982970655e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.411801953272647e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5565471232.0
		 entropy bonus: 0.19914628565311432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5482439680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6067357696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4118018982970655e+18 - Differentiable computation graph = True!
PPO iteration: 377/1000:
	 start solving instance: 49...
	 start solving instance: 27...
	 start solving instance: 72...
	 start solving instance: 147...
	 start solving instance: 139...
	 start solving instance: 130...
	 start solving instance: 52...
	 start solving instance: 101...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 40...
	 start solving instance: 31...
	 start solving instance: 7...
	 start solving instance: 3...
	 start solving instance: 53...
	 start solving instance: 112...
	 start solving instance: 144...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2604493398581182e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5556282880.0
		 entropy bonus: 0.20078983902931213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5283112448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5990518272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.260449449809281e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2604493398581182e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5556282880.0
		 entropy bonus: 0.20078983902931213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5283112448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5990518272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.260449449809281e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2604493398581182e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5556282880.0
		 entropy bonus: 0.20078983902931213
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5283112448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5990518272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.260449449809281e+18 - Differentiable computation graph = True!
PPO iteration: 378/1000:
	 start solving instance: 53...
	 start solving instance: 31...
	 start solving instance: 27...
	 start solving instance: 112...
	 start solving instance: 130...
	 start solving instance: 101...
	 start solving instance: 147...
	 start solving instance: 40...
	 start solving instance: 67...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 144...
	 start solving instance: 3...
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 72...
	 start solving instance: 50...
	 start solving instance: 52...
	 start solving instance: 145...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5530073937767563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702708736.0
		 entropy bonus: 0.2083422690629959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5570348544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6289450496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.553007503727919e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5530073937767563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702708736.0
		 entropy bonus: 0.2083422690629959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5570348544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6289450496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.553007503727919e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5530073937767563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702708736.0
		 entropy bonus: 0.2083422690629959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5570348544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6289450496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.553007503727919e+18 - Differentiable computation graph = True!
PPO iteration: 379/1000:
	 start solving instance: 145...
	 start solving instance: 72...
	 start solving instance: 130...
	 start solving instance: 52...
	 start solving instance: 67...
	 start solving instance: 49...
	 start solving instance: 27...
	 start solving instance: 101...
	 start solving instance: 112...
	 start solving instance: 139...
	 start solving instance: 31...
	 start solving instance: 18...
	 start solving instance: 7...
	 start solving instance: 89...
	 start solving instance: 147...
	 start solving instance: 53...
	 start solving instance: 40...
	 start solving instance: 50...
	 start solving instance: 144...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.412940387612046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5659771392.0
		 entropy bonus: 0.19096215069293976
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5466256896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6312176640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4129404425876275e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.412940387612046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5659771392.0
		 entropy bonus: 0.19096215069293976
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5466256896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6312176640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4129404425876275e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.412940387612046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5659771392.0
		 entropy bonus: 0.19096215069293976
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5466256896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6312176640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4129404425876275e+18 - Differentiable computation graph = True!
PPO iteration: 380/1000:
	 start solving instance: 27...
	 start solving instance: 18...
	 start solving instance: 89...
	 start solving instance: 3...
	 start solving instance: 144...
	 start solving instance: 145...
	 start solving instance: 130...
	 start solving instance: 53...
	 start solving instance: 52...
	 start solving instance: 112...
	 start solving instance: 31...
	 start solving instance: 101...
	 start solving instance: 7...
	 start solving instance: 67...
	 start solving instance: 139...
	 start solving instance: 72...
	 start solving instance: 50...
	 start solving instance: 40...
	 start solving instance: 49...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5418724196199432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5729367552.0
		 entropy bonus: 0.20703081786632538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5549966848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6720935424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5418724745955246e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5418724196199432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5729367552.0
		 entropy bonus: 0.20703081786632538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5549966848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6720935424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5418724745955246e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5418724196199432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5729367552.0
		 entropy bonus: 0.20703081786632538
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5549966848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6720935424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5418724745955246e+18 - Differentiable computation graph = True!
PPO iteration: 381/1000:
	 New training batch of size 20...
	 start solving instance: 20...
	 start solving instance: 140...
	 start solving instance: 79...
	 start solving instance: 69...
	 start solving instance: 101...
	 start solving instance: 46...
	 start solving instance: 108...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 31...
	 start solving instance: 147...
	 start solving instance: 134...
	 start solving instance: 25...
	 start solving instance: 96...
	 start solving instance: 4...
	 start solving instance: 93...
	 start solving instance: 21...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.157094695142005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998019584.0
		 entropy bonus: 0.22295594215393066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315670016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6954982912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1570948600687493e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.157094695142005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998019584.0
		 entropy bonus: 0.22295594215393066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315670016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6954982912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1570948600687493e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.157094695142005e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998019584.0
		 entropy bonus: 0.22295594215393066
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315670016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6954982912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1570948600687493e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.8363334002621284e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5258893824.0
		 entropy bonus: 0.19905732572078705
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4919602688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5836215296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2836333455237709824.0000
PPO iteration: 382/1000:
	 start solving instance: 31...
	 start solving instance: 69...
	 start solving instance: 25...
	 start solving instance: 4...
	 start solving instance: 46...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 93...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 132...
	 start solving instance: 36...
	 start solving instance: 140...
	 start solving instance: 108...
	 start solving instance: 21...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 96...
	 start solving instance: 20...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1384245478977176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6061529600.0
		 entropy bonus: 0.21889233589172363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6259969536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7221025280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.138424602873299e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1384245478977176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6061529600.0
		 entropy bonus: 0.21889233589172363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6259969536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7221025280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.138424602873299e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1384245478977176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6061529600.0
		 entropy bonus: 0.21889233589172363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6259969536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7221025280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.138424602873299e+18 - Differentiable computation graph = True!
PPO iteration: 383/1000:
	 start solving instance: 69...
	 start solving instance: 147...
	 start solving instance: 96...
	 start solving instance: 109...
	 start solving instance: 93...
	 start solving instance: 95...
	 start solving instance: 117...
	 start solving instance: 79...
	 start solving instance: 31...
	 start solving instance: 132...
	 start solving instance: 108...
	 start solving instance: 21...
	 start solving instance: 101...
	 start solving instance: 134...
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 4...
	 start solving instance: 46...
	 start solving instance: 140...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.364647306094025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6128506880.0
		 entropy bonus: 0.22179506719112396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6422068224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7132950528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3646474710207693e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.364647306094025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6208288256.0
		 entropy bonus: 0.21794424951076508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6422068224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7132950528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3646474710207693e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.364647306094025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6128506880.0
		 entropy bonus: 0.22179506719112396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6422068224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7132950528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3646474710207693e+18 - Differentiable computation graph = True!
PPO iteration: 384/1000:
	 start solving instance: 4...
	 start solving instance: 20...
	 start solving instance: 109...
	 start solving instance: 132...
	 start solving instance: 117...
	 start solving instance: 31...
	 start solving instance: 46...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 96...
	 start solving instance: 108...
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 93...
	 start solving instance: 140...
	 start solving instance: 134...
	 start solving instance: 69...
	 start solving instance: 25...
	 start solving instance: 95...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.004443778397399e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6088513024.0
		 entropy bonus: 0.21255691349506378
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053040128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6892812288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0044438883485614e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.004443778397399e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6088513024.0
		 entropy bonus: 0.21255691349506378
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053040128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6892812288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0044438883485614e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.004443778397399e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6088513024.0
		 entropy bonus: 0.21255691349506378
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053040128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6892812288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0044438883485614e+18 - Differentiable computation graph = True!
PPO iteration: 385/1000:
	 start solving instance: 147...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 79...
	 start solving instance: 69...
	 start solving instance: 132...
	 start solving instance: 134...
	 start solving instance: 25...
	 start solving instance: 21...
	 start solving instance: 108...
	 start solving instance: 31...
	 start solving instance: 96...
	 start solving instance: 4...
	 start solving instance: 20...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 140...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.132405821247272e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112114688.0
		 entropy bonus: 0.2159724235534668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6264772608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6874544128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.132405876222853e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.132405821247272e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112114688.0
		 entropy bonus: 0.2159724235534668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6264772608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6874544128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.132405876222853e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.132405821247272e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112114688.0
		 entropy bonus: 0.2159724235534668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6264772608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6874544128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.132405876222853e+18 - Differentiable computation graph = True!
PPO iteration: 386/1000:
	 start solving instance: 93...
	 start solving instance: 140...
	 start solving instance: 21...
	 start solving instance: 20...
	 start solving instance: 79...
	 start solving instance: 96...
	 start solving instance: 4...
	 start solving instance: 108...
	 start solving instance: 147...
	 start solving instance: 31...
	 start solving instance: 109...
	 start solving instance: 25...
	 start solving instance: 46...
	 start solving instance: 117...
	 start solving instance: 134...
	 start solving instance: 132...
	 start solving instance: 69...
	 start solving instance: 36...
	 start solving instance: 95...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3885550869283865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112178176.0
		 entropy bonus: 0.2302609533071518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6469985792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7144595456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3885552518551306e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3885550869283865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112178176.0
		 entropy bonus: 0.2302609533071518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6469985792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7144595456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3885552518551306e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3885550869283865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112178176.0
		 entropy bonus: 0.2302609533071518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6469985792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7144595456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3885552518551306e+18 - Differentiable computation graph = True!
PPO iteration: 387/1000:
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 109...
	 start solving instance: 25...
	 start solving instance: 4...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 95...
	 start solving instance: 117...
	 start solving instance: 46...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 132...
	 start solving instance: 69...
	 start solving instance: 21...
	 start solving instance: 93...
	 start solving instance: 31...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.247045301605709e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099136512.0
		 entropy bonus: 0.21502219140529633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6310768128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7145428480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.24704535658129e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.247045301605709e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099136512.0
		 entropy bonus: 0.21502219140529633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6310768128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7145428480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.24704535658129e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.247045301605709e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099136512.0
		 entropy bonus: 0.21502219140529633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6310768128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7145428480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.24704535658129e+18 - Differentiable computation graph = True!
PPO iteration: 388/1000:
	 start solving instance: 96...
	 start solving instance: 132...
	 start solving instance: 36...
	 start solving instance: 109...
	 start solving instance: 140...
	 start solving instance: 20...
	 start solving instance: 25...
	 start solving instance: 69...
	 start solving instance: 108...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 4...
	 start solving instance: 147...
	 start solving instance: 101...
	 start solving instance: 46...
	 start solving instance: 93...
	 start solving instance: 95...
	 start solving instance: 79...
	 start solving instance: 31...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.297895075562442e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6130716160.0
		 entropy bonus: 0.20640356838703156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6394630144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7249203712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2978950205868605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.297895075562442e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6130716160.0
		 entropy bonus: 0.20640356838703156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6394630144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7249203712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2978950205868605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.297895075562442e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6130716160.0
		 entropy bonus: 0.20640356838703156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6394630144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7249203712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2978950205868605e+18 - Differentiable computation graph = True!
PPO iteration: 389/1000:
	 start solving instance: 36...
	 start solving instance: 20...
	 start solving instance: 117...
	 start solving instance: 46...
	 start solving instance: 109...
	 start solving instance: 132...
	 start solving instance: 69...
	 start solving instance: 93...
	 start solving instance: 4...
	 start solving instance: 79...
	 start solving instance: 21...
	 start solving instance: 134...
	 start solving instance: 95...
	 start solving instance: 108...
	 start solving instance: 140...
	 start solving instance: 25...
	 start solving instance: 31...
	 start solving instance: 147...
	 start solving instance: 96...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.037366674970221e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5954304512.0
		 entropy bonus: 0.21716494858264923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6126431744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172032512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037366839896965e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.037366674970221e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5954304512.0
		 entropy bonus: 0.21716494858264923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6126431744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172032512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037366839896965e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.037366674970221e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5954304512.0
		 entropy bonus: 0.21716494858264923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6126431744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172032512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037366839896965e+18 - Differentiable computation graph = True!
PPO iteration: 390/1000:
	 start solving instance: 69...
	 start solving instance: 140...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 134...
	 start solving instance: 96...
	 start solving instance: 147...
	 start solving instance: 46...
	 start solving instance: 93...
	 start solving instance: 132...
	 start solving instance: 109...
	 start solving instance: 31...
	 start solving instance: 79...
	 start solving instance: 20...
	 start solving instance: 108...
	 start solving instance: 101...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 36...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.282588994094498e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113151488.0
		 entropy bonus: 0.2252431958913803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6384958464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6966264320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.282588994094498e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.282588994094498e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113151488.0
		 entropy bonus: 0.2252431958913803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6384958464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6966264320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.282588994094498e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.282588994094498e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113151488.0
		 entropy bonus: 0.2252431958913803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6384958464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6966264320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.282588994094498e+18 - Differentiable computation graph = True!
PPO iteration: 391/1000:
	 New training batch of size 20...
	 start solving instance: 57...
	 start solving instance: 96...
	 start solving instance: 127...
	 start solving instance: 7...
	 start solving instance: 138...
	 start solving instance: 64...
	 start solving instance: 45...
	 start solving instance: 14...
	 start solving instance: 108...
	 start solving instance: 36...
	 start solving instance: 117...
	 start solving instance: 34...
	 start solving instance: 19...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 89...
	 start solving instance: 110...
	 start solving instance: 133...
	 start solving instance: 115...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.900539049963264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5664192000.0
		 entropy bonus: 0.2170579731464386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922037248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6910960640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9005392148900086e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.900539049963264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5664192000.0
		 entropy bonus: 0.2170579731464386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922037248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6910960640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9005392148900086e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.900539049963264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5664192000.0
		 entropy bonus: 0.2170579731464386
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922037248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6910960640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9005392148900086e+18 - Differentiable computation graph = True!
PPO iteration: 392/1000:
	 start solving instance: 64...
	 start solving instance: 115...
	 start solving instance: 36...
	 start solving instance: 117...
	 start solving instance: 19...
	 start solving instance: 96...
	 start solving instance: 101...
	 start solving instance: 133...
	 start solving instance: 7...
	 start solving instance: 127...
	 start solving instance: 45...
	 start solving instance: 138...
	 start solving instance: 34...
	 start solving instance: 108...
	 start solving instance: 89...
	 start solving instance: 118...
	 start solving instance: 57...
	 start solving instance: 97...
	 start solving instance: 110...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4765042543254045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5610857472.0
		 entropy bonus: 0.212672621011734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5476040192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6521170432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.476504309300986e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4765042543254045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5610857472.0
		 entropy bonus: 0.212672621011734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5476040192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6521170432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.476504309300986e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4765042543254045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5610857472.0
		 entropy bonus: 0.212672621011734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5476040192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6521170432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.476504309300986e+18 - Differentiable computation graph = True!
PPO iteration: 393/1000:
	 start solving instance: 34...
	 start solving instance: 118...
	 start solving instance: 14...
	 start solving instance: 108...
	 start solving instance: 110...
	 start solving instance: 127...
	 start solving instance: 101...
	 start solving instance: 133...
	 start solving instance: 36...
	 start solving instance: 64...
	 start solving instance: 97...
	 start solving instance: 138...
	 start solving instance: 7...
	 start solving instance: 115...
	 start solving instance: 45...
	 start solving instance: 57...
	 start solving instance: 96...
	 start solving instance: 117...
	 start solving instance: 19...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.686199153732983e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5699399168.0
		 entropy bonus: 0.21904781460762024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5674743296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6785906688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6861993186597274e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.686199153732983e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5699399168.0
		 entropy bonus: 0.21904781460762024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5674743296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6785906688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6861993186597274e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.686199153732983e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5699399168.0
		 entropy bonus: 0.21904781460762024
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5674743296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6785906688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6861993186597274e+18 - Differentiable computation graph = True!
PPO iteration: 394/1000:
	 start solving instance: 64...
	 start solving instance: 36...
	 start solving instance: 138...
	 start solving instance: 133...
	 start solving instance: 115...
	 start solving instance: 108...
	 start solving instance: 45...
	 start solving instance: 110...
	 start solving instance: 127...
	 start solving instance: 96...
	 start solving instance: 118...
	 start solving instance: 19...
	 start solving instance: 34...
	 start solving instance: 14...
	 start solving instance: 89...
	 start solving instance: 101...
	 start solving instance: 97...
	 start solving instance: 57...
	 start solving instance: 117...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9049810769394794e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5707456512.0
		 entropy bonus: 0.22333014011383057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5928828416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179676672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9049812418662236e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9049810769394794e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5707456512.0
		 entropy bonus: 0.22333014011383057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5928828416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179676672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9049812418662236e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9049810769394794e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5707456512.0
		 entropy bonus: 0.22333014011383057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5928828416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179676672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9049812418662236e+18 - Differentiable computation graph = True!
PPO iteration: 395/1000:
	 start solving instance: 7...
	 start solving instance: 96...
	 start solving instance: 64...
	 start solving instance: 19...
	 start solving instance: 115...
	 start solving instance: 57...
	 start solving instance: 133...
	 start solving instance: 36...
	 start solving instance: 108...
	 start solving instance: 14...
	 start solving instance: 101...
	 start solving instance: 45...
	 start solving instance: 97...
	 start solving instance: 118...
	 start solving instance: 110...
	 start solving instance: 138...
	 start solving instance: 117...
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.630821810795394e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5732683264.0
		 entropy bonus: 0.21725964546203613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5627316736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504182272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.630821865770975e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.630821810795394e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5732683264.0
		 entropy bonus: 0.21725964546203613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5627316736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504182272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.630821865770975e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.630821810795394e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5732683264.0
		 entropy bonus: 0.21725964546203613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5627316736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504182272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.630821865770975e+18 - Differentiable computation graph = True!
PPO iteration: 396/1000:
	 start solving instance: 133...
	 start solving instance: 117...
	 start solving instance: 127...
	 start solving instance: 45...
	 start solving instance: 96...
	 start solving instance: 7...
	 start solving instance: 14...
	 start solving instance: 115...
	 start solving instance: 36...
	 start solving instance: 110...
	 start solving instance: 138...
	 start solving instance: 108...
	 start solving instance: 89...
	 start solving instance: 97...
	 start solving instance: 101...
	 start solving instance: 34...
	 start solving instance: 19...
	 start solving instance: 57...
	 start solving instance: 118...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.742168473730967e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715968000.0
		 entropy bonus: 0.2208334505558014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5811704320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779024896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.74216858368213e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.742168473730967e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715968000.0
		 entropy bonus: 0.2208334505558014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5811704320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779024896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.74216858368213e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.742168473730967e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715968000.0
		 entropy bonus: 0.2208334505558014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5811704320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779024896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.74216858368213e+18 - Differentiable computation graph = True!
PPO iteration: 397/1000:
	 start solving instance: 101...
	 start solving instance: 19...
	 start solving instance: 89...
	 start solving instance: 64...
	 start solving instance: 133...
	 start solving instance: 34...
	 start solving instance: 14...
	 start solving instance: 110...
	 start solving instance: 117...
	 start solving instance: 118...
	 start solving instance: 115...
	 start solving instance: 108...
	 start solving instance: 36...
	 start solving instance: 97...
	 start solving instance: 138...
	 start solving instance: 57...
	 start solving instance: 96...
	 start solving instance: 7...
	 start solving instance: 45...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.413621205211965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5703833088.0
		 entropy bonus: 0.21363584697246552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5467935744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6546903552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.413621315163128e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.413621205211965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5703833088.0
		 entropy bonus: 0.21363584697246552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5467935744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6546903552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.413621315163128e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.413621205211965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5703833088.0
		 entropy bonus: 0.21363584697246552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5467935744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6546903552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.413621315163128e+18 - Differentiable computation graph = True!
PPO iteration: 398/1000:
	 start solving instance: 89...
	 start solving instance: 64...
	 start solving instance: 57...
	 start solving instance: 110...
	 start solving instance: 117...
	 start solving instance: 19...
	 start solving instance: 108...
	 start solving instance: 133...
	 start solving instance: 45...
	 start solving instance: 101...
	 start solving instance: 96...
	 start solving instance: 115...
	 start solving instance: 138...
	 start solving instance: 14...
	 start solving instance: 97...
	 start solving instance: 7...
	 start solving instance: 118...
	 start solving instance: 127...
	 start solving instance: 34...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4696811249680777e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5597694464.0
		 entropy bonus: 0.22407177090644836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5522523136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6354494464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.469681289894822e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4696811249680777e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5597694464.0
		 entropy bonus: 0.22407177090644836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5522523136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6354494464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.469681289894822e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4696811249680777e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5597694464.0
		 entropy bonus: 0.22407177090644836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5522523136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6354494464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.469681289894822e+18 - Differentiable computation graph = True!
PPO iteration: 399/1000:
	 start solving instance: 97...
	 start solving instance: 110...
	 start solving instance: 64...
	 start solving instance: 138...
	 start solving instance: 36...
	 start solving instance: 118...
	 start solving instance: 89...
	 start solving instance: 127...
	 start solving instance: 133...
	 start solving instance: 101...
	 start solving instance: 96...
	 start solving instance: 34...
	 start solving instance: 115...
	 start solving instance: 14...
	 start solving instance: 108...
	 start solving instance: 45...
	 start solving instance: 7...
	 start solving instance: 117...
	 start solving instance: 57...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.687138136663104e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5703953920.0
		 entropy bonus: 0.2079106569290161
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5705561088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6547792384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.687138301589848e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.687138136663104e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5703953920.0
		 entropy bonus: 0.2079106569290161
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5705561088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6547792384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.687138301589848e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.687138136663104e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5703953920.0
		 entropy bonus: 0.2079106569290161
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5705561088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6547792384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.687138301589848e+18 - Differentiable computation graph = True!
PPO iteration: 400/1000:
	 start solving instance: 118...
	 start solving instance: 64...
	 start solving instance: 108...
	 start solving instance: 138...
	 start solving instance: 45...
	 start solving instance: 89...
	 start solving instance: 101...
	 start solving instance: 133...
	 start solving instance: 14...
	 start solving instance: 115...
	 start solving instance: 96...
	 start solving instance: 57...
	 start solving instance: 36...
	 start solving instance: 19...
	 start solving instance: 127...
	 start solving instance: 7...
	 start solving instance: 110...
	 start solving instance: 117...
	 start solving instance: 97...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.773065190276124e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5760711168.0
		 entropy bonus: 0.2213820517063141
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5747820032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6748538368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7730651353005425e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.773065190276124e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5760711168.0
		 entropy bonus: 0.2213820517063141
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5747820032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6748538368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7730651353005425e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.773065190276124e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5760711168.0
		 entropy bonus: 0.2213820517063141
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5747820032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6748538368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7730651353005425e+18 - Differentiable computation graph = True!
PPO iteration: 401/1000:
	 New training batch of size 20...
	 start solving instance: 129...
	 start solving instance: 52...
	 start solving instance: 28...
	 start solving instance: 115...
	 start solving instance: 22...
	 start solving instance: 53...
	 start solving instance: 34...
	 start solving instance: 17...
	 start solving instance: 150...
	 start solving instance: 149...
	 start solving instance: 120...
	 start solving instance: 112...
	 start solving instance: 102...
	 start solving instance: 125...
	 start solving instance: 27...
	 start solving instance: 107...
	 start solving instance: 26...
	 start solving instance: 47...
	 start solving instance: 46...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.91208700068747e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5996752384.0
		 entropy bonus: 0.22456958889961243
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6063377408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6686945280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.912087110638633e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.91208700068747e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5996752384.0
		 entropy bonus: 0.22456958889961243
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6063377408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6686945280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.912087110638633e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.91208700068747e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5996752384.0
		 entropy bonus: 0.22456958889961243
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6063377408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6686945280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.912087110638633e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9981898681591267e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5200930816.0
		 entropy bonus: 0.21025431156158447
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5067512320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5792478208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2998189813183545344.0000
PPO iteration: 402/1000:
	 start solving instance: 120...
	 start solving instance: 47...
	 start solving instance: 53...
	 start solving instance: 28...
	 start solving instance: 34...
	 start solving instance: 112...
	 start solving instance: 115...
	 start solving instance: 52...
	 start solving instance: 27...
	 start solving instance: 150...
	 start solving instance: 26...
	 start solving instance: 17...
	 start solving instance: 129...
	 start solving instance: 149...
	 start solving instance: 22...
	 start solving instance: 46...
	 start solving instance: 107...
	 start solving instance: 142...
	 start solving instance: 102...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.807695408504557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027132928.0
		 entropy bonus: 0.2102576047182083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5927322624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6433282048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8076953535289754e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.807695408504557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027132928.0
		 entropy bonus: 0.2102576047182083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5927322624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6433282048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8076953535289754e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.807695408504557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027132928.0
		 entropy bonus: 0.2102576047182083
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5927322624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6433282048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8076953535289754e+18 - Differentiable computation graph = True!
PPO iteration: 403/1000:
	 start solving instance: 142...
	 start solving instance: 47...
	 start solving instance: 115...
	 start solving instance: 26...
	 start solving instance: 150...
	 start solving instance: 53...
	 start solving instance: 112...
	 start solving instance: 120...
	 start solving instance: 34...
	 start solving instance: 46...
	 start solving instance: 52...
	 start solving instance: 17...
	 start solving instance: 149...
	 start solving instance: 107...
	 start solving instance: 27...
	 start solving instance: 28...
	 start solving instance: 22...
	 start solving instance: 125...
	 start solving instance: 129...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.945430790311405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5935797248.0
		 entropy bonus: 0.22116370499134064
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018608640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6500025856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.945430900262568e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.945430790311405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5935797248.0
		 entropy bonus: 0.22116370499134064
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018608640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6500025856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.945430900262568e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.945430790311405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5935797248.0
		 entropy bonus: 0.22116370499134064
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018608640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6500025856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.945430900262568e+18 - Differentiable computation graph = True!
PPO iteration: 404/1000:
	 start solving instance: 28...
	 start solving instance: 149...
	 start solving instance: 129...
	 start solving instance: 142...
	 start solving instance: 107...
	 start solving instance: 34...
	 start solving instance: 46...
	 start solving instance: 115...
	 start solving instance: 17...
	 start solving instance: 27...
	 start solving instance: 125...
	 start solving instance: 120...
	 start solving instance: 22...
	 start solving instance: 52...
	 start solving instance: 53...
	 start solving instance: 47...
	 start solving instance: 26...
	 start solving instance: 150...
	 start solving instance: 102...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.945849924143913e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6035416576.0
		 entropy bonus: 0.2203667163848877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032737792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6755471360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9458500890706575e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.945849924143913e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6035416576.0
		 entropy bonus: 0.2203667163848877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032737792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6755471360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9458500890706575e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.945849924143913e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6035416576.0
		 entropy bonus: 0.2203667163848877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032737792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6755471360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9458500890706575e+18 - Differentiable computation graph = True!
PPO iteration: 405/1000:
	 start solving instance: 22...
	 start solving instance: 34...
	 start solving instance: 142...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 107...
	 start solving instance: 120...
	 start solving instance: 17...
	 start solving instance: 149...
	 start solving instance: 125...
	 start solving instance: 129...
	 start solving instance: 115...
	 start solving instance: 150...
	 start solving instance: 102...
	 start solving instance: 27...
	 start solving instance: 53...
	 start solving instance: 112...
	 start solving instance: 46...
	 start solving instance: 52...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.116834977379359e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031674880.0
		 entropy bonus: 0.21710996329784393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6272242176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6909969920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1168351423061033e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.116834977379359e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031674880.0
		 entropy bonus: 0.21710996329784393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6272242176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6909969920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1168351423061033e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.116834977379359e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6031674880.0
		 entropy bonus: 0.21710996329784393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6272242176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6909969920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1168351423061033e+18 - Differentiable computation graph = True!
PPO iteration: 406/1000:
	 start solving instance: 129...
	 start solving instance: 149...
	 start solving instance: 112...
	 start solving instance: 17...
	 start solving instance: 102...
	 start solving instance: 52...
	 start solving instance: 120...
	 start solving instance: 150...
	 start solving instance: 27...
	 start solving instance: 28...
	 start solving instance: 107...
	 start solving instance: 142...
	 start solving instance: 47...
	 start solving instance: 26...
	 start solving instance: 22...
	 start solving instance: 53...
	 start solving instance: 125...
	 start solving instance: 34...
	 start solving instance: 46...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8807284892586476e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113560064.0
		 entropy bonus: 0.20844407379627228
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970132480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6695302656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8807284892586476e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8807284892586476e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113560064.0
		 entropy bonus: 0.20844407379627228
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970132480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6695302656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8807284892586476e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8807284892586476e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6113560064.0
		 entropy bonus: 0.20844407379627228
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970132480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6695302656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8807284892586476e+18 - Differentiable computation graph = True!
PPO iteration: 407/1000:
	 start solving instance: 115...
	 start solving instance: 47...
	 start solving instance: 27...
	 start solving instance: 150...
	 start solving instance: 53...
	 start solving instance: 52...
	 start solving instance: 125...
	 start solving instance: 149...
	 start solving instance: 46...
	 start solving instance: 142...
	 start solving instance: 22...
	 start solving instance: 102...
	 start solving instance: 28...
	 start solving instance: 17...
	 start solving instance: 34...
	 start solving instance: 26...
	 start solving instance: 107...
	 start solving instance: 120...
	 start solving instance: 129...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1760304843955634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024911360.0
		 entropy bonus: 0.22010338306427002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6350140928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6939573248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1760306493223076e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1760304843955634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024911360.0
		 entropy bonus: 0.22010338306427002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6350140928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6939573248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1760306493223076e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1760304843955634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024911360.0
		 entropy bonus: 0.22010338306427002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6350140928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6939573248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1760306493223076e+18 - Differentiable computation graph = True!
PPO iteration: 408/1000:
	 start solving instance: 107...
	 start solving instance: 149...
	 start solving instance: 112...
	 start solving instance: 17...
	 start solving instance: 125...
	 start solving instance: 47...
	 start solving instance: 129...
	 start solving instance: 34...
	 start solving instance: 142...
	 start solving instance: 115...
	 start solving instance: 27...
	 start solving instance: 26...
	 start solving instance: 120...
	 start solving instance: 53...
	 start solving instance: 22...
	 start solving instance: 150...
	 start solving instance: 52...
	 start solving instance: 46...
	 start solving instance: 102...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.924041770713953e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5893916160.0
		 entropy bonus: 0.21839968860149384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6061256704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6634721280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9240418256895345e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.924041770713953e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5893916160.0
		 entropy bonus: 0.21839968860149384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6061256704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6634721280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9240418256895345e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.924041770713953e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5893916160.0
		 entropy bonus: 0.21839968860149384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6061256704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6634721280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9240418256895345e+18 - Differentiable computation graph = True!
PPO iteration: 409/1000:
	 start solving instance: 52...
	 start solving instance: 26...
	 start solving instance: 46...
	 start solving instance: 17...
	 start solving instance: 34...
	 start solving instance: 150...
	 start solving instance: 142...
	 start solving instance: 125...
	 start solving instance: 47...
	 start solving instance: 53...
	 start solving instance: 27...
	 start solving instance: 107...
	 start solving instance: 149...
	 start solving instance: 28...
	 start solving instance: 120...
	 start solving instance: 112...
	 start solving instance: 129...
	 start solving instance: 115...
	 start solving instance: 22...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.110044833370866e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027280896.0
		 entropy bonus: 0.21207068860530853
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6310221312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6921651712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1100448333708657e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.110044833370866e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027280896.0
		 entropy bonus: 0.21207068860530853
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6310221312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6921651712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1100448333708657e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.110044833370866e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6027280896.0
		 entropy bonus: 0.21207068860530853
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6310221312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6921651712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1100448333708657e+18 - Differentiable computation graph = True!
PPO iteration: 410/1000:
	 start solving instance: 26...
	 start solving instance: 47...
	 start solving instance: 107...
	 start solving instance: 102...
	 start solving instance: 150...
	 start solving instance: 34...
	 start solving instance: 120...
	 start solving instance: 52...
	 start solving instance: 149...
	 start solving instance: 17...
	 start solving instance: 125...
	 start solving instance: 142...
	 start solving instance: 28...
	 start solving instance: 46...
	 start solving instance: 129...
	 start solving instance: 22...
	 start solving instance: 112...
	 start solving instance: 27...
	 start solving instance: 53...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.07296578284505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099659776.0
		 entropy bonus: 0.21803632378578186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6197159424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6751484928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0729657278694687e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.07296578284505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099659776.0
		 entropy bonus: 0.21803632378578186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6197159424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6751484928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0729657278694687e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.07296578284505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099659776.0
		 entropy bonus: 0.21803632378578186
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6197159424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6751484928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0729657278694687e+18 - Differentiable computation graph = True!
PPO iteration: 411/1000:
	 New training batch of size 20...
	 start solving instance: 17...
	 start solving instance: 99...
	 start solving instance: 32...
	 start solving instance: 105...
	 start solving instance: 63...
	 start solving instance: 5...
	 start solving instance: 34...
	 start solving instance: 67...
	 start solving instance: 45...
	 start solving instance: 90...
	 start solving instance: 42...
	 start solving instance: 97...
	 start solving instance: 84...
	 start solving instance: 85...
	 start solving instance: 83...
	 start solving instance: 92...
	 start solving instance: 128...
	 start solving instance: 35...
	 start solving instance: 111...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.380960540213012e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6243782656.0
		 entropy bonus: 0.2130858451128006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6384243200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6951188480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380960650164175e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.380960540213012e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6243782656.0
		 entropy bonus: 0.2130858451128006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6384243200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6951188480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380960650164175e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.380960540213012e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6243782656.0
		 entropy bonus: 0.2130858451128006
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6384243200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6951188480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380960650164175e+18 - Differentiable computation graph = True!
PPO iteration: 412/1000:
	 start solving instance: 67...
	 start solving instance: 99...
	 start solving instance: 84...
	 start solving instance: 111...
	 start solving instance: 115...
	 start solving instance: 32...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 85...
	 start solving instance: 97...
	 start solving instance: 83...
	 start solving instance: 90...
	 start solving instance: 42...
	 start solving instance: 105...
	 start solving instance: 45...
	 start solving instance: 34...
	 start solving instance: 128...
	 start solving instance: 63...
	 start solving instance: 17...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.407289005847085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6311126528.0
		 entropy bonus: 0.20157156884670258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6397978112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7255214080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.407289005847085e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.407289005847085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6311126528.0
		 entropy bonus: 0.20157156884670258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6397978112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7255214080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.407289005847085e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.407289005847085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6311126528.0
		 entropy bonus: 0.20157156884670258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6397978112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7255214080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.407289005847085e+18 - Differentiable computation graph = True!
PPO iteration: 413/1000:
	 start solving instance: 90...
	 start solving instance: 85...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 83...
	 start solving instance: 45...
	 start solving instance: 34...
	 start solving instance: 128...
	 start solving instance: 42...
	 start solving instance: 99...
	 start solving instance: 5...
	 start solving instance: 111...
	 start solving instance: 32...
	 start solving instance: 115...
	 start solving instance: 67...
	 start solving instance: 97...
	 start solving instance: 105...
	 start solving instance: 17...
	 start solving instance: 84...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.278246802774085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6240677376.0
		 entropy bonus: 0.2003064602613449
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315585024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6980397056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2782467477985034e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.278246802774085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6240677376.0
		 entropy bonus: 0.2003064602613449
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315585024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6980397056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2782467477985034e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.278246802774085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6240677376.0
		 entropy bonus: 0.2003064602613449
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315585024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6980397056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2782467477985034e+18 - Differentiable computation graph = True!
PPO iteration: 414/1000:
	 start solving instance: 32...
	 start solving instance: 128...
	 start solving instance: 45...
	 start solving instance: 97...
	 start solving instance: 83...
	 start solving instance: 85...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 90...
	 start solving instance: 35...
	 start solving instance: 34...
	 start solving instance: 111...
	 start solving instance: 99...
	 start solving instance: 67...
	 start solving instance: 84...
	 start solving instance: 5...
	 start solving instance: 92...
	 start solving instance: 42...
	 start solving instance: 17...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.183493529520256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6228185088.0
		 entropy bonus: 0.20861676335334778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6314676736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6340940288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.183493584495837e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.183493529520256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6228185088.0
		 entropy bonus: 0.20861676335334778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6314676736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6340940288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.183493584495837e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.183493529520256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6228185088.0
		 entropy bonus: 0.20861676335334778
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6314676736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6340940288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.183493584495837e+18 - Differentiable computation graph = True!
PPO iteration: 415/1000:
	 start solving instance: 32...
	 start solving instance: 128...
	 start solving instance: 42...
	 start solving instance: 17...
	 start solving instance: 99...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 97...
	 start solving instance: 105...
	 start solving instance: 83...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 67...
	 start solving instance: 45...
	 start solving instance: 35...
	 start solving instance: 84...
	 start solving instance: 5...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.516372873852695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6311043072.0
		 entropy bonus: 0.2062329351902008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6570244608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7251526144.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5163729288282767e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.516372873852695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6311043072.0
		 entropy bonus: 0.2062329351902008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6570244608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7251526144.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5163729288282767e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.516372873852695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6311043072.0
		 entropy bonus: 0.2062329351902008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6570244608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7251526144.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5163729288282767e+18 - Differentiable computation graph = True!
PPO iteration: 416/1000:
	 start solving instance: 128...
	 start solving instance: 45...
	 start solving instance: 90...
	 start solving instance: 17...
	 start solving instance: 32...
	 start solving instance: 92...
	 start solving instance: 35...
	 start solving instance: 84...
	 start solving instance: 111...
	 start solving instance: 42...
	 start solving instance: 5...
	 start solving instance: 83...
	 start solving instance: 85...
	 start solving instance: 67...
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 105...
	 start solving instance: 63...
	 start solving instance: 115...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.312578833449065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6291641856.0
		 entropy bonus: 0.2002549022436142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6269476352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6943716352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.312578998375809e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.312578833449065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6291641856.0
		 entropy bonus: 0.2002549022436142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6269476352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6943716352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.312578998375809e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.312578833449065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6291641856.0
		 entropy bonus: 0.2002549022436142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6269476352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6943716352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.312578998375809e+18 - Differentiable computation graph = True!
PPO iteration: 417/1000:
	 start solving instance: 85...
	 start solving instance: 90...
	 start solving instance: 105...
	 start solving instance: 63...
	 start solving instance: 99...
	 start solving instance: 115...
	 start solving instance: 128...
	 start solving instance: 83...
	 start solving instance: 32...
	 start solving instance: 97...
	 start solving instance: 42...
	 start solving instance: 34...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 17...
	 start solving instance: 84...
	 start solving instance: 67...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.341351293529358e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6348152320.0
		 entropy bonus: 0.20968464016914368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6362010112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6787551744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3413512935293583e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.341351293529358e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6348152320.0
		 entropy bonus: 0.20968464016914368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6362010112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6787551744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3413512935293583e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.341351293529358e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6348152320.0
		 entropy bonus: 0.20968464016914368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6362010112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6787551744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3413512935293583e+18 - Differentiable computation graph = True!
PPO iteration: 418/1000:
	 start solving instance: 105...
	 start solving instance: 90...
	 start solving instance: 92...
	 start solving instance: 17...
	 start solving instance: 32...
	 start solving instance: 63...
	 start solving instance: 97...
	 start solving instance: 67...
	 start solving instance: 42...
	 start solving instance: 115...
	 start solving instance: 5...
	 start solving instance: 99...
	 start solving instance: 45...
	 start solving instance: 111...
	 start solving instance: 83...
	 start solving instance: 128...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 84...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.387144193607624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6323053568.0
		 entropy bonus: 0.2047504037618637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6431734272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7025254400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.387144303558787e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.387144193607624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6323053568.0
		 entropy bonus: 0.2047504037618637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6431734272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7025254400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.387144303558787e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.387144193607624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6323053568.0
		 entropy bonus: 0.2047504037618637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6431734272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7025254400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.387144303558787e+18 - Differentiable computation graph = True!
PPO iteration: 419/1000:
	 start solving instance: 99...
	 start solving instance: 32...
	 start solving instance: 34...
	 start solving instance: 90...
	 start solving instance: 83...
	 start solving instance: 45...
	 start solving instance: 63...
	 start solving instance: 92...
	 start solving instance: 35...
	 start solving instance: 105...
	 start solving instance: 111...
	 start solving instance: 5...
	 start solving instance: 85...
	 start solving instance: 17...
	 start solving instance: 84...
	 start solving instance: 42...
	 start solving instance: 115...
	 start solving instance: 97...
	 start solving instance: 128...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.710539590443519e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6488192512.0
		 entropy bonus: 0.20646750926971436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6615030272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7157723136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.710539810345845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.710539590443519e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6488192512.0
		 entropy bonus: 0.20646750926971436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6615030272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7157723136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.710539810345845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.710539590443519e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6488192512.0
		 entropy bonus: 0.20646750926971436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6615030272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7157723136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.710539810345845e+18 - Differentiable computation graph = True!
PPO iteration: 420/1000:
	 start solving instance: 35...
	 start solving instance: 111...
	 start solving instance: 67...
	 start solving instance: 105...
	 start solving instance: 128...
	 start solving instance: 5...
	 start solving instance: 32...
	 start solving instance: 84...
	 start solving instance: 115...
	 start solving instance: 83...
	 start solving instance: 92...
	 start solving instance: 85...
	 start solving instance: 63...
	 start solving instance: 45...
	 start solving instance: 90...
	 start solving instance: 97...
	 start solving instance: 17...
	 start solving instance: 42...
	 start solving instance: 99...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.440170120978052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6308417024.0
		 entropy bonus: 0.20498478412628174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6523096576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6643281408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4401701759536333e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.440170120978052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6308417024.0
		 entropy bonus: 0.20498478412628174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6523096576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6643281408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4401701759536333e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.440170120978052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6308417024.0
		 entropy bonus: 0.20498478412628174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6523096576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6643281408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4401701759536333e+18 - Differentiable computation graph = True!
PPO iteration: 421/1000:
	 New training batch of size 20...
	 start solving instance: 44...
	 start solving instance: 122...
	 start solving instance: 96...
	 start solving instance: 31...
	 start solving instance: 139...
	 start solving instance: 92...
	 start solving instance: 51...
	 start solving instance: 89...
	 start solving instance: 72...
	 start solving instance: 64...
	 start solving instance: 56...
	 start solving instance: 109...
	 start solving instance: 117...
	 start solving instance: 129...
	 start solving instance: 30...
	 start solving instance: 19...
	 start solving instance: 130...
	 start solving instance: 52...
	 start solving instance: 74...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1970378654563697e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5525241344.0
		 entropy bonus: 0.20341412723064423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5285658112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6116822528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1970378654563697e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1970378654563697e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5525241344.0
		 entropy bonus: 0.20341412723064423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5285658112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6116822528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1970378654563697e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1970378654563697e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5525241344.0
		 entropy bonus: 0.20341412723064423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5285658112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6116822528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1970378654563697e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.914847326578357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5231753728.0
		 entropy bonus: 0.1909305453300476
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5055852544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5818113024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2914847381553938432.0000
PPO iteration: 422/1000:
	 start solving instance: 44...
	 start solving instance: 139...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 117...
	 start solving instance: 52...
	 start solving instance: 109...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 89...
	 start solving instance: 92...
	 start solving instance: 64...
	 start solving instance: 129...
	 start solving instance: 96...
	 start solving instance: 31...
	 start solving instance: 56...
	 start solving instance: 122...
	 start solving instance: 74...
	 start solving instance: 66...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.342952294359918e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5571193344.0
		 entropy bonus: 0.19967809319496155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417033216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6021340160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.342952404311081e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.342952294359918e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5571193344.0
		 entropy bonus: 0.19967809319496155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417033216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6021340160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.342952404311081e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.342952294359918e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5571193344.0
		 entropy bonus: 0.19967809319496155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417033216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6021340160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.342952404311081e+18 - Differentiable computation graph = True!
PPO iteration: 423/1000:
	 start solving instance: 64...
	 start solving instance: 92...
	 start solving instance: 72...
	 start solving instance: 109...
	 start solving instance: 117...
	 start solving instance: 52...
	 start solving instance: 89...
	 start solving instance: 56...
	 start solving instance: 31...
	 start solving instance: 129...
	 start solving instance: 44...
	 start solving instance: 96...
	 start solving instance: 30...
	 start solving instance: 19...
	 start solving instance: 122...
	 start solving instance: 130...
	 start solving instance: 74...
	 start solving instance: 66...
	 start solving instance: 139...
	 start solving instance: 51...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4371610894556725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5575516160.0
		 entropy bonus: 0.2044084072113037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5388526592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6106691584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.437161034480091e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4371610894556725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5575516160.0
		 entropy bonus: 0.2044084072113037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5388526592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6106691584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.437161034480091e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4371610894556725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5575516160.0
		 entropy bonus: 0.2044084072113037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5388526592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6106691584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.437161034480091e+18 - Differentiable computation graph = True!
PPO iteration: 424/1000:
	 start solving instance: 51...
	 start solving instance: 74...
	 start solving instance: 139...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 44...
	 start solving instance: 129...
	 start solving instance: 92...
	 start solving instance: 19...
	 start solving instance: 109...
	 start solving instance: 89...
	 start solving instance: 122...
	 start solving instance: 64...
	 start solving instance: 31...
	 start solving instance: 72...
	 start solving instance: 117...
	 start solving instance: 96...
	 start solving instance: 30...
	 start solving instance: 52...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3834347731783516e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5555835392.0
		 entropy bonus: 0.2155335396528244
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5330723840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6147309568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3834347731783516e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3834347731783516e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5555835392.0
		 entropy bonus: 0.2155335396528244
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5330723840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6147309568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3834347731783516e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3834347731783516e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5555835392.0
		 entropy bonus: 0.2155335396528244
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5330723840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6147309568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3834347731783516e+18 - Differentiable computation graph = True!
PPO iteration: 425/1000:
	 start solving instance: 44...
	 start solving instance: 74...
	 start solving instance: 66...
	 start solving instance: 89...
	 start solving instance: 52...
	 start solving instance: 64...
	 start solving instance: 96...
	 start solving instance: 122...
	 start solving instance: 109...
	 start solving instance: 72...
	 start solving instance: 30...
	 start solving instance: 92...
	 start solving instance: 56...
	 start solving instance: 139...
	 start solving instance: 19...
	 start solving instance: 130...
	 start solving instance: 117...
	 start solving instance: 129...
	 start solving instance: 31...
	 start solving instance: 51...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3875361714522817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5497916928.0
		 entropy bonus: 0.22042234241962433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5392802304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5971696640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.387536226427863e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3875361714522817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5497916928.0
		 entropy bonus: 0.22042234241962433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5392802304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5971696640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.387536226427863e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3875361714522817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5497916928.0
		 entropy bonus: 0.22042234241962433
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5392802304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5971696640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.387536226427863e+18 - Differentiable computation graph = True!
PPO iteration: 426/1000:
	 start solving instance: 66...
	 start solving instance: 52...
	 start solving instance: 122...
	 start solving instance: 56...
	 start solving instance: 139...
	 start solving instance: 72...
	 start solving instance: 89...
	 start solving instance: 92...
	 start solving instance: 117...
	 start solving instance: 96...
	 start solving instance: 31...
	 start solving instance: 109...
	 start solving instance: 51...
	 start solving instance: 64...
	 start solving instance: 30...
	 start solving instance: 44...
	 start solving instance: 74...
	 start solving instance: 130...
	 start solving instance: 19...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5240225080499765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5692636160.0
		 entropy bonus: 0.2069195955991745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5419531264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6702811648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.524022453074395e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5240225080499765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5692636160.0
		 entropy bonus: 0.2069195955991745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5419531264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6702811648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.524022453074395e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5240225080499765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5692636160.0
		 entropy bonus: 0.2069195955991745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5419531264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6702811648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.524022453074395e+18 - Differentiable computation graph = True!
PPO iteration: 427/1000:
	 start solving instance: 64...
	 start solving instance: 109...
	 start solving instance: 19...
	 start solving instance: 66...
	 start solving instance: 117...
	 start solving instance: 30...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 44...
	 start solving instance: 74...
	 start solving instance: 96...
	 start solving instance: 139...
	 start solving instance: 56...
	 start solving instance: 89...
	 start solving instance: 72...
	 start solving instance: 122...
	 start solving instance: 129...
	 start solving instance: 31...
	 start solving instance: 52...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.305045531480713e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5632124416.0
		 entropy bonus: 0.19975978136062622
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5271672320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428489728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3050456414318756e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.305045531480713e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5686164480.0
		 entropy bonus: 0.19709382951259613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5271672320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428489728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3050456414318756e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.305045531480713e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5632124416.0
		 entropy bonus: 0.19975978136062622
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5271672320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428489728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3050456414318756e+18 - Differentiable computation graph = True!
PPO iteration: 428/1000:
	 start solving instance: 51...
	 start solving instance: 122...
	 start solving instance: 44...
	 start solving instance: 74...
	 start solving instance: 31...
	 start solving instance: 56...
	 start solving instance: 72...
	 start solving instance: 117...
	 start solving instance: 89...
	 start solving instance: 66...
	 start solving instance: 30...
	 start solving instance: 52...
	 start solving instance: 96...
	 start solving instance: 109...
	 start solving instance: 19...
	 start solving instance: 139...
	 start solving instance: 64...
	 start solving instance: 129...
	 start solving instance: 92...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.546252214238026e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5643013632.0
		 entropy bonus: 0.21026907861232758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5552721920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6503761920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5462523791647703e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.546252214238026e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5643013632.0
		 entropy bonus: 0.21026907861232758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5552721920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6503761920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5462523791647703e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.546252214238026e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5643013632.0
		 entropy bonus: 0.21026907861232758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5552721920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6503761920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5462523791647703e+18 - Differentiable computation graph = True!
PPO iteration: 429/1000:
	 start solving instance: 122...
	 start solving instance: 139...
	 start solving instance: 89...
	 start solving instance: 129...
	 start solving instance: 64...
	 start solving instance: 52...
	 start solving instance: 56...
	 start solving instance: 30...
	 start solving instance: 19...
	 start solving instance: 72...
	 start solving instance: 74...
	 start solving instance: 31...
	 start solving instance: 130...
	 start solving instance: 44...
	 start solving instance: 109...
	 start solving instance: 51...
	 start solving instance: 96...
	 start solving instance: 117...
	 start solving instance: 66...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3127669618379325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5512076800.0
		 entropy bonus: 0.19797064363956451
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5287161856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447368704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3127669618379325e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3127669618379325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5512076800.0
		 entropy bonus: 0.19797064363956451
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5287161856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447368704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3127669618379325e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3127669618379325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5512076800.0
		 entropy bonus: 0.19797064363956451
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5287161856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447368704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3127669618379325e+18 - Differentiable computation graph = True!
PPO iteration: 430/1000:
	 start solving instance: 96...
	 start solving instance: 89...
	 start solving instance: 30...
	 start solving instance: 117...
	 start solving instance: 44...
	 start solving instance: 51...
	 start solving instance: 66...
	 start solving instance: 130...
	 start solving instance: 31...
	 start solving instance: 64...
	 start solving instance: 19...
	 start solving instance: 109...
	 start solving instance: 72...
	 start solving instance: 56...
	 start solving instance: 129...
	 start solving instance: 139...
	 start solving instance: 52...
	 start solving instance: 92...
	 start solving instance: 74...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3327046260867203e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503176192.0
		 entropy bonus: 0.21365006268024445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5344423936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6170138112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3327046810623017e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3327046260867203e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503176192.0
		 entropy bonus: 0.21365006268024445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5344423936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6170138112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3327046810623017e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3327046260867203e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503176192.0
		 entropy bonus: 0.21365006268024445
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5344423936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6170138112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3327046810623017e+18 - Differentiable computation graph = True!
PPO iteration: 431/1000:
	 New training batch of size 20...
	 start solving instance: 109...
	 start solving instance: 121...
	 start solving instance: 49...
	 start solving instance: 74...
	 start solving instance: 24...
	 start solving instance: 42...
	 start solving instance: 11...
	 start solving instance: 117...
	 start solving instance: 47...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 91...
	 start solving instance: 124...
	 start solving instance: 98...
	 start solving instance: 13...
	 start solving instance: 5...
	 start solving instance: 128...
	 start solving instance: 65...
	 start solving instance: 112...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.9762640669849944e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5192986112.0
		 entropy bonus: 0.21203342080116272
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5238107136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5919434240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.976264176936157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.9762640669849944e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5192986112.0
		 entropy bonus: 0.21203342080116272
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5238107136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5919434240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.976264176936157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.9762640669849944e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5192986112.0
		 entropy bonus: 0.21203342080116272
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5238107136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5919434240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.976264176936157e+18 - Differentiable computation graph = True!
PPO iteration: 432/1000:
	 start solving instance: 11...
	 start solving instance: 13...
	 start solving instance: 57...
	 start solving instance: 65...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 117...
	 start solving instance: 89...
	 start solving instance: 91...
	 start solving instance: 53...
	 start solving instance: 49...
	 start solving instance: 74...
	 start solving instance: 24...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 47...
	 start solving instance: 5...
	 start solving instance: 121...
	 start solving instance: 109...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1011089943701225e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5367275520.0
		 entropy bonus: 0.20335076749324799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5311275008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6221168128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.101109049345704e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1011089943701225e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5367275520.0
		 entropy bonus: 0.20335076749324799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5311275008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6221168128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.101109049345704e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1011089943701225e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5367275520.0
		 entropy bonus: 0.20335076749324799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5311275008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6221168128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.101109049345704e+18 - Differentiable computation graph = True!
PPO iteration: 433/1000:
	 start solving instance: 42...
	 start solving instance: 89...
	 start solving instance: 13...
	 start solving instance: 53...
	 start solving instance: 74...
	 start solving instance: 57...
	 start solving instance: 109...
	 start solving instance: 11...
	 start solving instance: 124...
	 start solving instance: 5...
	 start solving instance: 65...
	 start solving instance: 24...
	 start solving instance: 47...
	 start solving instance: 49...
	 start solving instance: 98...
	 start solving instance: 117...
	 start solving instance: 112...
	 start solving instance: 91...
	 start solving instance: 128...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1081674192157934e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5375888896.0
		 entropy bonus: 0.20576214790344238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5341437440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6134701056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.108167364240212e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1081674192157934e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5375888896.0
		 entropy bonus: 0.20576214790344238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5341437440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6134701056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.108167364240212e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1081674192157934e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5375888896.0
		 entropy bonus: 0.20576214790344238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5341437440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6134701056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.108167364240212e+18 - Differentiable computation graph = True!
PPO iteration: 434/1000:
	 start solving instance: 47...
	 start solving instance: 89...
	 start solving instance: 65...
	 start solving instance: 74...
	 start solving instance: 11...
	 start solving instance: 109...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 117...
	 start solving instance: 24...
	 start solving instance: 49...
	 start solving instance: 91...
	 start solving instance: 5...
	 start solving instance: 13...
	 start solving instance: 53...
	 start solving instance: 57...
	 start solving instance: 42...
	 start solving instance: 98...
	 start solving instance: 112...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 2.8781588225827275e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5322716672.0
		 entropy bonus: 0.20948170125484467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5110824960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5899761664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.878158877558309e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 2.8781588225827275e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5322716672.0
		 entropy bonus: 0.20948170125484467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5110824960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5899761664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.878158877558309e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 2.8781588225827275e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5322716672.0
		 entropy bonus: 0.20948170125484467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5110824960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5899761664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2.878158877558309e+18 - Differentiable computation graph = True!
PPO iteration: 435/1000:
	 start solving instance: 91...
	 start solving instance: 117...
	 start solving instance: 65...
	 start solving instance: 13...
	 start solving instance: 42...
	 start solving instance: 24...
	 start solving instance: 11...
	 start solving instance: 49...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 57...
	 start solving instance: 74...
	 start solving instance: 109...
	 start solving instance: 5...
	 start solving instance: 112...
	 start solving instance: 53...
	 start solving instance: 98...
	 start solving instance: 121...
	 start solving instance: 89...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1852187751647543e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5341531648.0
		 entropy bonus: 0.21597468852996826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5444363264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6160754176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1852189400914985e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1852187751647543e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5341531648.0
		 entropy bonus: 0.21597468852996826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5444363264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6160754176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1852189400914985e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1852187751647543e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5341531648.0
		 entropy bonus: 0.21597468852996826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5444363264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6160754176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1852189400914985e+18 - Differentiable computation graph = True!
PPO iteration: 436/1000:
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 124...
	 start solving instance: 121...
	 start solving instance: 74...
	 start solving instance: 57...
	 start solving instance: 42...
	 start solving instance: 47...
	 start solving instance: 24...
	 start solving instance: 49...
	 start solving instance: 128...
	 start solving instance: 65...
	 start solving instance: 91...
	 start solving instance: 53...
	 start solving instance: 109...
	 start solving instance: 98...
	 start solving instance: 112...
	 start solving instance: 11...
	 start solving instance: 5...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.113404173196565e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5403131904.0
		 entropy bonus: 0.20952294766902924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5301085184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6162247680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.113404338123309e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.113404173196565e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5403131904.0
		 entropy bonus: 0.20952294766902924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5301085184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6162247680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.113404338123309e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.113404173196565e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5403131904.0
		 entropy bonus: 0.20952294766902924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5301085184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6162247680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.113404338123309e+18 - Differentiable computation graph = True!
PPO iteration: 437/1000:
	 start solving instance: 57...
	 start solving instance: 11...
	 start solving instance: 74...
	 start solving instance: 112...
	 start solving instance: 121...
	 start solving instance: 117...
	 start solving instance: 65...
	 start solving instance: 13...
	 start solving instance: 98...
	 start solving instance: 53...
	 start solving instance: 89...
	 start solving instance: 124...
	 start solving instance: 91...
	 start solving instance: 42...
	 start solving instance: 47...
	 start solving instance: 24...
	 start solving instance: 49...
	 start solving instance: 109...
	 start solving instance: 5...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.025050057616392e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5328992256.0
		 entropy bonus: 0.20687952637672424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5289393664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6033977344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.025050057616392e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.025050057616392e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5328992256.0
		 entropy bonus: 0.20687952637672424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5289393664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6033977344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.025050057616392e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.025050057616392e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5328992256.0
		 entropy bonus: 0.20687952637672424
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5289393664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6033977344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.025050057616392e+18 - Differentiable computation graph = True!
PPO iteration: 438/1000:
	 start solving instance: 117...
	 start solving instance: 91...
	 start solving instance: 89...
	 start solving instance: 128...
	 start solving instance: 47...
	 start solving instance: 124...
	 start solving instance: 13...
	 start solving instance: 24...
	 start solving instance: 121...
	 start solving instance: 65...
	 start solving instance: 109...
	 start solving instance: 49...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 57...
	 start solving instance: 53...
	 start solving instance: 74...
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.032135750350432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5403248640.0
		 entropy bonus: 0.20426423847675323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5243655680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6033474048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0321358603015946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.032135750350432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5403248640.0
		 entropy bonus: 0.20426423847675323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5243655680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6033474048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0321358603015946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.032135750350432e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5403248640.0
		 entropy bonus: 0.20426423847675323
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5243655680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6033474048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0321358603015946e+18 - Differentiable computation graph = True!
PPO iteration: 439/1000:
	 start solving instance: 13...
	 start solving instance: 109...
	 start solving instance: 57...
	 start solving instance: 11...
	 start solving instance: 91...
	 start solving instance: 49...
	 start solving instance: 53...
	 start solving instance: 112...
	 start solving instance: 89...
	 start solving instance: 24...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 121...
	 start solving instance: 65...
	 start solving instance: 5...
	 start solving instance: 74...
	 start solving instance: 117...
	 start solving instance: 124...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0272356668300853e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5332649472.0
		 entropy bonus: 0.19384825229644775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5178142720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6044040704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.027235611854504e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0272356668300853e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5332649472.0
		 entropy bonus: 0.19384825229644775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5178142720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6044040704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.027235611854504e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0272356668300853e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5332649472.0
		 entropy bonus: 0.19384825229644775
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5178142720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6044040704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.027235611854504e+18 - Differentiable computation graph = True!
PPO iteration: 440/1000:
	 start solving instance: 65...
	 start solving instance: 13...
	 start solving instance: 47...
	 start solving instance: 117...
	 start solving instance: 121...
	 start solving instance: 112...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 91...
	 start solving instance: 109...
	 start solving instance: 5...
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 74...
	 start solving instance: 24...
	 start solving instance: 11...
	 start solving instance: 53...
	 start solving instance: 57...
	 start solving instance: 98...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0785749433635045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5386656768.0
		 entropy bonus: 0.20378175377845764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266597888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6265265664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0785751082902487e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0785749433635045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5386656768.0
		 entropy bonus: 0.20378175377845764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266597888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6265265664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0785751082902487e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0785749433635045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5386656768.0
		 entropy bonus: 0.20378175377845764
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266597888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6265265664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0785751082902487e+18 - Differentiable computation graph = True!
PPO iteration: 441/1000:
	 New training batch of size 20...
	 start solving instance: 81...
	 start solving instance: 61...
	 start solving instance: 114...
	 start solving instance: 44...
	 start solving instance: 87...
	 start solving instance: 116...
	 start solving instance: 107...
	 start solving instance: 102...
	 start solving instance: 125...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 80...
	 start solving instance: 20...
	 start solving instance: 84...
	 start solving instance: 69...
	 start solving instance: 9...
	 start solving instance: 38...
	 start solving instance: 26...
	 start solving instance: 22...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.053747307202635e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6478376960.0
		 entropy bonus: 0.21366964280605316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7027146752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7525745664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.053747417153798e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.053747307202635e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6478376960.0
		 entropy bonus: 0.21366964280605316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7027146752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7525745664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.053747417153798e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.053747307202635e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6478376960.0
		 entropy bonus: 0.21366964280605316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7027146752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7525745664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.053747417153798e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.1243111086417773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5225653760.0
		 entropy bonus: 0.21344225108623505
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5254952960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6167023104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3124311218592940032.0000
PPO iteration: 442/1000:
	 start solving instance: 69...
	 start solving instance: 85...
	 start solving instance: 20...
	 start solving instance: 80...
	 start solving instance: 61...
	 start solving instance: 44...
	 start solving instance: 38...
	 start solving instance: 117...
	 start solving instance: 34...
	 start solving instance: 81...
	 start solving instance: 87...
	 start solving instance: 22...
	 start solving instance: 26...
	 start solving instance: 116...
	 start solving instance: 114...
	 start solving instance: 9...
	 start solving instance: 125...
	 start solving instance: 107...
	 start solving instance: 84...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.858236987402669e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6466308608.0
		 entropy bonus: 0.21299533545970917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6802413568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7128431616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.858237207304995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.858236987402669e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6466308608.0
		 entropy bonus: 0.21299533545970917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6802413568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7128431616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.858237207304995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.858236987402669e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6466308608.0
		 entropy bonus: 0.21299533545970917
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6802413568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7128431616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.858237207304995e+18 - Differentiable computation graph = True!
PPO iteration: 443/1000:
	 start solving instance: 34...
	 start solving instance: 9...
	 start solving instance: 20...
	 start solving instance: 117...
	 start solving instance: 80...
	 start solving instance: 114...
	 start solving instance: 107...
	 start solving instance: 87...
	 start solving instance: 38...
	 start solving instance: 22...
	 start solving instance: 81...
	 start solving instance: 116...
	 start solving instance: 125...
	 start solving instance: 61...
	 start solving instance: 85...
	 start solving instance: 69...
	 start solving instance: 84...
	 start solving instance: 44...
	 start solving instance: 26...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.925807254585318e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6499485184.0
		 entropy bonus: 0.2128545045852661
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7011229696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7376185344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.925807144634155e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.925807254585318e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6499485184.0
		 entropy bonus: 0.2128545045852661
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7011229696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7376185344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.925807144634155e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.925807254585318e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6499485184.0
		 entropy bonus: 0.2128545045852661
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7011229696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7376185344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.925807144634155e+18 - Differentiable computation graph = True!
PPO iteration: 444/1000:
	 start solving instance: 44...
	 start solving instance: 69...
	 start solving instance: 22...
	 start solving instance: 61...
	 start solving instance: 34...
	 start solving instance: 9...
	 start solving instance: 80...
	 start solving instance: 87...
	 start solving instance: 81...
	 start solving instance: 116...
	 start solving instance: 20...
	 start solving instance: 102...
	 start solving instance: 125...
	 start solving instance: 84...
	 start solving instance: 107...
	 start solving instance: 26...
	 start solving instance: 85...
	 start solving instance: 38...
	 start solving instance: 114...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.964842116394621e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6509944320.0
		 entropy bonus: 0.21216164529323578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6858137600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7455337472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.964842006443459e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.964842116394621e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6509944320.0
		 entropy bonus: 0.21216164529323578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6858137600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7455337472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.964842006443459e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.964842116394621e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6509944320.0
		 entropy bonus: 0.21216164529323578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6858137600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7455337472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.964842006443459e+18 - Differentiable computation graph = True!
PPO iteration: 445/1000:
	 start solving instance: 61...
	 start solving instance: 9...
	 start solving instance: 116...
	 start solving instance: 20...
	 start solving instance: 87...
	 start solving instance: 44...
	 start solving instance: 80...
	 start solving instance: 34...
	 start solving instance: 26...
	 start solving instance: 84...
	 start solving instance: 102...
	 start solving instance: 125...
	 start solving instance: 69...
	 start solving instance: 114...
	 start solving instance: 117...
	 start solving instance: 22...
	 start solving instance: 107...
	 start solving instance: 81...
	 start solving instance: 38...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.0701726915076555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6502776320.0
		 entropy bonus: 0.21524515748023987
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7016199168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7276741120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.070173021361144e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.0701726915076555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6502776320.0
		 entropy bonus: 0.21524515748023987
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7016199168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7276741120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.070173021361144e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.0701726915076555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6502776320.0
		 entropy bonus: 0.21524515748023987
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7016199168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7276741120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.070173021361144e+18 - Differentiable computation graph = True!
PPO iteration: 446/1000:
	 start solving instance: 38...
	 start solving instance: 116...
	 start solving instance: 87...
	 start solving instance: 20...
	 start solving instance: 9...
	 start solving instance: 22...
	 start solving instance: 81...
	 start solving instance: 34...
	 start solving instance: 26...
	 start solving instance: 44...
	 start solving instance: 61...
	 start solving instance: 117...
	 start solving instance: 85...
	 start solving instance: 102...
	 start solving instance: 107...
	 start solving instance: 80...
	 start solving instance: 114...
	 start solving instance: 84...
	 start solving instance: 125...
	 start solving instance: 69...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8478127375620506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6494870016.0
		 entropy bonus: 0.20102964341640472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6772931072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7138166784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.847812737562051e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8478127375620506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6494870016.0
		 entropy bonus: 0.20102964341640472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6772931072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7138166784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.847812737562051e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8478127375620506e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6494870016.0
		 entropy bonus: 0.20102964341640472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6772931072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7138166784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.847812737562051e+18 - Differentiable computation graph = True!
PPO iteration: 447/1000:
	 start solving instance: 85...
	 start solving instance: 117...
	 start solving instance: 114...
	 start solving instance: 125...
	 start solving instance: 87...
	 start solving instance: 107...
	 start solving instance: 9...
	 start solving instance: 69...
	 start solving instance: 102...
	 start solving instance: 34...
	 start solving instance: 20...
	 start solving instance: 80...
	 start solving instance: 22...
	 start solving instance: 26...
	 start solving instance: 61...
	 start solving instance: 84...
	 start solving instance: 116...
	 start solving instance: 38...
	 start solving instance: 44...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.663397809500298e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6453568512.0
		 entropy bonus: 0.21747033298015594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6667501056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7084058112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.663397699549135e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.663397809500298e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6453568512.0
		 entropy bonus: 0.21747033298015594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6667501056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7084058112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.663397699549135e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.663397809500298e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6453568512.0
		 entropy bonus: 0.21747033298015594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6667501056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7084058112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.663397699549135e+18 - Differentiable computation graph = True!
PPO iteration: 448/1000:
	 start solving instance: 20...
	 start solving instance: 81...
	 start solving instance: 125...
	 start solving instance: 61...
	 start solving instance: 85...
	 start solving instance: 116...
	 start solving instance: 87...
	 start solving instance: 114...
	 start solving instance: 107...
	 start solving instance: 38...
	 start solving instance: 22...
	 start solving instance: 69...
	 start solving instance: 117...
	 start solving instance: 102...
	 start solving instance: 34...
	 start solving instance: 80...
	 start solving instance: 9...
	 start solving instance: 44...
	 start solving instance: 84...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.790775351968845e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6530120192.0
		 entropy bonus: 0.20838387310504913
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737820672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7112330240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.790775571871171e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.790775351968845e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6530120192.0
		 entropy bonus: 0.20838387310504913
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737820672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7112330240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.790775571871171e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.790775351968845e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6530120192.0
		 entropy bonus: 0.20838387310504913
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737820672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7112330240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.790775571871171e+18 - Differentiable computation graph = True!
PPO iteration: 449/1000:
	 start solving instance: 102...
	 start solving instance: 85...
	 start solving instance: 114...
	 start solving instance: 22...
	 start solving instance: 81...
	 start solving instance: 34...
	 start solving instance: 125...
	 start solving instance: 44...
	 start solving instance: 84...
	 start solving instance: 9...
	 start solving instance: 107...
	 start solving instance: 87...
	 start solving instance: 116...
	 start solving instance: 80...
	 start solving instance: 117...
	 start solving instance: 38...
	 start solving instance: 61...
	 start solving instance: 69...
	 start solving instance: 20...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.998448029590618e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6522371584.0
		 entropy bonus: 0.1976146250963211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6966784000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7658085376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.998448029590618e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.998448029590618e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6522371584.0
		 entropy bonus: 0.1976146250963211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6966784000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7658085376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.998448029590618e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.998448029590618e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6522371584.0
		 entropy bonus: 0.1976146250963211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6966784000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7658085376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.998448029590618e+18 - Differentiable computation graph = True!
PPO iteration: 450/1000:
	 start solving instance: 34...
	 start solving instance: 117...
	 start solving instance: 85...
	 start solving instance: 61...
	 start solving instance: 107...
	 start solving instance: 102...
	 start solving instance: 20...
	 start solving instance: 81...
	 start solving instance: 80...
	 start solving instance: 44...
	 start solving instance: 69...
	 start solving instance: 38...
	 start solving instance: 22...
	 start solving instance: 116...
	 start solving instance: 9...
	 start solving instance: 125...
	 start solving instance: 114...
	 start solving instance: 84...
	 start solving instance: 87...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.02965964626597e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6578118144.0
		 entropy bonus: 0.20312726497650146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6819208704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7379127808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.029659866168295e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.02965964626597e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6578118144.0
		 entropy bonus: 0.20312726497650146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6819208704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7379127808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.029659866168295e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.02965964626597e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6578118144.0
		 entropy bonus: 0.20312726497650146
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6819208704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7379127808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.029659866168295e+18 - Differentiable computation graph = True!
PPO iteration: 451/1000:
	 New training batch of size 20...
	 start solving instance: 106...
	 start solving instance: 103...
	 start solving instance: 26...
	 start solving instance: 90...
	 start solving instance: 102...
	 start solving instance: 93...
	 start solving instance: 12...
	 start solving instance: 79...
	 start solving instance: 124...
	 start solving instance: 113...
	 start solving instance: 10...
	 start solving instance: 57...
	 start solving instance: 46...
	 start solving instance: 31...
	 start solving instance: 9...
	 start solving instance: 136...
	 start solving instance: 60...
	 start solving instance: 52...
	 start solving instance: 118...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2565896142399734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5580461568.0
		 entropy bonus: 0.2038903534412384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5236030976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5850903040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2565896142399734e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2565896142399734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5580461568.0
		 entropy bonus: 0.2038903534412384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5236030976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5850903040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2565896142399734e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2565896142399734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5580461568.0
		 entropy bonus: 0.2038903534412384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5236030976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5850903040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2565896142399734e+18 - Differentiable computation graph = True!
PPO iteration: 452/1000:
	 start solving instance: 136...
	 start solving instance: 10...
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 9...
	 start solving instance: 57...
	 start solving instance: 31...
	 start solving instance: 60...
	 start solving instance: 103...
	 start solving instance: 52...
	 start solving instance: 106...
	 start solving instance: 46...
	 start solving instance: 113...
	 start solving instance: 90...
	 start solving instance: 12...
	 start solving instance: 26...
	 start solving instance: 102...
	 start solving instance: 93...
	 start solving instance: 118...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4106041453053477e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5686177280.0
		 entropy bonus: 0.20325112342834473
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5411632128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6288847360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4106042552565105e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4106041453053477e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5686177280.0
		 entropy bonus: 0.20325112342834473
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5411632128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6288847360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4106042552565105e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4106041453053477e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5686177280.0
		 entropy bonus: 0.20325112342834473
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5411632128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6288847360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4106042552565105e+18 - Differentiable computation graph = True!
PPO iteration: 453/1000:
	 start solving instance: 136...
	 start solving instance: 52...
	 start solving instance: 26...
	 start solving instance: 103...
	 start solving instance: 9...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 113...
	 start solving instance: 124...
	 start solving instance: 12...
	 start solving instance: 10...
	 start solving instance: 79...
	 start solving instance: 102...
	 start solving instance: 90...
	 start solving instance: 106...
	 start solving instance: 31...
	 start solving instance: 118...
	 start solving instance: 129...
	 start solving instance: 46...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4999583766621454e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5728071680.0
		 entropy bonus: 0.19925536215305328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5515428352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6465571840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4999585415888896e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4999583766621454e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5728071680.0
		 entropy bonus: 0.19925536215305328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5515428352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6465571840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4999585415888896e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4999583766621454e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5728071680.0
		 entropy bonus: 0.19925536215305328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5515428352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6465571840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4999585415888896e+18 - Differentiable computation graph = True!
PPO iteration: 454/1000:
	 start solving instance: 113...
	 start solving instance: 124...
	 start solving instance: 102...
	 start solving instance: 129...
	 start solving instance: 136...
	 start solving instance: 118...
	 start solving instance: 12...
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 26...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 31...
	 start solving instance: 57...
	 start solving instance: 103...
	 start solving instance: 60...
	 start solving instance: 46...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.447767418421851e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631214080.0
		 entropy bonus: 0.21021537482738495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5512454144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6280702464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4477674733974323e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.447767418421851e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631214080.0
		 entropy bonus: 0.21021537482738495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5512454144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6280702464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4477674733974323e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.447767418421851e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631214080.0
		 entropy bonus: 0.21021537482738495
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5512454144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6280702464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4477674733974323e+18 - Differentiable computation graph = True!
PPO iteration: 455/1000:
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 9...
	 start solving instance: 79...
	 start solving instance: 52...
	 start solving instance: 106...
	 start solving instance: 103...
	 start solving instance: 26...
	 start solving instance: 60...
	 start solving instance: 57...
	 start solving instance: 31...
	 start solving instance: 90...
	 start solving instance: 102...
	 start solving instance: 12...
	 start solving instance: 93...
	 start solving instance: 46...
	 start solving instance: 113...
	 start solving instance: 118...
	 start solving instance: 136...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4413271390133158e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5737107456.0
		 entropy bonus: 0.2139948159456253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5423293952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6388922880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4413270840377344e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4413271390133158e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5737107456.0
		 entropy bonus: 0.2139948159456253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5423293952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6388922880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4413270840377344e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4413271390133158e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5737107456.0
		 entropy bonus: 0.2139948159456253
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5423293952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6388922880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4413270840377344e+18 - Differentiable computation graph = True!
PPO iteration: 456/1000:
	 start solving instance: 26...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 46...
	 start solving instance: 31...
	 start solving instance: 106...
	 start solving instance: 10...
	 start solving instance: 136...
	 start solving instance: 103...
	 start solving instance: 9...
	 start solving instance: 113...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 12...
	 start solving instance: 57...
	 start solving instance: 102...
	 start solving instance: 60...
	 start solving instance: 93...
	 start solving instance: 124...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5769756477506454e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5736672768.0
		 entropy bonus: 0.199649378657341
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5585769984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6649876480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.576975757701808e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5769756477506454e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5736672768.0
		 entropy bonus: 0.199649378657341
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5585769984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6649876480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.576975757701808e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5769756477506454e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5736672768.0
		 entropy bonus: 0.199649378657341
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5585769984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6649876480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.576975757701808e+18 - Differentiable computation graph = True!
PPO iteration: 457/1000:
	 start solving instance: 106...
	 start solving instance: 12...
	 start solving instance: 57...
	 start solving instance: 103...
	 start solving instance: 10...
	 start solving instance: 102...
	 start solving instance: 90...
	 start solving instance: 129...
	 start solving instance: 93...
	 start solving instance: 118...
	 start solving instance: 26...
	 start solving instance: 79...
	 start solving instance: 124...
	 start solving instance: 9...
	 start solving instance: 136...
	 start solving instance: 46...
	 start solving instance: 60...
	 start solving instance: 52...
	 start solving instance: 31...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.747503304148936e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5747823616.0
		 entropy bonus: 0.20989318192005157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810755072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6552272896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.747503414100099e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.747503304148936e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5747823616.0
		 entropy bonus: 0.20989318192005157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810755072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6552272896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.747503414100099e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.747503304148936e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5747823616.0
		 entropy bonus: 0.20989318192005157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810755072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6552272896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.747503414100099e+18 - Differentiable computation graph = True!
PPO iteration: 458/1000:
	 start solving instance: 102...
	 start solving instance: 12...
	 start solving instance: 113...
	 start solving instance: 129...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 9...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 60...
	 start solving instance: 106...
	 start solving instance: 118...
	 start solving instance: 31...
	 start solving instance: 103...
	 start solving instance: 124...
	 start solving instance: 52...
	 start solving instance: 10...
	 start solving instance: 136...
	 start solving instance: 46...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4193208535880303e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5590883840.0
		 entropy bonus: 0.21548159420490265
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5442147840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6223548416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4193209085636116e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4193208535880303e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5590883840.0
		 entropy bonus: 0.21548159420490265
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5442147840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6223548416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4193209085636116e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4193208535880303e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5590883840.0
		 entropy bonus: 0.21548159420490265
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5442147840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6223548416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4193209085636116e+18 - Differentiable computation graph = True!
PPO iteration: 459/1000:
	 start solving instance: 31...
	 start solving instance: 9...
	 start solving instance: 26...
	 start solving instance: 113...
	 start solving instance: 118...
	 start solving instance: 124...
	 start solving instance: 102...
	 start solving instance: 57...
	 start solving instance: 60...
	 start solving instance: 93...
	 start solving instance: 129...
	 start solving instance: 12...
	 start solving instance: 136...
	 start solving instance: 90...
	 start solving instance: 10...
	 start solving instance: 106...
	 start solving instance: 79...
	 start solving instance: 52...
	 start solving instance: 103...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.629179800130473e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5670168576.0
		 entropy bonus: 0.21477437019348145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5637871104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6297135104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.629179745154892e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.629179800130473e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5670168576.0
		 entropy bonus: 0.21477437019348145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5637871104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6297135104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.629179745154892e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.629179800130473e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5670168576.0
		 entropy bonus: 0.21477437019348145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5637871104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6297135104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.629179745154892e+18 - Differentiable computation graph = True!
PPO iteration: 460/1000:
	 start solving instance: 52...
	 start solving instance: 129...
	 start solving instance: 12...
	 start solving instance: 60...
	 start solving instance: 79...
	 start solving instance: 9...
	 start solving instance: 113...
	 start solving instance: 136...
	 start solving instance: 10...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 106...
	 start solving instance: 31...
	 start solving instance: 118...
	 start solving instance: 124...
	 start solving instance: 46...
	 start solving instance: 26...
	 start solving instance: 102...
	 start solving instance: 90...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6876692007793197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5658074624.0
		 entropy bonus: 0.21646860241889954
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5790195200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486575104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.687669365706064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6876692007793197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5658074624.0
		 entropy bonus: 0.21646860241889954
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5790195200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486575104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.687669365706064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6876692007793197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5658074624.0
		 entropy bonus: 0.21646860241889954
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5790195200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486575104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.687669365706064e+18 - Differentiable computation graph = True!
PPO iteration: 461/1000:
	 New training batch of size 20...
	 start solving instance: 83...
	 start solving instance: 105...
	 start solving instance: 15...
	 start solving instance: 147...
	 start solving instance: 35...
	 start solving instance: 104...
	 start solving instance: 62...
	 start solving instance: 40...
	 start solving instance: 149...
	 start solving instance: 24...
	 start solving instance: 65...
	 start solving instance: 91...
	 start solving instance: 125...
	 start solving instance: 144...
	 start solving instance: 68...
	 start solving instance: 7...
	 start solving instance: 5...
	 start solving instance: 142...
	 start solving instance: 136...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.037270357751628e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5901767168.0
		 entropy bonus: 0.2126178741455078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6117232128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6866838528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037270357751628e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.037270357751628e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5901767168.0
		 entropy bonus: 0.2126178741455078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6117232128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6866838528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037270357751628e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.037270357751628e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5901767168.0
		 entropy bonus: 0.2126178741455078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6117232128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6866838528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037270357751628e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.782740344794094e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5067940864.0
		 entropy bonus: 0.19847483932971954
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4869940736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5739138560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2782740509720838144.0000
PPO iteration: 462/1000:
	 start solving instance: 125...
	 start solving instance: 5...
	 start solving instance: 91...
	 start solving instance: 24...
	 start solving instance: 75...
	 start solving instance: 147...
	 start solving instance: 105...
	 start solving instance: 40...
	 start solving instance: 35...
	 start solving instance: 68...
	 start solving instance: 136...
	 start solving instance: 62...
	 start solving instance: 142...
	 start solving instance: 65...
	 start solving instance: 104...
	 start solving instance: 144...
	 start solving instance: 15...
	 start solving instance: 149...
	 start solving instance: 7...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.817934940391709e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5784333824.0
		 entropy bonus: 0.2154243439435959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5875080704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6292593152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.817935105318453e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.817934940391709e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5784333824.0
		 entropy bonus: 0.2154243439435959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5875080704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6292593152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.817935105318453e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.817934940391709e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5784333824.0
		 entropy bonus: 0.2154243439435959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5875080704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6292593152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.817935105318453e+18 - Differentiable computation graph = True!
PPO iteration: 463/1000:
	 start solving instance: 62...
	 start solving instance: 5...
	 start solving instance: 75...
	 start solving instance: 65...
	 start solving instance: 83...
	 start solving instance: 24...
	 start solving instance: 68...
	 start solving instance: 91...
	 start solving instance: 125...
	 start solving instance: 7...
	 start solving instance: 15...
	 start solving instance: 144...
	 start solving instance: 142...
	 start solving instance: 149...
	 start solving instance: 35...
	 start solving instance: 104...
	 start solving instance: 147...
	 start solving instance: 136...
	 start solving instance: 40...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.966376486820538e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5869212160.0
		 entropy bonus: 0.21922877430915833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6029618688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6790074880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9663765967717007e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.966376486820538e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5869212160.0
		 entropy bonus: 0.21922877430915833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6029618688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6790074880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9663765967717007e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.966376486820538e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5869212160.0
		 entropy bonus: 0.21922877430915833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6029618688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6790074880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9663765967717007e+18 - Differentiable computation graph = True!
PPO iteration: 464/1000:
	 start solving instance: 65...
	 start solving instance: 68...
	 start solving instance: 83...
	 start solving instance: 142...
	 start solving instance: 149...
	 start solving instance: 62...
	 start solving instance: 7...
	 start solving instance: 40...
	 start solving instance: 105...
	 start solving instance: 91...
	 start solving instance: 136...
	 start solving instance: 147...
	 start solving instance: 75...
	 start solving instance: 125...
	 start solving instance: 15...
	 start solving instance: 144...
	 start solving instance: 104...
	 start solving instance: 24...
	 start solving instance: 35...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.781110536758886e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5890039296.0
		 entropy bonus: 0.21218208968639374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5830631424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400239104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7811105367588864e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.781110536758886e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5890039296.0
		 entropy bonus: 0.21218208968639374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5830631424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400239104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7811105367588864e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.781110536758886e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5890039296.0
		 entropy bonus: 0.21218208968639374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5830631424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400239104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7811105367588864e+18 - Differentiable computation graph = True!
PPO iteration: 465/1000:
	 start solving instance: 35...
	 start solving instance: 144...
	 start solving instance: 91...
	 start solving instance: 62...
	 start solving instance: 105...
	 start solving instance: 136...
	 start solving instance: 65...
	 start solving instance: 5...
	 start solving instance: 142...
	 start solving instance: 7...
	 start solving instance: 125...
	 start solving instance: 68...
	 start solving instance: 147...
	 start solving instance: 83...
	 start solving instance: 40...
	 start solving instance: 15...
	 start solving instance: 24...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.829725223478677e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5854502400.0
		 entropy bonus: 0.2136681079864502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5885340160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6763880448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8297251685030953e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.829725223478677e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5854502400.0
		 entropy bonus: 0.2136681079864502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5885340160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6763880448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8297251685030953e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.829725223478677e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5854502400.0
		 entropy bonus: 0.2136681079864502
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5885340160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6763880448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8297251685030953e+18 - Differentiable computation graph = True!
PPO iteration: 466/1000:
	 start solving instance: 83...
	 start solving instance: 144...
	 start solving instance: 7...
	 start solving instance: 149...
	 start solving instance: 68...
	 start solving instance: 35...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 125...
	 start solving instance: 5...
	 start solving instance: 147...
	 start solving instance: 136...
	 start solving instance: 62...
	 start solving instance: 24...
	 start solving instance: 40...
	 start solving instance: 65...
	 start solving instance: 91...
	 start solving instance: 75...
	 start solving instance: 15...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.874868971891904e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5874789888.0
		 entropy bonus: 0.2046479731798172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974888448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172851712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8748689169163223e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.874868971891904e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5874789888.0
		 entropy bonus: 0.2046479731798172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974888448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172851712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8748689169163223e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.874868971891904e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5874789888.0
		 entropy bonus: 0.2046479731798172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974888448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7172851712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8748689169163223e+18 - Differentiable computation graph = True!
PPO iteration: 467/1000:
	 start solving instance: 83...
	 start solving instance: 35...
	 start solving instance: 24...
	 start solving instance: 15...
	 start solving instance: 144...
	 start solving instance: 136...
	 start solving instance: 75...
	 start solving instance: 125...
	 start solving instance: 40...
	 start solving instance: 147...
	 start solving instance: 142...
	 start solving instance: 105...
	 start solving instance: 104...
	 start solving instance: 65...
	 start solving instance: 5...
	 start solving instance: 7...
	 start solving instance: 68...
	 start solving instance: 149...
	 start solving instance: 91...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.874204866868727e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5815251968.0
		 entropy bonus: 0.21902452409267426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5953515520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6763781632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8742048118931456e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.874204866868727e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5815251968.0
		 entropy bonus: 0.21902452409267426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5953515520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6763781632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8742048118931456e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.874204866868727e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5815251968.0
		 entropy bonus: 0.21902452409267426
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5953515520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6763781632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8742048118931456e+18 - Differentiable computation graph = True!
PPO iteration: 468/1000:
	 start solving instance: 142...
	 start solving instance: 149...
	 start solving instance: 91...
	 start solving instance: 144...
	 start solving instance: 147...
	 start solving instance: 65...
	 start solving instance: 5...
	 start solving instance: 136...
	 start solving instance: 40...
	 start solving instance: 35...
	 start solving instance: 15...
	 start solving instance: 24...
	 start solving instance: 75...
	 start solving instance: 83...
	 start solving instance: 7...
	 start solving instance: 105...
	 start solving instance: 125...
	 start solving instance: 104...
	 start solving instance: 68...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.71860681915703e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5864619008.0
		 entropy bonus: 0.20312224328517914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5768990208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6422025728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.718606874132611e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.71860681915703e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5864619008.0
		 entropy bonus: 0.20312224328517914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5768990208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6422025728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.718606874132611e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.71860681915703e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5864619008.0
		 entropy bonus: 0.20312224328517914
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5768990208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6422025728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.718606874132611e+18 - Differentiable computation graph = True!
PPO iteration: 469/1000:
	 start solving instance: 65...
	 start solving instance: 40...
	 start solving instance: 35...
	 start solving instance: 144...
	 start solving instance: 83...
	 start solving instance: 147...
	 start solving instance: 7...
	 start solving instance: 68...
	 start solving instance: 149...
	 start solving instance: 15...
	 start solving instance: 91...
	 start solving instance: 62...
	 start solving instance: 136...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 24...
	 start solving instance: 104...
	 start solving instance: 125...
	 start solving instance: 5...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7201914353149805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5923748864.0
		 entropy bonus: 0.19931438565254211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5712651776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6490826240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.720191545266143e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7201914353149805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5923748864.0
		 entropy bonus: 0.19931438565254211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5712651776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6490826240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.720191545266143e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7201914353149805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5923748864.0
		 entropy bonus: 0.19931438565254211
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5712651776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6490826240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.720191545266143e+18 - Differentiable computation graph = True!
PPO iteration: 470/1000:
	 start solving instance: 105...
	 start solving instance: 149...
	 start solving instance: 142...
	 start solving instance: 24...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 40...
	 start solving instance: 7...
	 start solving instance: 125...
	 start solving instance: 104...
	 start solving instance: 136...
	 start solving instance: 144...
	 start solving instance: 15...
	 start solving instance: 91...
	 start solving instance: 83...
	 start solving instance: 65...
	 start solving instance: 62...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.443685151650244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5758513152.0
		 entropy bonus: 0.20678141713142395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5491429376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6245191168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.443685261601407e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.443685151650244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5758513152.0
		 entropy bonus: 0.20678141713142395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5491429376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6245191168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.443685261601407e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.443685151650244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5758513152.0
		 entropy bonus: 0.20678141713142395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5491429376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6245191168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.443685261601407e+18 - Differentiable computation graph = True!
PPO iteration: 471/1000:
	 New training batch of size 20...
	 start solving instance: 132...
	 start solving instance: 41...
	 start solving instance: 101...
	 start solving instance: 100...
	 start solving instance: 124...
	 start solving instance: 116...
	 start solving instance: 138...
	 start solving instance: 150...
	 start solving instance: 5...
	 start solving instance: 89...
	 start solving instance: 46...
	 start solving instance: 64...
	 start solving instance: 144...
	 start solving instance: 111...
	 start solving instance: 11...
	 start solving instance: 90...
	 start solving instance: 26...
	 start solving instance: 40...
	 start solving instance: 129...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.026440608022685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5884969472.0
		 entropy bonus: 0.21847692131996155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5826446848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6889892352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.026440717973848e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.026440608022685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5884969472.0
		 entropy bonus: 0.21847692131996155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5826446848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6889892352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.026440717973848e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.026440608022685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5884969472.0
		 entropy bonus: 0.21847692131996155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5826446848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6889892352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.026440717973848e+18 - Differentiable computation graph = True!
PPO iteration: 472/1000:
	 start solving instance: 40...
	 start solving instance: 64...
	 start solving instance: 111...
	 start solving instance: 124...
	 start solving instance: 5...
	 start solving instance: 101...
	 start solving instance: 46...
	 start solving instance: 26...
	 start solving instance: 100...
	 start solving instance: 90...
	 start solving instance: 41...
	 start solving instance: 129...
	 start solving instance: 144...
	 start solving instance: 17...
	 start solving instance: 138...
	 start solving instance: 89...
	 start solving instance: 132...
	 start solving instance: 150...
	 start solving instance: 116...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.921555994825877e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981277184.0
		 entropy bonus: 0.20862935483455658
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842429952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6812577792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.92155610477704e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.921555994825877e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981277184.0
		 entropy bonus: 0.20862935483455658
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842429952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6812577792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.92155610477704e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.921555994825877e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981277184.0
		 entropy bonus: 0.20862935483455658
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842429952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6812577792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.92155610477704e+18 - Differentiable computation graph = True!
PPO iteration: 473/1000:
	 start solving instance: 129...
	 start solving instance: 150...
	 start solving instance: 89...
	 start solving instance: 26...
	 start solving instance: 124...
	 start solving instance: 116...
	 start solving instance: 101...
	 start solving instance: 40...
	 start solving instance: 138...
	 start solving instance: 17...
	 start solving instance: 111...
	 start solving instance: 144...
	 start solving instance: 90...
	 start solving instance: 46...
	 start solving instance: 11...
	 start solving instance: 132...
	 start solving instance: 5...
	 start solving instance: 41...
	 start solving instance: 64...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0692146889757295e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967887872.0
		 entropy bonus: 0.21339169144630432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938288128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6800250880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.069214743951311e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0692146889757295e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967887872.0
		 entropy bonus: 0.21339169144630432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938288128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6800250880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.069214743951311e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0692146889757295e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967887872.0
		 entropy bonus: 0.21339169144630432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938288128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6800250880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.069214743951311e+18 - Differentiable computation graph = True!
PPO iteration: 474/1000:
	 start solving instance: 5...
	 start solving instance: 100...
	 start solving instance: 46...
	 start solving instance: 64...
	 start solving instance: 101...
	 start solving instance: 132...
	 start solving instance: 129...
	 start solving instance: 40...
	 start solving instance: 111...
	 start solving instance: 41...
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 138...
	 start solving instance: 17...
	 start solving instance: 89...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 150...
	 start solving instance: 90...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.73965850858708e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5891458560.0
		 entropy bonus: 0.21191148459911346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5610591232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584041472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.739658673513824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.73965850858708e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5891458560.0
		 entropy bonus: 0.21191148459911346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5610591232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584041472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.739658673513824e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.73965850858708e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5891458560.0
		 entropy bonus: 0.21191148459911346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5610591232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584041472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.739658673513824e+18 - Differentiable computation graph = True!
PPO iteration: 475/1000:
	 start solving instance: 129...
	 start solving instance: 111...
	 start solving instance: 11...
	 start solving instance: 144...
	 start solving instance: 17...
	 start solving instance: 26...
	 start solving instance: 46...
	 start solving instance: 101...
	 start solving instance: 138...
	 start solving instance: 90...
	 start solving instance: 100...
	 start solving instance: 132...
	 start solving instance: 124...
	 start solving instance: 64...
	 start solving instance: 89...
	 start solving instance: 41...
	 start solving instance: 40...
	 start solving instance: 116...
	 start solving instance: 150...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.011624908740729e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6036432384.0
		 entropy bonus: 0.20849798619747162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5900344832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6647533568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0116250736674734e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.011624908740729e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6036432384.0
		 entropy bonus: 0.20849798619747162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5900344832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6647533568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0116250736674734e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.011624908740729e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6036432384.0
		 entropy bonus: 0.20849798619747162
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5900344832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6647533568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0116250736674734e+18 - Differentiable computation graph = True!
PPO iteration: 476/1000:
	 start solving instance: 116...
	 start solving instance: 101...
	 start solving instance: 138...
	 start solving instance: 100...
	 start solving instance: 89...
	 start solving instance: 124...
	 start solving instance: 150...
	 start solving instance: 129...
	 start solving instance: 40...
	 start solving instance: 90...
	 start solving instance: 5...
	 start solving instance: 64...
	 start solving instance: 11...
	 start solving instance: 46...
	 start solving instance: 17...
	 start solving instance: 144...
	 start solving instance: 111...
	 start solving instance: 132...
	 start solving instance: 41...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.098413319762949e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022009344.0
		 entropy bonus: 0.21266542375087738
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6042272768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6829136896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0984133747385303e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.098413319762949e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022009344.0
		 entropy bonus: 0.21266542375087738
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6042272768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6829136896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0984133747385303e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.098413319762949e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022009344.0
		 entropy bonus: 0.21266542375087738
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6042272768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6829136896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0984133747385303e+18 - Differentiable computation graph = True!
PPO iteration: 477/1000:
	 start solving instance: 138...
	 start solving instance: 41...
	 start solving instance: 46...
	 start solving instance: 132...
	 start solving instance: 17...
	 start solving instance: 101...
	 start solving instance: 111...
	 start solving instance: 64...
	 start solving instance: 5...
	 start solving instance: 11...
	 start solving instance: 129...
	 start solving instance: 150...
	 start solving instance: 90...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 124...
	 start solving instance: 100...
	 start solving instance: 26...
	 start solving instance: 40...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.001654097495405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6073658368.0
		 entropy bonus: 0.20415177941322327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922020352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6825719808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.001654152470987e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.001654097495405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6073658368.0
		 entropy bonus: 0.20415177941322327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922020352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6825719808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.001654152470987e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.001654097495405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6073658368.0
		 entropy bonus: 0.20415177941322327
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922020352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6825719808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.001654152470987e+18 - Differentiable computation graph = True!
PPO iteration: 478/1000:
	 start solving instance: 101...
	 start solving instance: 11...
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 100...
	 start solving instance: 132...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 90...
	 start solving instance: 150...
	 start solving instance: 116...
	 start solving instance: 5...
	 start solving instance: 46...
	 start solving instance: 26...
	 start solving instance: 89...
	 start solving instance: 17...
	 start solving instance: 111...
	 start solving instance: 41...
	 start solving instance: 64...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.188297955528986e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6072331776.0
		 entropy bonus: 0.216742143034935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6033047040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6947672064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1882979005534044e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.188297955528986e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6072331776.0
		 entropy bonus: 0.216742143034935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6033047040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6947672064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1882979005534044e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.188297955528986e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6072331776.0
		 entropy bonus: 0.216742143034935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6033047040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6947672064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1882979005534044e+18 - Differentiable computation graph = True!
PPO iteration: 479/1000:
	 start solving instance: 17...
	 start solving instance: 129...
	 start solving instance: 116...
	 start solving instance: 101...
	 start solving instance: 144...
	 start solving instance: 41...
	 start solving instance: 46...
	 start solving instance: 11...
	 start solving instance: 64...
	 start solving instance: 89...
	 start solving instance: 138...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 111...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 26...
	 start solving instance: 150...
	 start solving instance: 5...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.957207439454188e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5984221696.0
		 entropy bonus: 0.20884661376476288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920522240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6766691840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9572074944297697e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.957207439454188e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5984221696.0
		 entropy bonus: 0.20884661376476288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920522240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6766691840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9572074944297697e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.957207439454188e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5984221696.0
		 entropy bonus: 0.20884661376476288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920522240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6766691840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9572074944297697e+18 - Differentiable computation graph = True!
PPO iteration: 480/1000:
	 start solving instance: 40...
	 start solving instance: 101...
	 start solving instance: 46...
	 start solving instance: 17...
	 start solving instance: 89...
	 start solving instance: 116...
	 start solving instance: 64...
	 start solving instance: 111...
	 start solving instance: 11...
	 start solving instance: 5...
	 start solving instance: 41...
	 start solving instance: 138...
	 start solving instance: 124...
	 start solving instance: 150...
	 start solving instance: 132...
	 start solving instance: 90...
	 start solving instance: 100...
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.038183832011984e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6174935040.0
		 entropy bonus: 0.20862407982349396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5803141632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6799185408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0381837770364027e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.038183832011984e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6174935040.0
		 entropy bonus: 0.20862407982349396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5803141632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6799185408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0381837770364027e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.038183832011984e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6174935040.0
		 entropy bonus: 0.20862407982349396
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5803141632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6799185408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0381837770364027e+18 - Differentiable computation graph = True!
PPO iteration: 481/1000:
	 New training batch of size 20...
	 start solving instance: 104...
	 start solving instance: 78...
	 start solving instance: 120...
	 start solving instance: 111...
	 start solving instance: 126...
	 start solving instance: 105...
	 start solving instance: 41...
	 start solving instance: 12...
	 start solving instance: 128...
	 start solving instance: 103...
	 start solving instance: 89...
	 start solving instance: 65...
	 start solving instance: 39...
	 start solving instance: 49...
	 start solving instance: 150...
	 start solving instance: 18...
	 start solving instance: 108...
	 start solving instance: 125...
	 start solving instance: 9...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.770396015848535e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5862076416.0
		 entropy bonus: 0.21919865906238556
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842464256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486065664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.770396070824116e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.770396015848535e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5862076416.0
		 entropy bonus: 0.21919865906238556
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842464256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486065664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.770396070824116e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.770396015848535e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5862076416.0
		 entropy bonus: 0.21919865906238556
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842464256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486065664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.770396070824116e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.064222798183819e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5187209728.0
		 entropy bonus: 0.22289219498634338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5150112256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6162663936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3064222908134981632.0000
PPO iteration: 482/1000:
	 start solving instance: 39...
	 start solving instance: 78...
	 start solving instance: 18...
	 start solving instance: 9...
	 start solving instance: 111...
	 start solving instance: 103...
	 start solving instance: 89...
	 start solving instance: 65...
	 start solving instance: 105...
	 start solving instance: 104...
	 start solving instance: 108...
	 start solving instance: 12...
	 start solving instance: 49...
	 start solving instance: 125...
	 start solving instance: 149...
	 start solving instance: 128...
	 start solving instance: 126...
	 start solving instance: 41...
	 start solving instance: 150...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5878201309354e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745098752.0
		 entropy bonus: 0.21617089211940765
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5683609088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6749718528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.587820240886563e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5878201309354e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745098752.0
		 entropy bonus: 0.21617089211940765
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5683609088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6749718528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.587820240886563e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5878201309354e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745098752.0
		 entropy bonus: 0.21617089211940765
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5683609088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6749718528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.587820240886563e+18 - Differentiable computation graph = True!
PPO iteration: 483/1000:
	 start solving instance: 9...
	 start solving instance: 12...
	 start solving instance: 111...
	 start solving instance: 105...
	 start solving instance: 103...
	 start solving instance: 49...
	 start solving instance: 120...
	 start solving instance: 125...
	 start solving instance: 150...
	 start solving instance: 65...
	 start solving instance: 78...
	 start solving instance: 18...
	 start solving instance: 149...
	 start solving instance: 108...
	 start solving instance: 126...
	 start solving instance: 104...
	 start solving instance: 128...
	 start solving instance: 41...
	 start solving instance: 39...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.676561714413201e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5746138624.0
		 entropy bonus: 0.22175590693950653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5804088832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330119168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676561824364364e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.676561714413201e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5746138624.0
		 entropy bonus: 0.22175590693950653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5804088832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330119168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676561824364364e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.676561714413201e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5746138624.0
		 entropy bonus: 0.22175590693950653
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5804088832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330119168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676561824364364e+18 - Differentiable computation graph = True!
PPO iteration: 484/1000:
	 start solving instance: 39...
	 start solving instance: 108...
	 start solving instance: 150...
	 start solving instance: 18...
	 start solving instance: 104...
	 start solving instance: 41...
	 start solving instance: 65...
	 start solving instance: 12...
	 start solving instance: 105...
	 start solving instance: 78...
	 start solving instance: 149...
	 start solving instance: 128...
	 start solving instance: 120...
	 start solving instance: 125...
	 start solving instance: 103...
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 126...
	 start solving instance: 111...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.862746636293348e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5911315456.0
		 entropy bonus: 0.216043621301651
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5948655616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661036032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.862746801220092e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.862746636293348e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5911315456.0
		 entropy bonus: 0.216043621301651
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5948655616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661036032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.862746801220092e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.862746636293348e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5911315456.0
		 entropy bonus: 0.216043621301651
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5948655616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661036032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.862746801220092e+18 - Differentiable computation graph = True!
PPO iteration: 485/1000:
	 start solving instance: 89...
	 start solving instance: 126...
	 start solving instance: 105...
	 start solving instance: 125...
	 start solving instance: 120...
	 start solving instance: 9...
	 start solving instance: 150...
	 start solving instance: 103...
	 start solving instance: 128...
	 start solving instance: 18...
	 start solving instance: 78...
	 start solving instance: 65...
	 start solving instance: 108...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 41...
	 start solving instance: 12...
	 start solving instance: 39...
	 start solving instance: 111...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.418407819132325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5658932224.0
		 entropy bonus: 0.2119964212179184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5525065216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330560512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4184077641567437e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.418407819132325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5658932224.0
		 entropy bonus: 0.2119964212179184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5525065216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330560512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4184077641567437e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.418407819132325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5658932224.0
		 entropy bonus: 0.2119964212179184
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5525065216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330560512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4184077641567437e+18 - Differentiable computation graph = True!
PPO iteration: 486/1000:
	 start solving instance: 111...
	 start solving instance: 65...
	 start solving instance: 49...
	 start solving instance: 104...
	 start solving instance: 9...
	 start solving instance: 39...
	 start solving instance: 89...
	 start solving instance: 18...
	 start solving instance: 128...
	 start solving instance: 126...
	 start solving instance: 120...
	 start solving instance: 150...
	 start solving instance: 103...
	 start solving instance: 12...
	 start solving instance: 78...
	 start solving instance: 41...
	 start solving instance: 108...
	 start solving instance: 125...
	 start solving instance: 149...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.73535721909922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5843211776.0
		 entropy bonus: 0.21809081733226776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5806878720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6481720320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7353573840259645e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.73535721909922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5843211776.0
		 entropy bonus: 0.21809081733226776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5806878720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6481720320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7353573840259645e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.73535721909922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5843211776.0
		 entropy bonus: 0.21809081733226776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5806878720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6481720320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7353573840259645e+18 - Differentiable computation graph = True!
PPO iteration: 487/1000:
	 start solving instance: 150...
	 start solving instance: 104...
	 start solving instance: 128...
	 start solving instance: 65...
	 start solving instance: 9...
	 start solving instance: 39...
	 start solving instance: 41...
	 start solving instance: 105...
	 start solving instance: 78...
	 start solving instance: 103...
	 start solving instance: 89...
	 start solving instance: 108...
	 start solving instance: 12...
	 start solving instance: 49...
	 start solving instance: 18...
	 start solving instance: 126...
	 start solving instance: 149...
	 start solving instance: 111...
	 start solving instance: 125...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.790475736999631e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885591552.0
		 entropy bonus: 0.21672625839710236
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5884744704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6427841024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7904759019263754e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.790475736999631e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885591552.0
		 entropy bonus: 0.21672625839710236
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5884744704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6427841024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7904759019263754e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.790475736999631e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885591552.0
		 entropy bonus: 0.21672625839710236
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5884744704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6427841024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7904759019263754e+18 - Differentiable computation graph = True!
PPO iteration: 488/1000:
	 start solving instance: 89...
	 start solving instance: 103...
	 start solving instance: 128...
	 start solving instance: 49...
	 start solving instance: 41...
	 start solving instance: 120...
	 start solving instance: 125...
	 start solving instance: 12...
	 start solving instance: 111...
	 start solving instance: 149...
	 start solving instance: 39...
	 start solving instance: 9...
	 start solving instance: 104...
	 start solving instance: 18...
	 start solving instance: 108...
	 start solving instance: 78...
	 start solving instance: 65...
	 start solving instance: 126...
	 start solving instance: 150...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.946697867511254e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5947205120.0
		 entropy bonus: 0.2241867333650589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6025485312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988860416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.946697812535673e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.946697867511254e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5947205120.0
		 entropy bonus: 0.2241867333650589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6025485312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988860416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.946697812535673e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.946697867511254e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5947205120.0
		 entropy bonus: 0.2241867333650589
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6025485312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988860416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.946697812535673e+18 - Differentiable computation graph = True!
PPO iteration: 489/1000:
	 start solving instance: 12...
	 start solving instance: 111...
	 start solving instance: 78...
	 start solving instance: 39...
	 start solving instance: 89...
	 start solving instance: 108...
	 start solving instance: 65...
	 start solving instance: 128...
	 start solving instance: 9...
	 start solving instance: 126...
	 start solving instance: 41...
	 start solving instance: 150...
	 start solving instance: 104...
	 start solving instance: 120...
	 start solving instance: 49...
	 start solving instance: 149...
	 start solving instance: 105...
	 start solving instance: 18...
	 start solving instance: 103...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.690909681448701e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5717303296.0
		 entropy bonus: 0.21918439865112305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5778172416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419850752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.69090962647312e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.690909681448701e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5717303296.0
		 entropy bonus: 0.21918439865112305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5778172416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419850752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.69090962647312e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.690909681448701e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5717303296.0
		 entropy bonus: 0.21918439865112305
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5778172416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419850752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.69090962647312e+18 - Differentiable computation graph = True!
PPO iteration: 490/1000:
	 start solving instance: 149...
	 start solving instance: 103...
	 start solving instance: 39...
	 start solving instance: 108...
	 start solving instance: 78...
	 start solving instance: 65...
	 start solving instance: 9...
	 start solving instance: 120...
	 start solving instance: 18...
	 start solving instance: 12...
	 start solving instance: 104...
	 start solving instance: 105...
	 start solving instance: 126...
	 start solving instance: 150...
	 start solving instance: 89...
	 start solving instance: 41...
	 start solving instance: 125...
	 start solving instance: 128...
	 start solving instance: 49...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.753716424455173e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5871662592.0
		 entropy bonus: 0.22703535854816437
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5885660672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6950696960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7537164794307543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.753716424455173e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5871662592.0
		 entropy bonus: 0.22703535854816437
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5885660672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6950696960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7537164794307543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.753716424455173e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5871662592.0
		 entropy bonus: 0.22703535854816437
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5885660672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6950696960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7537164794307543e+18 - Differentiable computation graph = True!
PPO iteration: 491/1000:
	 New training batch of size 20...
	 start solving instance: 87...
	 start solving instance: 120...
	 start solving instance: 42...
	 start solving instance: 68...
	 start solving instance: 51...
	 start solving instance: 144...
	 start solving instance: 133...
	 start solving instance: 137...
	 start solving instance: 12...
	 start solving instance: 65...
	 start solving instance: 79...
	 start solving instance: 81...
	 start solving instance: 23...
	 start solving instance: 85...
	 start solving instance: 125...
	 start solving instance: 50...
	 start solving instance: 54...
	 start solving instance: 97...
	 start solving instance: 99...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.959778097639929e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5920972800.0
		 entropy bonus: 0.20495522022247314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5688241664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6808809984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.95977815261551e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.959778097639929e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5920972800.0
		 entropy bonus: 0.20495522022247314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5688241664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6808809984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.95977815261551e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.959778097639929e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5920972800.0
		 entropy bonus: 0.20495522022247314
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5688241664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6808809984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.95977815261551e+18 - Differentiable computation graph = True!
PPO iteration: 492/1000:
	 start solving instance: 133...
	 start solving instance: 54...
	 start solving instance: 12...
	 start solving instance: 42...
	 start solving instance: 51...
	 start solving instance: 144...
	 start solving instance: 97...
	 start solving instance: 65...
	 start solving instance: 23...
	 start solving instance: 85...
	 start solving instance: 120...
	 start solving instance: 79...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 87...
	 start solving instance: 50...
	 start solving instance: 57...
	 start solving instance: 81...
	 start solving instance: 68...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2298190330310164e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030548992.0
		 entropy bonus: 0.20099616050720215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6119157760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7543042048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2298190330310164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2298190330310164e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030548992.0
		 entropy bonus: 0.20099616050720215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6119157760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7543042048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2298190330310164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2298190330310164e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030548992.0
		 entropy bonus: 0.20099616050720215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6119157760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7543042048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2298190330310164e+18 - Differentiable computation graph = True!
PPO iteration: 493/1000:
	 start solving instance: 81...
	 start solving instance: 85...
	 start solving instance: 12...
	 start solving instance: 125...
	 start solving instance: 42...
	 start solving instance: 23...
	 start solving instance: 97...
	 start solving instance: 133...
	 start solving instance: 79...
	 start solving instance: 144...
	 start solving instance: 54...
	 start solving instance: 50...
	 start solving instance: 57...
	 start solving instance: 99...
	 start solving instance: 65...
	 start solving instance: 137...
	 start solving instance: 87...
	 start solving instance: 51...
	 start solving instance: 120...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2430932170108305e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5988012032.0
		 entropy bonus: 0.20339007675647736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032636928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6621936128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.243093162035249e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2430932170108305e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5988012032.0
		 entropy bonus: 0.20339007675647736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032636928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6621936128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.243093162035249e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2430932170108305e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5988012032.0
		 entropy bonus: 0.20339007675647736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032636928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6621936128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.243093162035249e+18 - Differentiable computation graph = True!
PPO iteration: 494/1000:
	 start solving instance: 42...
	 start solving instance: 85...
	 start solving instance: 125...
	 start solving instance: 68...
	 start solving instance: 120...
	 start solving instance: 23...
	 start solving instance: 79...
	 start solving instance: 81...
	 start solving instance: 65...
	 start solving instance: 144...
	 start solving instance: 54...
	 start solving instance: 87...
	 start solving instance: 50...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 51...
	 start solving instance: 97...
	 start solving instance: 57...
	 start solving instance: 12...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.808773369704428e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5849954816.0
		 entropy bonus: 0.19783735275268555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5614679040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486045184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8087734246800097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.808773369704428e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5849954816.0
		 entropy bonus: 0.19783735275268555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5614679040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486045184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8087734246800097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.808773369704428e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5849954816.0
		 entropy bonus: 0.19783735275268555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5614679040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6486045184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8087734246800097e+18 - Differentiable computation graph = True!
PPO iteration: 495/1000:
	 start solving instance: 137...
	 start solving instance: 50...
	 start solving instance: 68...
	 start solving instance: 125...
	 start solving instance: 87...
	 start solving instance: 99...
	 start solving instance: 51...
	 start solving instance: 97...
	 start solving instance: 79...
	 start solving instance: 12...
	 start solving instance: 23...
	 start solving instance: 42...
	 start solving instance: 81...
	 start solving instance: 65...
	 start solving instance: 144...
	 start solving instance: 54...
	 start solving instance: 85...
	 start solving instance: 57...
	 start solving instance: 120...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.263396798729342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5993235968.0
		 entropy bonus: 0.2053239792585373
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6133907456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7127029760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.263396743753761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.263396798729342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5993235968.0
		 entropy bonus: 0.2053239792585373
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6133907456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7127029760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.263396743753761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.263396798729342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5993235968.0
		 entropy bonus: 0.2053239792585373
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6133907456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7127029760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.263396743753761e+18 - Differentiable computation graph = True!
PPO iteration: 496/1000:
	 start solving instance: 87...
	 start solving instance: 68...
	 start solving instance: 125...
	 start solving instance: 81...
	 start solving instance: 12...
	 start solving instance: 120...
	 start solving instance: 50...
	 start solving instance: 85...
	 start solving instance: 42...
	 start solving instance: 51...
	 start solving instance: 133...
	 start solving instance: 144...
	 start solving instance: 54...
	 start solving instance: 137...
	 start solving instance: 65...
	 start solving instance: 99...
	 start solving instance: 57...
	 start solving instance: 97...
	 start solving instance: 23...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.290437308093563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5977893888.0
		 entropy bonus: 0.2100812941789627
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6238991360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7171808256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.290437308093563e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.290437308093563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5977893888.0
		 entropy bonus: 0.2100812941789627
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6238991360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7171808256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.290437308093563e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.290437308093563e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5977893888.0
		 entropy bonus: 0.2100812941789627
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6238991360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7171808256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.290437308093563e+18 - Differentiable computation graph = True!
PPO iteration: 497/1000:
	 start solving instance: 65...
	 start solving instance: 23...
	 start solving instance: 12...
	 start solving instance: 120...
	 start solving instance: 137...
	 start solving instance: 51...
	 start solving instance: 50...
	 start solving instance: 97...
	 start solving instance: 79...
	 start solving instance: 57...
	 start solving instance: 87...
	 start solving instance: 99...
	 start solving instance: 54...
	 start solving instance: 125...
	 start solving instance: 42...
	 start solving instance: 81...
	 start solving instance: 85...
	 start solving instance: 133...
	 start solving instance: 68...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.032286931249896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5922713600.0
		 entropy bonus: 0.21307122707366943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5939721728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7142072832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.03228709617664e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.032286931249896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5922713600.0
		 entropy bonus: 0.21307122707366943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5939721728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7142072832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.03228709617664e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.032286931249896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5922713600.0
		 entropy bonus: 0.21307122707366943
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5939721728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7142072832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.03228709617664e+18 - Differentiable computation graph = True!
PPO iteration: 498/1000:
	 start solving instance: 133...
	 start solving instance: 81...
	 start solving instance: 68...
	 start solving instance: 87...
	 start solving instance: 50...
	 start solving instance: 42...
	 start solving instance: 23...
	 start solving instance: 144...
	 start solving instance: 54...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 65...
	 start solving instance: 79...
	 start solving instance: 85...
	 start solving instance: 51...
	 start solving instance: 57...
	 start solving instance: 12...
	 start solving instance: 120...
	 start solving instance: 97...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.249062245735701e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069938176.0
		 entropy bonus: 0.19833509624004364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6205280256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7281142784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249062410662445e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.249062245735701e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069938176.0
		 entropy bonus: 0.19833509624004364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6205280256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7281142784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249062410662445e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.249062245735701e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069938176.0
		 entropy bonus: 0.19833509624004364
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6205280256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7281142784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.249062410662445e+18 - Differentiable computation graph = True!
PPO iteration: 499/1000:
	 start solving instance: 97...
	 start solving instance: 120...
	 start solving instance: 51...
	 start solving instance: 85...
	 start solving instance: 54...
	 start solving instance: 23...
	 start solving instance: 42...
	 start solving instance: 12...
	 start solving instance: 125...
	 start solving instance: 87...
	 start solving instance: 68...
	 start solving instance: 57...
	 start solving instance: 81...
	 start solving instance: 144...
	 start solving instance: 137...
	 start solving instance: 99...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 65...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.057405494288764e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023372288.0
		 entropy bonus: 0.1960686296224594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5932164096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6632883712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0574054393131827e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.057405494288764e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023372288.0
		 entropy bonus: 0.1960686296224594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5932164096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6632883712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0574054393131827e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.057405494288764e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023372288.0
		 entropy bonus: 0.1960686296224594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5932164096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6632883712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0574054393131827e+18 - Differentiable computation graph = True!
PPO iteration: 500/1000:
	 start solving instance: 97...
	 start solving instance: 99...
	 start solving instance: 125...
	 start solving instance: 65...
	 start solving instance: 133...
	 start solving instance: 12...
	 start solving instance: 23...
	 start solving instance: 81...
	 start solving instance: 50...
	 start solving instance: 68...
	 start solving instance: 120...
	 start solving instance: 85...
	 start solving instance: 144...
	 start solving instance: 42...
	 start solving instance: 54...
	 start solving instance: 137...
	 start solving instance: 79...
	 start solving instance: 51...
	 start solving instance: 87...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.395018456081105e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981711360.0
		 entropy bonus: 0.21716995537281036
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6348777984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7181221888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.395018456081105e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.395018456081105e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981711360.0
		 entropy bonus: 0.21716995537281036
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6348777984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7181221888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.395018456081105e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.395018456081105e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981711360.0
		 entropy bonus: 0.21716995537281036
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6348777984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7181221888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.395018456081105e+18 - Differentiable computation graph = True!
PPO iteration: 501/1000:
	 New training batch of size 20...
	 start solving instance: 142...
	 start solving instance: 98...
	 start solving instance: 114...
	 start solving instance: 135...
	 start solving instance: 78...
	 start solving instance: 132...
	 start solving instance: 130...
	 start solving instance: 45...
	 start solving instance: 41...
	 start solving instance: 101...
	 start solving instance: 3...
	 start solving instance: 42...
	 start solving instance: 127...
	 start solving instance: 92...
	 start solving instance: 80...
	 start solving instance: 83...
	 start solving instance: 54...
	 start solving instance: 63...
	 start solving instance: 76...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.750227893962565e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5931258880.0
		 entropy bonus: 0.2024879902601242
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5878872576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6508127744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.750228003913728e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.750227893962565e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5931258880.0
		 entropy bonus: 0.2024879902601242
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5878872576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6508127744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.750228003913728e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.750227893962565e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5931258880.0
		 entropy bonus: 0.2024879902601242
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5878872576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6508127744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.750228003913728e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.0364218665778282e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5392858112.0
		 entropy bonus: 0.1947234719991684
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5131608064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6263891968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3036422031504572416.0000
PPO iteration: 502/1000:
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 130...
	 start solving instance: 41...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 78...
	 start solving instance: 114...
	 start solving instance: 98...
	 start solving instance: 63...
	 start solving instance: 45...
	 start solving instance: 132...
	 start solving instance: 76...
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 127...
	 start solving instance: 146...
	 start solving instance: 80...
	 start solving instance: 83...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.821123084307608e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5949867520.0
		 entropy bonus: 0.2011713832616806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5919965696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6816293888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.82112313928319e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.821123084307608e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5949867520.0
		 entropy bonus: 0.2011713832616806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5919965696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6816293888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.82112313928319e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.821123084307608e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5949867520.0
		 entropy bonus: 0.2011713832616806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5919965696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6816293888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.82112313928319e+18 - Differentiable computation graph = True!
PPO iteration: 503/1000:
	 start solving instance: 92...
	 start solving instance: 54...
	 start solving instance: 127...
	 start solving instance: 78...
	 start solving instance: 142...
	 start solving instance: 114...
	 start solving instance: 80...
	 start solving instance: 132...
	 start solving instance: 130...
	 start solving instance: 45...
	 start solving instance: 42...
	 start solving instance: 63...
	 start solving instance: 146...
	 start solving instance: 76...
	 start solving instance: 135...
	 start solving instance: 101...
	 start solving instance: 41...
	 start solving instance: 83...
	 start solving instance: 98...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6520252328300773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5857290752.0
		 entropy bonus: 0.20260098576545715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5649295872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6176394752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6520253977568215e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6520252328300773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5857290752.0
		 entropy bonus: 0.20260098576545715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5649295872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6176394752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6520253977568215e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6520252328300773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5857290752.0
		 entropy bonus: 0.20260098576545715
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5649295872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6176394752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6520253977568215e+18 - Differentiable computation graph = True!
PPO iteration: 504/1000:
	 start solving instance: 78...
	 start solving instance: 76...
	 start solving instance: 54...
	 start solving instance: 63...
	 start solving instance: 83...
	 start solving instance: 135...
	 start solving instance: 130...
	 start solving instance: 45...
	 start solving instance: 132...
	 start solving instance: 101...
	 start solving instance: 98...
	 start solving instance: 92...
	 start solving instance: 80...
	 start solving instance: 42...
	 start solving instance: 114...
	 start solving instance: 3...
	 start solving instance: 127...
	 start solving instance: 146...
	 start solving instance: 41...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.863641638758357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023252480.0
		 entropy bonus: 0.21192319691181183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934401536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6422509568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8636418036851016e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.863641638758357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023252480.0
		 entropy bonus: 0.21192319691181183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934401536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6422509568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8636418036851016e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.863641638758357e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023252480.0
		 entropy bonus: 0.21192319691181183
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934401536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6422509568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8636418036851016e+18 - Differentiable computation graph = True!
PPO iteration: 505/1000:
	 start solving instance: 146...
	 start solving instance: 76...
	 start solving instance: 98...
	 start solving instance: 92...
	 start solving instance: 54...
	 start solving instance: 101...
	 start solving instance: 132...
	 start solving instance: 80...
	 start solving instance: 41...
	 start solving instance: 78...
	 start solving instance: 130...
	 start solving instance: 42...
	 start solving instance: 3...
	 start solving instance: 63...
	 start solving instance: 135...
	 start solving instance: 45...
	 start solving instance: 142...
	 start solving instance: 83...
	 start solving instance: 114...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.621948971861567e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5936004608.0
		 entropy bonus: 0.1995885670185089
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5680857088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6521458688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.62194908181273e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.621948971861567e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5936004608.0
		 entropy bonus: 0.1995885670185089
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5680857088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6521458688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.62194908181273e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.621948971861567e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5936004608.0
		 entropy bonus: 0.1995885670185089
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5680857088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6521458688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.62194908181273e+18 - Differentiable computation graph = True!
PPO iteration: 506/1000:
	 start solving instance: 45...
	 start solving instance: 78...
	 start solving instance: 83...
	 start solving instance: 92...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 3...
	 start solving instance: 42...
	 start solving instance: 76...
	 start solving instance: 146...
	 start solving instance: 41...
	 start solving instance: 63...
	 start solving instance: 130...
	 start solving instance: 135...
	 start solving instance: 127...
	 start solving instance: 98...
	 start solving instance: 132...
	 start solving instance: 142...
	 start solving instance: 80...
	 start solving instance: 114...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.840268660379746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5904406016.0
		 entropy bonus: 0.2016664743423462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5903817216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6697939968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8402686603797463e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.840268660379746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5904406016.0
		 entropy bonus: 0.2016664743423462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5903817216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6697939968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8402686603797463e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.840268660379746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5904406016.0
		 entropy bonus: 0.2016664743423462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5903817216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6697939968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8402686603797463e+18 - Differentiable computation graph = True!
PPO iteration: 507/1000:
	 start solving instance: 130...
	 start solving instance: 45...
	 start solving instance: 101...
	 start solving instance: 83...
	 start solving instance: 92...
	 start solving instance: 80...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 78...
	 start solving instance: 3...
	 start solving instance: 54...
	 start solving instance: 114...
	 start solving instance: 63...
	 start solving instance: 146...
	 start solving instance: 98...
	 start solving instance: 42...
	 start solving instance: 76...
	 start solving instance: 41...
	 start solving instance: 132...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.670969158469681e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5955397120.0
		 entropy bonus: 0.1993323713541031
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5647175168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6654265856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.670969158469681e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.670969158469681e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5955397120.0
		 entropy bonus: 0.1993323713541031
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5647175168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6654265856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.670969158469681e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.670969158469681e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5955397120.0
		 entropy bonus: 0.1993323713541031
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5647175168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6654265856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.670969158469681e+18 - Differentiable computation graph = True!
PPO iteration: 508/1000:
	 start solving instance: 146...
	 start solving instance: 80...
	 start solving instance: 114...
	 start solving instance: 63...
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 45...
	 start solving instance: 78...
	 start solving instance: 130...
	 start solving instance: 142...
	 start solving instance: 127...
	 start solving instance: 54...
	 start solving instance: 101...
	 start solving instance: 83...
	 start solving instance: 92...
	 start solving instance: 41...
	 start solving instance: 132...
	 start solving instance: 98...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6051822991472853e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5918354432.0
		 entropy bonus: 0.20125198364257812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5702904832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6174727680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6051823541228667e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6051822991472853e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5918354432.0
		 entropy bonus: 0.20125198364257812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5702904832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6174727680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6051823541228667e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6051822991472853e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5918354432.0
		 entropy bonus: 0.20125198364257812
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5702904832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6174727680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6051823541228667e+18 - Differentiable computation graph = True!
PPO iteration: 509/1000:
	 start solving instance: 130...
	 start solving instance: 98...
	 start solving instance: 80...
	 start solving instance: 83...
	 start solving instance: 54...
	 start solving instance: 63...
	 start solving instance: 135...
	 start solving instance: 146...
	 start solving instance: 142...
	 start solving instance: 132...
	 start solving instance: 78...
	 start solving instance: 3...
	 start solving instance: 114...
	 start solving instance: 127...
	 start solving instance: 101...
	 start solving instance: 42...
	 start solving instance: 41...
	 start solving instance: 45...
	 start solving instance: 92...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6075310758865404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5895484416.0
		 entropy bonus: 0.20249305665493011
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5553991168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6302183936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.607531185837703e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6075310758865404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5895484416.0
		 entropy bonus: 0.20249305665493011
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5553991168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6302183936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.607531185837703e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6075310758865404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5895484416.0
		 entropy bonus: 0.20249305665493011
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5553991168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6302183936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.607531185837703e+18 - Differentiable computation graph = True!
PPO iteration: 510/1000:
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 45...
	 start solving instance: 130...
	 start solving instance: 76...
	 start solving instance: 78...
	 start solving instance: 80...
	 start solving instance: 41...
	 start solving instance: 54...
	 start solving instance: 92...
	 start solving instance: 127...
	 start solving instance: 101...
	 start solving instance: 146...
	 start solving instance: 142...
	 start solving instance: 42...
	 start solving instance: 132...
	 start solving instance: 63...
	 start solving instance: 114...
	 start solving instance: 83...
	 start solving instance: 98...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.843512659486337e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886084608.0
		 entropy bonus: 0.21329550445079803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920799744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6528483840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8435127694374994e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.843512659486337e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886084608.0
		 entropy bonus: 0.21329550445079803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920799744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6528483840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8435127694374994e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.843512659486337e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5886084608.0
		 entropy bonus: 0.21329550445079803
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5920799744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6528483840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8435127694374994e+18 - Differentiable computation graph = True!
PPO iteration: 511/1000:
	 New training batch of size 20...
	 start solving instance: 45...
	 start solving instance: 135...
	 start solving instance: 81...
	 start solving instance: 85...
	 start solving instance: 127...
	 start solving instance: 73...
	 start solving instance: 86...
	 start solving instance: 104...
	 start solving instance: 11...
	 start solving instance: 99...
	 start solving instance: 96...
	 start solving instance: 100...
	 start solving instance: 72...
	 start solving instance: 27...
	 start solving instance: 38...
	 start solving instance: 35...
	 start solving instance: 1...
	 start solving instance: 110...
	 start solving instance: 130...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1785448475859616e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288517632.0
		 entropy bonus: 0.21957802772521973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6042995712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6581581824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1785449575371244e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1785448475859616e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288517632.0
		 entropy bonus: 0.21957802772521973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6042995712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6581581824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1785449575371244e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1785448475859616e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288517632.0
		 entropy bonus: 0.21957802772521973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6042995712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6581581824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1785449575371244e+18 - Differentiable computation graph = True!
PPO iteration: 512/1000:
	 start solving instance: 127...
	 start solving instance: 135...
	 start solving instance: 110...
	 start solving instance: 99...
	 start solving instance: 73...
	 start solving instance: 27...
	 start solving instance: 104...
	 start solving instance: 1...
	 start solving instance: 38...
	 start solving instance: 83...
	 start solving instance: 85...
	 start solving instance: 81...
	 start solving instance: 72...
	 start solving instance: 100...
	 start solving instance: 11...
	 start solving instance: 130...
	 start solving instance: 96...
	 start solving instance: 86...
	 start solving instance: 35...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.222239879478431e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6120900096.0
		 entropy bonus: 0.2152569741010666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6079553536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6944136192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2222398245028495e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.222239879478431e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6120900096.0
		 entropy bonus: 0.2152569741010666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6079553536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6944136192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2222398245028495e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.222239879478431e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6120900096.0
		 entropy bonus: 0.2152569741010666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6079553536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6944136192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2222398245028495e+18 - Differentiable computation graph = True!
PPO iteration: 513/1000:
	 start solving instance: 135...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 38...
	 start solving instance: 83...
	 start solving instance: 96...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 85...
	 start solving instance: 1...
	 start solving instance: 100...
	 start solving instance: 35...
	 start solving instance: 81...
	 start solving instance: 86...
	 start solving instance: 72...
	 start solving instance: 99...
	 start solving instance: 27...
	 start solving instance: 104...
	 start solving instance: 11...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.089083303894293e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193874432.0
		 entropy bonus: 0.22096538543701172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018416640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6523457024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.089083468821037e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.089083303894293e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193874432.0
		 entropy bonus: 0.22096538543701172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018416640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6523457024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.089083468821037e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.089083303894293e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193874432.0
		 entropy bonus: 0.22096538543701172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018416640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6523457024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.089083468821037e+18 - Differentiable computation graph = True!
PPO iteration: 514/1000:
	 start solving instance: 11...
	 start solving instance: 104...
	 start solving instance: 38...
	 start solving instance: 83...
	 start solving instance: 85...
	 start solving instance: 1...
	 start solving instance: 100...
	 start solving instance: 72...
	 start solving instance: 135...
	 start solving instance: 35...
	 start solving instance: 73...
	 start solving instance: 127...
	 start solving instance: 86...
	 start solving instance: 99...
	 start solving instance: 45...
	 start solving instance: 81...
	 start solving instance: 96...
	 start solving instance: 27...
	 start solving instance: 130...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.22153047457619e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6135076352.0
		 entropy bonus: 0.21555934846401215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6080621568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6635851264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.221530639502934e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.22153047457619e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6135076352.0
		 entropy bonus: 0.21555934846401215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6080621568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6635851264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.221530639502934e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.22153047457619e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6135076352.0
		 entropy bonus: 0.21555934846401215
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6080621568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6635851264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.221530639502934e+18 - Differentiable computation graph = True!
PPO iteration: 515/1000:
	 start solving instance: 35...
	 start solving instance: 135...
	 start solving instance: 100...
	 start solving instance: 130...
	 start solving instance: 110...
	 start solving instance: 83...
	 start solving instance: 99...
	 start solving instance: 86...
	 start solving instance: 1...
	 start solving instance: 38...
	 start solving instance: 85...
	 start solving instance: 72...
	 start solving instance: 81...
	 start solving instance: 96...
	 start solving instance: 127...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 11...
	 start solving instance: 45...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.139912407032424e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6111757824.0
		 entropy bonus: 0.21654155850410461
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5955410432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779659776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.139912516983587e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.139912407032424e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6111757824.0
		 entropy bonus: 0.21654155850410461
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5955410432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779659776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.139912516983587e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.139912407032424e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6111757824.0
		 entropy bonus: 0.21654155850410461
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5955410432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779659776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.139912516983587e+18 - Differentiable computation graph = True!
PPO iteration: 516/1000:
	 start solving instance: 73...
	 start solving instance: 35...
	 start solving instance: 110...
	 start solving instance: 99...
	 start solving instance: 96...
	 start solving instance: 104...
	 start solving instance: 27...
	 start solving instance: 86...
	 start solving instance: 45...
	 start solving instance: 83...
	 start solving instance: 85...
	 start solving instance: 38...
	 start solving instance: 130...
	 start solving instance: 127...
	 start solving instance: 100...
	 start solving instance: 135...
	 start solving instance: 11...
	 start solving instance: 72...
	 start solving instance: 1...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.320471127913241e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201152512.0
		 entropy bonus: 0.23308661580085754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6242502656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6608826880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.320471292839985e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.320471127913241e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201152512.0
		 entropy bonus: 0.23308661580085754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6242502656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6608826880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.320471292839985e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.320471127913241e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201152512.0
		 entropy bonus: 0.23308661580085754
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6242502656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6608826880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.320471292839985e+18 - Differentiable computation graph = True!
PPO iteration: 517/1000:
	 start solving instance: 85...
	 start solving instance: 110...
	 start solving instance: 11...
	 start solving instance: 27...
	 start solving instance: 130...
	 start solving instance: 86...
	 start solving instance: 35...
	 start solving instance: 96...
	 start solving instance: 81...
	 start solving instance: 127...
	 start solving instance: 104...
	 start solving instance: 45...
	 start solving instance: 100...
	 start solving instance: 73...
	 start solving instance: 72...
	 start solving instance: 99...
	 start solving instance: 1...
	 start solving instance: 135...
	 start solving instance: 83...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.20787366054991e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231070208.0
		 entropy bonus: 0.2188897579908371
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161447936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6785362944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2078736055743283e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.20787366054991e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231070208.0
		 entropy bonus: 0.2188897579908371
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161447936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6785362944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2078736055743283e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.20787366054991e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231070208.0
		 entropy bonus: 0.2188897579908371
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161447936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6785362944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2078736055743283e+18 - Differentiable computation graph = True!
PPO iteration: 518/1000:
	 start solving instance: 86...
	 start solving instance: 72...
	 start solving instance: 35...
	 start solving instance: 127...
	 start solving instance: 1...
	 start solving instance: 99...
	 start solving instance: 104...
	 start solving instance: 85...
	 start solving instance: 45...
	 start solving instance: 81...
	 start solving instance: 83...
	 start solving instance: 110...
	 start solving instance: 130...
	 start solving instance: 27...
	 start solving instance: 38...
	 start solving instance: 135...
	 start solving instance: 96...
	 start solving instance: 73...
	 start solving instance: 100...
	 start solving instance: 11...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1687174126569e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048480256.0
		 entropy bonus: 0.21829107403755188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5977209856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914646528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1687175226080625e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1687174126569e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048480256.0
		 entropy bonus: 0.21829107403755188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5977209856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914646528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1687175226080625e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1687174126569e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048480256.0
		 entropy bonus: 0.21829107403755188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5977209856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914646528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1687175226080625e+18 - Differentiable computation graph = True!
PPO iteration: 519/1000:
	 start solving instance: 127...
	 start solving instance: 35...
	 start solving instance: 38...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 81...
	 start solving instance: 86...
	 start solving instance: 27...
	 start solving instance: 99...
	 start solving instance: 72...
	 start solving instance: 110...
	 start solving instance: 83...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 1...
	 start solving instance: 104...
	 start solving instance: 135...
	 start solving instance: 11...
	 start solving instance: 85...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.245207357968718e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6144203776.0
		 entropy bonus: 0.21859697997570038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6131532288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6895901696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2452075228954624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.245207357968718e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6144203776.0
		 entropy bonus: 0.21859697997570038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6131532288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6895901696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2452075228954624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.245207357968718e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6144203776.0
		 entropy bonus: 0.21859697997570038
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6131532288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6895901696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2452075228954624e+18 - Differentiable computation graph = True!
PPO iteration: 520/1000:
	 start solving instance: 86...
	 start solving instance: 45...
	 start solving instance: 99...
	 start solving instance: 83...
	 start solving instance: 38...
	 start solving instance: 135...
	 start solving instance: 130...
	 start solving instance: 35...
	 start solving instance: 1...
	 start solving instance: 11...
	 start solving instance: 110...
	 start solving instance: 100...
	 start solving instance: 72...
	 start solving instance: 73...
	 start solving instance: 27...
	 start solving instance: 85...
	 start solving instance: 104...
	 start solving instance: 81...
	 start solving instance: 96...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.189995601482272e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6110051840.0
		 entropy bonus: 0.22094468772411346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6193505280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543953408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1899955465066906e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.189995601482272e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6110051840.0
		 entropy bonus: 0.22094468772411346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6193505280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543953408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1899955465066906e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.189995601482272e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6110051840.0
		 entropy bonus: 0.22094468772411346
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6193505280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543953408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1899955465066906e+18 - Differentiable computation graph = True!
PPO iteration: 521/1000:
	 New training batch of size 20...
	 start solving instance: 148...
	 start solving instance: 145...
	 start solving instance: 122...
	 start solving instance: 4...
	 start solving instance: 74...
	 start solving instance: 129...
	 start solving instance: 109...
	 start solving instance: 9...
	 start solving instance: 126...
	 start solving instance: 68...
	 start solving instance: 3...
	 start solving instance: 131...
	 start solving instance: 119...
	 start solving instance: 7...
	 start solving instance: 61...
	 start solving instance: 67...
	 start solving instance: 134...
	 start solving instance: 137...
	 start solving instance: 47...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9261787815136985e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998066176.0
		 entropy bonus: 0.22153320908546448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5947832832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660819968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.926178726538117e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9261787815136985e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998066176.0
		 entropy bonus: 0.22153320908546448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5947832832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660819968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.926178726538117e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9261787815136985e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998066176.0
		 entropy bonus: 0.22153320908546448
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5947832832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660819968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.926178726538117e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.220515077537294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5286893056.0
		 entropy bonus: 0.2086591273546219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5304286720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6114377728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3220515187488456704.0000
PPO iteration: 522/1000:
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 4...
	 start solving instance: 126...
	 start solving instance: 119...
	 start solving instance: 109...
	 start solving instance: 148...
	 start solving instance: 134...
	 start solving instance: 137...
	 start solving instance: 131...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 47...
	 start solving instance: 129...
	 start solving instance: 74...
	 start solving instance: 3...
	 start solving instance: 9...
	 start solving instance: 122...
	 start solving instance: 61...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.891972974773587e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6018272768.0
		 entropy bonus: 0.2068161517381668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938983424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6453515776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.891972919798006e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.891972974773587e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6018272768.0
		 entropy bonus: 0.2068161517381668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938983424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6453515776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.891972919798006e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.891972974773587e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6018272768.0
		 entropy bonus: 0.2068161517381668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938983424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6453515776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.891972919798006e+18 - Differentiable computation graph = True!
PPO iteration: 523/1000:
	 start solving instance: 119...
	 start solving instance: 131...
	 start solving instance: 9...
	 start solving instance: 109...
	 start solving instance: 61...
	 start solving instance: 3...
	 start solving instance: 148...
	 start solving instance: 47...
	 start solving instance: 129...
	 start solving instance: 7...
	 start solving instance: 4...
	 start solving instance: 74...
	 start solving instance: 137...
	 start solving instance: 122...
	 start solving instance: 145...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 67...
	 start solving instance: 68...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.01647331521457e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5948875776.0
		 entropy bonus: 0.2257624864578247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6045361664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6312371200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0164733701901517e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.01647331521457e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5948875776.0
		 entropy bonus: 0.2257624864578247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6045361664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6312371200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0164733701901517e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.01647331521457e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5948875776.0
		 entropy bonus: 0.2257624864578247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6045361664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6312371200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0164733701901517e+18 - Differentiable computation graph = True!
PPO iteration: 524/1000:
	 start solving instance: 68...
	 start solving instance: 67...
	 start solving instance: 61...
	 start solving instance: 148...
	 start solving instance: 122...
	 start solving instance: 126...
	 start solving instance: 131...
	 start solving instance: 137...
	 start solving instance: 109...
	 start solving instance: 7...
	 start solving instance: 4...
	 start solving instance: 145...
	 start solving instance: 74...
	 start solving instance: 35...
	 start solving instance: 47...
	 start solving instance: 129...
	 start solving instance: 3...
	 start solving instance: 119...
	 start solving instance: 134...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.979849462502654e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6003584512.0
		 entropy bonus: 0.2197498083114624
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6085682688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6589865984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.979849462502654e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.979849462502654e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6003584512.0
		 entropy bonus: 0.2197498083114624
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6085682688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6589865984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.979849462502654e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.979849462502654e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6003584512.0
		 entropy bonus: 0.2197498083114624
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6085682688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6589865984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.979849462502654e+18 - Differentiable computation graph = True!
PPO iteration: 525/1000:
	 start solving instance: 67...
	 start solving instance: 3...
	 start solving instance: 122...
	 start solving instance: 137...
	 start solving instance: 4...
	 start solving instance: 126...
	 start solving instance: 119...
	 start solving instance: 145...
	 start solving instance: 109...
	 start solving instance: 9...
	 start solving instance: 61...
	 start solving instance: 7...
	 start solving instance: 148...
	 start solving instance: 134...
	 start solving instance: 47...
	 start solving instance: 131...
	 start solving instance: 35...
	 start solving instance: 74...
	 start solving instance: 68...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.897098897982279e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030266368.0
		 entropy bonus: 0.21034438908100128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5809266688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6848482816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8970988430066975e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.897098897982279e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030266368.0
		 entropy bonus: 0.21034438908100128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5809266688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6848482816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8970988430066975e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.897098897982279e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030266368.0
		 entropy bonus: 0.21034438908100128
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5809266688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6848482816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8970988430066975e+18 - Differentiable computation graph = True!
PPO iteration: 526/1000:
	 start solving instance: 3...
	 start solving instance: 67...
	 start solving instance: 4...
	 start solving instance: 61...
	 start solving instance: 126...
	 start solving instance: 7...
	 start solving instance: 109...
	 start solving instance: 148...
	 start solving instance: 122...
	 start solving instance: 68...
	 start solving instance: 137...
	 start solving instance: 47...
	 start solving instance: 129...
	 start solving instance: 74...
	 start solving instance: 131...
	 start solving instance: 134...
	 start solving instance: 145...
	 start solving instance: 9...
	 start solving instance: 35...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.246536887429025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6007930368.0
		 entropy bonus: 0.22379617393016815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6263746048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6877737984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2465368324534436e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.246536887429025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6007930368.0
		 entropy bonus: 0.22379617393016815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6263746048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6877737984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2465368324534436e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.246536887429025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6007930368.0
		 entropy bonus: 0.22379617393016815
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6263746048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6877737984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2465368324534436e+18 - Differentiable computation graph = True!
PPO iteration: 527/1000:
	 start solving instance: 131...
	 start solving instance: 4...
	 start solving instance: 129...
	 start solving instance: 74...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 119...
	 start solving instance: 67...
	 start solving instance: 61...
	 start solving instance: 7...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 47...
	 start solving instance: 3...
	 start solving instance: 68...
	 start solving instance: 145...
	 start solving instance: 137...
	 start solving instance: 126...
	 start solving instance: 122...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.977315308102956e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969882624.0
		 entropy bonus: 0.21791020035743713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934775808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6550284288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.977315363078537e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.977315308102956e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969882624.0
		 entropy bonus: 0.21791020035743713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934775808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6550284288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.977315363078537e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.977315308102956e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5969882624.0
		 entropy bonus: 0.21791020035743713
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934775808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6550284288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.977315363078537e+18 - Differentiable computation graph = True!
PPO iteration: 528/1000:
	 start solving instance: 9...
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 7...
	 start solving instance: 3...
	 start solving instance: 134...
	 start solving instance: 67...
	 start solving instance: 74...
	 start solving instance: 131...
	 start solving instance: 4...
	 start solving instance: 137...
	 start solving instance: 35...
	 start solving instance: 109...
	 start solving instance: 119...
	 start solving instance: 129...
	 start solving instance: 68...
	 start solving instance: 126...
	 start solving instance: 61...
	 start solving instance: 145...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8150163967269405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063019008.0
		 entropy bonus: 0.20777510106563568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5762976768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447683584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.815016451702522e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8150163967269405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063019008.0
		 entropy bonus: 0.20777510106563568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5762976768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447683584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.815016451702522e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8150163967269405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063019008.0
		 entropy bonus: 0.20777510106563568
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5762976768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447683584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.815016451702522e+18 - Differentiable computation graph = True!
PPO iteration: 529/1000:
	 start solving instance: 68...
	 start solving instance: 3...
	 start solving instance: 7...
	 start solving instance: 109...
	 start solving instance: 35...
	 start solving instance: 134...
	 start solving instance: 74...
	 start solving instance: 122...
	 start solving instance: 137...
	 start solving instance: 148...
	 start solving instance: 126...
	 start solving instance: 145...
	 start solving instance: 129...
	 start solving instance: 67...
	 start solving instance: 9...
	 start solving instance: 61...
	 start solving instance: 119...
	 start solving instance: 131...
	 start solving instance: 4...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.807228775769729e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5994503680.0
		 entropy bonus: 0.2158893197774887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5819910144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6461230592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8072288857208914e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.807228775769729e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5994503680.0
		 entropy bonus: 0.2158893197774887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5819910144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6461230592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8072288857208914e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.807228775769729e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5994503680.0
		 entropy bonus: 0.2158893197774887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5819910144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6461230592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8072288857208914e+18 - Differentiable computation graph = True!
PPO iteration: 530/1000:
	 start solving instance: 67...
	 start solving instance: 134...
	 start solving instance: 7...
	 start solving instance: 145...
	 start solving instance: 131...
	 start solving instance: 74...
	 start solving instance: 35...
	 start solving instance: 68...
	 start solving instance: 148...
	 start solving instance: 126...
	 start solving instance: 47...
	 start solving instance: 61...
	 start solving instance: 9...
	 start solving instance: 129...
	 start solving instance: 109...
	 start solving instance: 119...
	 start solving instance: 3...
	 start solving instance: 4...
	 start solving instance: 122...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9392730853912084e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022440448.0
		 entropy bonus: 0.21106253564357758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5998422016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529943040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9392730853912084e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9392730853912084e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022440448.0
		 entropy bonus: 0.21106253564357758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5998422016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529943040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9392730853912084e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9392730853912084e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022440448.0
		 entropy bonus: 0.21106253564357758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5998422016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529943040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9392730853912084e+18 - Differentiable computation graph = True!
PPO iteration: 531/1000:
	 New training batch of size 20...
	 start solving instance: 56...
	 start solving instance: 21...
	 start solving instance: 59...
	 start solving instance: 146...
	 start solving instance: 148...
	 start solving instance: 11...
	 start solving instance: 1...
	 start solving instance: 136...
	 start solving instance: 132...
	 start solving instance: 84...
	 start solving instance: 126...
	 start solving instance: 89...
	 start solving instance: 140...
	 start solving instance: 60...
	 start solving instance: 55...
	 start solving instance: 143...
	 start solving instance: 77...
	 start solving instance: 138...
	 start solving instance: 98...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.747088568362939e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5790302208.0
		 entropy bonus: 0.2081342488527298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5699571712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6255396864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7470886233385206e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.747088568362939e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5790302208.0
		 entropy bonus: 0.2081342488527298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5699571712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6255396864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7470886233385206e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.747088568362939e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5790302208.0
		 entropy bonus: 0.2081342488527298
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5699571712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6255396864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7470886233385206e+18 - Differentiable computation graph = True!
PPO iteration: 532/1000:
	 start solving instance: 60...
	 start solving instance: 132...
	 start solving instance: 136...
	 start solving instance: 11...
	 start solving instance: 143...
	 start solving instance: 126...
	 start solving instance: 144...
	 start solving instance: 138...
	 start solving instance: 59...
	 start solving instance: 140...
	 start solving instance: 77...
	 start solving instance: 146...
	 start solving instance: 98...
	 start solving instance: 89...
	 start solving instance: 21...
	 start solving instance: 1...
	 start solving instance: 84...
	 start solving instance: 55...
	 start solving instance: 56...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.032698588403335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5935098880.0
		 entropy bonus: 0.19856508076190948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5959804416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6743062528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.032698588403335e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.032698588403335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5935098880.0
		 entropy bonus: 0.19856508076190948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5959804416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6743062528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.032698588403335e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.032698588403335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5935098880.0
		 entropy bonus: 0.19856508076190948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5959804416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6743062528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.032698588403335e+18 - Differentiable computation graph = True!
PPO iteration: 533/1000:
	 start solving instance: 55...
	 start solving instance: 148...
	 start solving instance: 1...
	 start solving instance: 138...
	 start solving instance: 143...
	 start solving instance: 146...
	 start solving instance: 136...
	 start solving instance: 126...
	 start solving instance: 11...
	 start solving instance: 77...
	 start solving instance: 140...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 60...
	 start solving instance: 132...
	 start solving instance: 98...
	 start solving instance: 21...
	 start solving instance: 84...
	 start solving instance: 56...
	 start solving instance: 59...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.788777211437043e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832313344.0
		 entropy bonus: 0.20149068534374237
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5677732864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6203210240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7887771564614615e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.788777211437043e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832313344.0
		 entropy bonus: 0.20149068534374237
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5677732864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6203210240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7887771564614615e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.788777211437043e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832313344.0
		 entropy bonus: 0.20149068534374237
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5677732864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6203210240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7887771564614615e+18 - Differentiable computation graph = True!
PPO iteration: 534/1000:
	 start solving instance: 143...
	 start solving instance: 138...
	 start solving instance: 84...
	 start solving instance: 11...
	 start solving instance: 98...
	 start solving instance: 77...
	 start solving instance: 140...
	 start solving instance: 60...
	 start solving instance: 126...
	 start solving instance: 136...
	 start solving instance: 21...
	 start solving instance: 55...
	 start solving instance: 146...
	 start solving instance: 56...
	 start solving instance: 144...
	 start solving instance: 132...
	 start solving instance: 148...
	 start solving instance: 59...
	 start solving instance: 89...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.860131118033194e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768075776.0
		 entropy bonus: 0.21093960106372833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810552320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6299752448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.860131063057613e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.860131118033194e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768075776.0
		 entropy bonus: 0.21093960106372833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810552320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6299752448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.860131063057613e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.860131118033194e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768075776.0
		 entropy bonus: 0.21093960106372833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810552320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6299752448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.860131063057613e+18 - Differentiable computation graph = True!
PPO iteration: 535/1000:
	 start solving instance: 98...
	 start solving instance: 1...
	 start solving instance: 55...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 11...
	 start solving instance: 138...
	 start solving instance: 21...
	 start solving instance: 59...
	 start solving instance: 77...
	 start solving instance: 84...
	 start solving instance: 148...
	 start solving instance: 143...
	 start solving instance: 56...
	 start solving instance: 60...
	 start solving instance: 146...
	 start solving instance: 132...
	 start solving instance: 136...
	 start solving instance: 126...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.903493657609424e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016105984.0
		 entropy bonus: 0.2049044668674469
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774675456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6670622208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9034936026338427e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.903493657609424e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016105984.0
		 entropy bonus: 0.2049044668674469
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774675456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6670622208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9034936026338427e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.903493657609424e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016105984.0
		 entropy bonus: 0.2049044668674469
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774675456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6670622208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9034936026338427e+18 - Differentiable computation graph = True!
PPO iteration: 536/1000:
	 start solving instance: 98...
	 start solving instance: 144...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 60...
	 start solving instance: 59...
	 start solving instance: 1...
	 start solving instance: 89...
	 start solving instance: 132...
	 start solving instance: 77...
	 start solving instance: 140...
	 start solving instance: 55...
	 start solving instance: 146...
	 start solving instance: 11...
	 start solving instance: 21...
	 start solving instance: 136...
	 start solving instance: 138...
	 start solving instance: 126...
	 start solving instance: 56...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.717384602031594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5800805888.0
		 entropy bonus: 0.1949211210012436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5640117760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6671208448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.717384766958338e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.717384602031594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5800805888.0
		 entropy bonus: 0.1949211210012436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5640117760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6671208448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.717384766958338e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.717384602031594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5800805888.0
		 entropy bonus: 0.1949211210012436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5640117760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6671208448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.717384766958338e+18 - Differentiable computation graph = True!
PPO iteration: 537/1000:
	 start solving instance: 126...
	 start solving instance: 143...
	 start solving instance: 136...
	 start solving instance: 55...
	 start solving instance: 132...
	 start solving instance: 98...
	 start solving instance: 56...
	 start solving instance: 89...
	 start solving instance: 11...
	 start solving instance: 148...
	 start solving instance: 84...
	 start solving instance: 59...
	 start solving instance: 140...
	 start solving instance: 21...
	 start solving instance: 138...
	 start solving instance: 146...
	 start solving instance: 77...
	 start solving instance: 60...
	 start solving instance: 1...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.868884110199593e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5905473024.0
		 entropy bonus: 0.21636536717414856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877286400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6576282112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8688842751263375e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.868884110199593e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5905473024.0
		 entropy bonus: 0.21636536717414856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877286400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6576282112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8688842751263375e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.868884110199593e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5905473024.0
		 entropy bonus: 0.21636536717414856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877286400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6576282112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8688842751263375e+18 - Differentiable computation graph = True!
PPO iteration: 538/1000:
	 start solving instance: 143...
	 start solving instance: 136...
	 start solving instance: 146...
	 start solving instance: 77...
	 start solving instance: 59...
	 start solving instance: 11...
	 start solving instance: 148...
	 start solving instance: 84...
	 start solving instance: 144...
	 start solving instance: 21...
	 start solving instance: 60...
	 start solving instance: 140...
	 start solving instance: 55...
	 start solving instance: 56...
	 start solving instance: 98...
	 start solving instance: 89...
	 start solving instance: 132...
	 start solving instance: 126...
	 start solving instance: 1...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.923241766053583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5918236672.0
		 entropy bonus: 0.21891741454601288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5876007424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6855597568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9232419309803274e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.923241766053583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5918236672.0
		 entropy bonus: 0.21891741454601288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5876007424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6855597568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9232419309803274e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.923241766053583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5918236672.0
		 entropy bonus: 0.21891741454601288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5876007424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6855597568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9232419309803274e+18 - Differentiable computation graph = True!
PPO iteration: 539/1000:
	 start solving instance: 1...
	 start solving instance: 136...
	 start solving instance: 89...
	 start solving instance: 98...
	 start solving instance: 55...
	 start solving instance: 140...
	 start solving instance: 11...
	 start solving instance: 60...
	 start solving instance: 59...
	 start solving instance: 56...
	 start solving instance: 146...
	 start solving instance: 126...
	 start solving instance: 21...
	 start solving instance: 138...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 77...
	 start solving instance: 144...
	 start solving instance: 132...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.994461972035797e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5964307456.0
		 entropy bonus: 0.21233247220516205
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5913562112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6850572288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.994461972035797e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.994461972035797e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5964307456.0
		 entropy bonus: 0.21233247220516205
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5913562112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6850572288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.994461972035797e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.994461972035797e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5964307456.0
		 entropy bonus: 0.21233247220516205
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5913562112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6850572288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.994461972035797e+18 - Differentiable computation graph = True!
PPO iteration: 540/1000:
	 start solving instance: 146...
	 start solving instance: 98...
	 start solving instance: 1...
	 start solving instance: 11...
	 start solving instance: 77...
	 start solving instance: 143...
	 start solving instance: 21...
	 start solving instance: 136...
	 start solving instance: 126...
	 start solving instance: 144...
	 start solving instance: 138...
	 start solving instance: 140...
	 start solving instance: 60...
	 start solving instance: 132...
	 start solving instance: 59...
	 start solving instance: 89...
	 start solving instance: 56...
	 start solving instance: 55...
	 start solving instance: 148...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.70796442620946e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5836463104.0
		 entropy bonus: 0.20212049782276154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5703227904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6213984256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.70796442620946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.70796442620946e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5836463104.0
		 entropy bonus: 0.20212049782276154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5703227904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6213984256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.70796442620946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.70796442620946e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5836463104.0
		 entropy bonus: 0.20212049782276154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5703227904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6213984256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.70796442620946e+18 - Differentiable computation graph = True!
PPO iteration: 541/1000:
	 New training batch of size 20...
	 start solving instance: 117...
	 start solving instance: 56...
	 start solving instance: 77...
	 start solving instance: 37...
	 start solving instance: 113...
	 start solving instance: 15...
	 start solving instance: 36...
	 start solving instance: 90...
	 start solving instance: 58...
	 start solving instance: 143...
	 start solving instance: 135...
	 start solving instance: 33...
	 start solving instance: 108...
	 start solving instance: 74...
	 start solving instance: 86...
	 start solving instance: 52...
	 start solving instance: 63...
	 start solving instance: 78...
	 start solving instance: 23...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.770438345096849e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6307780096.0
		 entropy bonus: 0.2414654791355133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6815383040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7253406720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.770438455048012e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.770438345096849e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6307780096.0
		 entropy bonus: 0.2414654791355133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6815383040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7253406720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.770438455048012e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.770438345096849e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6307780096.0
		 entropy bonus: 0.2414654791355133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6815383040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7253406720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.770438455048012e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.747082742900667e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5111802368.0
		 entropy bonus: 0.1960405856370926
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4868186112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5696003072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2747082797876248576.0000
PPO iteration: 542/1000:
	 start solving instance: 108...
	 start solving instance: 90...
	 start solving instance: 78...
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 58...
	 start solving instance: 56...
	 start solving instance: 77...
	 start solving instance: 74...
	 start solving instance: 15...
	 start solving instance: 143...
	 start solving instance: 63...
	 start solving instance: 113...
	 start solving instance: 117...
	 start solving instance: 86...
	 start solving instance: 49...
	 start solving instance: 23...
	 start solving instance: 36...
	 start solving instance: 37...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.885396683827341e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6293346304.0
		 entropy bonus: 0.24260902404785156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6902905344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7302629376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.885396793778504e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.885396683827341e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6293346304.0
		 entropy bonus: 0.24260902404785156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6902905344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7302629376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.885396793778504e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.885396683827341e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6293346304.0
		 entropy bonus: 0.24260902404785156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6902905344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7302629376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.885396793778504e+18 - Differentiable computation graph = True!
PPO iteration: 543/1000:
	 start solving instance: 33...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 63...
	 start solving instance: 74...
	 start solving instance: 58...
	 start solving instance: 23...
	 start solving instance: 90...
	 start solving instance: 113...
	 start solving instance: 52...
	 start solving instance: 15...
	 start solving instance: 37...
	 start solving instance: 117...
	 start solving instance: 49...
	 start solving instance: 86...
	 start solving instance: 108...
	 start solving instance: 36...
	 start solving instance: 143...
	 start solving instance: 78...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.777052567244898e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6316150272.0
		 entropy bonus: 0.23780909180641174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6739512320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7475315712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.777052567244898e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.777052567244898e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6316150272.0
		 entropy bonus: 0.23780909180641174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6739512320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7475315712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.777052567244898e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.777052567244898e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6316150272.0
		 entropy bonus: 0.23780909180641174
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6739512320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7475315712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.777052567244898e+18 - Differentiable computation graph = True!
PPO iteration: 544/1000:
	 start solving instance: 52...
	 start solving instance: 33...
	 start solving instance: 113...
	 start solving instance: 86...
	 start solving instance: 49...
	 start solving instance: 23...
	 start solving instance: 117...
	 start solving instance: 78...
	 start solving instance: 63...
	 start solving instance: 58...
	 start solving instance: 135...
	 start solving instance: 37...
	 start solving instance: 108...
	 start solving instance: 90...
	 start solving instance: 74...
	 start solving instance: 77...
	 start solving instance: 143...
	 start solving instance: 36...
	 start solving instance: 15...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.63188668585754e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6276830720.0
		 entropy bonus: 0.2372296303510666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6603400192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7238063104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.631886795808702e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.63188668585754e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6276830720.0
		 entropy bonus: 0.2372296303510666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6603400192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7238063104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.631886795808702e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.63188668585754e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6276830720.0
		 entropy bonus: 0.2372296303510666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6603400192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7238063104.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.631886795808702e+18 - Differentiable computation graph = True!
PPO iteration: 545/1000:
	 start solving instance: 90...
	 start solving instance: 56...
	 start solving instance: 74...
	 start solving instance: 135...
	 start solving instance: 108...
	 start solving instance: 37...
	 start solving instance: 143...
	 start solving instance: 23...
	 start solving instance: 36...
	 start solving instance: 77...
	 start solving instance: 63...
	 start solving instance: 15...
	 start solving instance: 113...
	 start solving instance: 49...
	 start solving instance: 117...
	 start solving instance: 58...
	 start solving instance: 52...
	 start solving instance: 78...
	 start solving instance: 33...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.738973840747109e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6259161600.0
		 entropy bonus: 0.24647274613380432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737202176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7299590656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738973730795946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.738973840747109e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6259161600.0
		 entropy bonus: 0.24647274613380432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737202176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7299590656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738973730795946e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.738973840747109e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6259161600.0
		 entropy bonus: 0.24647274613380432
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6737202176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7299590656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.738973730795946e+18 - Differentiable computation graph = True!
PPO iteration: 546/1000:
	 start solving instance: 52...
	 start solving instance: 15...
	 start solving instance: 58...
	 start solving instance: 78...
	 start solving instance: 113...
	 start solving instance: 135...
	 start solving instance: 117...
	 start solving instance: 49...
	 start solving instance: 86...
	 start solving instance: 63...
	 start solving instance: 37...
	 start solving instance: 74...
	 start solving instance: 36...
	 start solving instance: 56...
	 start solving instance: 33...
	 start solving instance: 77...
	 start solving instance: 90...
	 start solving instance: 108...
	 start solving instance: 143...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.628576276248632e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6182927872.0
		 entropy bonus: 0.24527107179164886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6627140096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7384465408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.628576166297469e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.628576276248632e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6182927872.0
		 entropy bonus: 0.24527107179164886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6627140096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7384465408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.628576166297469e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.628576276248632e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6182927872.0
		 entropy bonus: 0.24527107179164886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6627140096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7384465408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.628576166297469e+18 - Differentiable computation graph = True!
PPO iteration: 547/1000:
	 start solving instance: 52...
	 start solving instance: 37...
	 start solving instance: 58...
	 start solving instance: 74...
	 start solving instance: 90...
	 start solving instance: 78...
	 start solving instance: 108...
	 start solving instance: 15...
	 start solving instance: 33...
	 start solving instance: 36...
	 start solving instance: 143...
	 start solving instance: 23...
	 start solving instance: 49...
	 start solving instance: 113...
	 start solving instance: 56...
	 start solving instance: 117...
	 start solving instance: 86...
	 start solving instance: 77...
	 start solving instance: 63...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.652209179176049e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312114688.0
		 entropy bonus: 0.23386995494365692
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6678553088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7060050432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652209069224886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.652209179176049e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312114688.0
		 entropy bonus: 0.23386995494365692
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6678553088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7060050432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652209069224886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.652209179176049e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312114688.0
		 entropy bonus: 0.23386995494365692
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6678553088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7060050432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652209069224886e+18 - Differentiable computation graph = True!
PPO iteration: 548/1000:
	 start solving instance: 37...
	 start solving instance: 15...
	 start solving instance: 74...
	 start solving instance: 90...
	 start solving instance: 78...
	 start solving instance: 33...
	 start solving instance: 108...
	 start solving instance: 77...
	 start solving instance: 58...
	 start solving instance: 113...
	 start solving instance: 56...
	 start solving instance: 52...
	 start solving instance: 117...
	 start solving instance: 23...
	 start solving instance: 143...
	 start solving instance: 63...
	 start solving instance: 135...
	 start solving instance: 36...
	 start solving instance: 49...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.751018330922418e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6206894592.0
		 entropy bonus: 0.2343703955411911
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6759711744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7048842752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751018330922418e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.751018330922418e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6206894592.0
		 entropy bonus: 0.2343703955411911
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6759711744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7048842752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751018330922418e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.751018330922418e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6206894592.0
		 entropy bonus: 0.2343703955411911
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6759711744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7048842752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.751018330922418e+18 - Differentiable computation graph = True!
PPO iteration: 549/1000:
	 start solving instance: 143...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 52...
	 start solving instance: 49...
	 start solving instance: 74...
	 start solving instance: 33...
	 start solving instance: 56...
	 start solving instance: 23...
	 start solving instance: 37...
	 start solving instance: 78...
	 start solving instance: 58...
	 start solving instance: 63...
	 start solving instance: 86...
	 start solving instance: 90...
	 start solving instance: 15...
	 start solving instance: 108...
	 start solving instance: 36...
	 start solving instance: 113...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.41203185920466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201354240.0
		 entropy bonus: 0.2342725545167923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6452037120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6679498240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.412032024131404e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.41203185920466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201354240.0
		 entropy bonus: 0.2342725545167923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6452037120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6679498240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.412032024131404e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.41203185920466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201354240.0
		 entropy bonus: 0.2342725545167923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6452037120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6679498240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.412032024131404e+18 - Differentiable computation graph = True!
PPO iteration: 550/1000:
	 start solving instance: 56...
	 start solving instance: 49...
	 start solving instance: 37...
	 start solving instance: 23...
	 start solving instance: 90...
	 start solving instance: 117...
	 start solving instance: 108...
	 start solving instance: 86...
	 start solving instance: 36...
	 start solving instance: 143...
	 start solving instance: 77...
	 start solving instance: 74...
	 start solving instance: 15...
	 start solving instance: 78...
	 start solving instance: 113...
	 start solving instance: 58...
	 start solving instance: 135...
	 start solving instance: 52...
	 start solving instance: 63...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6522707518272045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6253662208.0
		 entropy bonus: 0.2329365760087967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6595185664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7181323776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652270641876042e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6522707518272045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6253662208.0
		 entropy bonus: 0.2329365760087967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6595185664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7181323776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652270641876042e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6522707518272045e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6253662208.0
		 entropy bonus: 0.2329365760087967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6595185664.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7181323776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.652270641876042e+18 - Differentiable computation graph = True!
PPO iteration: 551/1000:
	 New training batch of size 20...
	 start solving instance: 38...
	 start solving instance: 136...
	 start solving instance: 107...
	 start solving instance: 125...
	 start solving instance: 102...
	 start solving instance: 35...
	 start solving instance: 43...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 63...
	 start solving instance: 118...
	 start solving instance: 54...
	 start solving instance: 101...
	 start solving instance: 149...
	 start solving instance: 46...
	 start solving instance: 50...
	 start solving instance: 59...
	 start solving instance: 85...
	 start solving instance: 3...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.348324836077365e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6250692096.0
		 entropy bonus: 0.20114050805568695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6478319616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7047421952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3483249460285276e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.348324836077365e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6250692096.0
		 entropy bonus: 0.20114050805568695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6478319616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7047421952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3483249460285276e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.348324836077365e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6250692096.0
		 entropy bonus: 0.20114050805568695
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6478319616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7047421952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3483249460285276e+18 - Differentiable computation graph = True!
PPO iteration: 552/1000:
	 start solving instance: 63...
	 start solving instance: 143...
	 start solving instance: 54...
	 start solving instance: 35...
	 start solving instance: 5...
	 start solving instance: 59...
	 start solving instance: 46...
	 start solving instance: 101...
	 start solving instance: 3...
	 start solving instance: 136...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 38...
	 start solving instance: 50...
	 start solving instance: 28...
	 start solving instance: 102...
	 start solving instance: 149...
	 start solving instance: 85...
	 start solving instance: 43...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1053648720784e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6098150400.0
		 entropy bonus: 0.21800778806209564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6295411712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6805041664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.105365037005144e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1053648720784e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6098150400.0
		 entropy bonus: 0.21800778806209564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6295411712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6805041664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.105365037005144e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1053648720784e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6098150400.0
		 entropy bonus: 0.21800778806209564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6295411712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6805041664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.105365037005144e+18 - Differentiable computation graph = True!
PPO iteration: 553/1000:
	 start solving instance: 59...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 85...
	 start solving instance: 43...
	 start solving instance: 5...
	 start solving instance: 118...
	 start solving instance: 38...
	 start solving instance: 143...
	 start solving instance: 136...
	 start solving instance: 50...
	 start solving instance: 54...
	 start solving instance: 35...
	 start solving instance: 149...
	 start solving instance: 101...
	 start solving instance: 125...
	 start solving instance: 46...
	 start solving instance: 28...
	 start solving instance: 63...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.977283202363425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6114488832.0
		 entropy bonus: 0.2166295051574707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6071529472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6647009792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.977283202363425e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.977283202363425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6114488832.0
		 entropy bonus: 0.2166295051574707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6071529472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6647009792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.977283202363425e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.977283202363425e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6114488832.0
		 entropy bonus: 0.2166295051574707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6071529472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6647009792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.977283202363425e+18 - Differentiable computation graph = True!
PPO iteration: 554/1000:
	 start solving instance: 5...
	 start solving instance: 101...
	 start solving instance: 35...
	 start solving instance: 118...
	 start solving instance: 3...
	 start solving instance: 46...
	 start solving instance: 102...
	 start solving instance: 125...
	 start solving instance: 50...
	 start solving instance: 85...
	 start solving instance: 38...
	 start solving instance: 107...
	 start solving instance: 149...
	 start solving instance: 63...
	 start solving instance: 136...
	 start solving instance: 43...
	 start solving instance: 59...
	 start solving instance: 54...
	 start solving instance: 28...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.072066382333529e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6173293056.0
		 entropy bonus: 0.2217458337545395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140924416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6861261312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.072066327357948e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.072066382333529e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6173293056.0
		 entropy bonus: 0.2217458337545395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140924416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6861261312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.072066327357948e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.072066382333529e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6173293056.0
		 entropy bonus: 0.2217458337545395
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140924416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6861261312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.072066327357948e+18 - Differentiable computation graph = True!
PPO iteration: 555/1000:
	 start solving instance: 101...
	 start solving instance: 143...
	 start solving instance: 107...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 54...
	 start solving instance: 59...
	 start solving instance: 85...
	 start solving instance: 5...
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 149...
	 start solving instance: 3...
	 start solving instance: 136...
	 start solving instance: 50...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 28...
	 start solving instance: 118...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.421469627212838e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6280081408.0
		 entropy bonus: 0.21103449165821075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6601857536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7288544768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.421469682188419e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.421469627212838e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6280081408.0
		 entropy bonus: 0.21103449165821075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6601857536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7288544768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.421469682188419e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.421469627212838e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6280081408.0
		 entropy bonus: 0.21103449165821075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6601857536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7288544768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.421469682188419e+18 - Differentiable computation graph = True!
PPO iteration: 556/1000:
	 start solving instance: 3...
	 start solving instance: 46...
	 start solving instance: 107...
	 start solving instance: 118...
	 start solving instance: 125...
	 start solving instance: 136...
	 start solving instance: 35...
	 start solving instance: 43...
	 start solving instance: 149...
	 start solving instance: 102...
	 start solving instance: 5...
	 start solving instance: 28...
	 start solving instance: 59...
	 start solving instance: 50...
	 start solving instance: 63...
	 start solving instance: 54...
	 start solving instance: 101...
	 start solving instance: 143...
	 start solving instance: 85...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0848510637366575e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140632064.0
		 entropy bonus: 0.20508639514446259
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6187808256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6745952768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0848511736878203e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0848510637366575e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140632064.0
		 entropy bonus: 0.20508639514446259
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6187808256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6745952768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0848511736878203e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0848510637366575e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140632064.0
		 entropy bonus: 0.20508639514446259
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6187808256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6745952768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0848511736878203e+18 - Differentiable computation graph = True!
PPO iteration: 557/1000:
	 start solving instance: 63...
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 46...
	 start solving instance: 43...
	 start solving instance: 54...
	 start solving instance: 149...
	 start solving instance: 59...
	 start solving instance: 5...
	 start solving instance: 35...
	 start solving instance: 107...
	 start solving instance: 136...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 50...
	 start solving instance: 85...
	 start solving instance: 28...
	 start solving instance: 143...
	 start solving instance: 3...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.384962322733466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6285312000.0
		 entropy bonus: 0.21270088851451874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6483820032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7124271616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3849623227334656e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.384962322733466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6285312000.0
		 entropy bonus: 0.21270088851451874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6483820032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7124271616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3849623227334656e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.384962322733466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6285312000.0
		 entropy bonus: 0.21270088851451874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6483820032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7124271616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3849623227334656e+18 - Differentiable computation graph = True!
PPO iteration: 558/1000:
	 start solving instance: 125...
	 start solving instance: 143...
	 start solving instance: 28...
	 start solving instance: 136...
	 start solving instance: 85...
	 start solving instance: 63...
	 start solving instance: 101...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 38...
	 start solving instance: 149...
	 start solving instance: 107...
	 start solving instance: 118...
	 start solving instance: 54...
	 start solving instance: 50...
	 start solving instance: 59...
	 start solving instance: 35...
	 start solving instance: 46...
	 start solving instance: 5...
	 start solving instance: 43...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.840412476500659e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6168604160.0
		 entropy bonus: 0.214966282248497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5956695040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6596328448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.840412421525078e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.840412476500659e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6168604160.0
		 entropy bonus: 0.214966282248497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5956695040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6596328448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.840412421525078e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.840412476500659e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6168604160.0
		 entropy bonus: 0.214966282248497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5956695040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6596328448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.840412421525078e+18 - Differentiable computation graph = True!
PPO iteration: 559/1000:
	 start solving instance: 38...
	 start solving instance: 3...
	 start solving instance: 54...
	 start solving instance: 136...
	 start solving instance: 59...
	 start solving instance: 63...
	 start solving instance: 28...
	 start solving instance: 102...
	 start solving instance: 143...
	 start solving instance: 107...
	 start solving instance: 125...
	 start solving instance: 101...
	 start solving instance: 46...
	 start solving instance: 85...
	 start solving instance: 35...
	 start solving instance: 43...
	 start solving instance: 5...
	 start solving instance: 50...
	 start solving instance: 118...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.205054952540943e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6272248320.0
		 entropy bonus: 0.20194843411445618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6223474176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6784280576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2050550075165245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.205054952540943e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6272248320.0
		 entropy bonus: 0.20194843411445618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6223474176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6784280576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2050550075165245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.205054952540943e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6272248320.0
		 entropy bonus: 0.20194843411445618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6223474176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6784280576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2050550075165245e+18 - Differentiable computation graph = True!
PPO iteration: 560/1000:
	 start solving instance: 38...
	 start solving instance: 43...
	 start solving instance: 136...
	 start solving instance: 3...
	 start solving instance: 101...
	 start solving instance: 28...
	 start solving instance: 5...
	 start solving instance: 50...
	 start solving instance: 102...
	 start solving instance: 107...
	 start solving instance: 35...
	 start solving instance: 63...
	 start solving instance: 149...
	 start solving instance: 59...
	 start solving instance: 54...
	 start solving instance: 85...
	 start solving instance: 46...
	 start solving instance: 143...
	 start solving instance: 125...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.348816097872655e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288239104.0
		 entropy bonus: 0.20231130719184875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6530041856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7059883520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3488161528482365e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.348816097872655e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288239104.0
		 entropy bonus: 0.20231130719184875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6530041856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7059883520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3488161528482365e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.348816097872655e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6288239104.0
		 entropy bonus: 0.20231130719184875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6530041856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7059883520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3488161528482365e+18 - Differentiable computation graph = True!
PPO iteration: 561/1000:
	 New training batch of size 20...
	 start solving instance: 93...
	 start solving instance: 109...
	 start solving instance: 11...
	 start solving instance: 114...
	 start solving instance: 113...
	 start solving instance: 130...
	 start solving instance: 103...
	 start solving instance: 32...
	 start solving instance: 20...
	 start solving instance: 111...
	 start solving instance: 79...
	 start solving instance: 150...
	 start solving instance: 41...
	 start solving instance: 98...
	 start solving instance: 35...
	 start solving instance: 82...
	 start solving instance: 106...
	 start solving instance: 85...
	 start solving instance: 29...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1874127406668186e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5598340608.0
		 entropy bonus: 0.19998803734779358
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5245429760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6084254208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1874127406668186e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1874127406668186e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5598340608.0
		 entropy bonus: 0.19998803734779358
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5245429760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6084254208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1874127406668186e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1874127406668186e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5598340608.0
		 entropy bonus: 0.19998803734779358
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5245429760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6084254208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1874127406668186e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.099817508012137e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5273452032.0
		 entropy bonus: 0.21227280795574188
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5180812800.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6090717696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3099817672938881024.0000
PPO iteration: 562/1000:
	 start solving instance: 32...
	 start solving instance: 29...
	 start solving instance: 85...
	 start solving instance: 111...
	 start solving instance: 150...
	 start solving instance: 11...
	 start solving instance: 41...
	 start solving instance: 35...
	 start solving instance: 93...
	 start solving instance: 109...
	 start solving instance: 130...
	 start solving instance: 98...
	 start solving instance: 114...
	 start solving instance: 34...
	 start solving instance: 113...
	 start solving instance: 20...
	 start solving instance: 106...
	 start solving instance: 79...
	 start solving instance: 103...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2349765141727805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5621396992.0
		 entropy bonus: 0.20798270404338837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5288596480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5832431616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2349765141727805e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2349765141727805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5621396992.0
		 entropy bonus: 0.20798270404338837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5288596480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5832431616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2349765141727805e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2349765141727805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5621396992.0
		 entropy bonus: 0.20798270404338837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5288596480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5832431616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2349765141727805e+18 - Differentiable computation graph = True!
PPO iteration: 563/1000:
	 start solving instance: 35...
	 start solving instance: 41...
	 start solving instance: 29...
	 start solving instance: 109...
	 start solving instance: 34...
	 start solving instance: 32...
	 start solving instance: 150...
	 start solving instance: 20...
	 start solving instance: 130...
	 start solving instance: 114...
	 start solving instance: 111...
	 start solving instance: 82...
	 start solving instance: 85...
	 start solving instance: 93...
	 start solving instance: 11...
	 start solving instance: 103...
	 start solving instance: 113...
	 start solving instance: 98...
	 start solving instance: 79...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3354138227375604e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711382016.0
		 entropy bonus: 0.19738788902759552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5376754688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6064825344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.335413877713142e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3354138227375604e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711382016.0
		 entropy bonus: 0.19738788902759552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5376754688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6064825344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.335413877713142e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3354138227375604e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5711382016.0
		 entropy bonus: 0.19738788902759552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5376754688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6064825344.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.335413877713142e+18 - Differentiable computation graph = True!
PPO iteration: 564/1000:
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 113...
	 start solving instance: 98...
	 start solving instance: 29...
	 start solving instance: 130...
	 start solving instance: 111...
	 start solving instance: 114...
	 start solving instance: 41...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 35...
	 start solving instance: 85...
	 start solving instance: 32...
	 start solving instance: 109...
	 start solving instance: 79...
	 start solving instance: 20...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.196926374977313e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5557153280.0
		 entropy bonus: 0.19776630401611328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5194436608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6186886144.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1969265399040573e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.196926374977313e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5557153280.0
		 entropy bonus: 0.19776630401611328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5194436608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6186886144.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1969265399040573e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.196926374977313e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5557153280.0
		 entropy bonus: 0.19776630401611328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5194436608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6186886144.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1969265399040573e+18 - Differentiable computation graph = True!
PPO iteration: 565/1000:
	 start solving instance: 20...
	 start solving instance: 11...
	 start solving instance: 79...
	 start solving instance: 106...
	 start solving instance: 103...
	 start solving instance: 41...
	 start solving instance: 114...
	 start solving instance: 29...
	 start solving instance: 109...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 150...
	 start solving instance: 130...
	 start solving instance: 82...
	 start solving instance: 113...
	 start solving instance: 98...
	 start solving instance: 85...
	 start solving instance: 32...
	 start solving instance: 111...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.381857413797144e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5585792512.0
		 entropy bonus: 0.2081596404314041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5458224640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204726784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.381857523748307e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.381857413797144e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5585792512.0
		 entropy bonus: 0.2081596404314041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5458224640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204726784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.381857523748307e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.381857413797144e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5585792512.0
		 entropy bonus: 0.2081596404314041
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5458224640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6204726784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.381857523748307e+18 - Differentiable computation graph = True!
PPO iteration: 566/1000:
	 start solving instance: 98...
	 start solving instance: 35...
	 start solving instance: 85...
	 start solving instance: 113...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 29...
	 start solving instance: 109...
	 start solving instance: 150...
	 start solving instance: 20...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 114...
	 start solving instance: 130...
	 start solving instance: 11...
	 start solving instance: 82...
	 start solving instance: 111...
	 start solving instance: 32...
	 start solving instance: 79...
	 start solving instance: 41...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.181152561262913e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5553243648.0
		 entropy bonus: 0.19369986653327942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5215526400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6013411840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.181152671214076e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.181152561262913e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5553243648.0
		 entropy bonus: 0.19369986653327942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5215526400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6013411840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.181152671214076e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.181152561262913e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5553243648.0
		 entropy bonus: 0.19369986653327942
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5215526400.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6013411840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.181152671214076e+18 - Differentiable computation graph = True!
PPO iteration: 567/1000:
	 start solving instance: 114...
	 start solving instance: 85...
	 start solving instance: 41...
	 start solving instance: 29...
	 start solving instance: 79...
	 start solving instance: 82...
	 start solving instance: 98...
	 start solving instance: 32...
	 start solving instance: 103...
	 start solving instance: 113...
	 start solving instance: 150...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 35...
	 start solving instance: 109...
	 start solving instance: 111...
	 start solving instance: 20...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.173632121631251e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5515606528.0
		 entropy bonus: 0.2004023790359497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266667008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6028912128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.173632286557995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.173632121631251e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5515606528.0
		 entropy bonus: 0.2004023790359497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266667008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6028912128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.173632286557995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.173632121631251e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5515606528.0
		 entropy bonus: 0.2004023790359497
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5266667008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6028912128.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.173632286557995e+18 - Differentiable computation graph = True!
PPO iteration: 568/1000:
	 start solving instance: 98...
	 start solving instance: 41...
	 start solving instance: 34...
	 start solving instance: 20...
	 start solving instance: 130...
	 start solving instance: 79...
	 start solving instance: 103...
	 start solving instance: 114...
	 start solving instance: 111...
	 start solving instance: 93...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 109...
	 start solving instance: 82...
	 start solving instance: 29...
	 start solving instance: 35...
	 start solving instance: 85...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0812467566190002e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5541757440.0
		 entropy bonus: 0.19965635240077972
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5104997888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5875473920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0812469215457444e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0812467566190002e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5541757440.0
		 entropy bonus: 0.19965635240077972
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5104997888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5875473920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0812469215457444e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0812467566190002e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5541757440.0
		 entropy bonus: 0.19965635240077972
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5104997888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5875473920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.0812469215457444e+18 - Differentiable computation graph = True!
PPO iteration: 569/1000:
	 start solving instance: 111...
	 start solving instance: 29...
	 start solving instance: 32...
	 start solving instance: 150...
	 start solving instance: 85...
	 start solving instance: 35...
	 start solving instance: 114...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 41...
	 start solving instance: 98...
	 start solving instance: 82...
	 start solving instance: 79...
	 start solving instance: 130...
	 start solving instance: 20...
	 start solving instance: 11...
	 start solving instance: 93...
	 start solving instance: 113...
	 start solving instance: 109...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2783394935536615e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5638624768.0
		 entropy bonus: 0.19429348409175873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5315948032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6313774592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2783396035048243e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2783394935536615e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5638624768.0
		 entropy bonus: 0.19429348409175873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5315948032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6313774592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2783396035048243e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2783394935536615e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5638624768.0
		 entropy bonus: 0.19429348409175873
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5315948032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6313774592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2783396035048243e+18 - Differentiable computation graph = True!
PPO iteration: 570/1000:
	 start solving instance: 150...
	 start solving instance: 41...
	 start solving instance: 20...
	 start solving instance: 32...
	 start solving instance: 98...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 103...
	 start solving instance: 113...
	 start solving instance: 35...
	 start solving instance: 29...
	 start solving instance: 109...
	 start solving instance: 114...
	 start solving instance: 111...
	 start solving instance: 79...
	 start solving instance: 34...
	 start solving instance: 82...
	 start solving instance: 130...
	 start solving instance: 85...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1171117264054256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530413568.0
		 entropy bonus: 0.20006108283996582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5088584704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5971461632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1171118913321697e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1171117264054256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530413568.0
		 entropy bonus: 0.20006108283996582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5088584704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5971461632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1171118913321697e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1171117264054256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530413568.0
		 entropy bonus: 0.20006108283996582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5088584704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5971461632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1171118913321697e+18 - Differentiable computation graph = True!
PPO iteration: 571/1000:
	 New training batch of size 20...
	 start solving instance: 122...
	 start solving instance: 14...
	 start solving instance: 89...
	 start solving instance: 66...
	 start solving instance: 117...
	 start solving instance: 119...
	 start solving instance: 4...
	 start solving instance: 128...
	 start solving instance: 56...
	 start solving instance: 58...
	 start solving instance: 68...
	 start solving instance: 78...
	 start solving instance: 20...
	 start solving instance: 63...
	 start solving instance: 93...
	 start solving instance: 12...
	 start solving instance: 109...
	 start solving instance: 35...
	 start solving instance: 52...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.545515101642765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5648928768.0
		 entropy bonus: 0.2216728776693344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5767297024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6285412352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5455151566183465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.545515101642765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5648928768.0
		 entropy bonus: 0.2216728776693344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5767297024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6285412352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5455151566183465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.545515101642765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5648928768.0
		 entropy bonus: 0.2216728776693344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5767297024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6285412352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5455151566183465e+18 - Differentiable computation graph = True!
PPO iteration: 572/1000:
	 start solving instance: 109...
	 start solving instance: 93...
	 start solving instance: 122...
	 start solving instance: 78...
	 start solving instance: 4...
	 start solving instance: 68...
	 start solving instance: 149...
	 start solving instance: 119...
	 start solving instance: 117...
	 start solving instance: 20...
	 start solving instance: 58...
	 start solving instance: 89...
	 start solving instance: 66...
	 start solving instance: 128...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 52...
	 start solving instance: 56...
	 start solving instance: 14...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5697188710073238e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5618658816.0
		 entropy bonus: 0.2332514375448227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823825408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6177349632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5697189809584865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5697188710073238e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5618658816.0
		 entropy bonus: 0.2332514375448227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823825408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6177349632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5697189809584865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5697188710073238e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5618658816.0
		 entropy bonus: 0.2332514375448227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823825408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6177349632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5697189809584865e+18 - Differentiable computation graph = True!
PPO iteration: 573/1000:
	 start solving instance: 20...
	 start solving instance: 149...
	 start solving instance: 93...
	 start solving instance: 56...
	 start solving instance: 117...
	 start solving instance: 89...
	 start solving instance: 119...
	 start solving instance: 122...
	 start solving instance: 68...
	 start solving instance: 14...
	 start solving instance: 128...
	 start solving instance: 4...
	 start solving instance: 63...
	 start solving instance: 66...
	 start solving instance: 52...
	 start solving instance: 109...
	 start solving instance: 12...
	 start solving instance: 78...
	 start solving instance: 58...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5145282251441308e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5676500480.0
		 entropy bonus: 0.22005699574947357
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5649860096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6287961600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5145281701685494e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5145282251441308e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5676500480.0
		 entropy bonus: 0.22005699574947357
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5649860096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6287961600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5145281701685494e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5145282251441308e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5676500480.0
		 entropy bonus: 0.22005699574947357
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5649860096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6287961600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5145281701685494e+18 - Differentiable computation graph = True!
PPO iteration: 574/1000:
	 start solving instance: 35...
	 start solving instance: 117...
	 start solving instance: 66...
	 start solving instance: 128...
	 start solving instance: 68...
	 start solving instance: 109...
	 start solving instance: 89...
	 start solving instance: 78...
	 start solving instance: 93...
	 start solving instance: 4...
	 start solving instance: 52...
	 start solving instance: 63...
	 start solving instance: 56...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 149...
	 start solving instance: 12...
	 start solving instance: 122...
	 start solving instance: 119...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4594943696390586e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5541682688.0
		 entropy bonus: 0.2194858342409134
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5616764416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6217894912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.459494314663477e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4594943696390586e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5541682688.0
		 entropy bonus: 0.2194858342409134
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5616764416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6217894912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.459494314663477e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4594943696390586e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5541682688.0
		 entropy bonus: 0.2194858342409134
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5616764416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6217894912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.459494314663477e+18 - Differentiable computation graph = True!
PPO iteration: 575/1000:
	 start solving instance: 56...
	 start solving instance: 66...
	 start solving instance: 12...
	 start solving instance: 68...
	 start solving instance: 20...
	 start solving instance: 63...
	 start solving instance: 117...
	 start solving instance: 119...
	 start solving instance: 58...
	 start solving instance: 4...
	 start solving instance: 122...
	 start solving instance: 128...
	 start solving instance: 14...
	 start solving instance: 52...
	 start solving instance: 35...
	 start solving instance: 78...
	 start solving instance: 109...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 93...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3576908079256044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5539678720.0
		 entropy bonus: 0.20602063834667206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5538809344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6211484160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3576908079256044e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3576908079256044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5539678720.0
		 entropy bonus: 0.20602063834667206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5538809344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6211484160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3576908079256044e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3576908079256044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5539678720.0
		 entropy bonus: 0.20602063834667206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5538809344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6211484160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3576908079256044e+18 - Differentiable computation graph = True!
PPO iteration: 576/1000:
	 start solving instance: 119...
	 start solving instance: 20...
	 start solving instance: 68...
	 start solving instance: 63...
	 start solving instance: 66...
	 start solving instance: 12...
	 start solving instance: 93...
	 start solving instance: 56...
	 start solving instance: 14...
	 start solving instance: 35...
	 start solving instance: 4...
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 149...
	 start solving instance: 78...
	 start solving instance: 58...
	 start solving instance: 128...
	 start solving instance: 52...
	 start solving instance: 109...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3182572632000692e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5558936576.0
		 entropy bonus: 0.23112988471984863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5508319744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5991271424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.318257373151232e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3182572632000692e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5558936576.0
		 entropy bonus: 0.23112988471984863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5508319744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5991271424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.318257373151232e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3182572632000692e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5558936576.0
		 entropy bonus: 0.23112988471984863
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5508319744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5991271424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.318257373151232e+18 - Differentiable computation graph = True!
PPO iteration: 577/1000:
	 start solving instance: 128...
	 start solving instance: 78...
	 start solving instance: 68...
	 start solving instance: 58...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 109...
	 start solving instance: 149...
	 start solving instance: 119...
	 start solving instance: 52...
	 start solving instance: 35...
	 start solving instance: 63...
	 start solving instance: 89...
	 start solving instance: 14...
	 start solving instance: 20...
	 start solving instance: 56...
	 start solving instance: 12...
	 start solving instance: 93...
	 start solving instance: 4...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4815646466410807e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5651160576.0
		 entropy bonus: 0.2088378518819809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5583380480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6101549056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.481564811567825e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4815646466410807e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5651160576.0
		 entropy bonus: 0.2088378518819809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5583380480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6101549056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.481564811567825e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4815646466410807e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5651160576.0
		 entropy bonus: 0.2088378518819809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5583380480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6101549056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.481564811567825e+18 - Differentiable computation graph = True!
PPO iteration: 578/1000:
	 start solving instance: 58...
	 start solving instance: 117...
	 start solving instance: 109...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 52...
	 start solving instance: 93...
	 start solving instance: 12...
	 start solving instance: 66...
	 start solving instance: 89...
	 start solving instance: 119...
	 start solving instance: 128...
	 start solving instance: 68...
	 start solving instance: 149...
	 start solving instance: 14...
	 start solving instance: 4...
	 start solving instance: 122...
	 start solving instance: 56...
	 start solving instance: 20...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4781456052833485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5672431104.0
		 entropy bonus: 0.22101342678070068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5612059136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6409244672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4781456052833485e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4781456052833485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5672431104.0
		 entropy bonus: 0.22101342678070068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5612059136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6409244672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4781456052833485e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4781456052833485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5672431104.0
		 entropy bonus: 0.22101342678070068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5612059136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6409244672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4781456052833485e+18 - Differentiable computation graph = True!
PPO iteration: 579/1000:
	 start solving instance: 12...
	 start solving instance: 14...
	 start solving instance: 149...
	 start solving instance: 93...
	 start solving instance: 109...
	 start solving instance: 119...
	 start solving instance: 117...
	 start solving instance: 56...
	 start solving instance: 52...
	 start solving instance: 66...
	 start solving instance: 122...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 35...
	 start solving instance: 63...
	 start solving instance: 4...
	 start solving instance: 68...
	 start solving instance: 89...
	 start solving instance: 20...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.467887821503175e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5575335936.0
		 entropy bonus: 0.2162395566701889
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5632498176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6053270528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.467887986429919e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.467887821503175e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5575335936.0
		 entropy bonus: 0.2162395566701889
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5632498176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6053270528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.467887986429919e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.467887821503175e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5575335936.0
		 entropy bonus: 0.2162395566701889
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5632498176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6053270528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.467887986429919e+18 - Differentiable computation graph = True!
PPO iteration: 580/1000:
	 start solving instance: 117...
	 start solving instance: 122...
	 start solving instance: 20...
	 start solving instance: 4...
	 start solving instance: 58...
	 start solving instance: 149...
	 start solving instance: 66...
	 start solving instance: 119...
	 start solving instance: 93...
	 start solving instance: 109...
	 start solving instance: 56...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 52...
	 start solving instance: 89...
	 start solving instance: 12...
	 start solving instance: 68...
	 start solving instance: 35...
	 start solving instance: 14...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5470948799495537e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702100480.0
		 entropy bonus: 0.21410159766674042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5686035456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369131520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5470948799495537e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5470948799495537e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702100480.0
		 entropy bonus: 0.21410159766674042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5686035456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369131520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5470948799495537e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5470948799495537e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5702100480.0
		 entropy bonus: 0.21410159766674042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5686035456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369131520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5470948799495537e+18 - Differentiable computation graph = True!
PPO iteration: 581/1000:
	 New training batch of size 20...
	 start solving instance: 27...
	 start solving instance: 76...
	 start solving instance: 84...
	 start solving instance: 112...
	 start solving instance: 148...
	 start solving instance: 128...
	 start solving instance: 31...
	 start solving instance: 53...
	 start solving instance: 55...
	 start solving instance: 42...
	 start solving instance: 32...
	 start solving instance: 147...
	 start solving instance: 43...
	 start solving instance: 97...
	 start solving instance: 146...
	 start solving instance: 131...
	 start solving instance: 134...
	 start solving instance: 24...
	 start solving instance: 98...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5041515822076396e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6333938176.0
		 entropy bonus: 0.22099359333515167
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6509351936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7102061056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5041515822076396e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5041515822076396e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6333938176.0
		 entropy bonus: 0.22099359333515167
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6509351936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7102061056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5041515822076396e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5041515822076396e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6333938176.0
		 entropy bonus: 0.22099359333515167
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6509351936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7102061056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5041515822076396e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.919574566870817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5159216640.0
		 entropy bonus: 0.19166536629199982
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5055093248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5918900736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2919574731797561344.0000
PPO iteration: 582/1000:
	 start solving instance: 84...
	 start solving instance: 99...
	 start solving instance: 24...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 112...
	 start solving instance: 32...
	 start solving instance: 55...
	 start solving instance: 147...
	 start solving instance: 128...
	 start solving instance: 148...
	 start solving instance: 31...
	 start solving instance: 43...
	 start solving instance: 134...
	 start solving instance: 42...
	 start solving instance: 131...
	 start solving instance: 27...
	 start solving instance: 146...
	 start solving instance: 97...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.438906122410761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6338618880.0
		 entropy bonus: 0.23329739272594452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6520391680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967132160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.438906287337505e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.438906122410761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6338618880.0
		 entropy bonus: 0.23329739272594452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6520391680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967132160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.438906287337505e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.438906122410761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6338618880.0
		 entropy bonus: 0.23329739272594452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6520391680.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967132160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.438906287337505e+18 - Differentiable computation graph = True!
PPO iteration: 583/1000:
	 start solving instance: 42...
	 start solving instance: 31...
	 start solving instance: 98...
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 134...
	 start solving instance: 55...
	 start solving instance: 148...
	 start solving instance: 76...
	 start solving instance: 131...
	 start solving instance: 53...
	 start solving instance: 147...
	 start solving instance: 24...
	 start solving instance: 146...
	 start solving instance: 27...
	 start solving instance: 43...
	 start solving instance: 112...
	 start solving instance: 128...
	 start solving instance: 32...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.630872496332079e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6328448000.0
		 entropy bonus: 0.22312596440315247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6570449920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7185722368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.630872496332079e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.630872496332079e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6328448000.0
		 entropy bonus: 0.22312596440315247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6570449920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7185722368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.630872496332079e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.630872496332079e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6328448000.0
		 entropy bonus: 0.22312596440315247
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6570449920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7185722368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.630872496332079e+18 - Differentiable computation graph = True!
PPO iteration: 584/1000:
	 start solving instance: 131...
	 start solving instance: 43...
	 start solving instance: 147...
	 start solving instance: 134...
	 start solving instance: 53...
	 start solving instance: 76...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 146...
	 start solving instance: 24...
	 start solving instance: 84...
	 start solving instance: 31...
	 start solving instance: 27...
	 start solving instance: 98...
	 start solving instance: 128...
	 start solving instance: 148...
	 start solving instance: 112...
	 start solving instance: 97...
	 start solving instance: 42...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.547523797486194e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6327489536.0
		 entropy bonus: 0.22759251296520233
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6552795136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7081618944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5475237425106125e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.547523797486194e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6327489536.0
		 entropy bonus: 0.22759251296520233
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6552795136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7081618944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5475237425106125e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.547523797486194e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6327489536.0
		 entropy bonus: 0.22759251296520233
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6552795136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7081618944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5475237425106125e+18 - Differentiable computation graph = True!
PPO iteration: 585/1000:
	 start solving instance: 84...
	 start solving instance: 131...
	 start solving instance: 148...
	 start solving instance: 24...
	 start solving instance: 27...
	 start solving instance: 146...
	 start solving instance: 42...
	 start solving instance: 134...
	 start solving instance: 128...
	 start solving instance: 76...
	 start solving instance: 99...
	 start solving instance: 43...
	 start solving instance: 55...
	 start solving instance: 97...
	 start solving instance: 31...
	 start solving instance: 98...
	 start solving instance: 32...
	 start solving instance: 147...
	 start solving instance: 112...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.489290143241968e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6290081280.0
		 entropy bonus: 0.22436542809009552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6558545408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7080729600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.489290308168712e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.489290143241968e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6290081280.0
		 entropy bonus: 0.22436542809009552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6558545408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7080729600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.489290308168712e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.489290143241968e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6290081280.0
		 entropy bonus: 0.22436542809009552
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6558545408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7080729600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.489290308168712e+18 - Differentiable computation graph = True!
PPO iteration: 586/1000:
	 start solving instance: 146...
	 start solving instance: 98...
	 start solving instance: 131...
	 start solving instance: 148...
	 start solving instance: 128...
	 start solving instance: 84...
	 start solving instance: 24...
	 start solving instance: 99...
	 start solving instance: 147...
	 start solving instance: 42...
	 start solving instance: 53...
	 start solving instance: 112...
	 start solving instance: 32...
	 start solving instance: 134...
	 start solving instance: 27...
	 start solving instance: 55...
	 start solving instance: 43...
	 start solving instance: 76...
	 start solving instance: 31...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.207882896447583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244057600.0
		 entropy bonus: 0.22118723392486572
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270818816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696609792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2078829514231644e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.207882896447583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244057600.0
		 entropy bonus: 0.22118723392486572
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270818816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696609792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2078829514231644e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.207882896447583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244057600.0
		 entropy bonus: 0.22118723392486572
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270818816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6696609792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2078829514231644e+18 - Differentiable computation graph = True!
PPO iteration: 587/1000:
	 start solving instance: 42...
	 start solving instance: 84...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 146...
	 start solving instance: 131...
	 start solving instance: 53...
	 start solving instance: 31...
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 43...
	 start solving instance: 148...
	 start solving instance: 32...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 27...
	 start solving instance: 24...
	 start solving instance: 55...
	 start solving instance: 147...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7453945488486695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6345491968.0
		 entropy bonus: 0.2294960469007492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6788778496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7408812544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.745394878702158e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7453945488486695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6345491968.0
		 entropy bonus: 0.2294960469007492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6788778496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7408812544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.745394878702158e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7453945488486695e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6345491968.0
		 entropy bonus: 0.2294960469007492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6788778496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7408812544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.745394878702158e+18 - Differentiable computation graph = True!
PPO iteration: 588/1000:
	 start solving instance: 42...
	 start solving instance: 43...
	 start solving instance: 55...
	 start solving instance: 112...
	 start solving instance: 31...
	 start solving instance: 84...
	 start solving instance: 24...
	 start solving instance: 134...
	 start solving instance: 97...
	 start solving instance: 147...
	 start solving instance: 99...
	 start solving instance: 32...
	 start solving instance: 27...
	 start solving instance: 76...
	 start solving instance: 131...
	 start solving instance: 98...
	 start solving instance: 53...
	 start solving instance: 148...
	 start solving instance: 128...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.50309825006823e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6245383680.0
		 entropy bonus: 0.23150388896465302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6459858432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7195280384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.50309825006823e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.50309825006823e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6245383680.0
		 entropy bonus: 0.23150388896465302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6459858432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7195280384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.50309825006823e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.50309825006823e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6245383680.0
		 entropy bonus: 0.23150388896465302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6459858432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7195280384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.50309825006823e+18 - Differentiable computation graph = True!
PPO iteration: 589/1000:
	 start solving instance: 147...
	 start solving instance: 31...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 76...
	 start solving instance: 148...
	 start solving instance: 55...
	 start solving instance: 131...
	 start solving instance: 24...
	 start solving instance: 146...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 43...
	 start solving instance: 134...
	 start solving instance: 53...
	 start solving instance: 27...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.496975289715471e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6418067456.0
		 entropy bonus: 0.2146596759557724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6458017280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7264695296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4969753446910525e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.496975289715471e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6418067456.0
		 entropy bonus: 0.2146596759557724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6458017280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7264695296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4969753446910525e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.496975289715471e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6418067456.0
		 entropy bonus: 0.2146596759557724
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6458017280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7264695296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4969753446910525e+18 - Differentiable computation graph = True!
PPO iteration: 590/1000:
	 start solving instance: 99...
	 start solving instance: 97...
	 start solving instance: 146...
	 start solving instance: 84...
	 start solving instance: 42...
	 start solving instance: 55...
	 start solving instance: 27...
	 start solving instance: 134...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 147...
	 start solving instance: 112...
	 start solving instance: 53...
	 start solving instance: 131...
	 start solving instance: 43...
	 start solving instance: 148...
	 start solving instance: 24...
	 start solving instance: 31...
	 start solving instance: 32...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4662901192074985e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6349649920.0
		 entropy bonus: 0.21533994376659393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6402528256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7032199680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.46629017418308e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4662901192074985e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6349649920.0
		 entropy bonus: 0.21533994376659393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6402528256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7032199680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.46629017418308e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4662901192074985e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6349649920.0
		 entropy bonus: 0.21533994376659393
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6402528256.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7032199680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.46629017418308e+18 - Differentiable computation graph = True!
PPO iteration: 591/1000:
	 New training batch of size 20...
	 start solving instance: 139...
	 start solving instance: 3...
	 start solving instance: 46...
	 start solving instance: 116...
	 start solving instance: 102...
	 start solving instance: 81...
	 start solving instance: 77...
	 start solving instance: 34...
	 start solving instance: 84...
	 start solving instance: 22...
	 start solving instance: 146...
	 start solving instance: 143...
	 start solving instance: 27...
	 start solving instance: 126...
	 start solving instance: 87...
	 start solving instance: 33...
	 start solving instance: 119...
	 start solving instance: 89...
	 start solving instance: 31...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9793019057120215e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167842304.0
		 entropy bonus: 0.20435094833374023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5930876416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6431950336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9793019057120215e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9793019057120215e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167842304.0
		 entropy bonus: 0.20435094833374023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5930876416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6431950336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9793019057120215e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9793019057120215e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167842304.0
		 entropy bonus: 0.20435094833374023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5930876416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6431950336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9793019057120215e+18 - Differentiable computation graph = True!
PPO iteration: 592/1000:
	 start solving instance: 143...
	 start solving instance: 22...
	 start solving instance: 46...
	 start solving instance: 31...
	 start solving instance: 77...
	 start solving instance: 34...
	 start solving instance: 3...
	 start solving instance: 62...
	 start solving instance: 102...
	 start solving instance: 116...
	 start solving instance: 89...
	 start solving instance: 87...
	 start solving instance: 33...
	 start solving instance: 139...
	 start solving instance: 119...
	 start solving instance: 146...
	 start solving instance: 81...
	 start solving instance: 126...
	 start solving instance: 84...
	 start solving instance: 27...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.021552619130244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6057734144.0
		 entropy bonus: 0.21878282725811005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6011004416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6146058752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.021552564154663e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.021552619130244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6057734144.0
		 entropy bonus: 0.21878282725811005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6011004416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6146058752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.021552564154663e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.021552619130244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6057734144.0
		 entropy bonus: 0.21878282725811005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6011004416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6146058752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.021552564154663e+18 - Differentiable computation graph = True!
PPO iteration: 593/1000:
	 start solving instance: 87...
	 start solving instance: 84...
	 start solving instance: 126...
	 start solving instance: 119...
	 start solving instance: 146...
	 start solving instance: 81...
	 start solving instance: 143...
	 start solving instance: 62...
	 start solving instance: 89...
	 start solving instance: 102...
	 start solving instance: 31...
	 start solving instance: 22...
	 start solving instance: 46...
	 start solving instance: 139...
	 start solving instance: 27...
	 start solving instance: 116...
	 start solving instance: 3...
	 start solving instance: 77...
	 start solving instance: 33...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.230019583951923e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6152744448.0
		 entropy bonus: 0.20538155734539032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276673536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6789864960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2300196939030856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.230019583951923e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6152744448.0
		 entropy bonus: 0.20538155734539032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276673536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6789864960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2300196939030856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.230019583951923e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6152744448.0
		 entropy bonus: 0.20538155734539032
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276673536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6789864960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2300196939030856e+18 - Differentiable computation graph = True!
PPO iteration: 594/1000:
	 start solving instance: 46...
	 start solving instance: 27...
	 start solving instance: 119...
	 start solving instance: 102...
	 start solving instance: 139...
	 start solving instance: 62...
	 start solving instance: 34...
	 start solving instance: 126...
	 start solving instance: 116...
	 start solving instance: 81...
	 start solving instance: 33...
	 start solving instance: 3...
	 start solving instance: 84...
	 start solving instance: 87...
	 start solving instance: 146...
	 start solving instance: 77...
	 start solving instance: 143...
	 start solving instance: 89...
	 start solving instance: 31...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.250870722461067e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6173492224.0
		 entropy bonus: 0.20183801651000977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6234706944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6717384192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2508708324122296e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.250870722461067e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6173492224.0
		 entropy bonus: 0.20183801651000977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6234706944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6717384192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2508708324122296e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.250870722461067e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6173492224.0
		 entropy bonus: 0.20183801651000977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6234706944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6717384192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2508708324122296e+18 - Differentiable computation graph = True!
PPO iteration: 595/1000:
	 start solving instance: 84...
	 start solving instance: 139...
	 start solving instance: 33...
	 start solving instance: 27...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 22...
	 start solving instance: 77...
	 start solving instance: 89...
	 start solving instance: 34...
	 start solving instance: 126...
	 start solving instance: 62...
	 start solving instance: 119...
	 start solving instance: 143...
	 start solving instance: 146...
	 start solving instance: 87...
	 start solving instance: 116...
	 start solving instance: 31...
	 start solving instance: 46...
	 start solving instance: 81...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.743893387572622e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927196160.0
		 entropy bonus: 0.21669240295886993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5736964096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6025532928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7438934425482035e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.743893387572622e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927196160.0
		 entropy bonus: 0.21669240295886993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5736964096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6025532928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7438934425482035e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.743893387572622e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927196160.0
		 entropy bonus: 0.21669240295886993
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5736964096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6025532928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7438934425482035e+18 - Differentiable computation graph = True!
PPO iteration: 596/1000:
	 start solving instance: 126...
	 start solving instance: 89...
	 start solving instance: 116...
	 start solving instance: 3...
	 start solving instance: 87...
	 start solving instance: 34...
	 start solving instance: 62...
	 start solving instance: 119...
	 start solving instance: 27...
	 start solving instance: 143...
	 start solving instance: 77...
	 start solving instance: 33...
	 start solving instance: 139...
	 start solving instance: 22...
	 start solving instance: 46...
	 start solving instance: 81...
	 start solving instance: 102...
	 start solving instance: 31...
	 start solving instance: 84...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.029363109929314e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6155699200.0
		 entropy bonus: 0.19626198709011078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5955748864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6754332160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0293632198804767e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.029363109929314e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6155699200.0
		 entropy bonus: 0.19626198709011078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5955748864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6754332160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0293632198804767e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.029363109929314e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6155699200.0
		 entropy bonus: 0.19626198709011078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5955748864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6754332160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0293632198804767e+18 - Differentiable computation graph = True!
PPO iteration: 597/1000:
	 start solving instance: 102...
	 start solving instance: 126...
	 start solving instance: 34...
	 start solving instance: 62...
	 start solving instance: 46...
	 start solving instance: 116...
	 start solving instance: 119...
	 start solving instance: 143...
	 start solving instance: 31...
	 start solving instance: 139...
	 start solving instance: 27...
	 start solving instance: 33...
	 start solving instance: 146...
	 start solving instance: 22...
	 start solving instance: 84...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 77...
	 start solving instance: 81...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.200414573667077e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059633152.0
		 entropy bonus: 0.20681428909301758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6209496576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6949419008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.200414518691496e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.200414573667077e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059633152.0
		 entropy bonus: 0.20681428909301758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6209496576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6949419008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.200414518691496e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.200414573667077e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059633152.0
		 entropy bonus: 0.20681428909301758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6209496576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6949419008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.200414518691496e+18 - Differentiable computation graph = True!
PPO iteration: 598/1000:
	 start solving instance: 116...
	 start solving instance: 146...
	 start solving instance: 22...
	 start solving instance: 77...
	 start solving instance: 89...
	 start solving instance: 33...
	 start solving instance: 46...
	 start solving instance: 119...
	 start solving instance: 139...
	 start solving instance: 62...
	 start solving instance: 81...
	 start solving instance: 84...
	 start solving instance: 87...
	 start solving instance: 31...
	 start solving instance: 143...
	 start solving instance: 102...
	 start solving instance: 34...
	 start solving instance: 27...
	 start solving instance: 126...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.184732899027085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023023616.0
		 entropy bonus: 0.2060277909040451
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6164729344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836038656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1847330089782477e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.184732899027085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023023616.0
		 entropy bonus: 0.2060277909040451
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6164729344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836038656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1847330089782477e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.184732899027085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023023616.0
		 entropy bonus: 0.2060277909040451
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6164729344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836038656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1847330089782477e+18 - Differentiable computation graph = True!
PPO iteration: 599/1000:
	 start solving instance: 143...
	 start solving instance: 119...
	 start solving instance: 102...
	 start solving instance: 77...
	 start solving instance: 139...
	 start solving instance: 81...
	 start solving instance: 22...
	 start solving instance: 84...
	 start solving instance: 34...
	 start solving instance: 116...
	 start solving instance: 126...
	 start solving instance: 87...
	 start solving instance: 3...
	 start solving instance: 62...
	 start solving instance: 31...
	 start solving instance: 146...
	 start solving instance: 46...
	 start solving instance: 27...
	 start solving instance: 33...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.113851342626226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6025586176.0
		 entropy bonus: 0.21057572960853577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6056291840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6348966912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.113851342626226e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.113851342626226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6025586176.0
		 entropy bonus: 0.21057572960853577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6056291840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6348966912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.113851342626226e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.113851342626226e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6025586176.0
		 entropy bonus: 0.21057572960853577
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6056291840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6348966912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.113851342626226e+18 - Differentiable computation graph = True!
PPO iteration: 600/1000:
	 start solving instance: 81...
	 start solving instance: 27...
	 start solving instance: 143...
	 start solving instance: 62...
	 start solving instance: 139...
	 start solving instance: 31...
	 start solving instance: 146...
	 start solving instance: 119...
	 start solving instance: 34...
	 start solving instance: 116...
	 start solving instance: 46...
	 start solving instance: 84...
	 start solving instance: 102...
	 start solving instance: 33...
	 start solving instance: 87...
	 start solving instance: 3...
	 start solving instance: 126...
	 start solving instance: 77...
	 start solving instance: 22...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.328163311261162e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6081239040.0
		 entropy bonus: 0.21211953461170197
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315282432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6732535296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328163476187906e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.328163311261162e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6081239040.0
		 entropy bonus: 0.21211953461170197
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315282432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6732535296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328163476187906e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.328163311261162e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6081239040.0
		 entropy bonus: 0.21211953461170197
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6315282432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6732535296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328163476187906e+18 - Differentiable computation graph = True!
PPO iteration: 601/1000:
	 New training batch of size 20...
	 start solving instance: 40...
	 start solving instance: 28...
	 start solving instance: 45...
	 start solving instance: 129...
	 start solving instance: 12...
	 start solving instance: 56...
	 start solving instance: 85...
	 start solving instance: 107...
	 start solving instance: 121...
	 start solving instance: 147...
	 start solving instance: 124...
	 start solving instance: 49...
	 start solving instance: 31...
	 start solving instance: 87...
	 start solving instance: 61...
	 start solving instance: 1...
	 start solving instance: 95...
	 start solving instance: 137...
	 start solving instance: 69...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1796364427300176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5960990720.0
		 entropy bonus: 0.19658957421779633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6105536000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7096718848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.179636497705599e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1796364427300176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5960990720.0
		 entropy bonus: 0.19658957421779633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6105536000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7096718848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.179636497705599e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1796364427300176e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5960990720.0
		 entropy bonus: 0.19658957421779633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6105536000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7096718848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.179636497705599e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9414638642589073e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5232006656.0
		 entropy bonus: 0.1913304328918457
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5017401344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5966330368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2941463809283325952.0000
PPO iteration: 602/1000:
	 start solving instance: 56...
	 start solving instance: 49...
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 147...
	 start solving instance: 137...
	 start solving instance: 87...
	 start solving instance: 107...
	 start solving instance: 45...
	 start solving instance: 28...
	 start solving instance: 9...
	 start solving instance: 12...
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 40...
	 start solving instance: 1...
	 start solving instance: 31...
	 start solving instance: 95...
	 start solving instance: 69...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.002489726332515e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5812254208.0
		 entropy bonus: 0.21014805138111115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877855232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774554624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0024897813080965e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.002489726332515e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5812254208.0
		 entropy bonus: 0.21014805138111115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877855232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774554624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0024897813080965e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.002489726332515e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5812254208.0
		 entropy bonus: 0.21014805138111115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5877855232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774554624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0024897813080965e+18 - Differentiable computation graph = True!
PPO iteration: 603/1000:
	 start solving instance: 49...
	 start solving instance: 9...
	 start solving instance: 12...
	 start solving instance: 129...
	 start solving instance: 87...
	 start solving instance: 95...
	 start solving instance: 40...
	 start solving instance: 31...
	 start solving instance: 56...
	 start solving instance: 69...
	 start solving instance: 28...
	 start solving instance: 121...
	 start solving instance: 124...
	 start solving instance: 137...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 85...
	 start solving instance: 45...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.702413211903145e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763918336.0
		 entropy bonus: 0.2076987773180008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5777644032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6886519808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.702413266878726e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.702413211903145e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763918336.0
		 entropy bonus: 0.2076987773180008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5777644032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6886519808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.702413266878726e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.702413211903145e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763918336.0
		 entropy bonus: 0.2076987773180008
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5777644032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6886519808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.702413266878726e+18 - Differentiable computation graph = True!
PPO iteration: 604/1000:
	 start solving instance: 49...
	 start solving instance: 87...
	 start solving instance: 61...
	 start solving instance: 137...
	 start solving instance: 121...
	 start solving instance: 31...
	 start solving instance: 107...
	 start solving instance: 9...
	 start solving instance: 56...
	 start solving instance: 12...
	 start solving instance: 69...
	 start solving instance: 45...
	 start solving instance: 124...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 28...
	 start solving instance: 95...
	 start solving instance: 85...
	 start solving instance: 40...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.913708560436114e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5893902848.0
		 entropy bonus: 0.196219801902771
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5815544832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6533639680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9137086154116956e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.913708560436114e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5893902848.0
		 entropy bonus: 0.196219801902771
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5815544832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6533639680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9137086154116956e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.913708560436114e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5893902848.0
		 entropy bonus: 0.196219801902771
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5815544832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6533639680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9137086154116956e+18 - Differentiable computation graph = True!
PPO iteration: 605/1000:
	 start solving instance: 40...
	 start solving instance: 28...
	 start solving instance: 45...
	 start solving instance: 121...
	 start solving instance: 69...
	 start solving instance: 56...
	 start solving instance: 1...
	 start solving instance: 87...
	 start solving instance: 12...
	 start solving instance: 129...
	 start solving instance: 31...
	 start solving instance: 9...
	 start solving instance: 49...
	 start solving instance: 61...
	 start solving instance: 85...
	 start solving instance: 124...
	 start solving instance: 137...
	 start solving instance: 147...
	 start solving instance: 95...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.211142288716962e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5926227968.0
		 entropy bonus: 0.20512187480926514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114303488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7390564864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2111424536437064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.211142288716962e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5926227968.0
		 entropy bonus: 0.20512187480926514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114303488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7390564864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2111424536437064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.211142288716962e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5926227968.0
		 entropy bonus: 0.20512187480926514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114303488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7390564864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2111424536437064e+18 - Differentiable computation graph = True!
PPO iteration: 606/1000:
	 start solving instance: 28...
	 start solving instance: 129...
	 start solving instance: 40...
	 start solving instance: 1...
	 start solving instance: 31...
	 start solving instance: 9...
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 124...
	 start solving instance: 56...
	 start solving instance: 87...
	 start solving instance: 45...
	 start solving instance: 61...
	 start solving instance: 12...
	 start solving instance: 49...
	 start solving instance: 137...
	 start solving instance: 107...
	 start solving instance: 95...
	 start solving instance: 69...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.046108672020342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5853816832.0
		 entropy bonus: 0.20024028420448303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053309952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7107149312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.046108781971505e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.046108672020342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5853816832.0
		 entropy bonus: 0.20024028420448303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053309952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7107149312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.046108781971505e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.046108672020342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5853816832.0
		 entropy bonus: 0.20024028420448303
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053309952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7107149312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.046108781971505e+18 - Differentiable computation graph = True!
PPO iteration: 607/1000:
	 start solving instance: 1...
	 start solving instance: 49...
	 start solving instance: 61...
	 start solving instance: 9...
	 start solving instance: 121...
	 start solving instance: 147...
	 start solving instance: 137...
	 start solving instance: 107...
	 start solving instance: 31...
	 start solving instance: 85...
	 start solving instance: 69...
	 start solving instance: 40...
	 start solving instance: 124...
	 start solving instance: 45...
	 start solving instance: 95...
	 start solving instance: 129...
	 start solving instance: 12...
	 start solving instance: 56...
	 start solving instance: 87...
	 start solving instance: 28...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.904940175106926e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5863568384.0
		 entropy bonus: 0.19991640746593475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5783759360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741015552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.904940285058089e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.904940175106926e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5863568384.0
		 entropy bonus: 0.19991640746593475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5783759360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741015552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.904940285058089e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.904940175106926e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5863568384.0
		 entropy bonus: 0.19991640746593475
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5783759360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741015552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.904940285058089e+18 - Differentiable computation graph = True!
PPO iteration: 608/1000:
	 start solving instance: 9...
	 start solving instance: 121...
	 start solving instance: 85...
	 start solving instance: 49...
	 start solving instance: 45...
	 start solving instance: 95...
	 start solving instance: 107...
	 start solving instance: 129...
	 start solving instance: 61...
	 start solving instance: 12...
	 start solving instance: 28...
	 start solving instance: 31...
	 start solving instance: 56...
	 start solving instance: 87...
	 start solving instance: 147...
	 start solving instance: 1...
	 start solving instance: 124...
	 start solving instance: 137...
	 start solving instance: 69...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.060048720241938e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5839006208.0
		 entropy bonus: 0.19993147253990173
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5987827200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7286363136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.060048665266356e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.060048720241938e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5839006208.0
		 entropy bonus: 0.19993147253990173
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5987827200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7286363136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.060048665266356e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.060048720241938e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5839006208.0
		 entropy bonus: 0.19993147253990173
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5987827200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7286363136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.060048665266356e+18 - Differentiable computation graph = True!
PPO iteration: 609/1000:
	 start solving instance: 12...
	 start solving instance: 147...
	 start solving instance: 137...
	 start solving instance: 40...
	 start solving instance: 28...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 107...
	 start solving instance: 56...
	 start solving instance: 9...
	 start solving instance: 45...
	 start solving instance: 129...
	 start solving instance: 95...
	 start solving instance: 69...
	 start solving instance: 31...
	 start solving instance: 87...
	 start solving instance: 49...
	 start solving instance: 85...
	 start solving instance: 124...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.186158305901334e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928306688.0
		 entropy bonus: 0.20471881330013275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6057541632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7327816192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1861582509257523e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.186158305901334e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928306688.0
		 entropy bonus: 0.20471881330013275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6057541632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7327816192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1861582509257523e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.186158305901334e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928306688.0
		 entropy bonus: 0.20471881330013275
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6057541632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7327816192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1861582509257523e+18 - Differentiable computation graph = True!
PPO iteration: 610/1000:
	 start solving instance: 28...
	 start solving instance: 85...
	 start solving instance: 69...
	 start solving instance: 121...
	 start solving instance: 40...
	 start solving instance: 147...
	 start solving instance: 107...
	 start solving instance: 95...
	 start solving instance: 87...
	 start solving instance: 129...
	 start solving instance: 56...
	 start solving instance: 45...
	 start solving instance: 137...
	 start solving instance: 31...
	 start solving instance: 9...
	 start solving instance: 12...
	 start solving instance: 61...
	 start solving instance: 49...
	 start solving instance: 1...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.277861094095061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5952448000.0
		 entropy bonus: 0.21536198258399963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6283691008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7561296384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.277861094095061e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.277861094095061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5952448000.0
		 entropy bonus: 0.21536198258399963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6283691008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7561296384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.277861094095061e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.277861094095061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5952448000.0
		 entropy bonus: 0.21536198258399963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6283691008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7561296384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.277861094095061e+18 - Differentiable computation graph = True!
PPO iteration: 611/1000:
	 New training batch of size 20...
	 start solving instance: 119...
	 start solving instance: 120...
	 start solving instance: 75...
	 start solving instance: 108...
	 start solving instance: 96...
	 start solving instance: 126...
	 start solving instance: 62...
	 start solving instance: 60...
	 start solving instance: 113...
	 start solving instance: 31...
	 start solving instance: 51...
	 start solving instance: 73...
	 start solving instance: 21...
	 start solving instance: 4...
	 start solving instance: 93...
	 start solving instance: 86...
	 start solving instance: 43...
	 start solving instance: 64...
	 start solving instance: 117...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7507468634508755e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5897502208.0
		 entropy bonus: 0.21830081939697266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850794496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6512161280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7507469734020383e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7507468634508755e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5897502208.0
		 entropy bonus: 0.21830081939697266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850794496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6512161280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7507469734020383e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7507468634508755e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5897502208.0
		 entropy bonus: 0.21830081939697266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850794496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6512161280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7507469734020383e+18 - Differentiable computation graph = True!
PPO iteration: 612/1000:
	 start solving instance: 51...
	 start solving instance: 21...
	 start solving instance: 4...
	 start solving instance: 117...
	 start solving instance: 126...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 96...
	 start solving instance: 43...
	 start solving instance: 31...
	 start solving instance: 86...
	 start solving instance: 113...
	 start solving instance: 108...
	 start solving instance: 120...
	 start solving instance: 62...
	 start solving instance: 75...
	 start solving instance: 119...
	 start solving instance: 64...
	 start solving instance: 143...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8106025172483965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5865657344.0
		 entropy bonus: 0.2210613340139389
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5924078592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6573106688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.810602462272815e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8106025172483965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5865657344.0
		 entropy bonus: 0.2210613340139389
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5924078592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6573106688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.810602462272815e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8106025172483965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5865657344.0
		 entropy bonus: 0.2210613340139389
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5924078592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6573106688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.810602462272815e+18 - Differentiable computation graph = True!
PPO iteration: 613/1000:
	 start solving instance: 119...
	 start solving instance: 31...
	 start solving instance: 108...
	 start solving instance: 21...
	 start solving instance: 62...
	 start solving instance: 96...
	 start solving instance: 4...
	 start solving instance: 120...
	 start solving instance: 75...
	 start solving instance: 117...
	 start solving instance: 143...
	 start solving instance: 86...
	 start solving instance: 73...
	 start solving instance: 60...
	 start solving instance: 64...
	 start solving instance: 93...
	 start solving instance: 113...
	 start solving instance: 43...
	 start solving instance: 51...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9952769300543046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928637952.0
		 entropy bonus: 0.21394455432891846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6065756672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6733348864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.995276985029886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9952769300543046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928637952.0
		 entropy bonus: 0.21394455432891846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6065756672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6733348864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.995276985029886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9952769300543046e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928637952.0
		 entropy bonus: 0.21394455432891846
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6065756672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6733348864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.995276985029886e+18 - Differentiable computation graph = True!
PPO iteration: 614/1000:
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 86...
	 start solving instance: 143...
	 start solving instance: 62...
	 start solving instance: 21...
	 start solving instance: 108...
	 start solving instance: 43...
	 start solving instance: 117...
	 start solving instance: 60...
	 start solving instance: 75...
	 start solving instance: 96...
	 start solving instance: 64...
	 start solving instance: 51...
	 start solving instance: 120...
	 start solving instance: 4...
	 start solving instance: 119...
	 start solving instance: 126...
	 start solving instance: 93...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8469660056068555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5860610560.0
		 entropy bonus: 0.22389112412929535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938964480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6403463680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.846966060582437e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8469660056068555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5860610560.0
		 entropy bonus: 0.22389112412929535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938964480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6403463680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.846966060582437e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8469660056068555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5860610560.0
		 entropy bonus: 0.22389112412929535
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5938964480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6403463680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.846966060582437e+18 - Differentiable computation graph = True!
PPO iteration: 615/1000:
	 start solving instance: 120...
	 start solving instance: 117...
	 start solving instance: 62...
	 start solving instance: 43...
	 start solving instance: 51...
	 start solving instance: 143...
	 start solving instance: 119...
	 start solving instance: 108...
	 start solving instance: 21...
	 start solving instance: 31...
	 start solving instance: 93...
	 start solving instance: 4...
	 start solving instance: 126...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 64...
	 start solving instance: 96...
	 start solving instance: 60...
	 start solving instance: 75...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.004102489988137e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998861824.0
		 entropy bonus: 0.2222510129213333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6222865920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6690660864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.004102489988137e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.004102489988137e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998861824.0
		 entropy bonus: 0.2222510129213333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6222865920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6690660864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.004102489988137e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.004102489988137e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998861824.0
		 entropy bonus: 0.2222510129213333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6222865920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6690660864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.004102489988137e+18 - Differentiable computation graph = True!
PPO iteration: 616/1000:
	 start solving instance: 86...
	 start solving instance: 51...
	 start solving instance: 119...
	 start solving instance: 108...
	 start solving instance: 75...
	 start solving instance: 120...
	 start solving instance: 93...
	 start solving instance: 64...
	 start solving instance: 21...
	 start solving instance: 60...
	 start solving instance: 143...
	 start solving instance: 126...
	 start solving instance: 113...
	 start solving instance: 43...
	 start solving instance: 4...
	 start solving instance: 96...
	 start solving instance: 73...
	 start solving instance: 62...
	 start solving instance: 31...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.96694383482047e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5986509312.0
		 entropy bonus: 0.22935442626476288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156572672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661184000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.966943944771633e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.96694383482047e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5986509312.0
		 entropy bonus: 0.22935442626476288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156572672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661184000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.966943944771633e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.96694383482047e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5986509312.0
		 entropy bonus: 0.22935442626476288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156572672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661184000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.966943944771633e+18 - Differentiable computation graph = True!
PPO iteration: 617/1000:
	 start solving instance: 86...
	 start solving instance: 62...
	 start solving instance: 93...
	 start solving instance: 143...
	 start solving instance: 75...
	 start solving instance: 21...
	 start solving instance: 64...
	 start solving instance: 108...
	 start solving instance: 73...
	 start solving instance: 51...
	 start solving instance: 96...
	 start solving instance: 120...
	 start solving instance: 113...
	 start solving instance: 43...
	 start solving instance: 31...
	 start solving instance: 60...
	 start solving instance: 126...
	 start solving instance: 4...
	 start solving instance: 117...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.989442041748023e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982825984.0
		 entropy bonus: 0.21963195502758026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6070294016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840283648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9894421516991857e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.989442041748023e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982825984.0
		 entropy bonus: 0.21963195502758026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6070294016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840283648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9894421516991857e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.989442041748023e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982825984.0
		 entropy bonus: 0.21963195502758026
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6070294016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840283648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9894421516991857e+18 - Differentiable computation graph = True!
PPO iteration: 618/1000:
	 start solving instance: 4...
	 start solving instance: 93...
	 start solving instance: 120...
	 start solving instance: 31...
	 start solving instance: 143...
	 start solving instance: 96...
	 start solving instance: 60...
	 start solving instance: 21...
	 start solving instance: 51...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 75...
	 start solving instance: 108...
	 start solving instance: 62...
	 start solving instance: 43...
	 start solving instance: 126...
	 start solving instance: 117...
	 start solving instance: 64...
	 start solving instance: 86...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.040833655034924e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985650688.0
		 entropy bonus: 0.2212069034576416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6162505216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6757948928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.040833600059343e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.040833655034924e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985650688.0
		 entropy bonus: 0.2212069034576416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6162505216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6757948928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.040833600059343e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.040833655034924e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985650688.0
		 entropy bonus: 0.2212069034576416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6162505216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6757948928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.040833600059343e+18 - Differentiable computation graph = True!
PPO iteration: 619/1000:
	 start solving instance: 119...
	 start solving instance: 51...
	 start solving instance: 43...
	 start solving instance: 4...
	 start solving instance: 113...
	 start solving instance: 75...
	 start solving instance: 62...
	 start solving instance: 117...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 31...
	 start solving instance: 126...
	 start solving instance: 143...
	 start solving instance: 86...
	 start solving instance: 64...
	 start solving instance: 21...
	 start solving instance: 120...
	 start solving instance: 73...
	 start solving instance: 96...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.996682545719253e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6053382144.0
		 entropy bonus: 0.22644388675689697
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114085888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660200448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9966827106459976e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.996682545719253e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6053382144.0
		 entropy bonus: 0.22644388675689697
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114085888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660200448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9966827106459976e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.996682545719253e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6053382144.0
		 entropy bonus: 0.22644388675689697
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6114085888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660200448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9966827106459976e+18 - Differentiable computation graph = True!
PPO iteration: 620/1000:
	 start solving instance: 86...
	 start solving instance: 93...
	 start solving instance: 117...
	 start solving instance: 31...
	 start solving instance: 143...
	 start solving instance: 21...
	 start solving instance: 119...
	 start solving instance: 51...
	 start solving instance: 126...
	 start solving instance: 43...
	 start solving instance: 96...
	 start solving instance: 113...
	 start solving instance: 60...
	 start solving instance: 120...
	 start solving instance: 62...
	 start solving instance: 64...
	 start solving instance: 108...
	 start solving instance: 4...
	 start solving instance: 73...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.858502081605481e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5897618944.0
		 entropy bonus: 0.2154070883989334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5896701440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6572987904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8585021365810627e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.858502081605481e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5897618944.0
		 entropy bonus: 0.2154070883989334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5896701440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6572987904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8585021365810627e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.858502081605481e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5897618944.0
		 entropy bonus: 0.2154070883989334
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5896701440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6572987904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8585021365810627e+18 - Differentiable computation graph = True!
PPO iteration: 621/1000:
	 New training batch of size 20...
	 start solving instance: 117...
	 start solving instance: 69...
	 start solving instance: 7...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 43...
	 start solving instance: 106...
	 start solving instance: 21...
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 139...
	 start solving instance: 81...
	 start solving instance: 4...
	 start solving instance: 101...
	 start solving instance: 57...
	 start solving instance: 148...
	 start solving instance: 34...
	 start solving instance: 61...
	 start solving instance: 100...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.300972388706261e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5916115456.0
		 entropy bonus: 0.20630097389221191
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6105409024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6973944832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3009725536330056e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.300972388706261e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5916115456.0
		 entropy bonus: 0.20630097389221191
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6105409024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6973944832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3009725536330056e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.300972388706261e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5916115456.0
		 entropy bonus: 0.20630097389221191
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6105409024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6973944832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3009725536330056e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.190073778708362e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5324506624.0
		 entropy bonus: 0.2053915560245514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5255437824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6048116736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3190073833683943424.0000
PPO iteration: 622/1000:
	 start solving instance: 92...
	 start solving instance: 139...
	 start solving instance: 4...
	 start solving instance: 21...
	 start solving instance: 7...
	 start solving instance: 117...
	 start solving instance: 81...
	 start solving instance: 100...
	 start solving instance: 57...
	 start solving instance: 42...
	 start solving instance: 69...
	 start solving instance: 145...
	 start solving instance: 61...
	 start solving instance: 43...
	 start solving instance: 147...
	 start solving instance: 77...
	 start solving instance: 101...
	 start solving instance: 148...
	 start solving instance: 34...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.852320627234125e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5841917440.0
		 entropy bonus: 0.21882103383541107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5851523584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6807574528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.852320682209706e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.852320627234125e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5841917440.0
		 entropy bonus: 0.21882103383541107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5851523584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6807574528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.852320682209706e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.852320627234125e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5841917440.0
		 entropy bonus: 0.21882103383541107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5851523584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6807574528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.852320682209706e+18 - Differentiable computation graph = True!
PPO iteration: 623/1000:
	 start solving instance: 148...
	 start solving instance: 57...
	 start solving instance: 81...
	 start solving instance: 77...
	 start solving instance: 34...
	 start solving instance: 101...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 43...
	 start solving instance: 42...
	 start solving instance: 100...
	 start solving instance: 139...
	 start solving instance: 61...
	 start solving instance: 7...
	 start solving instance: 106...
	 start solving instance: 4...
	 start solving instance: 21...
	 start solving instance: 92...
	 start solving instance: 69...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8989060552936915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5789316608.0
		 entropy bonus: 0.20852608978748322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5791844352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543279616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8989061652448543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8989060552936915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5789316608.0
		 entropy bonus: 0.20852608978748322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5791844352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543279616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8989061652448543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8989060552936915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5789316608.0
		 entropy bonus: 0.20852608978748322
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5791844352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543279616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8989061652448543e+18 - Differentiable computation graph = True!
PPO iteration: 624/1000:
	 start solving instance: 81...
	 start solving instance: 69...
	 start solving instance: 147...
	 start solving instance: 57...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 34...
	 start solving instance: 4...
	 start solving instance: 100...
	 start solving instance: 92...
	 start solving instance: 139...
	 start solving instance: 145...
	 start solving instance: 43...
	 start solving instance: 7...
	 start solving instance: 148...
	 start solving instance: 21...
	 start solving instance: 61...
	 start solving instance: 42...
	 start solving instance: 106...
	 start solving instance: 77...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.073508941589171e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5875127296.0
		 entropy bonus: 0.21405728161334991
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6021816320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687432192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.07350888661359e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.073508941589171e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5875127296.0
		 entropy bonus: 0.21405728161334991
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6021816320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687432192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.07350888661359e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.073508941589171e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5875127296.0
		 entropy bonus: 0.21405728161334991
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6021816320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687432192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.07350888661359e+18 - Differentiable computation graph = True!
PPO iteration: 625/1000:
	 start solving instance: 4...
	 start solving instance: 101...
	 start solving instance: 117...
	 start solving instance: 69...
	 start solving instance: 77...
	 start solving instance: 43...
	 start solving instance: 92...
	 start solving instance: 42...
	 start solving instance: 100...
	 start solving instance: 81...
	 start solving instance: 148...
	 start solving instance: 145...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 106...
	 start solving instance: 57...
	 start solving instance: 139...
	 start solving instance: 34...
	 start solving instance: 7...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7983961789614785e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832727552.0
		 entropy bonus: 0.21222268044948578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5802733568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504102912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.79839623393706e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7983961789614785e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832727552.0
		 entropy bonus: 0.21222268044948578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5802733568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504102912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.79839623393706e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7983961789614785e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832727552.0
		 entropy bonus: 0.21222268044948578
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5802733568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504102912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.79839623393706e+18 - Differentiable computation graph = True!
PPO iteration: 626/1000:
	 start solving instance: 139...
	 start solving instance: 81...
	 start solving instance: 57...
	 start solving instance: 69...
	 start solving instance: 77...
	 start solving instance: 117...
	 start solving instance: 101...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 21...
	 start solving instance: 42...
	 start solving instance: 7...
	 start solving instance: 145...
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 100...
	 start solving instance: 92...
	 start solving instance: 106...
	 start solving instance: 61...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.996223389663494e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5912798720.0
		 entropy bonus: 0.20514117181301117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5962181120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584501760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.996223389663494e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.996223389663494e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5912798720.0
		 entropy bonus: 0.20514117181301117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5962181120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584501760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.996223389663494e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.996223389663494e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5912798720.0
		 entropy bonus: 0.20514117181301117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5962181120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584501760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.996223389663494e+18 - Differentiable computation graph = True!
PPO iteration: 627/1000:
	 start solving instance: 92...
	 start solving instance: 69...
	 start solving instance: 42...
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 21...
	 start solving instance: 77...
	 start solving instance: 106...
	 start solving instance: 100...
	 start solving instance: 43...
	 start solving instance: 57...
	 start solving instance: 101...
	 start solving instance: 4...
	 start solving instance: 147...
	 start solving instance: 139...
	 start solving instance: 117...
	 start solving instance: 81...
	 start solving instance: 145...
	 start solving instance: 7...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.753111693059896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5783433728.0
		 entropy bonus: 0.2072794884443283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5732306944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6511571968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7531117480354775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.753111693059896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5783433728.0
		 entropy bonus: 0.2072794884443283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5732306944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6511571968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7531117480354775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.753111693059896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5783433728.0
		 entropy bonus: 0.2072794884443283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5732306944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6511571968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7531117480354775e+18 - Differentiable computation graph = True!
PPO iteration: 628/1000:
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 100...
	 start solving instance: 7...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 145...
	 start solving instance: 42...
	 start solving instance: 77...
	 start solving instance: 117...
	 start solving instance: 57...
	 start solving instance: 106...
	 start solving instance: 69...
	 start solving instance: 139...
	 start solving instance: 61...
	 start solving instance: 21...
	 start solving instance: 101...
	 start solving instance: 92...
	 start solving instance: 81...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7910144976972415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5823839744.0
		 entropy bonus: 0.19795037806034088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718406144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6532887040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7910146626239857e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7910144976972415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5823839744.0
		 entropy bonus: 0.19795037806034088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718406144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6532887040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7910146626239857e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7910144976972415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5823839744.0
		 entropy bonus: 0.19795037806034088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718406144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6532887040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7910146626239857e+18 - Differentiable computation graph = True!
PPO iteration: 629/1000:
	 start solving instance: 92...
	 start solving instance: 21...
	 start solving instance: 61...
	 start solving instance: 139...
	 start solving instance: 34...
	 start solving instance: 100...
	 start solving instance: 42...
	 start solving instance: 43...
	 start solving instance: 101...
	 start solving instance: 145...
	 start solving instance: 77...
	 start solving instance: 4...
	 start solving instance: 7...
	 start solving instance: 106...
	 start solving instance: 147...
	 start solving instance: 69...
	 start solving instance: 81...
	 start solving instance: 57...
	 start solving instance: 117...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.966464007946109e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834454528.0
		 entropy bonus: 0.21152587234973907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880319488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6738670080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.966464007946109e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.966464007946109e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834454528.0
		 entropy bonus: 0.21152587234973907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880319488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6738670080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.966464007946109e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.966464007946109e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834454528.0
		 entropy bonus: 0.21152587234973907
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880319488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6738670080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.966464007946109e+18 - Differentiable computation graph = True!
PPO iteration: 630/1000:
	 start solving instance: 43...
	 start solving instance: 4...
	 start solving instance: 69...
	 start solving instance: 148...
	 start solving instance: 147...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 77...
	 start solving instance: 100...
	 start solving instance: 101...
	 start solving instance: 106...
	 start solving instance: 61...
	 start solving instance: 81...
	 start solving instance: 139...
	 start solving instance: 34...
	 start solving instance: 57...
	 start solving instance: 145...
	 start solving instance: 7...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.961246165565335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5837279232.0
		 entropy bonus: 0.20730172097682953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5924298752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6564520448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.961246275516498e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.961246165565335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5837279232.0
		 entropy bonus: 0.20730172097682953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5924298752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6564520448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.961246275516498e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.961246165565335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5837279232.0
		 entropy bonus: 0.20730172097682953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5924298752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6564520448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.961246275516498e+18 - Differentiable computation graph = True!
PPO iteration: 631/1000:
	 New training batch of size 20...
	 start solving instance: 119...
	 start solving instance: 86...
	 start solving instance: 18...
	 start solving instance: 35...
	 start solving instance: 75...
	 start solving instance: 150...
	 start solving instance: 117...
	 start solving instance: 138...
	 start solving instance: 55...
	 start solving instance: 84...
	 start solving instance: 20...
	 start solving instance: 2...
	 start solving instance: 85...
	 start solving instance: 125...
	 start solving instance: 93...
	 start solving instance: 66...
	 start solving instance: 47...
	 start solving instance: 127...
	 start solving instance: 25...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.037078602923744e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6104899584.0
		 entropy bonus: 0.2203487604856491
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6132176384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6751942656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037078767850488e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.037078602923744e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6104899584.0
		 entropy bonus: 0.2203487604856491
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6132176384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6751942656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037078767850488e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.037078602923744e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6104899584.0
		 entropy bonus: 0.2203487604856491
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6132176384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6751942656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.037078767850488e+18 - Differentiable computation graph = True!
PPO iteration: 632/1000:
	 start solving instance: 2...
	 start solving instance: 125...
	 start solving instance: 84...
	 start solving instance: 75...
	 start solving instance: 55...
	 start solving instance: 85...
	 start solving instance: 93...
	 start solving instance: 20...
	 start solving instance: 117...
	 start solving instance: 25...
	 start solving instance: 119...
	 start solving instance: 35...
	 start solving instance: 127...
	 start solving instance: 66...
	 start solving instance: 47...
	 start solving instance: 150...
	 start solving instance: 86...
	 start solving instance: 18...
	 start solving instance: 56...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.974324636475405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132654080.0
		 entropy bonus: 0.21674714982509613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6050594816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6930845184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9743246914509865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.974324636475405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132654080.0
		 entropy bonus: 0.21674714982509613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6050594816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6930845184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9743246914509865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.974324636475405e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132654080.0
		 entropy bonus: 0.21674714982509613
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6050594816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6930845184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9743246914509865e+18 - Differentiable computation graph = True!
PPO iteration: 633/1000:
	 start solving instance: 56...
	 start solving instance: 25...
	 start solving instance: 18...
	 start solving instance: 85...
	 start solving instance: 84...
	 start solving instance: 86...
	 start solving instance: 138...
	 start solving instance: 150...
	 start solving instance: 66...
	 start solving instance: 20...
	 start solving instance: 47...
	 start solving instance: 93...
	 start solving instance: 2...
	 start solving instance: 127...
	 start solving instance: 125...
	 start solving instance: 119...
	 start solving instance: 117...
	 start solving instance: 75...
	 start solving instance: 35...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3281382423960486e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201364480.0
		 entropy bonus: 0.2184508591890335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6434148864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7289577984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328138187420467e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3281382423960486e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201364480.0
		 entropy bonus: 0.2184508591890335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6434148864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7289577984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328138187420467e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3281382423960486e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201364480.0
		 entropy bonus: 0.2184508591890335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6434148864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7289577984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.328138187420467e+18 - Differentiable computation graph = True!
PPO iteration: 634/1000:
	 start solving instance: 119...
	 start solving instance: 18...
	 start solving instance: 86...
	 start solving instance: 138...
	 start solving instance: 25...
	 start solving instance: 85...
	 start solving instance: 84...
	 start solving instance: 117...
	 start solving instance: 47...
	 start solving instance: 56...
	 start solving instance: 55...
	 start solving instance: 20...
	 start solving instance: 66...
	 start solving instance: 35...
	 start solving instance: 125...
	 start solving instance: 127...
	 start solving instance: 93...
	 start solving instance: 150...
	 start solving instance: 2...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.23243455129117e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6128659968.0
		 entropy bonus: 0.21832187473773956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6394629632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7103915520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2324344963155886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.23243455129117e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6128659968.0
		 entropy bonus: 0.21832187473773956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6394629632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7103915520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2324344963155886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.23243455129117e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6128659968.0
		 entropy bonus: 0.21832187473773956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6394629632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7103915520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2324344963155886e+18 - Differentiable computation graph = True!
PPO iteration: 635/1000:
	 start solving instance: 150...
	 start solving instance: 56...
	 start solving instance: 119...
	 start solving instance: 86...
	 start solving instance: 85...
	 start solving instance: 75...
	 start solving instance: 2...
	 start solving instance: 138...
	 start solving instance: 66...
	 start solving instance: 20...
	 start solving instance: 47...
	 start solving instance: 25...
	 start solving instance: 125...
	 start solving instance: 127...
	 start solving instance: 93...
	 start solving instance: 55...
	 start solving instance: 18...
	 start solving instance: 117...
	 start solving instance: 35...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.142625561925124e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6090095104.0
		 entropy bonus: 0.21372750401496887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6216034816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6715788288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.142625561925124e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.142625561925124e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6090095104.0
		 entropy bonus: 0.21372750401496887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6216034816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6715788288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.142625561925124e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.142625561925124e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6090095104.0
		 entropy bonus: 0.21372750401496887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6216034816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6715788288.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.142625561925124e+18 - Differentiable computation graph = True!
PPO iteration: 636/1000:
	 start solving instance: 20...
	 start solving instance: 84...
	 start solving instance: 25...
	 start solving instance: 127...
	 start solving instance: 47...
	 start solving instance: 66...
	 start solving instance: 86...
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 119...
	 start solving instance: 85...
	 start solving instance: 18...
	 start solving instance: 117...
	 start solving instance: 150...
	 start solving instance: 55...
	 start solving instance: 75...
	 start solving instance: 93...
	 start solving instance: 138...
	 start solving instance: 2...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.015041311270555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6047453696.0
		 entropy bonus: 0.21027135848999023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6088275968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6893717504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0150412562949734e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.015041311270555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6047453696.0
		 entropy bonus: 0.21027135848999023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6088275968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6893717504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0150412562949734e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.015041311270555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6047453696.0
		 entropy bonus: 0.21027135848999023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6088275968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6893717504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0150412562949734e+18 - Differentiable computation graph = True!
PPO iteration: 637/1000:
	 start solving instance: 86...
	 start solving instance: 55...
	 start solving instance: 25...
	 start solving instance: 20...
	 start solving instance: 125...
	 start solving instance: 150...
	 start solving instance: 85...
	 start solving instance: 127...
	 start solving instance: 66...
	 start solving instance: 119...
	 start solving instance: 18...
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 117...
	 start solving instance: 84...
	 start solving instance: 93...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 47...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.162598410546001e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142962688.0
		 entropy bonus: 0.21743054687976837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6260957696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6946386432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.162598465521582e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.162598410546001e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142962688.0
		 entropy bonus: 0.21743054687976837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6260957696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6946386432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.162598465521582e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.162598410546001e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142962688.0
		 entropy bonus: 0.21743054687976837
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6260957696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6946386432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.162598465521582e+18 - Differentiable computation graph = True!
PPO iteration: 638/1000:
	 start solving instance: 47...
	 start solving instance: 55...
	 start solving instance: 35...
	 start solving instance: 84...
	 start solving instance: 125...
	 start solving instance: 86...
	 start solving instance: 119...
	 start solving instance: 127...
	 start solving instance: 138...
	 start solving instance: 75...
	 start solving instance: 2...
	 start solving instance: 20...
	 start solving instance: 93...
	 start solving instance: 85...
	 start solving instance: 117...
	 start solving instance: 18...
	 start solving instance: 150...
	 start solving instance: 66...
	 start solving instance: 25...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.777068292210531e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5999009792.0
		 entropy bonus: 0.21442842483520508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880776192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6522301440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.777068457137275e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.777068292210531e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5999009792.0
		 entropy bonus: 0.21442842483520508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880776192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6522301440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.777068457137275e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.777068292210531e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5999009792.0
		 entropy bonus: 0.21442842483520508
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880776192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6522301440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.777068457137275e+18 - Differentiable computation graph = True!
PPO iteration: 639/1000:
	 start solving instance: 47...
	 start solving instance: 93...
	 start solving instance: 119...
	 start solving instance: 84...
	 start solving instance: 85...
	 start solving instance: 18...
	 start solving instance: 127...
	 start solving instance: 117...
	 start solving instance: 125...
	 start solving instance: 66...
	 start solving instance: 75...
	 start solving instance: 35...
	 start solving instance: 86...
	 start solving instance: 20...
	 start solving instance: 56...
	 start solving instance: 138...
	 start solving instance: 25...
	 start solving instance: 150...
	 start solving instance: 2...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.89503973260578e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022514176.0
		 entropy bonus: 0.20664165914058685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5949737472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7068969472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.89503973260578e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.89503973260578e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022514176.0
		 entropy bonus: 0.20664165914058685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5949737472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7068969472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.89503973260578e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.89503973260578e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022514176.0
		 entropy bonus: 0.20664165914058685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5949737472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7068969472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.89503973260578e+18 - Differentiable computation graph = True!
PPO iteration: 640/1000:
	 start solving instance: 47...
	 start solving instance: 125...
	 start solving instance: 86...
	 start solving instance: 93...
	 start solving instance: 127...
	 start solving instance: 85...
	 start solving instance: 25...
	 start solving instance: 75...
	 start solving instance: 117...
	 start solving instance: 56...
	 start solving instance: 55...
	 start solving instance: 2...
	 start solving instance: 20...
	 start solving instance: 66...
	 start solving instance: 150...
	 start solving instance: 35...
	 start solving instance: 119...
	 start solving instance: 84...
	 start solving instance: 138...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.91503765009177e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5962647552.0
		 entropy bonus: 0.2060966044664383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5978014720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774797824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.91503765009177e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.91503765009177e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5962647552.0
		 entropy bonus: 0.2060966044664383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5978014720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774797824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.91503765009177e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.91503765009177e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5962647552.0
		 entropy bonus: 0.2060966044664383
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5978014720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6774797824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.91503765009177e+18 - Differentiable computation graph = True!
PPO iteration: 641/1000:
	 New training batch of size 20...
	 start solving instance: 5...
	 start solving instance: 61...
	 start solving instance: 21...
	 start solving instance: 136...
	 start solving instance: 53...
	 start solving instance: 100...
	 start solving instance: 24...
	 start solving instance: 137...
	 start solving instance: 146...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 150...
	 start solving instance: 64...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 133...
	 start solving instance: 57...
	 start solving instance: 111...
	 start solving instance: 63...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.964370098002172e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5817286656.0
		 entropy bonus: 0.21535658836364746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6087779840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6868371456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9643702629289165e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.964370098002172e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5817286656.0
		 entropy bonus: 0.21535658836364746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6087779840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6868371456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9643702629289165e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.964370098002172e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5817286656.0
		 entropy bonus: 0.21535658836364746
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6087779840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6868371456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9643702629289165e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.837852925331715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5102383104.0
		 entropy bonus: 0.20497320592403412
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5010943488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5878594560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2837852980307296256.0000
PPO iteration: 642/1000:
	 start solving instance: 21...
	 start solving instance: 133...
	 start solving instance: 5...
	 start solving instance: 136...
	 start solving instance: 64...
	 start solving instance: 100...
	 start solving instance: 150...
	 start solving instance: 113...
	 start solving instance: 61...
	 start solving instance: 137...
	 start solving instance: 63...
	 start solving instance: 53...
	 start solving instance: 24...
	 start solving instance: 54...
	 start solving instance: 146...
	 start solving instance: 111...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 147...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0062241076250935e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5831505920.0
		 entropy bonus: 0.21887627243995667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6046303744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836629504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0062242725518377e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0062241076250935e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5831505920.0
		 entropy bonus: 0.21887627243995667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6046303744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836629504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0062242725518377e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0062241076250935e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5831505920.0
		 entropy bonus: 0.21887627243995667
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6046303744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6836629504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0062242725518377e+18 - Differentiable computation graph = True!
PPO iteration: 643/1000:
	 start solving instance: 24...
	 start solving instance: 100...
	 start solving instance: 53...
	 start solving instance: 57...
	 start solving instance: 150...
	 start solving instance: 61...
	 start solving instance: 111...
	 start solving instance: 63...
	 start solving instance: 146...
	 start solving instance: 136...
	 start solving instance: 5...
	 start solving instance: 64...
	 start solving instance: 147...
	 start solving instance: 137...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 21...
	 start solving instance: 113...
	 start solving instance: 133...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.019200543856106e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5723282944.0
		 entropy bonus: 0.22279439866542816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6157805568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6944363520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.01920070878285e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.019200543856106e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5723282944.0
		 entropy bonus: 0.22279439866542816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6157805568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6944363520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.01920070878285e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.019200543856106e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5723282944.0
		 entropy bonus: 0.22279439866542816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6157805568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6944363520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.01920070878285e+18 - Differentiable computation graph = True!
PPO iteration: 644/1000:
	 start solving instance: 137...
	 start solving instance: 133...
	 start solving instance: 5...
	 start solving instance: 63...
	 start solving instance: 113...
	 start solving instance: 54...
	 start solving instance: 61...
	 start solving instance: 136...
	 start solving instance: 147...
	 start solving instance: 150...
	 start solving instance: 43...
	 start solving instance: 21...
	 start solving instance: 111...
	 start solving instance: 57...
	 start solving instance: 4...
	 start solving instance: 146...
	 start solving instance: 24...
	 start solving instance: 53...
	 start solving instance: 100...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.819077992679945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5730817536.0
		 entropy bonus: 0.22269617021083832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974190592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624359424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8190780476555264e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.819077992679945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5730817536.0
		 entropy bonus: 0.22269617021083832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974190592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624359424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8190780476555264e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.819077992679945e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5730817536.0
		 entropy bonus: 0.22269617021083832
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974190592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624359424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8190780476555264e+18 - Differentiable computation graph = True!
PPO iteration: 645/1000:
	 start solving instance: 63...
	 start solving instance: 43...
	 start solving instance: 57...
	 start solving instance: 5...
	 start solving instance: 111...
	 start solving instance: 150...
	 start solving instance: 133...
	 start solving instance: 54...
	 start solving instance: 61...
	 start solving instance: 100...
	 start solving instance: 137...
	 start solving instance: 113...
	 start solving instance: 146...
	 start solving instance: 136...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 64...
	 start solving instance: 24...
	 start solving instance: 4...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.032147513175494e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5765297664.0
		 entropy bonus: 0.22149591147899628
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6158552576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6912625664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0321474581999124e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.032147513175494e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5765297664.0
		 entropy bonus: 0.22149591147899628
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6158552576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6912625664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0321474581999124e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.032147513175494e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5765297664.0
		 entropy bonus: 0.22149591147899628
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6158552576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6912625664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0321474581999124e+18 - Differentiable computation graph = True!
PPO iteration: 646/1000:
	 start solving instance: 61...
	 start solving instance: 137...
	 start solving instance: 53...
	 start solving instance: 5...
	 start solving instance: 24...
	 start solving instance: 150...
	 start solving instance: 146...
	 start solving instance: 64...
	 start solving instance: 4...
	 start solving instance: 136...
	 start solving instance: 63...
	 start solving instance: 43...
	 start solving instance: 54...
	 start solving instance: 100...
	 start solving instance: 113...
	 start solving instance: 57...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 133...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.079738334667499e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738621440.0
		 entropy bonus: 0.21783919632434845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198737920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926466048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.079738444618662e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.079738334667499e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738621440.0
		 entropy bonus: 0.21783919632434845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198737920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926466048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.079738444618662e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.079738334667499e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738621440.0
		 entropy bonus: 0.21783919632434845
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198737920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6926466048.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.079738444618662e+18 - Differentiable computation graph = True!
PPO iteration: 647/1000:
	 start solving instance: 136...
	 start solving instance: 54...
	 start solving instance: 64...
	 start solving instance: 61...
	 start solving instance: 63...
	 start solving instance: 57...
	 start solving instance: 111...
	 start solving instance: 147...
	 start solving instance: 5...
	 start solving instance: 53...
	 start solving instance: 4...
	 start solving instance: 21...
	 start solving instance: 133...
	 start solving instance: 137...
	 start solving instance: 100...
	 start solving instance: 146...
	 start solving instance: 43...
	 start solving instance: 24...
	 start solving instance: 113...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.739617606754527e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5685090816.0
		 entropy bonus: 0.22096402943134308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5914812416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6405044736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7396177167056896e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.739617606754527e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5685090816.0
		 entropy bonus: 0.22096402943134308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5914812416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6405044736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7396177167056896e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.739617606754527e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5685090816.0
		 entropy bonus: 0.22096402943134308
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5914812416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6405044736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7396177167056896e+18 - Differentiable computation graph = True!
PPO iteration: 648/1000:
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 61...
	 start solving instance: 146...
	 start solving instance: 137...
	 start solving instance: 133...
	 start solving instance: 64...
	 start solving instance: 63...
	 start solving instance: 111...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 150...
	 start solving instance: 21...
	 start solving instance: 24...
	 start solving instance: 53...
	 start solving instance: 136...
	 start solving instance: 113...
	 start solving instance: 57...
	 start solving instance: 100...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5280489196308922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5740142080.0
		 entropy bonus: 0.20927293598651886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5706407424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6468978176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.528048864655311e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5280489196308922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5740142080.0
		 entropy bonus: 0.20927293598651886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5706407424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6468978176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.528048864655311e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5280489196308922e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5740142080.0
		 entropy bonus: 0.20927293598651886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5706407424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6468978176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.528048864655311e+18 - Differentiable computation graph = True!
PPO iteration: 649/1000:
	 start solving instance: 5...
	 start solving instance: 100...
	 start solving instance: 137...
	 start solving instance: 150...
	 start solving instance: 64...
	 start solving instance: 133...
	 start solving instance: 146...
	 start solving instance: 21...
	 start solving instance: 4...
	 start solving instance: 43...
	 start solving instance: 53...
	 start solving instance: 24...
	 start solving instance: 57...
	 start solving instance: 113...
	 start solving instance: 111...
	 start solving instance: 63...
	 start solving instance: 136...
	 start solving instance: 61...
	 start solving instance: 54...
	 start solving instance: 147...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.822582795944644e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5744612352.0
		 entropy bonus: 0.21135841310024261
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5986625024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6874447360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8225827409690624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.822582795944644e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5744612352.0
		 entropy bonus: 0.21135841310024261
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5986625024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6874447360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8225827409690624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.822582795944644e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5744612352.0
		 entropy bonus: 0.21135841310024261
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5986625024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6874447360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8225827409690624e+18 - Differentiable computation graph = True!
PPO iteration: 650/1000:
	 start solving instance: 100...
	 start solving instance: 43...
	 start solving instance: 146...
	 start solving instance: 63...
	 start solving instance: 53...
	 start solving instance: 137...
	 start solving instance: 136...
	 start solving instance: 21...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 54...
	 start solving instance: 64...
	 start solving instance: 5...
	 start solving instance: 111...
	 start solving instance: 24...
	 start solving instance: 113...
	 start solving instance: 133...
	 start solving instance: 57...
	 start solving instance: 150...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.693234488834471e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5777183744.0
		 entropy bonus: 0.20822763442993164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922757632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6786364416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.693234543810052e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.693234488834471e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5777183744.0
		 entropy bonus: 0.20822763442993164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922757632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6786364416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.693234543810052e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.693234488834471e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5777183744.0
		 entropy bonus: 0.20822763442993164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5922757632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6786364416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.693234543810052e+18 - Differentiable computation graph = True!
PPO iteration: 651/1000:
	 New training batch of size 20...
	 start solving instance: 59...
	 start solving instance: 104...
	 start solving instance: 55...
	 start solving instance: 29...
	 start solving instance: 140...
	 start solving instance: 150...
	 start solving instance: 39...
	 start solving instance: 101...
	 start solving instance: 106...
	 start solving instance: 9...
	 start solving instance: 24...
	 start solving instance: 49...
	 start solving instance: 50...
	 start solving instance: 19...
	 start solving instance: 138...
	 start solving instance: 100...
	 start solving instance: 32...
	 start solving instance: 125...
	 start solving instance: 139...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.318597999904162e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6148353536.0
		 entropy bonus: 0.21532678604125977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6222180864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6731153408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.318597999904162e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.318597999904162e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6148353536.0
		 entropy bonus: 0.21532678604125977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6222180864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6731153408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.318597999904162e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.318597999904162e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6148353536.0
		 entropy bonus: 0.21532678604125977
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6222180864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6731153408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.318597999904162e+18 - Differentiable computation graph = True!
PPO iteration: 652/1000:
	 start solving instance: 140...
	 start solving instance: 39...
	 start solving instance: 50...
	 start solving instance: 55...
	 start solving instance: 59...
	 start solving instance: 49...
	 start solving instance: 108...
	 start solving instance: 139...
	 start solving instance: 104...
	 start solving instance: 150...
	 start solving instance: 29...
	 start solving instance: 19...
	 start solving instance: 32...
	 start solving instance: 9...
	 start solving instance: 100...
	 start solving instance: 138...
	 start solving instance: 125...
	 start solving instance: 101...
	 start solving instance: 24...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.330829846860844e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6196141056.0
		 entropy bonus: 0.217393159866333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6277035520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7073884672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.330829791885263e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.330829846860844e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6196141056.0
		 entropy bonus: 0.217393159866333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6277035520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7073884672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.330829791885263e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.330829846860844e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6196141056.0
		 entropy bonus: 0.217393159866333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6277035520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7073884672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.330829791885263e+18 - Differentiable computation graph = True!
PPO iteration: 653/1000:
	 start solving instance: 24...
	 start solving instance: 125...
	 start solving instance: 106...
	 start solving instance: 55...
	 start solving instance: 49...
	 start solving instance: 140...
	 start solving instance: 108...
	 start solving instance: 150...
	 start solving instance: 29...
	 start solving instance: 138...
	 start solving instance: 39...
	 start solving instance: 100...
	 start solving instance: 139...
	 start solving instance: 19...
	 start solving instance: 50...
	 start solving instance: 101...
	 start solving instance: 104...
	 start solving instance: 59...
	 start solving instance: 9...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.353727836216256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6157637120.0
		 entropy bonus: 0.22943221032619476
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6234385920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7151892480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.353727946167419e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.353727836216256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6157637120.0
		 entropy bonus: 0.22943221032619476
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6234385920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7151892480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.353727946167419e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.353727836216256e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6157637120.0
		 entropy bonus: 0.22943221032619476
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6234385920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7151892480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.353727946167419e+18 - Differentiable computation graph = True!
PPO iteration: 654/1000:
	 start solving instance: 138...
	 start solving instance: 139...
	 start solving instance: 100...
	 start solving instance: 125...
	 start solving instance: 32...
	 start solving instance: 55...
	 start solving instance: 50...
	 start solving instance: 29...
	 start solving instance: 104...
	 start solving instance: 101...
	 start solving instance: 150...
	 start solving instance: 59...
	 start solving instance: 106...
	 start solving instance: 49...
	 start solving instance: 39...
	 start solving instance: 24...
	 start solving instance: 140...
	 start solving instance: 108...
	 start solving instance: 19...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.131447047107851e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6127450624.0
		 entropy bonus: 0.21693789958953857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6087861248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6803175424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1314471020834324e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.131447047107851e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6127450624.0
		 entropy bonus: 0.21693789958953857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6087861248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6803175424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1314471020834324e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.131447047107851e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6127450624.0
		 entropy bonus: 0.21693789958953857
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6087861248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6803175424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1314471020834324e+18 - Differentiable computation graph = True!
PPO iteration: 655/1000:
	 start solving instance: 49...
	 start solving instance: 39...
	 start solving instance: 9...
	 start solving instance: 139...
	 start solving instance: 29...
	 start solving instance: 108...
	 start solving instance: 50...
	 start solving instance: 150...
	 start solving instance: 100...
	 start solving instance: 101...
	 start solving instance: 19...
	 start solving instance: 140...
	 start solving instance: 138...
	 start solving instance: 24...
	 start solving instance: 59...
	 start solving instance: 125...
	 start solving instance: 32...
	 start solving instance: 104...
	 start solving instance: 106...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.129753799201076e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231801856.0
		 entropy bonus: 0.2137133628129959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156509184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6956385792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1297538541766574e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.129753799201076e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231801856.0
		 entropy bonus: 0.2137133628129959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156509184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6956385792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1297538541766574e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.129753799201076e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6231801856.0
		 entropy bonus: 0.2137133628129959
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156509184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6956385792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1297538541766574e+18 - Differentiable computation graph = True!
PPO iteration: 656/1000:
	 start solving instance: 32...
	 start solving instance: 49...
	 start solving instance: 19...
	 start solving instance: 108...
	 start solving instance: 39...
	 start solving instance: 140...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 125...
	 start solving instance: 101...
	 start solving instance: 106...
	 start solving instance: 104...
	 start solving instance: 50...
	 start solving instance: 9...
	 start solving instance: 24...
	 start solving instance: 139...
	 start solving instance: 100...
	 start solving instance: 29...
	 start solving instance: 55...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.038377346058473e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6118589952.0
		 entropy bonus: 0.21700595319271088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6094364160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6734311936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0383772910828913e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.038377346058473e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6118589952.0
		 entropy bonus: 0.21700595319271088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6094364160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6734311936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0383772910828913e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.038377346058473e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6118589952.0
		 entropy bonus: 0.21700595319271088
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6094364160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6734311936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0383772910828913e+18 - Differentiable computation graph = True!
PPO iteration: 657/1000:
	 start solving instance: 125...
	 start solving instance: 100...
	 start solving instance: 59...
	 start solving instance: 140...
	 start solving instance: 150...
	 start solving instance: 29...
	 start solving instance: 138...
	 start solving instance: 106...
	 start solving instance: 39...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 50...
	 start solving instance: 24...
	 start solving instance: 104...
	 start solving instance: 9...
	 start solving instance: 101...
	 start solving instance: 55...
	 start solving instance: 19...
	 start solving instance: 32...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.030490769054761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6141891584.0
		 entropy bonus: 0.22011148929595947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934876160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6765213696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.030490769054761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.030490769054761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6141891584.0
		 entropy bonus: 0.22011148929595947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934876160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6765213696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.030490769054761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.030490769054761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6141891584.0
		 entropy bonus: 0.22011148929595947
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5934876160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6765213696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.030490769054761e+18 - Differentiable computation graph = True!
PPO iteration: 658/1000:
	 start solving instance: 50...
	 start solving instance: 100...
	 start solving instance: 49...
	 start solving instance: 55...
	 start solving instance: 39...
	 start solving instance: 125...
	 start solving instance: 29...
	 start solving instance: 32...
	 start solving instance: 139...
	 start solving instance: 150...
	 start solving instance: 19...
	 start solving instance: 140...
	 start solving instance: 59...
	 start solving instance: 104...
	 start solving instance: 9...
	 start solving instance: 24...
	 start solving instance: 108...
	 start solving instance: 138...
	 start solving instance: 101...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.972526275257015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6185067520.0
		 entropy bonus: 0.2128903865814209
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5965196288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6337852416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.972526440183759e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.972526275257015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6185067520.0
		 entropy bonus: 0.2128903865814209
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5965196288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6337852416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.972526440183759e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.972526275257015e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6185067520.0
		 entropy bonus: 0.2128903865814209
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5965196288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6337852416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.972526440183759e+18 - Differentiable computation graph = True!
PPO iteration: 659/1000:
	 start solving instance: 125...
	 start solving instance: 138...
	 start solving instance: 55...
	 start solving instance: 9...
	 start solving instance: 19...
	 start solving instance: 32...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 39...
	 start solving instance: 59...
	 start solving instance: 29...
	 start solving instance: 49...
	 start solving instance: 104...
	 start solving instance: 50...
	 start solving instance: 108...
	 start solving instance: 139...
	 start solving instance: 106...
	 start solving instance: 150...
	 start solving instance: 24...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.023026844320766e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167244800.0
		 entropy bonus: 0.21127577126026154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5981083136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6467616768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0230270092475105e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.023026844320766e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167244800.0
		 entropy bonus: 0.21127577126026154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5981083136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6467616768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0230270092475105e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.023026844320766e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6167244800.0
		 entropy bonus: 0.21127577126026154
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5981083136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6467616768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0230270092475105e+18 - Differentiable computation graph = True!
PPO iteration: 660/1000:
	 start solving instance: 55...
	 start solving instance: 101...
	 start solving instance: 106...
	 start solving instance: 32...
	 start solving instance: 139...
	 start solving instance: 50...
	 start solving instance: 29...
	 start solving instance: 9...
	 start solving instance: 150...
	 start solving instance: 125...
	 start solving instance: 39...
	 start solving instance: 59...
	 start solving instance: 19...
	 start solving instance: 104...
	 start solving instance: 108...
	 start solving instance: 100...
	 start solving instance: 24...
	 start solving instance: 140...
	 start solving instance: 138...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0211708686930805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6104509440.0
		 entropy bonus: 0.2138621062040329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6020450816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6516196352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0211710336198246e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0211708686930805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6104509440.0
		 entropy bonus: 0.2138621062040329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6020450816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6516196352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0211710336198246e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0211708686930805e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6104509440.0
		 entropy bonus: 0.2138621062040329
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6020450816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6516196352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0211710336198246e+18 - Differentiable computation graph = True!
PPO iteration: 661/1000:
	 New training batch of size 20...
	 start solving instance: 87...
	 start solving instance: 148...
	 start solving instance: 91...
	 start solving instance: 35...
	 start solving instance: 26...
	 start solving instance: 120...
	 start solving instance: 149...
	 start solving instance: 106...
	 start solving instance: 107...
	 start solving instance: 9...
	 start solving instance: 85...
	 start solving instance: 29...
	 start solving instance: 117...
	 start solving instance: 60...
	 start solving instance: 116...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4239179117037617e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5529517568.0
		 entropy bonus: 0.20096945762634277
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5431928320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6121949184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.423917966679343e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4239179117037617e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5529517568.0
		 entropy bonus: 0.20096945762634277
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5431928320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6121949184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.423917966679343e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4239179117037617e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5529517568.0
		 entropy bonus: 0.20096945762634277
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5431928320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6121949184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.423917966679343e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.759126133564349e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5251556352.0
		 entropy bonus: 0.20027752220630646
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4830504448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5920608768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2759126298491092992.0000
PPO iteration: 662/1000:
	 start solving instance: 149...
	 start solving instance: 106...
	 start solving instance: 26...
	 start solving instance: 87...
	 start solving instance: 29...
	 start solving instance: 107...
	 start solving instance: 35...
	 start solving instance: 60...
	 start solving instance: 120...
	 start solving instance: 89...
	 start solving instance: 52...
	 start solving instance: 118...
	 start solving instance: 9...
	 start solving instance: 148...
	 start solving instance: 144...
	 start solving instance: 137...
	 start solving instance: 91...
	 start solving instance: 116...
	 start solving instance: 85...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.716955792496761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5693478400.0
		 entropy bonus: 0.20651474595069885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723718656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6276054528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7169559574235054e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.716955792496761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5693478400.0
		 entropy bonus: 0.20651474595069885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723718656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6276054528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7169559574235054e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.716955792496761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5693478400.0
		 entropy bonus: 0.20651474595069885
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723718656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6276054528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7169559574235054e+18 - Differentiable computation graph = True!
PPO iteration: 663/1000:
	 start solving instance: 91...
	 start solving instance: 60...
	 start solving instance: 107...
	 start solving instance: 35...
	 start solving instance: 29...
	 start solving instance: 89...
	 start solving instance: 120...
	 start solving instance: 26...
	 start solving instance: 87...
	 start solving instance: 137...
	 start solving instance: 106...
	 start solving instance: 149...
	 start solving instance: 116...
	 start solving instance: 9...
	 start solving instance: 52...
	 start solving instance: 148...
	 start solving instance: 117...
	 start solving instance: 118...
	 start solving instance: 85...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6891223153465885e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5806210560.0
		 entropy bonus: 0.20472252368927002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5656022016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6563896320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.68912237032217e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6891223153465885e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5806210560.0
		 entropy bonus: 0.20472252368927002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5656022016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6563896320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.68912237032217e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6891223153465885e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5806210560.0
		 entropy bonus: 0.20472252368927002
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5656022016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6563896320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.68912237032217e+18 - Differentiable computation graph = True!
PPO iteration: 664/1000:
	 start solving instance: 149...
	 start solving instance: 148...
	 start solving instance: 85...
	 start solving instance: 26...
	 start solving instance: 35...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 118...
	 start solving instance: 144...
	 start solving instance: 89...
	 start solving instance: 87...
	 start solving instance: 117...
	 start solving instance: 60...
	 start solving instance: 91...
	 start solving instance: 106...
	 start solving instance: 9...
	 start solving instance: 52...
	 start solving instance: 137...
	 start solving instance: 120...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6680693065025847e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5694042624.0
		 entropy bonus: 0.19888585805892944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5680954880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6414851072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.668069471429329e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6680693065025847e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5694042624.0
		 entropy bonus: 0.19888585805892944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5680954880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6414851072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.668069471429329e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6680693065025847e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5694042624.0
		 entropy bonus: 0.19888585805892944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5680954880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6414851072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.668069471429329e+18 - Differentiable computation graph = True!
PPO iteration: 665/1000:
	 start solving instance: 107...
	 start solving instance: 52...
	 start solving instance: 89...
	 start solving instance: 60...
	 start solving instance: 149...
	 start solving instance: 35...
	 start solving instance: 85...
	 start solving instance: 148...
	 start solving instance: 29...
	 start solving instance: 137...
	 start solving instance: 106...
	 start solving instance: 118...
	 start solving instance: 9...
	 start solving instance: 116...
	 start solving instance: 120...
	 start solving instance: 91...
	 start solving instance: 26...
	 start solving instance: 87...
	 start solving instance: 117...
	 start solving instance: 144...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4512737610028286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5608001024.0
		 entropy bonus: 0.21074938774108887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5366373888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6240658944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.45127381597841e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4512737610028286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5608001024.0
		 entropy bonus: 0.21074938774108887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5366373888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6240658944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.45127381597841e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4512737610028286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5608001024.0
		 entropy bonus: 0.21074938774108887
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5366373888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6240658944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.45127381597841e+18 - Differentiable computation graph = True!
PPO iteration: 666/1000:
	 start solving instance: 149...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 60...
	 start solving instance: 120...
	 start solving instance: 35...
	 start solving instance: 29...
	 start solving instance: 137...
	 start solving instance: 107...
	 start solving instance: 87...
	 start solving instance: 148...
	 start solving instance: 106...
	 start solving instance: 117...
	 start solving instance: 26...
	 start solving instance: 85...
	 start solving instance: 144...
	 start solving instance: 91...
	 start solving instance: 9...
	 start solving instance: 89...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.537217966997242e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5640673792.0
		 entropy bonus: 0.2171381562948227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5617389056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6005059072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.537217966997242e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.537217966997242e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5640673792.0
		 entropy bonus: 0.2171381562948227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5617389056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6005059072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.537217966997242e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.537217966997242e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5640673792.0
		 entropy bonus: 0.2171381562948227
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5617389056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6005059072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.537217966997242e+18 - Differentiable computation graph = True!
PPO iteration: 667/1000:
	 start solving instance: 35...
	 start solving instance: 116...
	 start solving instance: 107...
	 start solving instance: 60...
	 start solving instance: 117...
	 start solving instance: 91...
	 start solving instance: 89...
	 start solving instance: 9...
	 start solving instance: 149...
	 start solving instance: 118...
	 start solving instance: 52...
	 start solving instance: 106...
	 start solving instance: 137...
	 start solving instance: 144...
	 start solving instance: 87...
	 start solving instance: 29...
	 start solving instance: 120...
	 start solving instance: 85...
	 start solving instance: 26...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4225133955504407e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5651084800.0
		 entropy bonus: 0.19829979538917542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5383020032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6191408640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4225133405748593e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4225133955504407e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5651084800.0
		 entropy bonus: 0.19829979538917542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5383020032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6191408640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4225133405748593e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4225133955504407e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5651084800.0
		 entropy bonus: 0.19829979538917542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5383020032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6191408640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4225133405748593e+18 - Differentiable computation graph = True!
PPO iteration: 668/1000:
	 start solving instance: 144...
	 start solving instance: 87...
	 start solving instance: 137...
	 start solving instance: 85...
	 start solving instance: 149...
	 start solving instance: 106...
	 start solving instance: 26...
	 start solving instance: 35...
	 start solving instance: 9...
	 start solving instance: 120...
	 start solving instance: 107...
	 start solving instance: 116...
	 start solving instance: 52...
	 start solving instance: 117...
	 start solving instance: 60...
	 start solving instance: 91...
	 start solving instance: 118...
	 start solving instance: 89...
	 start solving instance: 29...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.676991403557336e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5674446336.0
		 entropy bonus: 0.20464101433753967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5724890624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6525684224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676991458532917e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.676991403557336e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5674446336.0
		 entropy bonus: 0.20464101433753967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5724890624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6525684224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676991458532917e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.676991403557336e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5674446336.0
		 entropy bonus: 0.20464101433753967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5724890624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6525684224.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676991458532917e+18 - Differentiable computation graph = True!
PPO iteration: 669/1000:
	 start solving instance: 60...
	 start solving instance: 137...
	 start solving instance: 149...
	 start solving instance: 116...
	 start solving instance: 118...
	 start solving instance: 85...
	 start solving instance: 52...
	 start solving instance: 117...
	 start solving instance: 91...
	 start solving instance: 144...
	 start solving instance: 35...
	 start solving instance: 120...
	 start solving instance: 107...
	 start solving instance: 29...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 106...
	 start solving instance: 9...
	 start solving instance: 26...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4398500550925615e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5612201984.0
		 entropy bonus: 0.19712181389331818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5454659584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6076054528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4398501650437243e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4398500550925615e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5612201984.0
		 entropy bonus: 0.19712181389331818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5454659584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6076054528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4398501650437243e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4398500550925615e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5612201984.0
		 entropy bonus: 0.19712181389331818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5454659584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6076054528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4398501650437243e+18 - Differentiable computation graph = True!
PPO iteration: 670/1000:
	 start solving instance: 35...
	 start solving instance: 91...
	 start solving instance: 120...
	 start solving instance: 106...
	 start solving instance: 107...
	 start solving instance: 148...
	 start solving instance: 9...
	 start solving instance: 137...
	 start solving instance: 89...
	 start solving instance: 117...
	 start solving instance: 52...
	 start solving instance: 87...
	 start solving instance: 144...
	 start solving instance: 85...
	 start solving instance: 118...
	 start solving instance: 26...
	 start solving instance: 149...
	 start solving instance: 116...
	 start solving instance: 60...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5737650737975394e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5611106304.0
		 entropy bonus: 0.2120349407196045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593560064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504536576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.573765183748702e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5737650737975394e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5611106304.0
		 entropy bonus: 0.2120349407196045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593560064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504536576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.573765183748702e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5737650737975394e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5611106304.0
		 entropy bonus: 0.2120349407196045
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593560064.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6504536576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.573765183748702e+18 - Differentiable computation graph = True!
PPO iteration: 671/1000:
	 New training batch of size 20...
	 start solving instance: 60...
	 start solving instance: 148...
	 start solving instance: 79...
	 start solving instance: 121...
	 start solving instance: 143...
	 start solving instance: 44...
	 start solving instance: 68...
	 start solving instance: 82...
	 start solving instance: 136...
	 start solving instance: 99...
	 start solving instance: 114...
	 start solving instance: 83...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 17...
	 start solving instance: 14...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 78...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.901506180391056e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6025219072.0
		 entropy bonus: 0.21182571351528168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970029568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509739008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9015062353666376e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.901506180391056e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6025219072.0
		 entropy bonus: 0.21182571351528168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970029568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509739008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9015062353666376e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.901506180391056e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6025219072.0
		 entropy bonus: 0.21182571351528168
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970029568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509739008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9015062353666376e+18 - Differentiable computation graph = True!
PPO iteration: 672/1000:
	 start solving instance: 78...
	 start solving instance: 54...
	 start solving instance: 114...
	 start solving instance: 79...
	 start solving instance: 83...
	 start solving instance: 17...
	 start solving instance: 44...
	 start solving instance: 143...
	 start solving instance: 14...
	 start solving instance: 75...
	 start solving instance: 99...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 82...
	 start solving instance: 60...
	 start solving instance: 136...
	 start solving instance: 68...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.76593815590488e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6010416640.0
		 entropy bonus: 0.2046135663986206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850978816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6613345280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7659381009292984e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.76593815590488e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6010416640.0
		 entropy bonus: 0.2046135663986206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850978816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6613345280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7659381009292984e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.76593815590488e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6010416640.0
		 entropy bonus: 0.2046135663986206
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5850978816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6613345280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7659381009292984e+18 - Differentiable computation graph = True!
PPO iteration: 673/1000:
	 start solving instance: 54...
	 start solving instance: 121...
	 start solving instance: 83...
	 start solving instance: 136...
	 start solving instance: 99...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 68...
	 start solving instance: 45...
	 start solving instance: 14...
	 start solving instance: 79...
	 start solving instance: 143...
	 start solving instance: 75...
	 start solving instance: 82...
	 start solving instance: 114...
	 start solving instance: 78...
	 start solving instance: 60...
	 start solving instance: 17...
	 start solving instance: 44...
	 start solving instance: 73...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.967975176727324e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079638016.0
		 entropy bonus: 0.20669253170490265
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032597504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6705628672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.967975286678487e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.967975176727324e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079638016.0
		 entropy bonus: 0.20669253170490265
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032597504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6705628672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.967975286678487e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.967975176727324e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079638016.0
		 entropy bonus: 0.20669253170490265
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6032597504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6705628672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.967975286678487e+18 - Differentiable computation graph = True!
PPO iteration: 674/1000:
	 start solving instance: 45...
	 start solving instance: 143...
	 start solving instance: 17...
	 start solving instance: 75...
	 start solving instance: 136...
	 start solving instance: 79...
	 start solving instance: 148...
	 start solving instance: 44...
	 start solving instance: 82...
	 start solving instance: 114...
	 start solving instance: 78...
	 start solving instance: 83...
	 start solving instance: 105...
	 start solving instance: 68...
	 start solving instance: 60...
	 start solving instance: 121...
	 start solving instance: 54...
	 start solving instance: 99...
	 start solving instance: 73...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.893931424884982e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6005889024.0
		 entropy bonus: 0.21069736778736115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5948983296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6594817024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.893931424884982e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.893931424884982e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6005889024.0
		 entropy bonus: 0.21069736778736115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5948983296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6594817024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.893931424884982e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.893931424884982e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6005889024.0
		 entropy bonus: 0.21069736778736115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5948983296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6594817024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.893931424884982e+18 - Differentiable computation graph = True!
PPO iteration: 675/1000:
	 start solving instance: 60...
	 start solving instance: 44...
	 start solving instance: 73...
	 start solving instance: 75...
	 start solving instance: 121...
	 start solving instance: 136...
	 start solving instance: 82...
	 start solving instance: 68...
	 start solving instance: 14...
	 start solving instance: 54...
	 start solving instance: 143...
	 start solving instance: 114...
	 start solving instance: 105...
	 start solving instance: 83...
	 start solving instance: 78...
	 start solving instance: 99...
	 start solving instance: 79...
	 start solving instance: 148...
	 start solving instance: 45...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.908344263106521e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959155712.0
		 entropy bonus: 0.20494584739208221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5988322816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6923569664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9083443730576835e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.908344263106521e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959155712.0
		 entropy bonus: 0.20494584739208221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5988322816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6923569664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9083443730576835e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.908344263106521e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959155712.0
		 entropy bonus: 0.20494584739208221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5988322816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6923569664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9083443730576835e+18 - Differentiable computation graph = True!
PPO iteration: 676/1000:
	 start solving instance: 121...
	 start solving instance: 83...
	 start solving instance: 143...
	 start solving instance: 114...
	 start solving instance: 82...
	 start solving instance: 60...
	 start solving instance: 148...
	 start solving instance: 17...
	 start solving instance: 105...
	 start solving instance: 79...
	 start solving instance: 14...
	 start solving instance: 75...
	 start solving instance: 78...
	 start solving instance: 136...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 44...
	 start solving instance: 68...
	 start solving instance: 99...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.041569448216232e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099503104.0
		 entropy bonus: 0.208014115691185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6192939008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6909677568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.041569448216232e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.041569448216232e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099503104.0
		 entropy bonus: 0.208014115691185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6192939008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6909677568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.041569448216232e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.041569448216232e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6099503104.0
		 entropy bonus: 0.208014115691185
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6192939008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6909677568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.041569448216232e+18 - Differentiable computation graph = True!
PPO iteration: 677/1000:
	 start solving instance: 121...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 136...
	 start solving instance: 78...
	 start solving instance: 114...
	 start solving instance: 44...
	 start solving instance: 148...
	 start solving instance: 83...
	 start solving instance: 82...
	 start solving instance: 54...
	 start solving instance: 75...
	 start solving instance: 105...
	 start solving instance: 60...
	 start solving instance: 68...
	 start solving instance: 17...
	 start solving instance: 99...
	 start solving instance: 79...
	 start solving instance: 14...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.848684762183395e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030708736.0
		 entropy bonus: 0.2026398628950119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5963878912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6554213376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8486848721345577e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.848684762183395e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030708736.0
		 entropy bonus: 0.2026398628950119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5963878912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6554213376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8486848721345577e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.848684762183395e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6030708736.0
		 entropy bonus: 0.2026398628950119
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5963878912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6554213376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8486848721345577e+18 - Differentiable computation graph = True!
PPO iteration: 678/1000:
	 start solving instance: 143...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 121...
	 start solving instance: 17...
	 start solving instance: 68...
	 start solving instance: 82...
	 start solving instance: 60...
	 start solving instance: 44...
	 start solving instance: 79...
	 start solving instance: 136...
	 start solving instance: 99...
	 start solving instance: 14...
	 start solving instance: 45...
	 start solving instance: 54...
	 start solving instance: 73...
	 start solving instance: 148...
	 start solving instance: 114...
	 start solving instance: 78...
	 start solving instance: 83...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.883904318644316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5986996736.0
		 entropy bonus: 0.21642577648162842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5996155392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6625121280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8839044285954785e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.883904318644316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5986996736.0
		 entropy bonus: 0.21642577648162842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5996155392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6625121280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8839044285954785e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.883904318644316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5986996736.0
		 entropy bonus: 0.21642577648162842
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5996155392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6625121280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8839044285954785e+18 - Differentiable computation graph = True!
PPO iteration: 679/1000:
	 start solving instance: 99...
	 start solving instance: 83...
	 start solving instance: 136...
	 start solving instance: 44...
	 start solving instance: 114...
	 start solving instance: 54...
	 start solving instance: 105...
	 start solving instance: 121...
	 start solving instance: 73...
	 start solving instance: 45...
	 start solving instance: 68...
	 start solving instance: 78...
	 start solving instance: 82...
	 start solving instance: 14...
	 start solving instance: 75...
	 start solving instance: 79...
	 start solving instance: 17...
	 start solving instance: 60...
	 start solving instance: 143...
	 start solving instance: 148...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5719966192954245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5875116032.0
		 entropy bonus: 0.20337934792041779
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5611492352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6458421760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5719966192954245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5719966192954245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5875116032.0
		 entropy bonus: 0.20337934792041779
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5611492352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6458421760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5719966192954245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5719966192954245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5875116032.0
		 entropy bonus: 0.20337934792041779
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5611492352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6458421760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5719966192954245e+18 - Differentiable computation graph = True!
PPO iteration: 680/1000:
	 start solving instance: 68...
	 start solving instance: 79...
	 start solving instance: 143...
	 start solving instance: 121...
	 start solving instance: 148...
	 start solving instance: 60...
	 start solving instance: 75...
	 start solving instance: 99...
	 start solving instance: 78...
	 start solving instance: 136...
	 start solving instance: 82...
	 start solving instance: 17...
	 start solving instance: 14...
	 start solving instance: 114...
	 start solving instance: 73...
	 start solving instance: 54...
	 start solving instance: 83...
	 start solving instance: 105...
	 start solving instance: 45...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8067106858907206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5939403264.0
		 entropy bonus: 0.2024008333683014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5836227584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6535442432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.806710740866302e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8067106858907206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5939403264.0
		 entropy bonus: 0.2024008333683014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5836227584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6535442432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.806710740866302e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8067106858907206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5939403264.0
		 entropy bonus: 0.2024008333683014
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5836227584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6535442432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.806710740866302e+18 - Differentiable computation graph = True!
PPO iteration: 681/1000:
	 New training batch of size 20...
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 49...
	 start solving instance: 127...
	 start solving instance: 55...
	 start solving instance: 104...
	 start solving instance: 47...
	 start solving instance: 110...
	 start solving instance: 93...
	 start solving instance: 79...
	 start solving instance: 13...
	 start solving instance: 42...
	 start solving instance: 92...
	 start solving instance: 82...
	 start solving instance: 148...
	 start solving instance: 21...
	 start solving instance: 135...
	 start solving instance: 81...
	 start solving instance: 99...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0960572862469505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112090624.0
		 entropy bonus: 0.18919788300991058
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6037154304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6765868032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0960573961981133e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0960572862469505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112090624.0
		 entropy bonus: 0.18919788300991058
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6037154304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6765868032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0960573961981133e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0960572862469505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6112090624.0
		 entropy bonus: 0.18919788300991058
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6037154304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6765868032.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0960573961981133e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9244955411120914e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5186854400.0
		 entropy bonus: 0.18993249535560608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5093389312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6026863616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2924495596087672832.0000
PPO iteration: 682/1000:
	 start solving instance: 110...
	 start solving instance: 79...
	 start solving instance: 99...
	 start solving instance: 143...
	 start solving instance: 104...
	 start solving instance: 127...
	 start solving instance: 93...
	 start solving instance: 21...
	 start solving instance: 148...
	 start solving instance: 55...
	 start solving instance: 92...
	 start solving instance: 42...
	 start solving instance: 62...
	 start solving instance: 81...
	 start solving instance: 49...
	 start solving instance: 100...
	 start solving instance: 13...
	 start solving instance: 47...
	 start solving instance: 135...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.753562053022633e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5975905792.0
		 entropy bonus: 0.1997423619031906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5816382976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6280743424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.753561998047052e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.753562053022633e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5975905792.0
		 entropy bonus: 0.1997423619031906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5816382976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6280743424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.753561998047052e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.753562053022633e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5975905792.0
		 entropy bonus: 0.1997423619031906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5816382976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6280743424.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.753561998047052e+18 - Differentiable computation graph = True!
PPO iteration: 683/1000:
	 start solving instance: 47...
	 start solving instance: 143...
	 start solving instance: 99...
	 start solving instance: 110...
	 start solving instance: 55...
	 start solving instance: 148...
	 start solving instance: 135...
	 start solving instance: 13...
	 start solving instance: 82...
	 start solving instance: 81...
	 start solving instance: 79...
	 start solving instance: 49...
	 start solving instance: 92...
	 start solving instance: 93...
	 start solving instance: 62...
	 start solving instance: 42...
	 start solving instance: 104...
	 start solving instance: 127...
	 start solving instance: 21...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.932661062266415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5996803584.0
		 entropy bonus: 0.19479675590991974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842618880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6445018112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9326611722175775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.932661062266415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5996803584.0
		 entropy bonus: 0.19479675590991974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842618880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6445018112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9326611722175775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.932661062266415e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5996803584.0
		 entropy bonus: 0.19479675590991974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842618880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6445018112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9326611722175775e+18 - Differentiable computation graph = True!
PPO iteration: 684/1000:
	 start solving instance: 47...
	 start solving instance: 100...
	 start solving instance: 79...
	 start solving instance: 55...
	 start solving instance: 81...
	 start solving instance: 93...
	 start solving instance: 110...
	 start solving instance: 49...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 148...
	 start solving instance: 42...
	 start solving instance: 104...
	 start solving instance: 21...
	 start solving instance: 143...
	 start solving instance: 92...
	 start solving instance: 99...
	 start solving instance: 62...
	 start solving instance: 135...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.938142787437855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6066089984.0
		 entropy bonus: 0.18347106873989105
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5933325824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726194176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9381427874378547e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.938142787437855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6066089984.0
		 entropy bonus: 0.18347106873989105
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5933325824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726194176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9381427874378547e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.938142787437855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6066089984.0
		 entropy bonus: 0.18347106873989105
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5933325824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726194176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9381427874378547e+18 - Differentiable computation graph = True!
PPO iteration: 685/1000:
	 start solving instance: 81...
	 start solving instance: 127...
	 start solving instance: 42...
	 start solving instance: 55...
	 start solving instance: 99...
	 start solving instance: 104...
	 start solving instance: 21...
	 start solving instance: 135...
	 start solving instance: 93...
	 start solving instance: 47...
	 start solving instance: 79...
	 start solving instance: 92...
	 start solving instance: 143...
	 start solving instance: 62...
	 start solving instance: 100...
	 start solving instance: 49...
	 start solving instance: 110...
	 start solving instance: 13...
	 start solving instance: 148...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.009987076219994e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6039254016.0
		 entropy bonus: 0.19756923615932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5957726208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6463825408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.009987076219994e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.009987076219994e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6039254016.0
		 entropy bonus: 0.19756923615932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5957726208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6463825408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.009987076219994e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.009987076219994e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6039254016.0
		 entropy bonus: 0.19756923615932465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5957726208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6463825408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.009987076219994e+18 - Differentiable computation graph = True!
PPO iteration: 686/1000:
	 start solving instance: 127...
	 start solving instance: 135...
	 start solving instance: 49...
	 start solving instance: 93...
	 start solving instance: 100...
	 start solving instance: 104...
	 start solving instance: 143...
	 start solving instance: 148...
	 start solving instance: 99...
	 start solving instance: 81...
	 start solving instance: 21...
	 start solving instance: 13...
	 start solving instance: 55...
	 start solving instance: 110...
	 start solving instance: 79...
	 start solving instance: 82...
	 start solving instance: 47...
	 start solving instance: 92...
	 start solving instance: 42...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.944328200051071e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064586752.0
		 entropy bonus: 0.1962023228406906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5857912832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6573422080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9443283649778156e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.944328200051071e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064586752.0
		 entropy bonus: 0.1962023228406906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5857912832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6573422080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9443283649778156e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.944328200051071e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064586752.0
		 entropy bonus: 0.1962023228406906
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5857912832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6573422080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9443283649778156e+18 - Differentiable computation graph = True!
PPO iteration: 687/1000:
	 start solving instance: 135...
	 start solving instance: 110...
	 start solving instance: 55...
	 start solving instance: 81...
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 93...
	 start solving instance: 148...
	 start solving instance: 21...
	 start solving instance: 42...
	 start solving instance: 47...
	 start solving instance: 92...
	 start solving instance: 82...
	 start solving instance: 79...
	 start solving instance: 104...
	 start solving instance: 100...
	 start solving instance: 99...
	 start solving instance: 13...
	 start solving instance: 127...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.961663100374588e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009636352.0
		 entropy bonus: 0.18839238584041595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5918861824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6391492096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.961663265301332e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.961663100374588e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009636352.0
		 entropy bonus: 0.18839238584041595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5918861824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6391492096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.961663265301332e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.961663100374588e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009636352.0
		 entropy bonus: 0.18839238584041595
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5918861824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6391492096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.961663265301332e+18 - Differentiable computation graph = True!
PPO iteration: 688/1000:
	 start solving instance: 79...
	 start solving instance: 81...
	 start solving instance: 104...
	 start solving instance: 55...
	 start solving instance: 127...
	 start solving instance: 82...
	 start solving instance: 92...
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 13...
	 start solving instance: 100...
	 start solving instance: 93...
	 start solving instance: 135...
	 start solving instance: 148...
	 start solving instance: 42...
	 start solving instance: 21...
	 start solving instance: 110...
	 start solving instance: 47...
	 start solving instance: 49...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.025995965520413e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6007490048.0
		 entropy bonus: 0.19512620568275452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004636160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6698064384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0259959655204127e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.025995965520413e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6007490048.0
		 entropy bonus: 0.19512620568275452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004636160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6698064384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0259959655204127e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.025995965520413e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6007490048.0
		 entropy bonus: 0.19512620568275452
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004636160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6698064384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0259959655204127e+18 - Differentiable computation graph = True!
PPO iteration: 689/1000:
	 start solving instance: 143...
	 start solving instance: 49...
	 start solving instance: 92...
	 start solving instance: 62...
	 start solving instance: 55...
	 start solving instance: 13...
	 start solving instance: 93...
	 start solving instance: 81...
	 start solving instance: 135...
	 start solving instance: 100...
	 start solving instance: 127...
	 start solving instance: 104...
	 start solving instance: 42...
	 start solving instance: 82...
	 start solving instance: 21...
	 start solving instance: 148...
	 start solving instance: 99...
	 start solving instance: 79...
	 start solving instance: 110...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.147142355692028e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069949440.0
		 entropy bonus: 0.18941305577754974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6130375168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6861738496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.147142355692028e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.147142355692028e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069949440.0
		 entropy bonus: 0.18941305577754974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6130375168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6861738496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.147142355692028e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.147142355692028e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6069949440.0
		 entropy bonus: 0.18941305577754974
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6130375168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6861738496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.147142355692028e+18 - Differentiable computation graph = True!
PPO iteration: 690/1000:
	 start solving instance: 135...
	 start solving instance: 42...
	 start solving instance: 21...
	 start solving instance: 92...
	 start solving instance: 79...
	 start solving instance: 55...
	 start solving instance: 49...
	 start solving instance: 148...
	 start solving instance: 100...
	 start solving instance: 104...
	 start solving instance: 93...
	 start solving instance: 47...
	 start solving instance: 62...
	 start solving instance: 110...
	 start solving instance: 127...
	 start solving instance: 82...
	 start solving instance: 143...
	 start solving instance: 81...
	 start solving instance: 99...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.923627914537258e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016132608.0
		 entropy bonus: 0.20155572891235352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5921936896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6610779648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.923627859561677e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.923627914537258e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016132608.0
		 entropy bonus: 0.20155572891235352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5921936896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6610779648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.923627859561677e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.923627914537258e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6016132608.0
		 entropy bonus: 0.20155572891235352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5921936896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6610779648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.923627859561677e+18 - Differentiable computation graph = True!
PPO iteration: 691/1000:
	 New training batch of size 20...
	 start solving instance: 62...
	 start solving instance: 73...
	 start solving instance: 32...
	 start solving instance: 107...
	 start solving instance: 145...
	 start solving instance: 13...
	 start solving instance: 37...
	 start solving instance: 1...
	 start solving instance: 51...
	 start solving instance: 67...
	 start solving instance: 69...
	 start solving instance: 108...
	 start solving instance: 5...
	 start solving instance: 97...
	 start solving instance: 124...
	 start solving instance: 133...
	 start solving instance: 40...
	 start solving instance: 113...
	 start solving instance: 129...
	 start solving instance: 136...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.154476098249294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6179255808.0
		 entropy bonus: 0.21517574787139893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6152121344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6810076160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.154476098249294e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.154476098249294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6179255808.0
		 entropy bonus: 0.21517574787139893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6152121344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6810076160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.154476098249294e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.154476098249294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6179255808.0
		 entropy bonus: 0.21517574787139893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6152121344.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6810076160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.154476098249294e+18 - Differentiable computation graph = True!
PPO iteration: 692/1000:
	 start solving instance: 32...
	 start solving instance: 67...
	 start solving instance: 13...
	 start solving instance: 113...
	 start solving instance: 107...
	 start solving instance: 129...
	 start solving instance: 133...
	 start solving instance: 97...
	 start solving instance: 40...
	 start solving instance: 69...
	 start solving instance: 1...
	 start solving instance: 5...
	 start solving instance: 145...
	 start solving instance: 136...
	 start solving instance: 73...
	 start solving instance: 62...
	 start solving instance: 108...
	 start solving instance: 124...
	 start solving instance: 37...
	 start solving instance: 51...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1096657217616085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6151084544.0
		 entropy bonus: 0.22085729241371155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018595328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6870050816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.10966577673719e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1096657217616085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6151084544.0
		 entropy bonus: 0.22085729241371155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018595328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6870050816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.10966577673719e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1096657217616085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6151084544.0
		 entropy bonus: 0.22085729241371155
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018595328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6870050816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.10966577673719e+18 - Differentiable computation graph = True!
PPO iteration: 693/1000:
	 start solving instance: 32...
	 start solving instance: 73...
	 start solving instance: 5...
	 start solving instance: 37...
	 start solving instance: 129...
	 start solving instance: 69...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 113...
	 start solving instance: 108...
	 start solving instance: 51...
	 start solving instance: 67...
	 start solving instance: 40...
	 start solving instance: 145...
	 start solving instance: 13...
	 start solving instance: 124...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 133...
	 start solving instance: 136...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.272913291770069e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064463360.0
		 entropy bonus: 0.21580873429775238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6291282432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6842336256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.272913291770069e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.272913291770069e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064463360.0
		 entropy bonus: 0.21580873429775238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6291282432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6842336256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.272913291770069e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.272913291770069e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064463360.0
		 entropy bonus: 0.21580873429775238
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6291282432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6842336256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.272913291770069e+18 - Differentiable computation graph = True!
PPO iteration: 694/1000:
	 start solving instance: 32...
	 start solving instance: 69...
	 start solving instance: 133...
	 start solving instance: 67...
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 129...
	 start solving instance: 1...
	 start solving instance: 124...
	 start solving instance: 73...
	 start solving instance: 13...
	 start solving instance: 136...
	 start solving instance: 5...
	 start solving instance: 40...
	 start solving instance: 145...
	 start solving instance: 37...
	 start solving instance: 113...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.037100153351648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982280192.0
		 entropy bonus: 0.22323603928089142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6015602176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6673180160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0371002083272294e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.037100153351648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982280192.0
		 entropy bonus: 0.22323603928089142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6015602176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6673180160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0371002083272294e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.037100153351648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982280192.0
		 entropy bonus: 0.22323603928089142
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6015602176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6673180160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0371002083272294e+18 - Differentiable computation graph = True!
PPO iteration: 695/1000:
	 start solving instance: 108...
	 start solving instance: 129...
	 start solving instance: 51...
	 start solving instance: 40...
	 start solving instance: 133...
	 start solving instance: 124...
	 start solving instance: 97...
	 start solving instance: 113...
	 start solving instance: 136...
	 start solving instance: 69...
	 start solving instance: 107...
	 start solving instance: 145...
	 start solving instance: 13...
	 start solving instance: 37...
	 start solving instance: 73...
	 start solving instance: 62...
	 start solving instance: 1...
	 start solving instance: 5...
	 start solving instance: 32...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.193270826719091e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132938240.0
		 entropy bonus: 0.21240125596523285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6095195136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914686976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1932709916458353e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.193270826719091e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132938240.0
		 entropy bonus: 0.21240125596523285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6095195136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914686976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1932709916458353e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.193270826719091e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6132938240.0
		 entropy bonus: 0.21240125596523285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6095195136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914686976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1932709916458353e+18 - Differentiable computation graph = True!
PPO iteration: 696/1000:
	 start solving instance: 145...
	 start solving instance: 113...
	 start solving instance: 67...
	 start solving instance: 13...
	 start solving instance: 124...
	 start solving instance: 51...
	 start solving instance: 107...
	 start solving instance: 133...
	 start solving instance: 136...
	 start solving instance: 129...
	 start solving instance: 73...
	 start solving instance: 40...
	 start solving instance: 1...
	 start solving instance: 37...
	 start solving instance: 5...
	 start solving instance: 97...
	 start solving instance: 69...
	 start solving instance: 62...
	 start solving instance: 108...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.315989518518426e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6034718208.0
		 entropy bonus: 0.2220522165298462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325721600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6931380736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.31598968344517e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.315989518518426e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6034718208.0
		 entropy bonus: 0.2220522165298462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325721600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6931380736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.31598968344517e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.315989518518426e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6034718208.0
		 entropy bonus: 0.2220522165298462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325721600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6931380736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.31598968344517e+18 - Differentiable computation graph = True!
PPO iteration: 697/1000:
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 136...
	 start solving instance: 51...
	 start solving instance: 97...
	 start solving instance: 113...
	 start solving instance: 73...
	 start solving instance: 1...
	 start solving instance: 107...
	 start solving instance: 145...
	 start solving instance: 67...
	 start solving instance: 32...
	 start solving instance: 40...
	 start solving instance: 129...
	 start solving instance: 37...
	 start solving instance: 5...
	 start solving instance: 124...
	 start solving instance: 62...
	 start solving instance: 69...
	 start solving instance: 133...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.265580868626756e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6192843776.0
		 entropy bonus: 0.2156120389699936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6241942016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089062400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.265580923602338e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.265580868626756e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6192843776.0
		 entropy bonus: 0.2156120389699936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6241942016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089062400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.265580923602338e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.265580868626756e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6192843776.0
		 entropy bonus: 0.2156120389699936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6241942016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7089062400.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.265580923602338e+18 - Differentiable computation graph = True!
PPO iteration: 698/1000:
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 40...
	 start solving instance: 108...
	 start solving instance: 124...
	 start solving instance: 5...
	 start solving instance: 1...
	 start solving instance: 136...
	 start solving instance: 69...
	 start solving instance: 32...
	 start solving instance: 13...
	 start solving instance: 97...
	 start solving instance: 62...
	 start solving instance: 145...
	 start solving instance: 133...
	 start solving instance: 37...
	 start solving instance: 113...
	 start solving instance: 67...
	 start solving instance: 73...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.400811562945531e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6185202688.0
		 entropy bonus: 0.21101582050323486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6278166016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7355864064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4008115079699497e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.400811562945531e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6185202688.0
		 entropy bonus: 0.21101582050323486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6278166016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7355864064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4008115079699497e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.400811562945531e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6185202688.0
		 entropy bonus: 0.21101582050323486
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6278166016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7355864064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4008115079699497e+18 - Differentiable computation graph = True!
PPO iteration: 699/1000:
	 start solving instance: 113...
	 start solving instance: 1...
	 start solving instance: 32...
	 start solving instance: 129...
	 start solving instance: 145...
	 start solving instance: 73...
	 start solving instance: 133...
	 start solving instance: 136...
	 start solving instance: 40...
	 start solving instance: 124...
	 start solving instance: 37...
	 start solving instance: 67...
	 start solving instance: 62...
	 start solving instance: 97...
	 start solving instance: 5...
	 start solving instance: 108...
	 start solving instance: 13...
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 69...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.195408717128139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203409920.0
		 entropy bonus: 0.22497425973415375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140868096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7031989760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.195408717128139e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.195408717128139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203409920.0
		 entropy bonus: 0.22497425973415375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140868096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7031989760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.195408717128139e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.195408717128139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203409920.0
		 entropy bonus: 0.22497425973415375
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6140868096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7031989760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.195408717128139e+18 - Differentiable computation graph = True!
PPO iteration: 700/1000:
	 start solving instance: 145...
	 start solving instance: 32...
	 start solving instance: 40...
	 start solving instance: 1...
	 start solving instance: 133...
	 start solving instance: 124...
	 start solving instance: 73...
	 start solving instance: 69...
	 start solving instance: 113...
	 start solving instance: 107...
	 start solving instance: 13...
	 start solving instance: 97...
	 start solving instance: 67...
	 start solving instance: 108...
	 start solving instance: 129...
	 start solving instance: 37...
	 start solving instance: 51...
	 start solving instance: 136...
	 start solving instance: 5...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.064751991180912e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6146633728.0
		 entropy bonus: 0.20720385015010834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6019220480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6737203200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.064752101132075e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.064751991180912e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6146633728.0
		 entropy bonus: 0.20720385015010834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6019220480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6737203200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.064752101132075e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.064751991180912e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6146633728.0
		 entropy bonus: 0.20720385015010834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6019220480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6737203200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.064752101132075e+18 - Differentiable computation graph = True!
PPO iteration: 701/1000:
	 New training batch of size 20...
	 start solving instance: 116...
	 start solving instance: 64...
	 start solving instance: 26...
	 start solving instance: 103...
	 start solving instance: 91...
	 start solving instance: 76...
	 start solving instance: 106...
	 start solving instance: 18...
	 start solving instance: 132...
	 start solving instance: 115...
	 start solving instance: 129...
	 start solving instance: 100...
	 start solving instance: 52...
	 start solving instance: 22...
	 start solving instance: 31...
	 start solving instance: 15...
	 start solving instance: 99...
	 start solving instance: 51...
	 start solving instance: 44...
	 start solving instance: 19...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.191633873807658e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064137728.0
		 entropy bonus: 0.21084342896938324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5975775744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6812949504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.191633818832077e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.191633873807658e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064137728.0
		 entropy bonus: 0.21084342896938324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5975775744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6812949504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.191633818832077e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.191633873807658e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6064137728.0
		 entropy bonus: 0.21084342896938324
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5975775744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6812949504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.191633818832077e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.061198481500458e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5271517184.0
		 entropy bonus: 0.2078818380832672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5127433216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5906807296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3061198426524876800.0000
PPO iteration: 702/1000:
	 start solving instance: 15...
	 start solving instance: 100...
	 start solving instance: 18...
	 start solving instance: 26...
	 start solving instance: 116...
	 start solving instance: 91...
	 start solving instance: 106...
	 start solving instance: 115...
	 start solving instance: 76...
	 start solving instance: 52...
	 start solving instance: 44...
	 start solving instance: 64...
	 start solving instance: 51...
	 start solving instance: 19...
	 start solving instance: 103...
	 start solving instance: 22...
	 start solving instance: 99...
	 start solving instance: 129...
	 start solving instance: 31...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.255826001465128e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6002631168.0
		 entropy bonus: 0.22073009610176086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6023767040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6923432960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.255826056440709e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.255826001465128e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6002631168.0
		 entropy bonus: 0.22073009610176086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6023767040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6923432960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.255826056440709e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.255826001465128e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6002631168.0
		 entropy bonus: 0.22073009610176086
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6023767040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6923432960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.255826056440709e+18 - Differentiable computation graph = True!
PPO iteration: 703/1000:
	 start solving instance: 52...
	 start solving instance: 64...
	 start solving instance: 26...
	 start solving instance: 100...
	 start solving instance: 51...
	 start solving instance: 103...
	 start solving instance: 19...
	 start solving instance: 91...
	 start solving instance: 129...
	 start solving instance: 22...
	 start solving instance: 15...
	 start solving instance: 115...
	 start solving instance: 76...
	 start solving instance: 106...
	 start solving instance: 31...
	 start solving instance: 99...
	 start solving instance: 18...
	 start solving instance: 132...
	 start solving instance: 116...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.399533050824753e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998493184.0
		 entropy bonus: 0.21838752925395966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6110729728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7062581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.399533050824753e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.399533050824753e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998493184.0
		 entropy bonus: 0.21838752925395966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6110729728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7062581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.399533050824753e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.399533050824753e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998493184.0
		 entropy bonus: 0.21838752925395966
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6110729728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7062581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.399533050824753e+18 - Differentiable computation graph = True!
PPO iteration: 704/1000:
	 start solving instance: 116...
	 start solving instance: 76...
	 start solving instance: 106...
	 start solving instance: 51...
	 start solving instance: 19...
	 start solving instance: 103...
	 start solving instance: 129...
	 start solving instance: 52...
	 start solving instance: 22...
	 start solving instance: 15...
	 start solving instance: 64...
	 start solving instance: 132...
	 start solving instance: 115...
	 start solving instance: 91...
	 start solving instance: 18...
	 start solving instance: 99...
	 start solving instance: 26...
	 start solving instance: 31...
	 start solving instance: 100...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.189656512096266e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5977954304.0
		 entropy bonus: 0.20654085278511047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6005960192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6860044800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1896566220474286e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.189656512096266e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5977954304.0
		 entropy bonus: 0.20654085278511047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6005960192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6860044800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1896566220474286e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.189656512096266e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5977954304.0
		 entropy bonus: 0.20654085278511047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6005960192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6860044800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1896566220474286e+18 - Differentiable computation graph = True!
PPO iteration: 705/1000:
	 start solving instance: 26...
	 start solving instance: 103...
	 start solving instance: 19...
	 start solving instance: 115...
	 start solving instance: 106...
	 start solving instance: 99...
	 start solving instance: 116...
	 start solving instance: 31...
	 start solving instance: 100...
	 start solving instance: 51...
	 start solving instance: 44...
	 start solving instance: 91...
	 start solving instance: 64...
	 start solving instance: 22...
	 start solving instance: 18...
	 start solving instance: 132...
	 start solving instance: 129...
	 start solving instance: 15...
	 start solving instance: 52...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.263825168459524e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6067653120.0
		 entropy bonus: 0.20389492809772491
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6031925248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7099742720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2638252784106865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.263825168459524e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059987968.0
		 entropy bonus: 0.21082639694213867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6031925248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7099742720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2638252784106865e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.263825168459524e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059987968.0
		 entropy bonus: 0.21082639694213867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6031925248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7099742720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2638252784106865e+18 - Differentiable computation graph = True!
PPO iteration: 706/1000:
	 start solving instance: 91...
	 start solving instance: 99...
	 start solving instance: 76...
	 start solving instance: 132...
	 start solving instance: 19...
	 start solving instance: 51...
	 start solving instance: 52...
	 start solving instance: 115...
	 start solving instance: 103...
	 start solving instance: 18...
	 start solving instance: 44...
	 start solving instance: 15...
	 start solving instance: 106...
	 start solving instance: 31...
	 start solving instance: 64...
	 start solving instance: 22...
	 start solving instance: 129...
	 start solving instance: 116...
	 start solving instance: 100...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5282088966233784e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6100174848.0
		 entropy bonus: 0.22357884049415588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6267080192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7157273600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5282088966233784e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5282088966233784e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6100174848.0
		 entropy bonus: 0.22357884049415588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6267080192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7157273600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5282088966233784e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5282088966233784e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6100174848.0
		 entropy bonus: 0.22357884049415588
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6267080192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7157273600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5282088966233784e+18 - Differentiable computation graph = True!
PPO iteration: 707/1000:
	 start solving instance: 103...
	 start solving instance: 76...
	 start solving instance: 99...
	 start solving instance: 52...
	 start solving instance: 26...
	 start solving instance: 115...
	 start solving instance: 64...
	 start solving instance: 129...
	 start solving instance: 91...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 51...
	 start solving instance: 22...
	 start solving instance: 132...
	 start solving instance: 31...
	 start solving instance: 18...
	 start solving instance: 100...
	 start solving instance: 106...
	 start solving instance: 19...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.23266017107719e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107828224.0
		 entropy bonus: 0.20816564559936523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5952337920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6919557632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2326601710771896e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.23266017107719e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107828224.0
		 entropy bonus: 0.20816564559936523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5952337920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6919557632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2326601710771896e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.23266017107719e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107828224.0
		 entropy bonus: 0.20816564559936523
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5952337920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6919557632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2326601710771896e+18 - Differentiable computation graph = True!
PPO iteration: 708/1000:
	 start solving instance: 115...
	 start solving instance: 99...
	 start solving instance: 106...
	 start solving instance: 51...
	 start solving instance: 100...
	 start solving instance: 26...
	 start solving instance: 64...
	 start solving instance: 31...
	 start solving instance: 103...
	 start solving instance: 129...
	 start solving instance: 76...
	 start solving instance: 116...
	 start solving instance: 19...
	 start solving instance: 44...
	 start solving instance: 22...
	 start solving instance: 91...
	 start solving instance: 132...
	 start solving instance: 52...
	 start solving instance: 18...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2436148253270475e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5954889216.0
		 entropy bonus: 0.21029625833034515
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6027789824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841256960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.243614880302629e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2436148253270475e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5954889216.0
		 entropy bonus: 0.21029625833034515
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6027789824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841256960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.243614880302629e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2436148253270475e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5954889216.0
		 entropy bonus: 0.21029625833034515
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6027789824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841256960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.243614880302629e+18 - Differentiable computation graph = True!
PPO iteration: 709/1000:
	 start solving instance: 116...
	 start solving instance: 19...
	 start solving instance: 31...
	 start solving instance: 106...
	 start solving instance: 51...
	 start solving instance: 103...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 52...
	 start solving instance: 132...
	 start solving instance: 18...
	 start solving instance: 99...
	 start solving instance: 22...
	 start solving instance: 64...
	 start solving instance: 129...
	 start solving instance: 76...
	 start solving instance: 26...
	 start solving instance: 91...
	 start solving instance: 100...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.35081808864451e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6043717632.0
		 entropy bonus: 0.21049141883850098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6098920448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6845458944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3508180886445097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.35081808864451e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6043717632.0
		 entropy bonus: 0.21049141883850098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6098920448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6845458944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3508180886445097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.35081808864451e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6043717632.0
		 entropy bonus: 0.21049141883850098
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6098920448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6845458944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3508180886445097e+18 - Differentiable computation graph = True!
PPO iteration: 710/1000:
	 start solving instance: 64...
	 start solving instance: 115...
	 start solving instance: 51...
	 start solving instance: 106...
	 start solving instance: 19...
	 start solving instance: 103...
	 start solving instance: 132...
	 start solving instance: 22...
	 start solving instance: 100...
	 start solving instance: 44...
	 start solving instance: 18...
	 start solving instance: 99...
	 start solving instance: 26...
	 start solving instance: 129...
	 start solving instance: 31...
	 start solving instance: 76...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 15...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.385356827505512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981123584.0
		 entropy bonus: 0.21299611032009125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6090413568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7091959296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.38535677252993e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.385356827505512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981123584.0
		 entropy bonus: 0.21299611032009125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6090413568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7091959296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.38535677252993e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.385356827505512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981123584.0
		 entropy bonus: 0.21299611032009125
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6090413568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7091959296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.38535677252993e+18 - Differentiable computation graph = True!
PPO iteration: 711/1000:
	 New training batch of size 20...
	 start solving instance: 74...
	 start solving instance: 148...
	 start solving instance: 63...
	 start solving instance: 60...
	 start solving instance: 44...
	 start solving instance: 99...
	 start solving instance: 32...
	 start solving instance: 23...
	 start solving instance: 7...
	 start solving instance: 113...
	 start solving instance: 119...
	 start solving instance: 75...
	 start solving instance: 15...
	 start solving instance: 34...
	 start solving instance: 35...
	 start solving instance: 79...
	 start solving instance: 134...
	 start solving instance: 19...
	 start solving instance: 104...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.014548730061311e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6080805888.0
		 entropy bonus: 0.19210143387317657
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6107042304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6689460736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.01454867508573e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.014548730061311e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6080805888.0
		 entropy bonus: 0.19210143387317657
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6107042304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6689460736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.01454867508573e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.014548730061311e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6080805888.0
		 entropy bonus: 0.19210143387317657
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6107042304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6689460736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.01454867508573e+18 - Differentiable computation graph = True!
PPO iteration: 712/1000:
	 start solving instance: 113...
	 start solving instance: 119...
	 start solving instance: 148...
	 start solving instance: 19...
	 start solving instance: 60...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 63...
	 start solving instance: 62...
	 start solving instance: 74...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 7...
	 start solving instance: 34...
	 start solving instance: 75...
	 start solving instance: 79...
	 start solving instance: 35...
	 start solving instance: 104...
	 start solving instance: 134...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.754207686250463e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5857743872.0
		 entropy bonus: 0.19450871646404266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723500544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6362780160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.754207686250463e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.754207686250463e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5857743872.0
		 entropy bonus: 0.19450871646404266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723500544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6362780160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.754207686250463e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.754207686250463e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5857743872.0
		 entropy bonus: 0.19450871646404266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723500544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6362780160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.754207686250463e+18 - Differentiable computation graph = True!
PPO iteration: 713/1000:
	 start solving instance: 60...
	 start solving instance: 148...
	 start solving instance: 99...
	 start solving instance: 35...
	 start solving instance: 79...
	 start solving instance: 134...
	 start solving instance: 7...
	 start solving instance: 32...
	 start solving instance: 62...
	 start solving instance: 119...
	 start solving instance: 23...
	 start solving instance: 63...
	 start solving instance: 34...
	 start solving instance: 113...
	 start solving instance: 104...
	 start solving instance: 74...
	 start solving instance: 75...
	 start solving instance: 19...
	 start solving instance: 15...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.81544388684782e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5820800512.0
		 entropy bonus: 0.2078086882829666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5818676736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6556160512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.81544388684782e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.81544388684782e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5820800512.0
		 entropy bonus: 0.2078086882829666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5818676736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6556160512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.81544388684782e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.81544388684782e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5820800512.0
		 entropy bonus: 0.2078086882829666
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5818676736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6556160512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.81544388684782e+18 - Differentiable computation graph = True!
PPO iteration: 714/1000:
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 35...
	 start solving instance: 63...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 134...
	 start solving instance: 19...
	 start solving instance: 79...
	 start solving instance: 119...
	 start solving instance: 15...
	 start solving instance: 74...
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 44...
	 start solving instance: 62...
	 start solving instance: 75...
	 start solving instance: 7...
	 start solving instance: 23...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.024607502236857e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6070972928.0
		 entropy bonus: 0.19129562377929688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6050679808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584402944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0246075572124385e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.024607502236857e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6070972928.0
		 entropy bonus: 0.19129562377929688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6050679808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584402944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0246075572124385e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.024607502236857e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6070972928.0
		 entropy bonus: 0.19129562377929688
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6050679808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6584402944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0246075572124385e+18 - Differentiable computation graph = True!
PPO iteration: 715/1000:
	 start solving instance: 74...
	 start solving instance: 75...
	 start solving instance: 104...
	 start solving instance: 63...
	 start solving instance: 44...
	 start solving instance: 15...
	 start solving instance: 119...
	 start solving instance: 34...
	 start solving instance: 19...
	 start solving instance: 60...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 113...
	 start solving instance: 148...
	 start solving instance: 7...
	 start solving instance: 99...
	 start solving instance: 32...
	 start solving instance: 62...
	 start solving instance: 35...
	 start solving instance: 23...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.857378380721894e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967081984.0
		 entropy bonus: 0.1987854391336441
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5941293056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6747645952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8573784356974756e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.857378380721894e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967081984.0
		 entropy bonus: 0.1987854391336441
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5941293056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6747645952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8573784356974756e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.857378380721894e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5967081984.0
		 entropy bonus: 0.1987854391336441
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5941293056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6747645952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8573784356974756e+18 - Differentiable computation graph = True!
PPO iteration: 716/1000:
	 start solving instance: 74...
	 start solving instance: 119...
	 start solving instance: 63...
	 start solving instance: 35...
	 start solving instance: 62...
	 start solving instance: 148...
	 start solving instance: 34...
	 start solving instance: 75...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 7...
	 start solving instance: 44...
	 start solving instance: 32...
	 start solving instance: 19...
	 start solving instance: 113...
	 start solving instance: 104...
	 start solving instance: 23...
	 start solving instance: 15...
	 start solving instance: 60...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.947326348357691e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5943026688.0
		 entropy bonus: 0.20804758369922638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6002097152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6752216576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.947326458308854e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.947326348357691e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5943026688.0
		 entropy bonus: 0.20804758369922638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6002097152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6752216576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.947326458308854e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.947326348357691e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5943026688.0
		 entropy bonus: 0.20804758369922638
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6002097152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6752216576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.947326458308854e+18 - Differentiable computation graph = True!
PPO iteration: 717/1000:
	 start solving instance: 74...
	 start solving instance: 34...
	 start solving instance: 75...
	 start solving instance: 60...
	 start solving instance: 15...
	 start solving instance: 79...
	 start solving instance: 35...
	 start solving instance: 99...
	 start solving instance: 119...
	 start solving instance: 104...
	 start solving instance: 7...
	 start solving instance: 62...
	 start solving instance: 23...
	 start solving instance: 44...
	 start solving instance: 63...
	 start solving instance: 113...
	 start solving instance: 19...
	 start solving instance: 134...
	 start solving instance: 148...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.743103498419228e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5965902848.0
		 entropy bonus: 0.19590435922145844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5787508736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6653904384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7431034434436465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.743103498419228e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5965902848.0
		 entropy bonus: 0.19590435922145844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5787508736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6653904384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7431034434436465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.743103498419228e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5965902848.0
		 entropy bonus: 0.19590435922145844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5787508736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6653904384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7431034434436465e+18 - Differentiable computation graph = True!
PPO iteration: 718/1000:
	 start solving instance: 35...
	 start solving instance: 113...
	 start solving instance: 63...
	 start solving instance: 34...
	 start solving instance: 60...
	 start solving instance: 44...
	 start solving instance: 74...
	 start solving instance: 134...
	 start solving instance: 99...
	 start solving instance: 148...
	 start solving instance: 15...
	 start solving instance: 104...
	 start solving instance: 119...
	 start solving instance: 7...
	 start solving instance: 23...
	 start solving instance: 19...
	 start solving instance: 79...
	 start solving instance: 75...
	 start solving instance: 32...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.81747578433595e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5930170880.0
		 entropy bonus: 0.20699577033519745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823938560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6698888704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.81747578433595e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.81747578433595e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5930170880.0
		 entropy bonus: 0.20699577033519745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823938560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6698888704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.81747578433595e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.81747578433595e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5930170880.0
		 entropy bonus: 0.20699577033519745
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823938560.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6698888704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.81747578433595e+18 - Differentiable computation graph = True!
PPO iteration: 719/1000:
	 start solving instance: 119...
	 start solving instance: 7...
	 start solving instance: 35...
	 start solving instance: 79...
	 start solving instance: 63...
	 start solving instance: 62...
	 start solving instance: 134...
	 start solving instance: 148...
	 start solving instance: 32...
	 start solving instance: 44...
	 start solving instance: 99...
	 start solving instance: 15...
	 start solving instance: 23...
	 start solving instance: 75...
	 start solving instance: 113...
	 start solving instance: 60...
	 start solving instance: 74...
	 start solving instance: 34...
	 start solving instance: 19...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.836430045384855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5966800384.0
		 entropy bonus: 0.19267217814922333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5787917312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6414044160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8364299904092733e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.836430045384855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5966800384.0
		 entropy bonus: 0.19267217814922333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5787917312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6414044160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8364299904092733e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.836430045384855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5966800384.0
		 entropy bonus: 0.19267217814922333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5787917312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6414044160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8364299904092733e+18 - Differentiable computation graph = True!
PPO iteration: 720/1000:
	 start solving instance: 148...
	 start solving instance: 119...
	 start solving instance: 63...
	 start solving instance: 62...
	 start solving instance: 15...
	 start solving instance: 19...
	 start solving instance: 23...
	 start solving instance: 134...
	 start solving instance: 99...
	 start solving instance: 34...
	 start solving instance: 44...
	 start solving instance: 75...
	 start solving instance: 60...
	 start solving instance: 79...
	 start solving instance: 35...
	 start solving instance: 7...
	 start solving instance: 113...
	 start solving instance: 74...
	 start solving instance: 32...
	 start solving instance: 104...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.800779040561195e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5888529920.0
		 entropy bonus: 0.20362742245197296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810471424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6394312192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8007791505123574e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.800779040561195e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5888529920.0
		 entropy bonus: 0.20362742245197296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810471424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6394312192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8007791505123574e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.800779040561195e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5888529920.0
		 entropy bonus: 0.20362742245197296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5810471424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6394312192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8007791505123574e+18 - Differentiable computation graph = True!
PPO iteration: 721/1000:
	 New training batch of size 20...
	 start solving instance: 120...
	 start solving instance: 78...
	 start solving instance: 98...
	 start solving instance: 144...
	 start solving instance: 65...
	 start solving instance: 130...
	 start solving instance: 134...
	 start solving instance: 79...
	 start solving instance: 127...
	 start solving instance: 118...
	 start solving instance: 50...
	 start solving instance: 126...
	 start solving instance: 137...
	 start solving instance: 97...
	 start solving instance: 135...
	 start solving instance: 80...
	 start solving instance: 76...
	 start solving instance: 1...
	 start solving instance: 108...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.088514636480407e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6081888256.0
		 entropy bonus: 0.21270053088665009
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5886896128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6887675392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.08851474643157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.088514636480407e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6081888256.0
		 entropy bonus: 0.21270053088665009
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5886896128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6887675392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.08851474643157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.088514636480407e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6081888256.0
		 entropy bonus: 0.21270053088665009
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5886896128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6887675392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.08851474643157e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.8477621639258833e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5146039808.0
		 entropy bonus: 0.19438359141349792
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5037405184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5850831872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2847762328852627456.0000
PPO iteration: 722/1000:
	 start solving instance: 108...
	 start solving instance: 144...
	 start solving instance: 78...
	 start solving instance: 135...
	 start solving instance: 80...
	 start solving instance: 65...
	 start solving instance: 120...
	 start solving instance: 130...
	 start solving instance: 50...
	 start solving instance: 76...
	 start solving instance: 127...
	 start solving instance: 118...
	 start solving instance: 137...
	 start solving instance: 97...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 98...
	 start solving instance: 1...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3055819812545495e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6130175488.0
		 entropy bonus: 0.21149876713752747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6150307840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661889536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3055819812545495e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3055819812545495e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6130175488.0
		 entropy bonus: 0.21149876713752747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6150307840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661889536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3055819812545495e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3055819812545495e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6130175488.0
		 entropy bonus: 0.21149876713752747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6150307840.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6661889536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3055819812545495e+18 - Differentiable computation graph = True!
PPO iteration: 723/1000:
	 start solving instance: 78...
	 start solving instance: 134...
	 start solving instance: 40...
	 start solving instance: 144...
	 start solving instance: 1...
	 start solving instance: 97...
	 start solving instance: 120...
	 start solving instance: 130...
	 start solving instance: 65...
	 start solving instance: 80...
	 start solving instance: 79...
	 start solving instance: 108...
	 start solving instance: 127...
	 start solving instance: 137...
	 start solving instance: 135...
	 start solving instance: 76...
	 start solving instance: 98...
	 start solving instance: 50...
	 start solving instance: 126...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.998018672249327e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6124837376.0
		 entropy bonus: 0.2019638568162918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5825417216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750757888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9980186172737454e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.998018672249327e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6124837376.0
		 entropy bonus: 0.2019638568162918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5825417216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750757888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9980186172737454e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.998018672249327e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6124837376.0
		 entropy bonus: 0.2019638568162918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5825417216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750757888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9980186172737454e+18 - Differentiable computation graph = True!
PPO iteration: 724/1000:
	 start solving instance: 40...
	 start solving instance: 97...
	 start solving instance: 120...
	 start solving instance: 144...
	 start solving instance: 118...
	 start solving instance: 1...
	 start solving instance: 65...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 127...
	 start solving instance: 76...
	 start solving instance: 80...
	 start solving instance: 108...
	 start solving instance: 126...
	 start solving instance: 137...
	 start solving instance: 135...
	 start solving instance: 134...
	 start solving instance: 98...
	 start solving instance: 130...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.19257329654243e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6137153536.0
		 entropy bonus: 0.2134428769350052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5994128384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6821133312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1925733515180114e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.19257329654243e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6137153536.0
		 entropy bonus: 0.2134428769350052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5994128384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6821133312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1925733515180114e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.19257329654243e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6137153536.0
		 entropy bonus: 0.2134428769350052
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5994128384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6821133312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1925733515180114e+18 - Differentiable computation graph = True!
PPO iteration: 725/1000:
	 start solving instance: 98...
	 start solving instance: 137...
	 start solving instance: 126...
	 start solving instance: 50...
	 start solving instance: 76...
	 start solving instance: 127...
	 start solving instance: 134...
	 start solving instance: 78...
	 start solving instance: 144...
	 start solving instance: 40...
	 start solving instance: 130...
	 start solving instance: 97...
	 start solving instance: 79...
	 start solving instance: 118...
	 start solving instance: 120...
	 start solving instance: 135...
	 start solving instance: 80...
	 start solving instance: 108...
	 start solving instance: 1...
	 start solving instance: 65...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2347668353560084e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149176320.0
		 entropy bonus: 0.21097098290920258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6115540480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6497925120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2347668353560084e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2347668353560084e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149176320.0
		 entropy bonus: 0.21097098290920258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6115540480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6497925120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2347668353560084e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2347668353560084e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149176320.0
		 entropy bonus: 0.21097098290920258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6115540480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6497925120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2347668353560084e+18 - Differentiable computation graph = True!
PPO iteration: 726/1000:
	 start solving instance: 130...
	 start solving instance: 78...
	 start solving instance: 118...
	 start solving instance: 97...
	 start solving instance: 127...
	 start solving instance: 120...
	 start solving instance: 144...
	 start solving instance: 98...
	 start solving instance: 50...
	 start solving instance: 65...
	 start solving instance: 79...
	 start solving instance: 40...
	 start solving instance: 134...
	 start solving instance: 108...
	 start solving instance: 1...
	 start solving instance: 137...
	 start solving instance: 126...
	 start solving instance: 135...
	 start solving instance: 76...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.523358730930933e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6157563392.0
		 entropy bonus: 0.21512289345264435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6381504000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7246222336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5233586759553516e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.523358730930933e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6157563392.0
		 entropy bonus: 0.21512289345264435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6381504000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7246222336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5233586759553516e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.523358730930933e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6157563392.0
		 entropy bonus: 0.21512289345264435
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6381504000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7246222336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5233586759553516e+18 - Differentiable computation graph = True!
PPO iteration: 727/1000:
	 start solving instance: 80...
	 start solving instance: 79...
	 start solving instance: 144...
	 start solving instance: 65...
	 start solving instance: 137...
	 start solving instance: 127...
	 start solving instance: 76...
	 start solving instance: 120...
	 start solving instance: 118...
	 start solving instance: 126...
	 start solving instance: 50...
	 start solving instance: 78...
	 start solving instance: 40...
	 start solving instance: 134...
	 start solving instance: 135...
	 start solving instance: 98...
	 start solving instance: 108...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.416534579222728e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6195970048.0
		 entropy bonus: 0.21518032252788544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6191335424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7198936064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4165345242471465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.416534579222728e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6195970048.0
		 entropy bonus: 0.21518032252788544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6191335424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7198936064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4165345242471465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.416534579222728e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6195970048.0
		 entropy bonus: 0.21518032252788544
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6191335424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7198936064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4165345242471465e+18 - Differentiable computation graph = True!
PPO iteration: 728/1000:
	 start solving instance: 1...
	 start solving instance: 76...
	 start solving instance: 126...
	 start solving instance: 80...
	 start solving instance: 79...
	 start solving instance: 144...
	 start solving instance: 108...
	 start solving instance: 50...
	 start solving instance: 137...
	 start solving instance: 134...
	 start solving instance: 97...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 40...
	 start solving instance: 120...
	 start solving instance: 78...
	 start solving instance: 98...
	 start solving instance: 127...
	 start solving instance: 130...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.393775128332416e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6205173760.0
		 entropy bonus: 0.21056930720806122
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188463104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7329640960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.393775183307997e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.393775128332416e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6205173760.0
		 entropy bonus: 0.21056930720806122
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188463104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7329640960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.393775183307997e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.393775128332416e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6205173760.0
		 entropy bonus: 0.21056930720806122
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188463104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7329640960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.393775183307997e+18 - Differentiable computation graph = True!
PPO iteration: 729/1000:
	 start solving instance: 98...
	 start solving instance: 137...
	 start solving instance: 144...
	 start solving instance: 97...
	 start solving instance: 120...
	 start solving instance: 40...
	 start solving instance: 50...
	 start solving instance: 78...
	 start solving instance: 108...
	 start solving instance: 1...
	 start solving instance: 130...
	 start solving instance: 65...
	 start solving instance: 135...
	 start solving instance: 76...
	 start solving instance: 118...
	 start solving instance: 79...
	 start solving instance: 126...
	 start solving instance: 134...
	 start solving instance: 127...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.412670455558072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244289024.0
		 entropy bonus: 0.19854508340358734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6285455872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7055542272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4126705655092347e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.412670455558072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244289024.0
		 entropy bonus: 0.19854508340358734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6285455872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7055542272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4126705655092347e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.412670455558072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6244289024.0
		 entropy bonus: 0.19854508340358734
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6285455872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7055542272.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4126705655092347e+18 - Differentiable computation graph = True!
PPO iteration: 730/1000:
	 start solving instance: 65...
	 start solving instance: 98...
	 start solving instance: 80...
	 start solving instance: 76...
	 start solving instance: 134...
	 start solving instance: 135...
	 start solving instance: 137...
	 start solving instance: 120...
	 start solving instance: 1...
	 start solving instance: 127...
	 start solving instance: 79...
	 start solving instance: 108...
	 start solving instance: 144...
	 start solving instance: 118...
	 start solving instance: 130...
	 start solving instance: 97...
	 start solving instance: 50...
	 start solving instance: 78...
	 start solving instance: 40...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3822447697942544e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6179046400.0
		 entropy bonus: 0.21743817627429962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161345536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662903808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.382244879745417e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3822447697942544e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6179046400.0
		 entropy bonus: 0.21743817627429962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161345536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662903808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.382244879745417e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3822447697942544e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6179046400.0
		 entropy bonus: 0.21743817627429962
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6161345536.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662903808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.382244879745417e+18 - Differentiable computation graph = True!
PPO iteration: 731/1000:
	 New training batch of size 20...
	 start solving instance: 34...
	 start solving instance: 134...
	 start solving instance: 138...
	 start solving instance: 136...
	 start solving instance: 92...
	 start solving instance: 95...
	 start solving instance: 15...
	 start solving instance: 25...
	 start solving instance: 56...
	 start solving instance: 93...
	 start solving instance: 130...
	 start solving instance: 126...
	 start solving instance: 143...
	 start solving instance: 5...
	 start solving instance: 33...
	 start solving instance: 111...
	 start solving instance: 72...
	 start solving instance: 127...
	 start solving instance: 124...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.008755623196885e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5914538496.0
		 entropy bonus: 0.21396782994270325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5954284544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6672953856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.008755623196885e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.008755623196885e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5914538496.0
		 entropy bonus: 0.21396782994270325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5954284544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6672953856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.008755623196885e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.008755623196885e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5914538496.0
		 entropy bonus: 0.21396782994270325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5954284544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6672953856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.008755623196885e+18 - Differentiable computation graph = True!
PPO iteration: 732/1000:
	 start solving instance: 130...
	 start solving instance: 111...
	 start solving instance: 34...
	 start solving instance: 25...
	 start solving instance: 56...
	 start solving instance: 95...
	 start solving instance: 61...
	 start solving instance: 5...
	 start solving instance: 72...
	 start solving instance: 126...
	 start solving instance: 143...
	 start solving instance: 136...
	 start solving instance: 93...
	 start solving instance: 138...
	 start solving instance: 15...
	 start solving instance: 124...
	 start solving instance: 33...
	 start solving instance: 127...
	 start solving instance: 134...
	 start solving instance: 92...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9400106377911206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5851446272.0
		 entropy bonus: 0.21069975197315216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5925882368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6635743232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.940010582815539e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9400106377911206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5851446272.0
		 entropy bonus: 0.21069975197315216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5925882368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6635743232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.940010582815539e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9400106377911206e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5851446272.0
		 entropy bonus: 0.21069975197315216
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5925882368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6635743232.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.940010582815539e+18 - Differentiable computation graph = True!
PPO iteration: 733/1000:
	 start solving instance: 56...
	 start solving instance: 34...
	 start solving instance: 61...
	 start solving instance: 93...
	 start solving instance: 126...
	 start solving instance: 95...
	 start solving instance: 134...
	 start solving instance: 5...
	 start solving instance: 130...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 136...
	 start solving instance: 25...
	 start solving instance: 124...
	 start solving instance: 33...
	 start solving instance: 15...
	 start solving instance: 143...
	 start solving instance: 127...
	 start solving instance: 72...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.695121250787734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5842291200.0
		 entropy bonus: 0.2173730880022049
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5763919360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6174757376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6951213057633157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.695121250787734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5842291200.0
		 entropy bonus: 0.2173730880022049
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5763919360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6174757376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6951213057633157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.695121250787734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5842291200.0
		 entropy bonus: 0.2173730880022049
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5763919360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6174757376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6951213057633157e+18 - Differentiable computation graph = True!
PPO iteration: 734/1000:
	 start solving instance: 61...
	 start solving instance: 138...
	 start solving instance: 5...
	 start solving instance: 33...
	 start solving instance: 134...
	 start solving instance: 130...
	 start solving instance: 93...
	 start solving instance: 72...
	 start solving instance: 124...
	 start solving instance: 15...
	 start solving instance: 136...
	 start solving instance: 127...
	 start solving instance: 111...
	 start solving instance: 25...
	 start solving instance: 143...
	 start solving instance: 92...
	 start solving instance: 95...
	 start solving instance: 126...
	 start solving instance: 56...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.169128630005688e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5852363264.0
		 entropy bonus: 0.2215288132429123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6171545600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6828749312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1691287399568507e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.169128630005688e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5852363264.0
		 entropy bonus: 0.2215288132429123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6171545600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6828749312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1691287399568507e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.169128630005688e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5852363264.0
		 entropy bonus: 0.2215288132429123
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6171545600.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6828749312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1691287399568507e+18 - Differentiable computation graph = True!
PPO iteration: 735/1000:
	 start solving instance: 126...
	 start solving instance: 25...
	 start solving instance: 72...
	 start solving instance: 56...
	 start solving instance: 33...
	 start solving instance: 130...
	 start solving instance: 127...
	 start solving instance: 95...
	 start solving instance: 134...
	 start solving instance: 138...
	 start solving instance: 34...
	 start solving instance: 143...
	 start solving instance: 136...
	 start solving instance: 61...
	 start solving instance: 111...
	 start solving instance: 15...
	 start solving instance: 92...
	 start solving instance: 5...
	 start solving instance: 93...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7728883888063775e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5788995584.0
		 entropy bonus: 0.22428691387176514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5776287232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6440211456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7728883888063775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7728883888063775e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5788995584.0
		 entropy bonus: 0.22428691387176514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5776287232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6440211456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7728883888063775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7728883888063775e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5788995584.0
		 entropy bonus: 0.22428691387176514
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5776287232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6440211456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7728883888063775e+18 - Differentiable computation graph = True!
PPO iteration: 736/1000:
	 start solving instance: 111...
	 start solving instance: 93...
	 start solving instance: 92...
	 start solving instance: 127...
	 start solving instance: 124...
	 start solving instance: 25...
	 start solving instance: 34...
	 start solving instance: 5...
	 start solving instance: 61...
	 start solving instance: 138...
	 start solving instance: 134...
	 start solving instance: 72...
	 start solving instance: 136...
	 start solving instance: 143...
	 start solving instance: 126...
	 start solving instance: 95...
	 start solving instance: 130...
	 start solving instance: 33...
	 start solving instance: 56...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.846363913039485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5792535040.0
		 entropy bonus: 0.21076937019824982
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823262208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6475836928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8463640779662295e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.846363913039485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5792535040.0
		 entropy bonus: 0.21076937019824982
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823262208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6475836928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8463640779662295e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.846363913039485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5792535040.0
		 entropy bonus: 0.21076937019824982
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5823262208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6475836928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8463640779662295e+18 - Differentiable computation graph = True!
PPO iteration: 737/1000:
	 start solving instance: 134...
	 start solving instance: 92...
	 start solving instance: 56...
	 start solving instance: 72...
	 start solving instance: 25...
	 start solving instance: 5...
	 start solving instance: 127...
	 start solving instance: 93...
	 start solving instance: 143...
	 start solving instance: 15...
	 start solving instance: 61...
	 start solving instance: 126...
	 start solving instance: 136...
	 start solving instance: 111...
	 start solving instance: 138...
	 start solving instance: 33...
	 start solving instance: 95...
	 start solving instance: 34...
	 start solving instance: 124...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.883859018765251e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5871570432.0
		 entropy bonus: 0.20970678329467773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5771993088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6753787392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.883859073740833e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.883859018765251e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5871570432.0
		 entropy bonus: 0.20970678329467773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5771993088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6753787392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.883859073740833e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.883859018765251e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5871570432.0
		 entropy bonus: 0.20970678329467773
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5771993088.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6753787392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.883859073740833e+18 - Differentiable computation graph = True!
PPO iteration: 738/1000:
	 start solving instance: 126...
	 start solving instance: 56...
	 start solving instance: 92...
	 start solving instance: 34...
	 start solving instance: 111...
	 start solving instance: 136...
	 start solving instance: 61...
	 start solving instance: 93...
	 start solving instance: 138...
	 start solving instance: 72...
	 start solving instance: 33...
	 start solving instance: 134...
	 start solving instance: 5...
	 start solving instance: 15...
	 start solving instance: 25...
	 start solving instance: 130...
	 start solving instance: 143...
	 start solving instance: 95...
	 start solving instance: 127...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.009019945792202e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5968562688.0
		 entropy bonus: 0.217246875166893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5898543104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7147990016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.009020055743365e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.009019945792202e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5968562688.0
		 entropy bonus: 0.217246875166893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5898543104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7147990016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.009020055743365e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.009019945792202e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5968562688.0
		 entropy bonus: 0.217246875166893
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5898543104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7147990016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.009020055743365e+18 - Differentiable computation graph = True!
PPO iteration: 739/1000:
	 start solving instance: 72...
	 start solving instance: 143...
	 start solving instance: 33...
	 start solving instance: 5...
	 start solving instance: 34...
	 start solving instance: 93...
	 start solving instance: 136...
	 start solving instance: 138...
	 start solving instance: 56...
	 start solving instance: 61...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 127...
	 start solving instance: 124...
	 start solving instance: 134...
	 start solving instance: 130...
	 start solving instance: 15...
	 start solving instance: 95...
	 start solving instance: 126...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.903562706939648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5799585280.0
		 entropy bonus: 0.22109508514404297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5892078080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6878227968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9035628718663926e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.903562706939648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5799585280.0
		 entropy bonus: 0.22109508514404297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5892078080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6878227968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9035628718663926e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.903562706939648e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5799585280.0
		 entropy bonus: 0.22109508514404297
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5892078080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6878227968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9035628718663926e+18 - Differentiable computation graph = True!
PPO iteration: 740/1000:
	 start solving instance: 127...
	 start solving instance: 25...
	 start solving instance: 92...
	 start solving instance: 130...
	 start solving instance: 61...
	 start solving instance: 34...
	 start solving instance: 143...
	 start solving instance: 138...
	 start solving instance: 93...
	 start solving instance: 124...
	 start solving instance: 126...
	 start solving instance: 136...
	 start solving instance: 56...
	 start solving instance: 15...
	 start solving instance: 111...
	 start solving instance: 72...
	 start solving instance: 95...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.952700321389609e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5879963136.0
		 entropy bonus: 0.22061076760292053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5977564672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6631378944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.952700321389609e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.952700321389609e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5879963136.0
		 entropy bonus: 0.22061076760292053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5977564672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6631378944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.952700321389609e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.952700321389609e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5879963136.0
		 entropy bonus: 0.22061076760292053
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5977564672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6631378944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.952700321389609e+18 - Differentiable computation graph = True!
PPO iteration: 741/1000:
	 New training batch of size 20...
	 start solving instance: 4...
	 start solving instance: 1...
	 start solving instance: 22...
	 start solving instance: 15...
	 start solving instance: 109...
	 start solving instance: 28...
	 start solving instance: 58...
	 start solving instance: 108...
	 start solving instance: 38...
	 start solving instance: 139...
	 start solving instance: 135...
	 start solving instance: 40...
	 start solving instance: 124...
	 start solving instance: 134...
	 start solving instance: 96...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 144...
	 start solving instance: 81...
	 start solving instance: 55...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5451595195823423e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5464924160.0
		 entropy bonus: 0.21252627670764923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5622021632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6271132672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.545159464606761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5451595195823423e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5464924160.0
		 entropy bonus: 0.21252627670764923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5622021632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6271132672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.545159464606761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5451595195823423e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5464924160.0
		 entropy bonus: 0.21252627670764923
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5622021632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6271132672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.545159464606761e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.0665531031277273e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5247719936.0
		 entropy bonus: 0.21436749398708344
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5145852416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5888461824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3066553048152145920.0000
PPO iteration: 742/1000:
	 start solving instance: 58...
	 start solving instance: 96...
	 start solving instance: 81...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 135...
	 start solving instance: 22...
	 start solving instance: 124...
	 start solving instance: 55...
	 start solving instance: 11...
	 start solving instance: 139...
	 start solving instance: 33...
	 start solving instance: 28...
	 start solving instance: 15...
	 start solving instance: 38...
	 start solving instance: 4...
	 start solving instance: 108...
	 start solving instance: 1...
	 start solving instance: 144...
	 start solving instance: 40...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.528346667379694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5449752064.0
		 entropy bonus: 0.2126503437757492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5581264384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6265464320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.528346832306438e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.528346667379694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5449752064.0
		 entropy bonus: 0.2126503437757492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5581264384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6265464320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.528346832306438e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.528346667379694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5449752064.0
		 entropy bonus: 0.2126503437757492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5581264384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6265464320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.528346832306438e+18 - Differentiable computation graph = True!
PPO iteration: 743/1000:
	 start solving instance: 1...
	 start solving instance: 134...
	 start solving instance: 11...
	 start solving instance: 144...
	 start solving instance: 135...
	 start solving instance: 108...
	 start solving instance: 40...
	 start solving instance: 96...
	 start solving instance: 81...
	 start solving instance: 109...
	 start solving instance: 28...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 15...
	 start solving instance: 124...
	 start solving instance: 139...
	 start solving instance: 58...
	 start solving instance: 4...
	 start solving instance: 33...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5131742865256874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5505346048.0
		 entropy bonus: 0.2079700082540512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5516627456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6433388544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.51317439647685e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5131742865256874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5505346048.0
		 entropy bonus: 0.2079700082540512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5516627456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6433388544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.51317439647685e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5131742865256874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5505346048.0
		 entropy bonus: 0.2079700082540512
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5516627456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6433388544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.51317439647685e+18 - Differentiable computation graph = True!
PPO iteration: 744/1000:
	 start solving instance: 15...
	 start solving instance: 55...
	 start solving instance: 124...
	 start solving instance: 134...
	 start solving instance: 108...
	 start solving instance: 22...
	 start solving instance: 38...
	 start solving instance: 109...
	 start solving instance: 1...
	 start solving instance: 33...
	 start solving instance: 28...
	 start solving instance: 4...
	 start solving instance: 139...
	 start solving instance: 135...
	 start solving instance: 81...
	 start solving instance: 40...
	 start solving instance: 96...
	 start solving instance: 144...
	 start solving instance: 11...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1424880149698445e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5424306176.0
		 entropy bonus: 0.21741953492164612
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5234728960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5933015552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.142488069945426e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1424880149698445e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5424306176.0
		 entropy bonus: 0.21741953492164612
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5234728960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5933015552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.142488069945426e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1424880149698445e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5424306176.0
		 entropy bonus: 0.21741953492164612
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5234728960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5933015552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.142488069945426e+18 - Differentiable computation graph = True!
PPO iteration: 745/1000:
	 start solving instance: 139...
	 start solving instance: 22...
	 start solving instance: 134...
	 start solving instance: 81...
	 start solving instance: 124...
	 start solving instance: 4...
	 start solving instance: 55...
	 start solving instance: 1...
	 start solving instance: 144...
	 start solving instance: 28...
	 start solving instance: 109...
	 start solving instance: 135...
	 start solving instance: 33...
	 start solving instance: 58...
	 start solving instance: 15...
	 start solving instance: 40...
	 start solving instance: 38...
	 start solving instance: 108...
	 start solving instance: 11...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5202181978178716e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5511060992.0
		 entropy bonus: 0.20495763421058655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5492443648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6259398656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.52021814284229e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5202181978178716e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5511060992.0
		 entropy bonus: 0.20495763421058655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5492443648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6259398656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.52021814284229e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5202181978178716e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5511060992.0
		 entropy bonus: 0.20495763421058655
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5492443648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6259398656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.52021814284229e+18 - Differentiable computation graph = True!
PPO iteration: 746/1000:
	 start solving instance: 124...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 38...
	 start solving instance: 33...
	 start solving instance: 81...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 96...
	 start solving instance: 139...
	 start solving instance: 28...
	 start solving instance: 4...
	 start solving instance: 40...
	 start solving instance: 11...
	 start solving instance: 1...
	 start solving instance: 144...
	 start solving instance: 15...
	 start solving instance: 135...
	 start solving instance: 108...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4934972065326825e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5471316992.0
		 entropy bonus: 0.2113046646118164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5530089984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419315200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.493497261508264e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4934972065326825e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5471316992.0
		 entropy bonus: 0.2113046646118164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5530089984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419315200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.493497261508264e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4934972065326825e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5471316992.0
		 entropy bonus: 0.2113046646118164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5530089984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6419315200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.493497261508264e+18 - Differentiable computation graph = True!
PPO iteration: 747/1000:
	 start solving instance: 109...
	 start solving instance: 55...
	 start solving instance: 22...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 1...
	 start solving instance: 135...
	 start solving instance: 58...
	 start solving instance: 81...
	 start solving instance: 38...
	 start solving instance: 40...
	 start solving instance: 134...
	 start solving instance: 144...
	 start solving instance: 139...
	 start solving instance: 15...
	 start solving instance: 96...
	 start solving instance: 28...
	 start solving instance: 108...
	 start solving instance: 33...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.470367660028461e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503981056.0
		 entropy bonus: 0.21118159592151642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5559547904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6295330816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.470367660028461e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.470367660028461e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503981056.0
		 entropy bonus: 0.21118159592151642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5559547904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6295330816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.470367660028461e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.470367660028461e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503981056.0
		 entropy bonus: 0.21118159592151642
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5559547904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6295330816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.470367660028461e+18 - Differentiable computation graph = True!
PPO iteration: 748/1000:
	 start solving instance: 144...
	 start solving instance: 38...
	 start solving instance: 108...
	 start solving instance: 139...
	 start solving instance: 11...
	 start solving instance: 15...
	 start solving instance: 109...
	 start solving instance: 1...
	 start solving instance: 81...
	 start solving instance: 96...
	 start solving instance: 33...
	 start solving instance: 58...
	 start solving instance: 22...
	 start solving instance: 134...
	 start solving instance: 4...
	 start solving instance: 40...
	 start solving instance: 55...
	 start solving instance: 135...
	 start solving instance: 28...
	 start solving instance: 124...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3462002517083685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5460113920.0
		 entropy bonus: 0.2123027890920639
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5370417152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6054639616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3462003616595313e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3462002517083685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5460113920.0
		 entropy bonus: 0.2123027890920639
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5370417152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6054639616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3462003616595313e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3462002517083685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5460113920.0
		 entropy bonus: 0.2123027890920639
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5370417152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6054639616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3462003616595313e+18 - Differentiable computation graph = True!
PPO iteration: 749/1000:
	 start solving instance: 15...
	 start solving instance: 109...
	 start solving instance: 139...
	 start solving instance: 58...
	 start solving instance: 81...
	 start solving instance: 134...
	 start solving instance: 135...
	 start solving instance: 38...
	 start solving instance: 28...
	 start solving instance: 144...
	 start solving instance: 96...
	 start solving instance: 108...
	 start solving instance: 124...
	 start solving instance: 40...
	 start solving instance: 1...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 55...
	 start solving instance: 4...
	 start solving instance: 22...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4626446903549624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5420002816.0
		 entropy bonus: 0.2202606201171875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5525680640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6118996480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4626446903549624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4626446903549624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5420002816.0
		 entropy bonus: 0.2202606201171875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5525680640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6118996480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4626446903549624e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4626446903549624e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5420002816.0
		 entropy bonus: 0.2202606201171875
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5525680640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6118996480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4626446903549624e+18 - Differentiable computation graph = True!
PPO iteration: 750/1000:
	 start solving instance: 96...
	 start solving instance: 135...
	 start solving instance: 144...
	 start solving instance: 11...
	 start solving instance: 38...
	 start solving instance: 109...
	 start solving instance: 58...
	 start solving instance: 28...
	 start solving instance: 124...
	 start solving instance: 1...
	 start solving instance: 4...
	 start solving instance: 22...
	 start solving instance: 40...
	 start solving instance: 81...
	 start solving instance: 55...
	 start solving instance: 33...
	 start solving instance: 108...
	 start solving instance: 15...
	 start solving instance: 139...
	 start solving instance: 134...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5546483049300492e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5456033280.0
		 entropy bonus: 0.20641875267028809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5603759616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6380660736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.554648249954468e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5546483049300492e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5456033280.0
		 entropy bonus: 0.20641875267028809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5603759616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6380660736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.554648249954468e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5546483049300492e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5456033280.0
		 entropy bonus: 0.20641875267028809
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5603759616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6380660736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.554648249954468e+18 - Differentiable computation graph = True!
PPO iteration: 751/1000:
	 New training batch of size 20...
	 start solving instance: 4...
	 start solving instance: 20...
	 start solving instance: 57...
	 start solving instance: 124...
	 start solving instance: 80...
	 start solving instance: 82...
	 start solving instance: 5...
	 start solving instance: 10...
	 start solving instance: 98...
	 start solving instance: 49...
	 start solving instance: 109...
	 start solving instance: 18...
	 start solving instance: 134...
	 start solving instance: 129...
	 start solving instance: 42...
	 start solving instance: 54...
	 start solving instance: 84...
	 start solving instance: 15...
	 start solving instance: 121...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.740057411405637e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5837099008.0
		 entropy bonus: 0.24596738815307617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5817672704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6071867904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7400575213568e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.740057411405637e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5837099008.0
		 entropy bonus: 0.24596738815307617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5817672704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6071867904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7400575213568e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.740057411405637e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5837099008.0
		 entropy bonus: 0.24596738815307617
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5817672704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6071867904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7400575213568e+18 - Differentiable computation graph = True!
PPO iteration: 752/1000:
	 start solving instance: 109...
	 start solving instance: 82...
	 start solving instance: 10...
	 start solving instance: 98...
	 start solving instance: 80...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 57...
	 start solving instance: 49...
	 start solving instance: 4...
	 start solving instance: 84...
	 start solving instance: 121...
	 start solving instance: 54...
	 start solving instance: 18...
	 start solving instance: 124...
	 start solving instance: 15...
	 start solving instance: 20...
	 start solving instance: 58...
	 start solving instance: 42...
	 start solving instance: 129...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.126640861880517e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5943701504.0
		 entropy bonus: 0.2435716688632965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6203887104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6609254912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1266408618805166e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.126640861880517e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5943701504.0
		 entropy bonus: 0.2435716688632965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6203887104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6609254912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1266408618805166e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.126640861880517e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5943701504.0
		 entropy bonus: 0.2435716688632965
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6203887104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6609254912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1266408618805166e+18 - Differentiable computation graph = True!
PPO iteration: 753/1000:
	 start solving instance: 109...
	 start solving instance: 121...
	 start solving instance: 124...
	 start solving instance: 58...
	 start solving instance: 134...
	 start solving instance: 57...
	 start solving instance: 49...
	 start solving instance: 5...
	 start solving instance: 129...
	 start solving instance: 18...
	 start solving instance: 4...
	 start solving instance: 10...
	 start solving instance: 15...
	 start solving instance: 84...
	 start solving instance: 42...
	 start solving instance: 80...
	 start solving instance: 54...
	 start solving instance: 82...
	 start solving instance: 98...
	 start solving instance: 20...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.797098315436052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927681536.0
		 entropy bonus: 0.23705677688121796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5841591296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6530231808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7970982604604703e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.797098315436052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927681536.0
		 entropy bonus: 0.23705677688121796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5841591296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6530231808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7970982604604703e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.797098315436052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927681536.0
		 entropy bonus: 0.23705677688121796
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5841591296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6530231808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7970982604604703e+18 - Differentiable computation graph = True!
PPO iteration: 754/1000:
	 start solving instance: 15...
	 start solving instance: 80...
	 start solving instance: 129...
	 start solving instance: 4...
	 start solving instance: 54...
	 start solving instance: 10...
	 start solving instance: 49...
	 start solving instance: 121...
	 start solving instance: 20...
	 start solving instance: 5...
	 start solving instance: 124...
	 start solving instance: 42...
	 start solving instance: 58...
	 start solving instance: 57...
	 start solving instance: 84...
	 start solving instance: 18...
	 start solving instance: 82...
	 start solving instance: 98...
	 start solving instance: 134...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.001886754155843e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5826324992.0
		 entropy bonus: 0.24544838070869446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6152268288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6448655872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0018866991802614e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.001886754155843e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5826324992.0
		 entropy bonus: 0.24544838070869446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6152268288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6448655872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0018866991802614e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.001886754155843e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5826324992.0
		 entropy bonus: 0.24544838070869446
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6152268288.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6448655872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0018866991802614e+18 - Differentiable computation graph = True!
PPO iteration: 755/1000:
	 start solving instance: 18...
	 start solving instance: 124...
	 start solving instance: 82...
	 start solving instance: 15...
	 start solving instance: 49...
	 start solving instance: 42...
	 start solving instance: 20...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 4...
	 start solving instance: 121...
	 start solving instance: 134...
	 start solving instance: 84...
	 start solving instance: 57...
	 start solving instance: 109...
	 start solving instance: 54...
	 start solving instance: 5...
	 start solving instance: 98...
	 start solving instance: 129...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.882783256588635e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5883779072.0
		 entropy bonus: 0.2314862459897995
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974241280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707522560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.882783201613054e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.882783256588635e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5883779072.0
		 entropy bonus: 0.2314862459897995
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974241280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707522560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.882783201613054e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.882783256588635e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5883779072.0
		 entropy bonus: 0.2314862459897995
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5974241280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707522560.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.882783201613054e+18 - Differentiable computation graph = True!
PPO iteration: 756/1000:
	 start solving instance: 18...
	 start solving instance: 82...
	 start solving instance: 54...
	 start solving instance: 124...
	 start solving instance: 15...
	 start solving instance: 84...
	 start solving instance: 80...
	 start solving instance: 98...
	 start solving instance: 121...
	 start solving instance: 20...
	 start solving instance: 134...
	 start solving instance: 58...
	 start solving instance: 5...
	 start solving instance: 4...
	 start solving instance: 57...
	 start solving instance: 129...
	 start solving instance: 42...
	 start solving instance: 49...
	 start solving instance: 10...
	 start solving instance: 109...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6695035094698557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5868342272.0
		 entropy bonus: 0.22817257046699524
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5690439168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6302263296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.669503509469856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6695035094698557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5868342272.0
		 entropy bonus: 0.22817257046699524
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5690439168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6302263296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.669503509469856e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6695035094698557e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5868342272.0
		 entropy bonus: 0.22817257046699524
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5690439168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6302263296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.669503509469856e+18 - Differentiable computation graph = True!
PPO iteration: 757/1000:
	 start solving instance: 109...
	 start solving instance: 84...
	 start solving instance: 49...
	 start solving instance: 134...
	 start solving instance: 42...
	 start solving instance: 129...
	 start solving instance: 54...
	 start solving instance: 10...
	 start solving instance: 82...
	 start solving instance: 98...
	 start solving instance: 57...
	 start solving instance: 18...
	 start solving instance: 58...
	 start solving instance: 80...
	 start solving instance: 121...
	 start solving instance: 5...
	 start solving instance: 15...
	 start solving instance: 20...
	 start solving instance: 124...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.097661693614201e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5948098048.0
		 entropy bonus: 0.24409131705760956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6221827072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6482071552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0976618585409454e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.097661693614201e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5948098048.0
		 entropy bonus: 0.24409131705760956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6221827072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6482071552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0976618585409454e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.097661693614201e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5948098048.0
		 entropy bonus: 0.24409131705760956
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6221827072.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6482071552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0976618585409454e+18 - Differentiable computation graph = True!
PPO iteration: 758/1000:
	 start solving instance: 42...
	 start solving instance: 4...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 109...
	 start solving instance: 15...
	 start solving instance: 18...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 129...
	 start solving instance: 57...
	 start solving instance: 82...
	 start solving instance: 54...
	 start solving instance: 124...
	 start solving instance: 121...
	 start solving instance: 20...
	 start solving instance: 49...
	 start solving instance: 98...
	 start solving instance: 84...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.747799732483785e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5829239808.0
		 entropy bonus: 0.23630717396736145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5863863296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6173986816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7477997324837847e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.747799732483785e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5829239808.0
		 entropy bonus: 0.23630717396736145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5863863296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6173986816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7477997324837847e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.747799732483785e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5829239808.0
		 entropy bonus: 0.23630717396736145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5863863296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6173986816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7477997324837847e+18 - Differentiable computation graph = True!
PPO iteration: 759/1000:
	 start solving instance: 98...
	 start solving instance: 109...
	 start solving instance: 5...
	 start solving instance: 10...
	 start solving instance: 15...
	 start solving instance: 58...
	 start solving instance: 121...
	 start solving instance: 129...
	 start solving instance: 4...
	 start solving instance: 134...
	 start solving instance: 20...
	 start solving instance: 82...
	 start solving instance: 18...
	 start solving instance: 57...
	 start solving instance: 42...
	 start solving instance: 80...
	 start solving instance: 54...
	 start solving instance: 84...
	 start solving instance: 124...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6811389813196325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5880450048.0
		 entropy bonus: 0.23755769431591034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5720926720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6052280832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6811390912707953e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6811389813196325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5880450048.0
		 entropy bonus: 0.23755769431591034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5720926720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6052280832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6811390912707953e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6811389813196325e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5880450048.0
		 entropy bonus: 0.23755769431591034
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5720926720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6052280832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6811390912707953e+18 - Differentiable computation graph = True!
PPO iteration: 760/1000:
	 start solving instance: 18...
	 start solving instance: 15...
	 start solving instance: 82...
	 start solving instance: 5...
	 start solving instance: 134...
	 start solving instance: 54...
	 start solving instance: 98...
	 start solving instance: 58...
	 start solving instance: 4...
	 start solving instance: 84...
	 start solving instance: 129...
	 start solving instance: 49...
	 start solving instance: 121...
	 start solving instance: 80...
	 start solving instance: 10...
	 start solving instance: 20...
	 start solving instance: 57...
	 start solving instance: 124...
	 start solving instance: 109...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.987638402873819e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981993472.0
		 entropy bonus: 0.24309003353118896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6104019968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6475569664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.987638402873819e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.987638402873819e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981993472.0
		 entropy bonus: 0.24309003353118896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6104019968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6475569664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.987638402873819e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.987638402873819e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5981993472.0
		 entropy bonus: 0.24309003353118896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6104019968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6475569664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.987638402873819e+18 - Differentiable computation graph = True!
PPO iteration: 761/1000:
	 New training batch of size 20...
	 start solving instance: 27...
	 start solving instance: 42...
	 start solving instance: 78...
	 start solving instance: 144...
	 start solving instance: 36...
	 start solving instance: 92...
	 start solving instance: 20...
	 start solving instance: 140...
	 start solving instance: 34...
	 start solving instance: 64...
	 start solving instance: 58...
	 start solving instance: 138...
	 start solving instance: 111...
	 start solving instance: 101...
	 start solving instance: 2...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 131...
	 start solving instance: 59...
	 start solving instance: 127...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8390424850124505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763908608.0
		 entropy bonus: 0.21767807006835938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657998848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6869728256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.839042430036869e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8390424850124505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763908608.0
		 entropy bonus: 0.21767807006835938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657998848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6869728256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.839042430036869e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8390424850124505e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763908608.0
		 entropy bonus: 0.21767807006835938
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657998848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6869728256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.839042430036869e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.165790624604278e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5317478400.0
		 entropy bonus: 0.2155051976442337
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5249297408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6203287552.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3165790569628696576.0000
PPO iteration: 762/1000:
	 start solving instance: 138...
	 start solving instance: 34...
	 start solving instance: 30...
	 start solving instance: 42...
	 start solving instance: 144...
	 start solving instance: 2...
	 start solving instance: 36...
	 start solving instance: 59...
	 start solving instance: 20...
	 start solving instance: 58...
	 start solving instance: 140...
	 start solving instance: 131...
	 start solving instance: 27...
	 start solving instance: 127...
	 start solving instance: 64...
	 start solving instance: 72...
	 start solving instance: 78...
	 start solving instance: 92...
	 start solving instance: 101...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.94517526380911e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5864177152.0
		 entropy bonus: 0.2241181880235672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5827410432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529349632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.94517526380911e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.94517526380911e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5864177152.0
		 entropy bonus: 0.2241181880235672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5827410432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529349632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.94517526380911e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.94517526380911e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5864177152.0
		 entropy bonus: 0.2241181880235672
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5827410432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529349632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.94517526380911e+18 - Differentiable computation graph = True!
PPO iteration: 763/1000:
	 start solving instance: 64...
	 start solving instance: 140...
	 start solving instance: 138...
	 start solving instance: 20...
	 start solving instance: 131...
	 start solving instance: 27...
	 start solving instance: 72...
	 start solving instance: 92...
	 start solving instance: 34...
	 start solving instance: 144...
	 start solving instance: 36...
	 start solving instance: 111...
	 start solving instance: 58...
	 start solving instance: 101...
	 start solving instance: 59...
	 start solving instance: 42...
	 start solving instance: 127...
	 start solving instance: 2...
	 start solving instance: 30...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.934945847428933e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5803769344.0
		 entropy bonus: 0.2265474647283554
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842411008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6868555264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.934945957380096e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.934945847428933e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802135552.0
		 entropy bonus: 0.22526386380195618
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842411008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6868555264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.934945957380096e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.934945847428933e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5803769344.0
		 entropy bonus: 0.2265474647283554
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5842411008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6868555264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.934945957380096e+18 - Differentiable computation graph = True!
PPO iteration: 764/1000:
	 start solving instance: 20...
	 start solving instance: 36...
	 start solving instance: 127...
	 start solving instance: 59...
	 start solving instance: 58...
	 start solving instance: 64...
	 start solving instance: 78...
	 start solving instance: 42...
	 start solving instance: 30...
	 start solving instance: 111...
	 start solving instance: 92...
	 start solving instance: 140...
	 start solving instance: 138...
	 start solving instance: 131...
	 start solving instance: 2...
	 start solving instance: 144...
	 start solving instance: 72...
	 start solving instance: 27...
	 start solving instance: 34...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8552044263314555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745496576.0
		 entropy bonus: 0.22443853318691254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5811104768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6597353984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8552044263314555e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8552044263314555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745496576.0
		 entropy bonus: 0.22443853318691254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5811104768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6597353984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8552044263314555e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8552044263314555e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745496576.0
		 entropy bonus: 0.22443853318691254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5811104768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6597353984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8552044263314555e+18 - Differentiable computation graph = True!
PPO iteration: 765/1000:
	 start solving instance: 27...
	 start solving instance: 131...
	 start solving instance: 2...
	 start solving instance: 101...
	 start solving instance: 138...
	 start solving instance: 111...
	 start solving instance: 58...
	 start solving instance: 78...
	 start solving instance: 20...
	 start solving instance: 59...
	 start solving instance: 42...
	 start solving instance: 140...
	 start solving instance: 127...
	 start solving instance: 34...
	 start solving instance: 30...
	 start solving instance: 36...
	 start solving instance: 72...
	 start solving instance: 144...
	 start solving instance: 92...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.676836592320145e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5721337344.0
		 entropy bonus: 0.2202320098876953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5635617792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6838451712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676836702271308e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.676836592320145e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5721337344.0
		 entropy bonus: 0.2202320098876953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5635617792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6838451712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676836702271308e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.676836592320145e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5721337344.0
		 entropy bonus: 0.2202320098876953
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5635617792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6838451712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676836702271308e+18 - Differentiable computation graph = True!
PPO iteration: 766/1000:
	 start solving instance: 36...
	 start solving instance: 138...
	 start solving instance: 20...
	 start solving instance: 27...
	 start solving instance: 101...
	 start solving instance: 72...
	 start solving instance: 42...
	 start solving instance: 111...
	 start solving instance: 64...
	 start solving instance: 30...
	 start solving instance: 59...
	 start solving instance: 34...
	 start solving instance: 140...
	 start solving instance: 58...
	 start solving instance: 127...
	 start solving instance: 144...
	 start solving instance: 2...
	 start solving instance: 92...
	 start solving instance: 131...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.885016144802323e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5850091008.0
		 entropy bonus: 0.22582335770130157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774078976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6594838016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.885016309729067e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.885016144802323e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5850091008.0
		 entropy bonus: 0.22582335770130157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774078976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6594838016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.885016309729067e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.885016144802323e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5850091008.0
		 entropy bonus: 0.22582335770130157
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774078976.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6594838016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.885016309729067e+18 - Differentiable computation graph = True!
PPO iteration: 767/1000:
	 start solving instance: 58...
	 start solving instance: 64...
	 start solving instance: 111...
	 start solving instance: 42...
	 start solving instance: 27...
	 start solving instance: 72...
	 start solving instance: 20...
	 start solving instance: 138...
	 start solving instance: 30...
	 start solving instance: 59...
	 start solving instance: 36...
	 start solving instance: 127...
	 start solving instance: 131...
	 start solving instance: 144...
	 start solving instance: 140...
	 start solving instance: 34...
	 start solving instance: 78...
	 start solving instance: 101...
	 start solving instance: 92...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8095386297973604e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5754007040.0
		 entropy bonus: 0.22608256340026855
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5741578752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6322423296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.809538684772942e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8095386297973604e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5754007040.0
		 entropy bonus: 0.22608256340026855
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5741578752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6322423296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.809538684772942e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8095386297973604e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5754007040.0
		 entropy bonus: 0.22608256340026855
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5741578752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6322423296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.809538684772942e+18 - Differentiable computation graph = True!
PPO iteration: 768/1000:
	 start solving instance: 101...
	 start solving instance: 58...
	 start solving instance: 144...
	 start solving instance: 127...
	 start solving instance: 131...
	 start solving instance: 30...
	 start solving instance: 20...
	 start solving instance: 140...
	 start solving instance: 92...
	 start solving instance: 72...
	 start solving instance: 27...
	 start solving instance: 138...
	 start solving instance: 64...
	 start solving instance: 36...
	 start solving instance: 34...
	 start solving instance: 111...
	 start solving instance: 59...
	 start solving instance: 78...
	 start solving instance: 42...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.732759293025111e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745923584.0
		 entropy bonus: 0.21231472492218018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657251328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6488256512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.73275923804953e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.732759293025111e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745923584.0
		 entropy bonus: 0.21231472492218018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657251328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6488256512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.73275923804953e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.732759293025111e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5745923584.0
		 entropy bonus: 0.21231472492218018
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657251328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6488256512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.73275923804953e+18 - Differentiable computation graph = True!
PPO iteration: 769/1000:
	 start solving instance: 144...
	 start solving instance: 36...
	 start solving instance: 30...
	 start solving instance: 127...
	 start solving instance: 72...
	 start solving instance: 59...
	 start solving instance: 131...
	 start solving instance: 140...
	 start solving instance: 58...
	 start solving instance: 92...
	 start solving instance: 64...
	 start solving instance: 2...
	 start solving instance: 34...
	 start solving instance: 101...
	 start solving instance: 138...
	 start solving instance: 42...
	 start solving instance: 20...
	 start solving instance: 111...
	 start solving instance: 78...
	 start solving instance: 27...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.862579510525926e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834097664.0
		 entropy bonus: 0.2229164093732834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5677142016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660725248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.86257967545267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.862579510525926e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834097664.0
		 entropy bonus: 0.2229164093732834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5677142016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660725248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.86257967545267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.862579510525926e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834097664.0
		 entropy bonus: 0.2229164093732834
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5677142016.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6660725248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.86257967545267e+18 - Differentiable computation graph = True!
PPO iteration: 770/1000:
	 start solving instance: 138...
	 start solving instance: 42...
	 start solving instance: 34...
	 start solving instance: 36...
	 start solving instance: 58...
	 start solving instance: 92...
	 start solving instance: 64...
	 start solving instance: 20...
	 start solving instance: 140...
	 start solving instance: 127...
	 start solving instance: 144...
	 start solving instance: 59...
	 start solving instance: 131...
	 start solving instance: 101...
	 start solving instance: 27...
	 start solving instance: 30...
	 start solving instance: 111...
	 start solving instance: 72...
	 start solving instance: 2...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.757247176194287e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5772388864.0
		 entropy bonus: 0.21498362720012665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5669268480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6476066304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.75724728614545e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.757247176194287e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5772388864.0
		 entropy bonus: 0.21498362720012665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5669268480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6476066304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.75724728614545e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.757247176194287e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5772388864.0
		 entropy bonus: 0.21498362720012665
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5669268480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6476066304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.75724728614545e+18 - Differentiable computation graph = True!
PPO iteration: 771/1000:
	 New training batch of size 20...
	 start solving instance: 120...
	 start solving instance: 109...
	 start solving instance: 33...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 98...
	 start solving instance: 49...
	 start solving instance: 45...
	 start solving instance: 78...
	 start solving instance: 58...
	 start solving instance: 2...
	 start solving instance: 82...
	 start solving instance: 56...
	 start solving instance: 97...
	 start solving instance: 130...
	 start solving instance: 17...
	 start solving instance: 96...
	 start solving instance: 131...
	 start solving instance: 115...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.778413214833626e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5723090944.0
		 entropy bonus: 0.2466004341840744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5873304576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373884928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.778413159858045e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.778413214833626e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5723090944.0
		 entropy bonus: 0.2466004341840744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5873304576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373884928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.778413159858045e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.778413214833626e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5723090944.0
		 entropy bonus: 0.2466004341840744
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5873304576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373884928.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.778413159858045e+18 - Differentiable computation graph = True!
PPO iteration: 772/1000:
	 start solving instance: 49...
	 start solving instance: 45...
	 start solving instance: 120...
	 start solving instance: 109...
	 start solving instance: 2...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 98...
	 start solving instance: 78...
	 start solving instance: 97...
	 start solving instance: 58...
	 start solving instance: 33...
	 start solving instance: 17...
	 start solving instance: 82...
	 start solving instance: 96...
	 start solving instance: 131...
	 start solving instance: 115...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6537039671833657e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785396736.0
		 entropy bonus: 0.2443668693304062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5726387712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509367808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6537040771345285e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6537039671833657e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785396736.0
		 entropy bonus: 0.2443668693304062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5726387712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509367808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6537040771345285e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6537039671833657e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785396736.0
		 entropy bonus: 0.2443668693304062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5726387712.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509367808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6537040771345285e+18 - Differentiable computation graph = True!
PPO iteration: 773/1000:
	 start solving instance: 58...
	 start solving instance: 45...
	 start solving instance: 56...
	 start solving instance: 115...
	 start solving instance: 120...
	 start solving instance: 98...
	 start solving instance: 131...
	 start solving instance: 60...
	 start solving instance: 17...
	 start solving instance: 82...
	 start solving instance: 33...
	 start solving instance: 96...
	 start solving instance: 2...
	 start solving instance: 49...
	 start solving instance: 78...
	 start solving instance: 93...
	 start solving instance: 109...
	 start solving instance: 130...
	 start solving instance: 97...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6666968960887947e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5706445824.0
		 entropy bonus: 0.24181197583675385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5807480320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6425864192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6666970060399575e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6666968960887947e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5706445824.0
		 entropy bonus: 0.24181197583675385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5807480320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6425864192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6666970060399575e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6666968960887947e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5706445824.0
		 entropy bonus: 0.24181197583675385
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5807480320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6425864192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6666970060399575e+18 - Differentiable computation graph = True!
PPO iteration: 774/1000:
	 start solving instance: 49...
	 start solving instance: 45...
	 start solving instance: 33...
	 start solving instance: 115...
	 start solving instance: 97...
	 start solving instance: 96...
	 start solving instance: 17...
	 start solving instance: 120...
	 start solving instance: 130...
	 start solving instance: 78...
	 start solving instance: 60...
	 start solving instance: 2...
	 start solving instance: 93...
	 start solving instance: 56...
	 start solving instance: 98...
	 start solving instance: 58...
	 start solving instance: 107...
	 start solving instance: 109...
	 start solving instance: 82...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.844226462435089e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5804849664.0
		 entropy bonus: 0.24068918824195862
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5900619264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624851968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844226627361833e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.844226462435089e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5804849664.0
		 entropy bonus: 0.24068918824195862
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5900619264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624851968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844226627361833e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.844226462435089e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5804849664.0
		 entropy bonus: 0.24068918824195862
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5900619264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6624851968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.844226627361833e+18 - Differentiable computation graph = True!
PPO iteration: 775/1000:
	 start solving instance: 93...
	 start solving instance: 49...
	 start solving instance: 33...
	 start solving instance: 120...
	 start solving instance: 2...
	 start solving instance: 131...
	 start solving instance: 78...
	 start solving instance: 107...
	 start solving instance: 17...
	 start solving instance: 82...
	 start solving instance: 98...
	 start solving instance: 56...
	 start solving instance: 96...
	 start solving instance: 109...
	 start solving instance: 58...
	 start solving instance: 60...
	 start solving instance: 45...
	 start solving instance: 115...
	 start solving instance: 97...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.698936116331466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5739741184.0
		 entropy bonus: 0.23809514939785004
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5708508672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268147200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6989360613558845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.698936116331466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5739741184.0
		 entropy bonus: 0.23809514939785004
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5708508672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268147200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6989360613558845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.698936116331466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5739741184.0
		 entropy bonus: 0.23809514939785004
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5708508672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268147200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6989360613558845e+18 - Differentiable computation graph = True!
PPO iteration: 776/1000:
	 start solving instance: 107...
	 start solving instance: 109...
	 start solving instance: 60...
	 start solving instance: 49...
	 start solving instance: 33...
	 start solving instance: 93...
	 start solving instance: 115...
	 start solving instance: 96...
	 start solving instance: 82...
	 start solving instance: 97...
	 start solving instance: 17...
	 start solving instance: 56...
	 start solving instance: 78...
	 start solving instance: 45...
	 start solving instance: 58...
	 start solving instance: 120...
	 start solving instance: 131...
	 start solving instance: 98...
	 start solving instance: 130...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.625836844977383e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5633581056.0
		 entropy bonus: 0.25188249349594116
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718552576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6379092992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.625836954928546e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.625836844977383e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5633581056.0
		 entropy bonus: 0.25188249349594116
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718552576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6379092992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.625836954928546e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.625836844977383e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5633581056.0
		 entropy bonus: 0.25188249349594116
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718552576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6379092992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.625836954928546e+18 - Differentiable computation graph = True!
PPO iteration: 777/1000:
	 start solving instance: 2...
	 start solving instance: 58...
	 start solving instance: 33...
	 start solving instance: 96...
	 start solving instance: 115...
	 start solving instance: 98...
	 start solving instance: 131...
	 start solving instance: 60...
	 start solving instance: 17...
	 start solving instance: 78...
	 start solving instance: 49...
	 start solving instance: 130...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 107...
	 start solving instance: 93...
	 start solving instance: 56...
	 start solving instance: 45...
	 start solving instance: 120...
	 start solving instance: 82...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.723361107435533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5687111168.0
		 entropy bonus: 0.24486325681209564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5835029504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726238720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7233611624111145e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.723361107435533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5687111168.0
		 entropy bonus: 0.24486325681209564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5835029504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726238720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7233611624111145e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.723361107435533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5687111168.0
		 entropy bonus: 0.24486325681209564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5835029504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6726238720.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7233611624111145e+18 - Differentiable computation graph = True!
PPO iteration: 778/1000:
	 start solving instance: 97...
	 start solving instance: 120...
	 start solving instance: 96...
	 start solving instance: 17...
	 start solving instance: 98...
	 start solving instance: 49...
	 start solving instance: 60...
	 start solving instance: 58...
	 start solving instance: 93...
	 start solving instance: 131...
	 start solving instance: 130...
	 start solving instance: 78...
	 start solving instance: 107...
	 start solving instance: 45...
	 start solving instance: 2...
	 start solving instance: 109...
	 start solving instance: 82...
	 start solving instance: 56...
	 start solving instance: 33...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6724502006322954e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5731872768.0
		 entropy bonus: 0.24445901811122894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5712052224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6700434432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6724502006322954e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6724502006322954e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5731872768.0
		 entropy bonus: 0.24445901811122894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5712052224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6700434432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6724502006322954e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6724502006322954e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5731872768.0
		 entropy bonus: 0.24445901811122894
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5712052224.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6700434432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6724502006322954e+18 - Differentiable computation graph = True!
PPO iteration: 779/1000:
	 start solving instance: 49...
	 start solving instance: 98...
	 start solving instance: 17...
	 start solving instance: 109...
	 start solving instance: 120...
	 start solving instance: 58...
	 start solving instance: 2...
	 start solving instance: 78...
	 start solving instance: 93...
	 start solving instance: 130...
	 start solving instance: 82...
	 start solving instance: 96...
	 start solving instance: 115...
	 start solving instance: 60...
	 start solving instance: 33...
	 start solving instance: 131...
	 start solving instance: 107...
	 start solving instance: 45...
	 start solving instance: 97...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.897196534614825e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5742681600.0
		 entropy bonus: 0.2440514862537384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5966788096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741292544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8971966995415695e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.897196534614825e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5742681600.0
		 entropy bonus: 0.2440514862537384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5966788096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741292544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8971966995415695e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.897196534614825e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5742681600.0
		 entropy bonus: 0.2440514862537384
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5966788096.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6741292544.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8971966995415695e+18 - Differentiable computation graph = True!
PPO iteration: 780/1000:
	 start solving instance: 109...
	 start solving instance: 45...
	 start solving instance: 56...
	 start solving instance: 82...
	 start solving instance: 33...
	 start solving instance: 2...
	 start solving instance: 130...
	 start solving instance: 98...
	 start solving instance: 49...
	 start solving instance: 93...
	 start solving instance: 58...
	 start solving instance: 96...
	 start solving instance: 60...
	 start solving instance: 115...
	 start solving instance: 120...
	 start solving instance: 107...
	 start solving instance: 17...
	 start solving instance: 97...
	 start solving instance: 131...
	 start solving instance: 78...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.507266610549647e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5712768512.0
		 entropy bonus: 0.22624905407428741
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518883328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6175538176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5072667205008097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.507266610549647e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5712768512.0
		 entropy bonus: 0.22624905407428741
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518883328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6175538176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5072667205008097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.507266610549647e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5712768512.0
		 entropy bonus: 0.22624905407428741
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5518883328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6175538176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5072667205008097e+18 - Differentiable computation graph = True!
PPO iteration: 781/1000:
	 New training batch of size 20...
	 start solving instance: 41...
	 start solving instance: 89...
	 start solving instance: 55...
	 start solving instance: 125...
	 start solving instance: 21...
	 start solving instance: 34...
	 start solving instance: 2...
	 start solving instance: 113...
	 start solving instance: 99...
	 start solving instance: 49...
	 start solving instance: 33...
	 start solving instance: 76...
	 start solving instance: 137...
	 start solving instance: 84...
	 start solving instance: 98...
	 start solving instance: 80...
	 start solving instance: 11...
	 start solving instance: 73...
	 start solving instance: 112...
	 start solving instance: 128...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.399780660843328e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6131484160.0
		 entropy bonus: 0.21878643333911896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6395674112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7162734080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3997807158189097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.399780660843328e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6131484160.0
		 entropy bonus: 0.21878643333911896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6395674112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7162734080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3997807158189097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.399780660843328e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6131484160.0
		 entropy bonus: 0.21878643333911896
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6395674112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7162734080.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3997807158189097e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.1839514780625797e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5268876800.0
		 entropy bonus: 0.21032701432704926
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5233783808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6272347136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3183951478062579712.0000
PPO iteration: 782/1000:
	 start solving instance: 55...
	 start solving instance: 11...
	 start solving instance: 84...
	 start solving instance: 125...
	 start solving instance: 73...
	 start solving instance: 89...
	 start solving instance: 2...
	 start solving instance: 137...
	 start solving instance: 21...
	 start solving instance: 112...
	 start solving instance: 33...
	 start solving instance: 41...
	 start solving instance: 34...
	 start solving instance: 128...
	 start solving instance: 76...
	 start solving instance: 99...
	 start solving instance: 98...
	 start solving instance: 49...
	 start solving instance: 113...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.988448083236513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021476864.0
		 entropy bonus: 0.21797768771648407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6060450816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6737741824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.988448193187676e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.988448083236513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021476864.0
		 entropy bonus: 0.21797768771648407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6060450816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6737741824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.988448193187676e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.988448083236513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021476864.0
		 entropy bonus: 0.21797768771648407
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6060450816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6737741824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.988448193187676e+18 - Differentiable computation graph = True!
PPO iteration: 783/1000:
	 start solving instance: 80...
	 start solving instance: 41...
	 start solving instance: 89...
	 start solving instance: 128...
	 start solving instance: 137...
	 start solving instance: 11...
	 start solving instance: 113...
	 start solving instance: 125...
	 start solving instance: 73...
	 start solving instance: 98...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 84...
	 start solving instance: 112...
	 start solving instance: 2...
	 start solving instance: 33...
	 start solving instance: 21...
	 start solving instance: 49...
	 start solving instance: 34...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3645848538335674e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6191786496.0
		 entropy bonus: 0.22137652337551117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6293437952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7314733056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.364584798857986e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3645848538335674e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6191786496.0
		 entropy bonus: 0.22137652337551117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6293437952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7314733056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.364584798857986e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3645848538335674e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6191786496.0
		 entropy bonus: 0.22137652337551117
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6293437952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7314733056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.364584798857986e+18 - Differentiable computation graph = True!
PPO iteration: 784/1000:
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 2...
	 start solving instance: 11...
	 start solving instance: 80...
	 start solving instance: 137...
	 start solving instance: 34...
	 start solving instance: 55...
	 start solving instance: 41...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 125...
	 start solving instance: 76...
	 start solving instance: 113...
	 start solving instance: 98...
	 start solving instance: 128...
	 start solving instance: 99...
	 start solving instance: 21...
	 start solving instance: 73...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2868779690521264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6134659072.0
		 entropy bonus: 0.210741326212883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6327920128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7317733376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.286877914076545e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2868779690521264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6134659072.0
		 entropy bonus: 0.210741326212883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6327920128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7317733376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.286877914076545e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2868779690521264e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6134659072.0
		 entropy bonus: 0.210741326212883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6327920128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7317733376.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.286877914076545e+18 - Differentiable computation graph = True!
PPO iteration: 785/1000:
	 start solving instance: 137...
	 start solving instance: 73...
	 start solving instance: 34...
	 start solving instance: 55...
	 start solving instance: 128...
	 start solving instance: 98...
	 start solving instance: 113...
	 start solving instance: 41...
	 start solving instance: 76...
	 start solving instance: 2...
	 start solving instance: 84...
	 start solving instance: 49...
	 start solving instance: 33...
	 start solving instance: 112...
	 start solving instance: 11...
	 start solving instance: 99...
	 start solving instance: 21...
	 start solving instance: 80...
	 start solving instance: 125...
	 start solving instance: 89...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0601797820279685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048742912.0
		 entropy bonus: 0.21823549270629883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6010644992.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6908946944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0601797820279685e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0601797820279685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048742912.0
		 entropy bonus: 0.21823549270629883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6010644992.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6908946944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0601797820279685e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0601797820279685e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048742912.0
		 entropy bonus: 0.21823549270629883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6010644992.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6908946944.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0601797820279685e+18 - Differentiable computation graph = True!
PPO iteration: 786/1000:
	 start solving instance: 89...
	 start solving instance: 2...
	 start solving instance: 73...
	 start solving instance: 113...
	 start solving instance: 76...
	 start solving instance: 99...
	 start solving instance: 11...
	 start solving instance: 49...
	 start solving instance: 80...
	 start solving instance: 84...
	 start solving instance: 125...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 98...
	 start solving instance: 21...
	 start solving instance: 128...
	 start solving instance: 112...
	 start solving instance: 137...
	 start solving instance: 34...
	 start solving instance: 33...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.387970586547061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203584000.0
		 entropy bonus: 0.21860435605049133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6400686592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7104380416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3879705865470607e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.387970586547061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203584000.0
		 entropy bonus: 0.21860435605049133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6400686592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7104380416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3879705865470607e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.387970586547061e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203584000.0
		 entropy bonus: 0.21860435605049133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6400686592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7104380416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3879705865470607e+18 - Differentiable computation graph = True!
PPO iteration: 787/1000:
	 start solving instance: 98...
	 start solving instance: 73...
	 start solving instance: 89...
	 start solving instance: 41...
	 start solving instance: 112...
	 start solving instance: 76...
	 start solving instance: 33...
	 start solving instance: 80...
	 start solving instance: 11...
	 start solving instance: 34...
	 start solving instance: 125...
	 start solving instance: 2...
	 start solving instance: 55...
	 start solving instance: 128...
	 start solving instance: 99...
	 start solving instance: 84...
	 start solving instance: 21...
	 start solving instance: 113...
	 start solving instance: 137...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.0506144706709684e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6017820160.0
		 entropy bonus: 0.2184940129518509
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6044321792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6863976960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.050614580622131e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.0506144706709684e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6017820160.0
		 entropy bonus: 0.2184940129518509
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6044321792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6863976960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.050614580622131e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.0506144706709684e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6017820160.0
		 entropy bonus: 0.2184940129518509
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6044321792.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6863976960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.050614580622131e+18 - Differentiable computation graph = True!
PPO iteration: 788/1000:
	 start solving instance: 41...
	 start solving instance: 21...
	 start solving instance: 34...
	 start solving instance: 11...
	 start solving instance: 125...
	 start solving instance: 112...
	 start solving instance: 55...
	 start solving instance: 137...
	 start solving instance: 49...
	 start solving instance: 98...
	 start solving instance: 76...
	 start solving instance: 80...
	 start solving instance: 33...
	 start solving instance: 89...
	 start solving instance: 113...
	 start solving instance: 99...
	 start solving instance: 128...
	 start solving instance: 84...
	 start solving instance: 73...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.462738696649782e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142035456.0
		 entropy bonus: 0.2288929969072342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6399988736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7320453120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4627387516253635e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.462738696649782e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142035456.0
		 entropy bonus: 0.2288929969072342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6399988736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7320453120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4627387516253635e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.462738696649782e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142035456.0
		 entropy bonus: 0.2288929969072342
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6399988736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7320453120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4627387516253635e+18 - Differentiable computation graph = True!
PPO iteration: 789/1000:
	 start solving instance: 2...
	 start solving instance: 89...
	 start solving instance: 84...
	 start solving instance: 137...
	 start solving instance: 80...
	 start solving instance: 128...
	 start solving instance: 41...
	 start solving instance: 33...
	 start solving instance: 98...
	 start solving instance: 49...
	 start solving instance: 113...
	 start solving instance: 99...
	 start solving instance: 73...
	 start solving instance: 125...
	 start solving instance: 34...
	 start solving instance: 21...
	 start solving instance: 55...
	 start solving instance: 11...
	 start solving instance: 112...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.465062184621598e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6192268288.0
		 entropy bonus: 0.22360287606716156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6396747264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7291736064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.465062294572761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.465062184621598e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6192268288.0
		 entropy bonus: 0.22360287606716156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6396747264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7291736064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.465062294572761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.465062184621598e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6192268288.0
		 entropy bonus: 0.22360287606716156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6396747264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7291736064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.465062294572761e+18 - Differentiable computation graph = True!
PPO iteration: 790/1000:
	 start solving instance: 99...
	 start solving instance: 49...
	 start solving instance: 98...
	 start solving instance: 113...
	 start solving instance: 128...
	 start solving instance: 34...
	 start solving instance: 76...
	 start solving instance: 84...
	 start solving instance: 33...
	 start solving instance: 41...
	 start solving instance: 125...
	 start solving instance: 73...
	 start solving instance: 89...
	 start solving instance: 11...
	 start solving instance: 21...
	 start solving instance: 55...
	 start solving instance: 137...
	 start solving instance: 2...
	 start solving instance: 112...
	 start solving instance: 80...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.376507518120519e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6092084736.0
		 entropy bonus: 0.2155720293521881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6353117184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7160668672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376507628071682e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.376507518120519e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6092084736.0
		 entropy bonus: 0.2155720293521881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6353117184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7160668672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376507628071682e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.376507518120519e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6092084736.0
		 entropy bonus: 0.2155720293521881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6353117184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7160668672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.376507628071682e+18 - Differentiable computation graph = True!
PPO iteration: 791/1000:
	 New training batch of size 20...
	 start solving instance: 75...
	 start solving instance: 15...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 49...
	 start solving instance: 55...
	 start solving instance: 10...
	 start solving instance: 139...
	 start solving instance: 9...
	 start solving instance: 82...
	 start solving instance: 65...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 7...
	 start solving instance: 27...
	 start solving instance: 51...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 101...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.296751143664904e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6214325760.0
		 entropy bonus: 0.21954207122325897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6399373824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988348416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2967512536160666e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.296751143664904e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6214325760.0
		 entropy bonus: 0.21954207122325897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6399373824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988348416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2967512536160666e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.296751143664904e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6214325760.0
		 entropy bonus: 0.21954207122325897
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6399373824.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6988348416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2967512536160666e+18 - Differentiable computation graph = True!
PPO iteration: 792/1000:
	 start solving instance: 50...
	 start solving instance: 55...
	 start solving instance: 15...
	 start solving instance: 107...
	 start solving instance: 7...
	 start solving instance: 42...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 9...
	 start solving instance: 99...
	 start solving instance: 51...
	 start solving instance: 140...
	 start solving instance: 49...
	 start solving instance: 111...
	 start solving instance: 101...
	 start solving instance: 27...
	 start solving instance: 139...
	 start solving instance: 82...
	 start solving instance: 65...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2534866805258715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6235196928.0
		 entropy bonus: 0.20540013909339905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6297876480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7078586880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2534868454526157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2534866805258715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6235196928.0
		 entropy bonus: 0.20540013909339905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6297876480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7078586880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2534868454526157e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2534866805258715e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6235196928.0
		 entropy bonus: 0.20540013909339905
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6297876480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7078586880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2534868454526157e+18 - Differentiable computation graph = True!
PPO iteration: 793/1000:
	 start solving instance: 49...
	 start solving instance: 10...
	 start solving instance: 111...
	 start solving instance: 7...
	 start solving instance: 101...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 139...
	 start solving instance: 50...
	 start solving instance: 140...
	 start solving instance: 27...
	 start solving instance: 82...
	 start solving instance: 65...
	 start solving instance: 99...
	 start solving instance: 42...
	 start solving instance: 51...
	 start solving instance: 55...
	 start solving instance: 15...
	 start solving instance: 107...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.319172384778512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6250067968.0
		 entropy bonus: 0.20088890194892883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6382518272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7141191168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.319172494729675e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.319172384778512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6250067968.0
		 entropy bonus: 0.20088890194892883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6382518272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7141191168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.319172494729675e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.319172384778512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6250067968.0
		 entropy bonus: 0.20088890194892883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6382518272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7141191168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.319172494729675e+18 - Differentiable computation graph = True!
PPO iteration: 794/1000:
	 start solving instance: 27...
	 start solving instance: 75...
	 start solving instance: 49...
	 start solving instance: 139...
	 start solving instance: 105...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 42...
	 start solving instance: 50...
	 start solving instance: 101...
	 start solving instance: 65...
	 start solving instance: 51...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 82...
	 start solving instance: 55...
	 start solving instance: 111...
	 start solving instance: 15...
	 start solving instance: 7...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.42746328499817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6226781184.0
		 entropy bonus: 0.21603377163410187
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6383203328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7063288832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.427463394949333e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.42746328499817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6226781184.0
		 entropy bonus: 0.21603377163410187
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6383203328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7063288832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.427463394949333e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.42746328499817e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6226781184.0
		 entropy bonus: 0.21603377163410187
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6383203328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7063288832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.427463394949333e+18 - Differentiable computation graph = True!
PPO iteration: 795/1000:
	 start solving instance: 50...
	 start solving instance: 7...
	 start solving instance: 101...
	 start solving instance: 15...
	 start solving instance: 99...
	 start solving instance: 75...
	 start solving instance: 140...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 9...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 10...
	 start solving instance: 42...
	 start solving instance: 51...
	 start solving instance: 105...
	 start solving instance: 55...
	 start solving instance: 27...
	 start solving instance: 82...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3317512376049205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6306637312.0
		 entropy bonus: 0.2041729986667633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325437952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7000055296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.331751182629339e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3317512376049205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6306637312.0
		 entropy bonus: 0.2041729986667633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325437952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7000055296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.331751182629339e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3317512376049205e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6306637312.0
		 entropy bonus: 0.2041729986667633
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325437952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7000055296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.331751182629339e+18 - Differentiable computation graph = True!
PPO iteration: 796/1000:
	 start solving instance: 10...
	 start solving instance: 111...
	 start solving instance: 65...
	 start solving instance: 51...
	 start solving instance: 49...
	 start solving instance: 7...
	 start solving instance: 50...
	 start solving instance: 15...
	 start solving instance: 9...
	 start solving instance: 27...
	 start solving instance: 139...
	 start solving instance: 107...
	 start solving instance: 55...
	 start solving instance: 101...
	 start solving instance: 42...
	 start solving instance: 82...
	 start solving instance: 105...
	 start solving instance: 140...
	 start solving instance: 99...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.338940724236622e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6335667712.0
		 entropy bonus: 0.20369403064250946
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6329672192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179471360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3389408891633664e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.338940724236622e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6335667712.0
		 entropy bonus: 0.20369403064250946
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6329672192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179471360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3389408891633664e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.338940724236622e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6335667712.0
		 entropy bonus: 0.20369403064250946
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6329672192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179471360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3389408891633664e+18 - Differentiable computation graph = True!
PPO iteration: 797/1000:
	 start solving instance: 99...
	 start solving instance: 50...
	 start solving instance: 15...
	 start solving instance: 82...
	 start solving instance: 49...
	 start solving instance: 75...
	 start solving instance: 140...
	 start solving instance: 42...
	 start solving instance: 101...
	 start solving instance: 27...
	 start solving instance: 111...
	 start solving instance: 51...
	 start solving instance: 10...
	 start solving instance: 105...
	 start solving instance: 7...
	 start solving instance: 9...
	 start solving instance: 55...
	 start solving instance: 107...
	 start solving instance: 65...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.996998325458751e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6278491648.0
		 entropy bonus: 0.20661380887031555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6033964544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6761269760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9969982704831693e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.996998325458751e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6278491648.0
		 entropy bonus: 0.20661380887031555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6033964544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6761269760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9969982704831693e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.996998325458751e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6278491648.0
		 entropy bonus: 0.20661380887031555
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6033964544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6761269760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9969982704831693e+18 - Differentiable computation graph = True!
PPO iteration: 798/1000:
	 start solving instance: 140...
	 start solving instance: 105...
	 start solving instance: 101...
	 start solving instance: 15...
	 start solving instance: 27...
	 start solving instance: 50...
	 start solving instance: 7...
	 start solving instance: 55...
	 start solving instance: 82...
	 start solving instance: 9...
	 start solving instance: 75...
	 start solving instance: 49...
	 start solving instance: 99...
	 start solving instance: 139...
	 start solving instance: 51...
	 start solving instance: 42...
	 start solving instance: 65...
	 start solving instance: 10...
	 start solving instance: 107...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.174193860172526e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187710464.0
		 entropy bonus: 0.2078520804643631
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6252941312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7208241152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.174193915148108e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.174193860172526e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187710464.0
		 entropy bonus: 0.2078520804643631
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6252941312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7208241152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.174193915148108e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.174193860172526e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6187710464.0
		 entropy bonus: 0.2078520804643631
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6252941312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7208241152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.174193915148108e+18 - Differentiable computation graph = True!
PPO iteration: 799/1000:
	 start solving instance: 82...
	 start solving instance: 140...
	 start solving instance: 99...
	 start solving instance: 7...
	 start solving instance: 101...
	 start solving instance: 15...
	 start solving instance: 42...
	 start solving instance: 51...
	 start solving instance: 107...
	 start solving instance: 105...
	 start solving instance: 49...
	 start solving instance: 55...
	 start solving instance: 65...
	 start solving instance: 10...
	 start solving instance: 139...
	 start solving instance: 111...
	 start solving instance: 27...
	 start solving instance: 9...
	 start solving instance: 50...
	 start solving instance: 75...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9732664664848335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6091195904.0
		 entropy bonus: 0.20781853795051575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935147520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622220800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.973266411509252e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9732664664848335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6091195904.0
		 entropy bonus: 0.20781853795051575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935147520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622220800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.973266411509252e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9732664664848335e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6091195904.0
		 entropy bonus: 0.20781853795051575
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935147520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622220800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.973266411509252e+18 - Differentiable computation graph = True!
PPO iteration: 800/1000:
	 start solving instance: 111...
	 start solving instance: 10...
	 start solving instance: 51...
	 start solving instance: 65...
	 start solving instance: 101...
	 start solving instance: 50...
	 start solving instance: 27...
	 start solving instance: 15...
	 start solving instance: 140...
	 start solving instance: 7...
	 start solving instance: 82...
	 start solving instance: 55...
	 start solving instance: 105...
	 start solving instance: 75...
	 start solving instance: 139...
	 start solving instance: 49...
	 start solving instance: 99...
	 start solving instance: 9...
	 start solving instance: 42...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.224072105654957e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193847808.0
		 entropy bonus: 0.20953360199928284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6250891264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6982715392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224072160630538e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.224072105654957e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193847808.0
		 entropy bonus: 0.20953360199928284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6250891264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6982715392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224072160630538e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.224072105654957e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6193847808.0
		 entropy bonus: 0.20953360199928284
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6250891264.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6982715392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.224072160630538e+18 - Differentiable computation graph = True!
PPO iteration: 801/1000:
	 New training batch of size 20...
	 start solving instance: 97...
	 start solving instance: 133...
	 start solving instance: 18...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 81...
	 start solving instance: 107...
	 start solving instance: 99...
	 start solving instance: 30...
	 start solving instance: 49...
	 start solving instance: 149...
	 start solving instance: 11...
	 start solving instance: 67...
	 start solving instance: 101...
	 start solving instance: 32...
	 start solving instance: 131...
	 start solving instance: 58...
	 start solving instance: 137...
	 start solving instance: 26...
	 start solving instance: 139...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.39477876254625e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6296147456.0
		 entropy bonus: 0.23035326600074768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6295198208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6918852608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3947787625462497e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.39477876254625e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6296147456.0
		 entropy bonus: 0.23035326600074768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6295198208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6918852608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3947787625462497e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.39477876254625e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6296147456.0
		 entropy bonus: 0.23035326600074768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6295198208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6918852608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3947787625462497e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.1858738641925833e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5181635072.0
		 entropy bonus: 0.21742065250873566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5288562688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6145041408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3185873974143746048.0000
PPO iteration: 802/1000:
	 start solving instance: 81...
	 start solving instance: 101...
	 start solving instance: 131...
	 start solving instance: 58...
	 start solving instance: 79...
	 start solving instance: 67...
	 start solving instance: 11...
	 start solving instance: 91...
	 start solving instance: 97...
	 start solving instance: 137...
	 start solving instance: 49...
	 start solving instance: 149...
	 start solving instance: 30...
	 start solving instance: 26...
	 start solving instance: 139...
	 start solving instance: 133...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 18...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.466196440816812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6177722368.0
		 entropy bonus: 0.2381717413663864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6407959040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067781632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.466196440816812e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.466196440816812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6177722368.0
		 entropy bonus: 0.2381717413663864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6407959040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067781632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.466196440816812e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.466196440816812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6177722368.0
		 entropy bonus: 0.2381717413663864
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6407959040.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067781632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.466196440816812e+18 - Differentiable computation graph = True!
PPO iteration: 803/1000:
	 start solving instance: 137...
	 start solving instance: 91...
	 start solving instance: 131...
	 start solving instance: 26...
	 start solving instance: 101...
	 start solving instance: 32...
	 start solving instance: 49...
	 start solving instance: 107...
	 start solving instance: 18...
	 start solving instance: 139...
	 start solving instance: 11...
	 start solving instance: 97...
	 start solving instance: 133...
	 start solving instance: 58...
	 start solving instance: 79...
	 start solving instance: 67...
	 start solving instance: 30...
	 start solving instance: 81...
	 start solving instance: 149...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4236281884404875e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6211475456.0
		 entropy bonus: 0.22043390572071075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6316073984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7288977408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4236282983916503e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4236281884404875e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6211475456.0
		 entropy bonus: 0.22043390572071075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6316073984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7288977408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4236282983916503e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4236281884404875e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6211475456.0
		 entropy bonus: 0.22043390572071075
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6316073984.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7288977408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4236282983916503e+18 - Differentiable computation graph = True!
PPO iteration: 804/1000:
	 start solving instance: 133...
	 start solving instance: 18...
	 start solving instance: 49...
	 start solving instance: 11...
	 start solving instance: 97...
	 start solving instance: 81...
	 start solving instance: 101...
	 start solving instance: 91...
	 start solving instance: 131...
	 start solving instance: 137...
	 start solving instance: 32...
	 start solving instance: 58...
	 start solving instance: 30...
	 start solving instance: 139...
	 start solving instance: 79...
	 start solving instance: 99...
	 start solving instance: 67...
	 start solving instance: 107...
	 start solving instance: 26...
	 start solving instance: 149...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.17896793966033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6178663936.0
		 entropy bonus: 0.21244163811206818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6127719936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001686016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.178967994635911e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.17896793966033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6178663936.0
		 entropy bonus: 0.21244163811206818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6127719936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001686016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.178967994635911e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.17896793966033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6178663936.0
		 entropy bonus: 0.21244163811206818
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6127719936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7001686016.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.178967994635911e+18 - Differentiable computation graph = True!
PPO iteration: 805/1000:
	 start solving instance: 101...
	 start solving instance: 32...
	 start solving instance: 91...
	 start solving instance: 131...
	 start solving instance: 81...
	 start solving instance: 11...
	 start solving instance: 79...
	 start solving instance: 149...
	 start solving instance: 139...
	 start solving instance: 133...
	 start solving instance: 30...
	 start solving instance: 49...
	 start solving instance: 137...
	 start solving instance: 97...
	 start solving instance: 67...
	 start solving instance: 99...
	 start solving instance: 18...
	 start solving instance: 58...
	 start solving instance: 26...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.257382030320756e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107718656.0
		 entropy bonus: 0.2287953943014145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6162433024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7022223360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257382140271919e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.257382030320756e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107718656.0
		 entropy bonus: 0.2287953943014145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6162433024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7022223360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257382140271919e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.257382030320756e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107718656.0
		 entropy bonus: 0.2287953943014145
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6162433024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7022223360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257382140271919e+18 - Differentiable computation graph = True!
PPO iteration: 806/1000:
	 start solving instance: 49...
	 start solving instance: 97...
	 start solving instance: 11...
	 start solving instance: 131...
	 start solving instance: 137...
	 start solving instance: 26...
	 start solving instance: 133...
	 start solving instance: 79...
	 start solving instance: 18...
	 start solving instance: 91...
	 start solving instance: 139...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 101...
	 start solving instance: 30...
	 start solving instance: 58...
	 start solving instance: 149...
	 start solving instance: 81...
	 start solving instance: 107...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.36024486153641e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107701248.0
		 entropy bonus: 0.22504186630249023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6327044608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179362816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.360245026463154e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.36024486153641e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107701248.0
		 entropy bonus: 0.22504186630249023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6327044608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179362816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.360245026463154e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.36024486153641e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6107701248.0
		 entropy bonus: 0.22504186630249023
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6327044608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7179362816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.360245026463154e+18 - Differentiable computation graph = True!
PPO iteration: 807/1000:
	 start solving instance: 67...
	 start solving instance: 81...
	 start solving instance: 137...
	 start solving instance: 139...
	 start solving instance: 133...
	 start solving instance: 99...
	 start solving instance: 131...
	 start solving instance: 149...
	 start solving instance: 58...
	 start solving instance: 30...
	 start solving instance: 79...
	 start solving instance: 97...
	 start solving instance: 11...
	 start solving instance: 49...
	 start solving instance: 91...
	 start solving instance: 18...
	 start solving instance: 101...
	 start solving instance: 107...
	 start solving instance: 32...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.449000078958395e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6259198464.0
		 entropy bonus: 0.22659659385681152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6336343552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7042820608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4490000789583954e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.449000078958395e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6259198464.0
		 entropy bonus: 0.22659659385681152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6336343552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7042820608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4490000789583954e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.449000078958395e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6259198464.0
		 entropy bonus: 0.22659659385681152
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6336343552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7042820608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4490000789583954e+18 - Differentiable computation graph = True!
PPO iteration: 808/1000:
	 start solving instance: 99...
	 start solving instance: 30...
	 start solving instance: 58...
	 start solving instance: 131...
	 start solving instance: 137...
	 start solving instance: 91...
	 start solving instance: 149...
	 start solving instance: 32...
	 start solving instance: 67...
	 start solving instance: 18...
	 start solving instance: 133...
	 start solving instance: 11...
	 start solving instance: 97...
	 start solving instance: 26...
	 start solving instance: 79...
	 start solving instance: 139...
	 start solving instance: 107...
	 start solving instance: 101...
	 start solving instance: 81...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.370928156316533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6162246144.0
		 entropy bonus: 0.22742147743701935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6350626816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7013167616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3709281563165327e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.370928156316533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6162246144.0
		 entropy bonus: 0.22742147743701935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6350626816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7013167616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3709281563165327e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.370928156316533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6162246144.0
		 entropy bonus: 0.22742147743701935
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6350626816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7013167616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3709281563165327e+18 - Differentiable computation graph = True!
PPO iteration: 809/1000:
	 start solving instance: 81...
	 start solving instance: 101...
	 start solving instance: 91...
	 start solving instance: 30...
	 start solving instance: 97...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 11...
	 start solving instance: 79...
	 start solving instance: 58...
	 start solving instance: 18...
	 start solving instance: 149...
	 start solving instance: 133...
	 start solving instance: 107...
	 start solving instance: 131...
	 start solving instance: 139...
	 start solving instance: 26...
	 start solving instance: 49...
	 start solving instance: 137...
	 start solving instance: 67...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.045094922299533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140832256.0
		 entropy bonus: 0.22292761504650116
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6029434880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6691272704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0450950322506957e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.045094922299533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140832256.0
		 entropy bonus: 0.22292761504650116
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6029434880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6691272704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0450950322506957e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.045094922299533e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6140832256.0
		 entropy bonus: 0.22292761504650116
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6029434880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6691272704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0450950322506957e+18 - Differentiable computation graph = True!
PPO iteration: 810/1000:
	 start solving instance: 49...
	 start solving instance: 97...
	 start solving instance: 26...
	 start solving instance: 18...
	 start solving instance: 11...
	 start solving instance: 79...
	 start solving instance: 32...
	 start solving instance: 131...
	 start solving instance: 107...
	 start solving instance: 101...
	 start solving instance: 99...
	 start solving instance: 58...
	 start solving instance: 137...
	 start solving instance: 30...
	 start solving instance: 139...
	 start solving instance: 133...
	 start solving instance: 81...
	 start solving instance: 67...
	 start solving instance: 149...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.362681819108213e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6114901504.0
		 entropy bonus: 0.23046927154064178
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6282284544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7029027328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3626818191082127e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.362681819108213e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6114901504.0
		 entropy bonus: 0.23046927154064178
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6282284544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7029027328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3626818191082127e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.362681819108213e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6114901504.0
		 entropy bonus: 0.23046927154064178
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6282284544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7029027328.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3626818191082127e+18 - Differentiable computation graph = True!
PPO iteration: 811/1000:
	 New training batch of size 20...
	 start solving instance: 18...
	 start solving instance: 32...
	 start solving instance: 61...
	 start solving instance: 115...
	 start solving instance: 15...
	 start solving instance: 63...
	 start solving instance: 52...
	 start solving instance: 103...
	 start solving instance: 100...
	 start solving instance: 56...
	 start solving instance: 149...
	 start solving instance: 90...
	 start solving instance: 36...
	 start solving instance: 137...
	 start solving instance: 143...
	 start solving instance: 79...
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 77...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.724946711204594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6549088256.0
		 entropy bonus: 0.21559453010559082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6506923008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7842653696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.724946711204594e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.724946711204594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6549088256.0
		 entropy bonus: 0.21559453010559082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6506923008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7842653696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.724946711204594e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.724946711204594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6549088256.0
		 entropy bonus: 0.21559453010559082
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6506923008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7842653696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.724946711204594e+18 - Differentiable computation graph = True!
PPO iteration: 812/1000:
	 start solving instance: 61...
	 start solving instance: 143...
	 start solving instance: 149...
	 start solving instance: 104...
	 start solving instance: 56...
	 start solving instance: 44...
	 start solving instance: 100...
	 start solving instance: 103...
	 start solving instance: 36...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 115...
	 start solving instance: 18...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 52...
	 start solving instance: 77...
	 start solving instance: 63...
	 start solving instance: 79...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.814310618263716e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6548431872.0
		 entropy bonus: 0.2299845665693283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6653218304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7608882688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.814310618263716e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.814310618263716e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6548431872.0
		 entropy bonus: 0.2299845665693283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6653218304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7608882688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.814310618263716e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.814310618263716e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6548431872.0
		 entropy bonus: 0.2299845665693283
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6653218304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7608882688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.814310618263716e+18 - Differentiable computation graph = True!
PPO iteration: 813/1000:
	 start solving instance: 15...
	 start solving instance: 18...
	 start solving instance: 143...
	 start solving instance: 44...
	 start solving instance: 149...
	 start solving instance: 61...
	 start solving instance: 113...
	 start solving instance: 77...
	 start solving instance: 103...
	 start solving instance: 32...
	 start solving instance: 56...
	 start solving instance: 79...
	 start solving instance: 137...
	 start solving instance: 36...
	 start solving instance: 104...
	 start solving instance: 100...
	 start solving instance: 115...
	 start solving instance: 63...
	 start solving instance: 52...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7093978575692366e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6439878656.0
		 entropy bonus: 0.22872547805309296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6466205184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7365145088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.709397967520399e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7093978575692366e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6439878656.0
		 entropy bonus: 0.22872547805309296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6466205184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7365145088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.709397967520399e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7093978575692366e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6439878656.0
		 entropy bonus: 0.22872547805309296
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6466205184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7365145088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.709397967520399e+18 - Differentiable computation graph = True!
PPO iteration: 814/1000:
	 start solving instance: 100...
	 start solving instance: 149...
	 start solving instance: 15...
	 start solving instance: 79...
	 start solving instance: 115...
	 start solving instance: 104...
	 start solving instance: 18...
	 start solving instance: 52...
	 start solving instance: 90...
	 start solving instance: 63...
	 start solving instance: 103...
	 start solving instance: 137...
	 start solving instance: 56...
	 start solving instance: 36...
	 start solving instance: 113...
	 start solving instance: 77...
	 start solving instance: 44...
	 start solving instance: 32...
	 start solving instance: 143...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.382272585489082e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6517867008.0
		 entropy bonus: 0.2509365677833557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7099087360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7909708800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.382272695440245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.382272585489082e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6517867008.0
		 entropy bonus: 0.2509365677833557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7099087360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7909708800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.382272695440245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.382272585489082e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6517867008.0
		 entropy bonus: 0.2509365677833557
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -7099087360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7909708800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.382272695440245e+18 - Differentiable computation graph = True!
PPO iteration: 815/1000:
	 start solving instance: 52...
	 start solving instance: 104...
	 start solving instance: 149...
	 start solving instance: 77...
	 start solving instance: 44...
	 start solving instance: 103...
	 start solving instance: 100...
	 start solving instance: 63...
	 start solving instance: 90...
	 start solving instance: 18...
	 start solving instance: 137...
	 start solving instance: 56...
	 start solving instance: 79...
	 start solving instance: 15...
	 start solving instance: 115...
	 start solving instance: 143...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 61...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.850439690743133e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6422859776.0
		 entropy bonus: 0.2276858389377594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6579016704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7377348096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.850440020596621e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.850439690743133e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6422859776.0
		 entropy bonus: 0.2276858389377594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6579016704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7377348096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.850440020596621e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.850439690743133e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6422859776.0
		 entropy bonus: 0.2276858389377594
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6579016704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7377348096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.850440020596621e+18 - Differentiable computation graph = True!
PPO iteration: 816/1000:
	 start solving instance: 36...
	 start solving instance: 137...
	 start solving instance: 56...
	 start solving instance: 77...
	 start solving instance: 115...
	 start solving instance: 103...
	 start solving instance: 113...
	 start solving instance: 63...
	 start solving instance: 44...
	 start solving instance: 100...
	 start solving instance: 104...
	 start solving instance: 18...
	 start solving instance: 32...
	 start solving instance: 52...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 15...
	 start solving instance: 61...
	 start solving instance: 149...
	 start solving instance: 143...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4553068776553185e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6304151040.0
		 entropy bonus: 0.22160683572292328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6175714816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914709504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4553068776553185e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4553068776553185e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6304151040.0
		 entropy bonus: 0.22160683572292328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6175714816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914709504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4553068776553185e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4553068776553185e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6304151040.0
		 entropy bonus: 0.22160683572292328
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6175714816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6914709504.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4553068776553185e+18 - Differentiable computation graph = True!
PPO iteration: 817/1000:
	 start solving instance: 36...
	 start solving instance: 100...
	 start solving instance: 52...
	 start solving instance: 143...
	 start solving instance: 113...
	 start solving instance: 63...
	 start solving instance: 32...
	 start solving instance: 77...
	 start solving instance: 149...
	 start solving instance: 104...
	 start solving instance: 18...
	 start solving instance: 44...
	 start solving instance: 56...
	 start solving instance: 103...
	 start solving instance: 15...
	 start solving instance: 115...
	 start solving instance: 137...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.343007158040789e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6357966336.0
		 entropy bonus: 0.22243662178516388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6057743872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7205482496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.343007158040789e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.343007158040789e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6357966336.0
		 entropy bonus: 0.22243662178516388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6057743872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7205482496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.343007158040789e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.343007158040789e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6357966336.0
		 entropy bonus: 0.22243662178516388
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6057743872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7205482496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.343007158040789e+18 - Differentiable computation graph = True!
PPO iteration: 818/1000:
	 start solving instance: 113...
	 start solving instance: 137...
	 start solving instance: 79...
	 start solving instance: 52...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 15...
	 start solving instance: 149...
	 start solving instance: 100...
	 start solving instance: 44...
	 start solving instance: 143...
	 start solving instance: 61...
	 start solving instance: 103...
	 start solving instance: 63...
	 start solving instance: 77...
	 start solving instance: 18...
	 start solving instance: 32...
	 start solving instance: 36...
	 start solving instance: 115...
	 start solving instance: 56...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.792853428945342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6393605120.0
		 entropy bonus: 0.23388099670410156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6518729216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7367434240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.792853648847667e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.792853428945342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6393605120.0
		 entropy bonus: 0.23388099670410156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6518729216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7367434240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.792853648847667e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.792853428945342e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6393605120.0
		 entropy bonus: 0.23388099670410156
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6518729216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7367434240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.792853648847667e+18 - Differentiable computation graph = True!
PPO iteration: 819/1000:
	 start solving instance: 100...
	 start solving instance: 18...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 15...
	 start solving instance: 63...
	 start solving instance: 115...
	 start solving instance: 61...
	 start solving instance: 77...
	 start solving instance: 104...
	 start solving instance: 113...
	 start solving instance: 32...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 56...
	 start solving instance: 36...
	 start solving instance: 44...
	 start solving instance: 143...
	 start solving instance: 149...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8685873500619014e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6414427648.0
		 entropy bonus: 0.22636428475379944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6600923648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7470552064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.868587460013064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8685873500619014e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6414427648.0
		 entropy bonus: 0.22636428475379944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6600923648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7470552064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.868587460013064e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8685873500619014e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6414427648.0
		 entropy bonus: 0.22636428475379944
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6600923648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7470552064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.868587460013064e+18 - Differentiable computation graph = True!
PPO iteration: 820/1000:
	 start solving instance: 103...
	 start solving instance: 36...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 143...
	 start solving instance: 32...
	 start solving instance: 79...
	 start solving instance: 18...
	 start solving instance: 149...
	 start solving instance: 115...
	 start solving instance: 77...
	 start solving instance: 15...
	 start solving instance: 137...
	 start solving instance: 44...
	 start solving instance: 56...
	 start solving instance: 61...
	 start solving instance: 52...
	 start solving instance: 113...
	 start solving instance: 63...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 5.10388855586643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6487674880.0
		 entropy bonus: 0.24123194813728333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6866258432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8011032064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.103888445915267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 5.10388855586643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6487674880.0
		 entropy bonus: 0.24123194813728333
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6866258432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8011032064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.103888445915267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 5.10388855586643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6483891200.0
		 entropy bonus: 0.23919327557086945
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6866258432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -8011032064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 5.103888445915267e+18 - Differentiable computation graph = True!
PPO iteration: 821/1000:
	 New training batch of size 20...
	 start solving instance: 125...
	 start solving instance: 35...
	 start solving instance: 86...
	 start solving instance: 24...
	 start solving instance: 132...
	 start solving instance: 95...
	 start solving instance: 29...
	 start solving instance: 89...
	 start solving instance: 81...
	 start solving instance: 42...
	 start solving instance: 143...
	 start solving instance: 115...
	 start solving instance: 40...
	 start solving instance: 73...
	 start solving instance: 111...
	 start solving instance: 121...
	 start solving instance: 119...
	 start solving instance: 145...
	 start solving instance: 62...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6682845908793033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5758727680.0
		 entropy bonus: 0.19329412281513214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5745615872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6612568064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.668284700830466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6682845908793033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5758727680.0
		 entropy bonus: 0.19329412281513214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5745615872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6612568064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.668284700830466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6682845908793033e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5758727680.0
		 entropy bonus: 0.19329412281513214
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5745615872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6612568064.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.668284700830466e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.2208365747372556e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5286321664.0
		 entropy bonus: 0.2056659758090973
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5301506048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6022739456.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3220836519761674240.0000
PPO iteration: 822/1000:
	 start solving instance: 95...
	 start solving instance: 29...
	 start solving instance: 40...
	 start solving instance: 62...
	 start solving instance: 125...
	 start solving instance: 115...
	 start solving instance: 111...
	 start solving instance: 89...
	 start solving instance: 86...
	 start solving instance: 73...
	 start solving instance: 24...
	 start solving instance: 81...
	 start solving instance: 143...
	 start solving instance: 132...
	 start solving instance: 145...
	 start solving instance: 35...
	 start solving instance: 121...
	 start solving instance: 42...
	 start solving instance: 12...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6606451840895156e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5653804032.0
		 entropy bonus: 0.2121003121137619
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5832688128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6256965632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6606452940406784e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6606451840895156e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5653804032.0
		 entropy bonus: 0.2121003121137619
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5832688128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6256965632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6606452940406784e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6606451840895156e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5653804032.0
		 entropy bonus: 0.2121003121137619
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5832688128.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6256965632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6606452940406784e+18 - Differentiable computation graph = True!
PPO iteration: 823/1000:
	 start solving instance: 145...
	 start solving instance: 40...
	 start solving instance: 121...
	 start solving instance: 24...
	 start solving instance: 35...
	 start solving instance: 29...
	 start solving instance: 125...
	 start solving instance: 119...
	 start solving instance: 62...
	 start solving instance: 111...
	 start solving instance: 73...
	 start solving instance: 143...
	 start solving instance: 81...
	 start solving instance: 86...
	 start solving instance: 132...
	 start solving instance: 42...
	 start solving instance: 89...
	 start solving instance: 95...
	 start solving instance: 12...
	 start solving instance: 115...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.701518209438135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5714476032.0
		 entropy bonus: 0.21164119243621826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5854345728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6441417216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7015182644137165e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.701518209438135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5714476032.0
		 entropy bonus: 0.21164119243621826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5854345728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6441417216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7015182644137165e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.701518209438135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5714476032.0
		 entropy bonus: 0.21164119243621826
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5854345728.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6441417216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7015182644137165e+18 - Differentiable computation graph = True!
PPO iteration: 824/1000:
	 start solving instance: 143...
	 start solving instance: 145...
	 start solving instance: 40...
	 start solving instance: 132...
	 start solving instance: 62...
	 start solving instance: 81...
	 start solving instance: 12...
	 start solving instance: 121...
	 start solving instance: 95...
	 start solving instance: 24...
	 start solving instance: 115...
	 start solving instance: 111...
	 start solving instance: 89...
	 start solving instance: 119...
	 start solving instance: 29...
	 start solving instance: 73...
	 start solving instance: 86...
	 start solving instance: 35...
	 start solving instance: 125...
	 start solving instance: 42...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4602152094622286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5604528128.0
		 entropy bonus: 0.19875097274780273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5542971904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6321472000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4602153194133914e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4602152094622286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5604528128.0
		 entropy bonus: 0.19875097274780273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5542971904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6321472000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4602153194133914e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4602152094622286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5604528128.0
		 entropy bonus: 0.19875097274780273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5542971904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6321472000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4602153194133914e+18 - Differentiable computation graph = True!
PPO iteration: 825/1000:
	 start solving instance: 125...
	 start solving instance: 40...
	 start solving instance: 73...
	 start solving instance: 12...
	 start solving instance: 95...
	 start solving instance: 119...
	 start solving instance: 86...
	 start solving instance: 111...
	 start solving instance: 143...
	 start solving instance: 42...
	 start solving instance: 132...
	 start solving instance: 121...
	 start solving instance: 29...
	 start solving instance: 62...
	 start solving instance: 81...
	 start solving instance: 35...
	 start solving instance: 115...
	 start solving instance: 89...
	 start solving instance: 24...
	 start solving instance: 145...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5056441711917007e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5677715456.0
		 entropy bonus: 0.19692659378051758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5598558720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6037323264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5056441162161193e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5056441711917007e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5677715456.0
		 entropy bonus: 0.19692659378051758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5598558720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6037323264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5056441162161193e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5056441711917007e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5677715456.0
		 entropy bonus: 0.19692659378051758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5598558720.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6037323264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5056441162161193e+18 - Differentiable computation graph = True!
PPO iteration: 826/1000:
	 start solving instance: 121...
	 start solving instance: 81...
	 start solving instance: 125...
	 start solving instance: 89...
	 start solving instance: 40...
	 start solving instance: 132...
	 start solving instance: 73...
	 start solving instance: 145...
	 start solving instance: 115...
	 start solving instance: 24...
	 start solving instance: 35...
	 start solving instance: 111...
	 start solving instance: 86...
	 start solving instance: 42...
	 start solving instance: 143...
	 start solving instance: 119...
	 start solving instance: 62...
	 start solving instance: 29...
	 start solving instance: 95...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.708700219390768e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802591744.0
		 entropy bonus: 0.19857902824878693
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5872074240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428108800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7087002743663493e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.708700219390768e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802591744.0
		 entropy bonus: 0.19857902824878693
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5872074240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428108800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7087002743663493e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.708700219390768e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5802591744.0
		 entropy bonus: 0.19857902824878693
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5872074240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6428108800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7087002743663493e+18 - Differentiable computation graph = True!
PPO iteration: 827/1000:
	 start solving instance: 95...
	 start solving instance: 40...
	 start solving instance: 132...
	 start solving instance: 86...
	 start solving instance: 35...
	 start solving instance: 24...
	 start solving instance: 111...
	 start solving instance: 12...
	 start solving instance: 143...
	 start solving instance: 145...
	 start solving instance: 125...
	 start solving instance: 81...
	 start solving instance: 115...
	 start solving instance: 73...
	 start solving instance: 89...
	 start solving instance: 29...
	 start solving instance: 62...
	 start solving instance: 42...
	 start solving instance: 119...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.771626149457691e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768642048.0
		 entropy bonus: 0.20174551010131836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5876972544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6290712576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7716261494576906e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.771626149457691e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768642048.0
		 entropy bonus: 0.20174551010131836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5876972544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6290712576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7716261494576906e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.771626149457691e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768642048.0
		 entropy bonus: 0.20174551010131836
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5876972544.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6290712576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7716261494576906e+18 - Differentiable computation graph = True!
PPO iteration: 828/1000:
	 start solving instance: 95...
	 start solving instance: 132...
	 start solving instance: 81...
	 start solving instance: 111...
	 start solving instance: 42...
	 start solving instance: 62...
	 start solving instance: 115...
	 start solving instance: 145...
	 start solving instance: 86...
	 start solving instance: 119...
	 start solving instance: 121...
	 start solving instance: 29...
	 start solving instance: 73...
	 start solving instance: 143...
	 start solving instance: 89...
	 start solving instance: 12...
	 start solving instance: 125...
	 start solving instance: 35...
	 start solving instance: 40...
	 start solving instance: 24...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5774130334761746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5680577024.0
		 entropy bonus: 0.2108735293149948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5726508032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6138409472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.577413088451756e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5774130334761746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5680577024.0
		 entropy bonus: 0.2108735293149948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5726508032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6138409472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.577413088451756e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5774130334761746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5680577024.0
		 entropy bonus: 0.2108735293149948
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5726508032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6138409472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.577413088451756e+18 - Differentiable computation graph = True!
PPO iteration: 829/1000:
	 start solving instance: 132...
	 start solving instance: 35...
	 start solving instance: 24...
	 start solving instance: 73...
	 start solving instance: 115...
	 start solving instance: 95...
	 start solving instance: 121...
	 start solving instance: 40...
	 start solving instance: 145...
	 start solving instance: 125...
	 start solving instance: 62...
	 start solving instance: 143...
	 start solving instance: 42...
	 start solving instance: 111...
	 start solving instance: 89...
	 start solving instance: 29...
	 start solving instance: 81...
	 start solving instance: 12...
	 start solving instance: 86...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6422754234219364e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5796358656.0
		 entropy bonus: 0.2066577672958374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5845276160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330591744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.642275478397518e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6422754234219364e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5796358656.0
		 entropy bonus: 0.2066577672958374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5845276160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330591744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.642275478397518e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6422754234219364e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5796358656.0
		 entropy bonus: 0.2066577672958374
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5845276160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6330591744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.642275478397518e+18 - Differentiable computation graph = True!
PPO iteration: 830/1000:
	 start solving instance: 111...
	 start solving instance: 143...
	 start solving instance: 12...
	 start solving instance: 132...
	 start solving instance: 115...
	 start solving instance: 121...
	 start solving instance: 145...
	 start solving instance: 29...
	 start solving instance: 40...
	 start solving instance: 73...
	 start solving instance: 42...
	 start solving instance: 81...
	 start solving instance: 24...
	 start solving instance: 86...
	 start solving instance: 119...
	 start solving instance: 35...
	 start solving instance: 95...
	 start solving instance: 125...
	 start solving instance: 89...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6148340321182286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715537920.0
		 entropy bonus: 0.209559828042984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5836926464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6494148608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6148341420693914e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6148340321182286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715537920.0
		 entropy bonus: 0.209559828042984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5836926464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6494148608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6148341420693914e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6148340321182286e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5715537920.0
		 entropy bonus: 0.209559828042984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5836926464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6494148608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6148341420693914e+18 - Differentiable computation graph = True!
PPO iteration: 831/1000:
	 New training batch of size 20...
	 start solving instance: 31...
	 start solving instance: 82...
	 start solving instance: 96...
	 start solving instance: 69...
	 start solving instance: 18...
	 start solving instance: 4...
	 start solving instance: 92...
	 start solving instance: 10...
	 start solving instance: 49...
	 start solving instance: 146...
	 start solving instance: 119...
	 start solving instance: 44...
	 start solving instance: 140...
	 start solving instance: 53...
	 start solving instance: 139...
	 start solving instance: 132...
	 start solving instance: 131...
	 start solving instance: 87...
	 start solving instance: 78...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.846953251271973e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6004876288.0
		 entropy bonus: 0.2064363956451416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5867613696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6754878464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8469534161987174e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.846953251271973e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6004876288.0
		 entropy bonus: 0.2064363956451416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5867613696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6754878464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8469534161987174e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.846953251271973e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6004876288.0
		 entropy bonus: 0.2064363956451416
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5867613696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6754878464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8469534161987174e+18 - Differentiable computation graph = True!
PPO iteration: 832/1000:
	 start solving instance: 78...
	 start solving instance: 108...
	 start solving instance: 146...
	 start solving instance: 132...
	 start solving instance: 4...
	 start solving instance: 18...
	 start solving instance: 140...
	 start solving instance: 131...
	 start solving instance: 69...
	 start solving instance: 87...
	 start solving instance: 82...
	 start solving instance: 139...
	 start solving instance: 31...
	 start solving instance: 10...
	 start solving instance: 44...
	 start solving instance: 49...
	 start solving instance: 119...
	 start solving instance: 96...
	 start solving instance: 92...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7880264648975974e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982678528.0
		 entropy bonus: 0.1995125263929367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865183744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6655149056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7880264648975974e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7880264648975974e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982678528.0
		 entropy bonus: 0.1995125263929367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865183744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6655149056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7880264648975974e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7880264648975974e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5982678528.0
		 entropy bonus: 0.1995125263929367
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865183744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6655149056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7880264648975974e+18 - Differentiable computation graph = True!
PPO iteration: 833/1000:
	 start solving instance: 140...
	 start solving instance: 87...
	 start solving instance: 96...
	 start solving instance: 131...
	 start solving instance: 146...
	 start solving instance: 108...
	 start solving instance: 139...
	 start solving instance: 10...
	 start solving instance: 4...
	 start solving instance: 69...
	 start solving instance: 18...
	 start solving instance: 53...
	 start solving instance: 44...
	 start solving instance: 132...
	 start solving instance: 78...
	 start solving instance: 119...
	 start solving instance: 92...
	 start solving instance: 49...
	 start solving instance: 82...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.004430584257865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5984958464.0
		 entropy bonus: 0.21110467612743378
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5961324032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6884297216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.004430694209028e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.004430584257865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5984958464.0
		 entropy bonus: 0.21110467612743378
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5961324032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6884297216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.004430694209028e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.004430584257865e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5984958464.0
		 entropy bonus: 0.21110467612743378
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5961324032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6884297216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.004430694209028e+18 - Differentiable computation graph = True!
PPO iteration: 834/1000:
	 start solving instance: 92...
	 start solving instance: 10...
	 start solving instance: 132...
	 start solving instance: 139...
	 start solving instance: 44...
	 start solving instance: 18...
	 start solving instance: 146...
	 start solving instance: 119...
	 start solving instance: 53...
	 start solving instance: 31...
	 start solving instance: 4...
	 start solving instance: 108...
	 start solving instance: 87...
	 start solving instance: 140...
	 start solving instance: 96...
	 start solving instance: 82...
	 start solving instance: 69...
	 start solving instance: 78...
	 start solving instance: 131...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.9022881530607305e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5983538688.0
		 entropy bonus: 0.1991950124502182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880566784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622776320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.902288263011893e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.9022881530607305e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5983538688.0
		 entropy bonus: 0.1991950124502182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880566784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622776320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.902288263011893e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.9022881530607305e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5983538688.0
		 entropy bonus: 0.1991950124502182
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5880566784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622776320.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.902288263011893e+18 - Differentiable computation graph = True!
PPO iteration: 835/1000:
	 start solving instance: 4...
	 start solving instance: 18...
	 start solving instance: 78...
	 start solving instance: 96...
	 start solving instance: 53...
	 start solving instance: 82...
	 start solving instance: 44...
	 start solving instance: 140...
	 start solving instance: 69...
	 start solving instance: 119...
	 start solving instance: 132...
	 start solving instance: 146...
	 start solving instance: 139...
	 start solving instance: 92...
	 start solving instance: 31...
	 start solving instance: 87...
	 start solving instance: 49...
	 start solving instance: 108...
	 start solving instance: 131...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.7903732625159225e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894135296.0
		 entropy bonus: 0.19123509526252747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5702889472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6426035200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7903733724670853e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.7903732625159225e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894135296.0
		 entropy bonus: 0.19123509526252747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5702889472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6426035200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7903733724670853e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.7903732625159225e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894135296.0
		 entropy bonus: 0.19123509526252747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5702889472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6426035200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7903733724670853e+18 - Differentiable computation graph = True!
PPO iteration: 836/1000:
	 start solving instance: 49...
	 start solving instance: 31...
	 start solving instance: 131...
	 start solving instance: 108...
	 start solving instance: 10...
	 start solving instance: 132...
	 start solving instance: 78...
	 start solving instance: 53...
	 start solving instance: 119...
	 start solving instance: 82...
	 start solving instance: 44...
	 start solving instance: 140...
	 start solving instance: 92...
	 start solving instance: 18...
	 start solving instance: 87...
	 start solving instance: 4...
	 start solving instance: 69...
	 start solving instance: 139...
	 start solving instance: 146...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.057676413953848e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5987703296.0
		 entropy bonus: 0.206410214304924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6064645120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6881018880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0576764689294295e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.057676413953848e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5987703296.0
		 entropy bonus: 0.206410214304924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6064645120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6881018880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0576764689294295e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.057676413953848e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5987703296.0
		 entropy bonus: 0.206410214304924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6064645120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6881018880.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0576764689294295e+18 - Differentiable computation graph = True!
PPO iteration: 837/1000:
	 start solving instance: 140...
	 start solving instance: 49...
	 start solving instance: 44...
	 start solving instance: 108...
	 start solving instance: 139...
	 start solving instance: 18...
	 start solving instance: 132...
	 start solving instance: 53...
	 start solving instance: 78...
	 start solving instance: 69...
	 start solving instance: 4...
	 start solving instance: 92...
	 start solving instance: 31...
	 start solving instance: 10...
	 start solving instance: 82...
	 start solving instance: 87...
	 start solving instance: 131...
	 start solving instance: 146...
	 start solving instance: 96...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.888001098969409e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5913800704.0
		 entropy bonus: 0.19972079992294312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5775643648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6663036416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.888001208920572e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.888001098969409e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5913800704.0
		 entropy bonus: 0.19972079992294312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5775643648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6663036416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.888001208920572e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.888001098969409e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5913800704.0
		 entropy bonus: 0.19972079992294312
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5775643648.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6663036416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.888001208920572e+18 - Differentiable computation graph = True!
PPO iteration: 838/1000:
	 start solving instance: 31...
	 start solving instance: 87...
	 start solving instance: 139...
	 start solving instance: 78...
	 start solving instance: 10...
	 start solving instance: 69...
	 start solving instance: 119...
	 start solving instance: 132...
	 start solving instance: 49...
	 start solving instance: 96...
	 start solving instance: 53...
	 start solving instance: 108...
	 start solving instance: 131...
	 start solving instance: 140...
	 start solving instance: 82...
	 start solving instance: 4...
	 start solving instance: 44...
	 start solving instance: 146...
	 start solving instance: 92...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.151014395840404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021629952.0
		 entropy bonus: 0.20863346755504608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156105216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841952768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.151014560767148e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.151014395840404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021629952.0
		 entropy bonus: 0.20863346755504608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156105216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841952768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.151014560767148e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.151014395840404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021629952.0
		 entropy bonus: 0.20863346755504608
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6156105216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6841952768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.151014560767148e+18 - Differentiable computation graph = True!
PPO iteration: 839/1000:
	 start solving instance: 18...
	 start solving instance: 92...
	 start solving instance: 119...
	 start solving instance: 131...
	 start solving instance: 140...
	 start solving instance: 78...
	 start solving instance: 49...
	 start solving instance: 53...
	 start solving instance: 4...
	 start solving instance: 69...
	 start solving instance: 146...
	 start solving instance: 132...
	 start solving instance: 96...
	 start solving instance: 139...
	 start solving instance: 87...
	 start solving instance: 10...
	 start solving instance: 108...
	 start solving instance: 44...
	 start solving instance: 82...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.032508152989404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5988443648.0
		 entropy bonus: 0.20596018433570862
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6016943104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7161844736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.032508098013823e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.032508152989404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5988443648.0
		 entropy bonus: 0.20596018433570862
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6016943104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7161844736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.032508098013823e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.032508152989404e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5988443648.0
		 entropy bonus: 0.20596018433570862
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6016943104.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7161844736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.032508098013823e+18 - Differentiable computation graph = True!
PPO iteration: 840/1000:
	 start solving instance: 119...
	 start solving instance: 92...
	 start solving instance: 132...
	 start solving instance: 87...
	 start solving instance: 18...
	 start solving instance: 69...
	 start solving instance: 139...
	 start solving instance: 10...
	 start solving instance: 49...
	 start solving instance: 82...
	 start solving instance: 78...
	 start solving instance: 140...
	 start solving instance: 108...
	 start solving instance: 31...
	 start solving instance: 44...
	 start solving instance: 131...
	 start solving instance: 96...
	 start solving instance: 146...
	 start solving instance: 53...
	 start solving instance: 4...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.844026791123485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5956397568.0
		 entropy bonus: 0.2012975662946701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5854492160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6577241088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8440267911234847e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.844026791123485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5956397568.0
		 entropy bonus: 0.2012975662946701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5854492160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6577241088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8440267911234847e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.844026791123485e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5956397568.0
		 entropy bonus: 0.2012975662946701
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5854492160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6577241088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8440267911234847e+18 - Differentiable computation graph = True!
PPO iteration: 841/1000:
	 New training batch of size 20...
	 start solving instance: 60...
	 start solving instance: 38...
	 start solving instance: 119...
	 start solving instance: 12...
	 start solving instance: 18...
	 start solving instance: 29...
	 start solving instance: 51...
	 start solving instance: 116...
	 start solving instance: 27...
	 start solving instance: 3...
	 start solving instance: 19...
	 start solving instance: 125...
	 start solving instance: 117...
	 start solving instance: 4...
	 start solving instance: 134...
	 start solving instance: 137...
	 start solving instance: 17...
	 start solving instance: 98...
	 start solving instance: 68...
	 start solving instance: 49...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3207597516648874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5596937728.0
		 entropy bonus: 0.20869021117687225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5507614208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6085621248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.32075986161605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3207597516648874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5596937728.0
		 entropy bonus: 0.20869021117687225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5507614208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6085621248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.32075986161605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3207597516648874e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5596937728.0
		 entropy bonus: 0.20869021117687225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5507614208.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6085621248.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.32075986161605e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.9418198861239812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5264301568.0
		 entropy bonus: 0.20430819690227509
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5055844352.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6155871744.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2941820051050725376.0000
PPO iteration: 842/1000:
	 start solving instance: 119...
	 start solving instance: 68...
	 start solving instance: 17...
	 start solving instance: 60...
	 start solving instance: 12...
	 start solving instance: 134...
	 start solving instance: 29...
	 start solving instance: 18...
	 start solving instance: 19...
	 start solving instance: 27...
	 start solving instance: 98...
	 start solving instance: 4...
	 start solving instance: 117...
	 start solving instance: 116...
	 start solving instance: 51...
	 start solving instance: 125...
	 start solving instance: 137...
	 start solving instance: 49...
	 start solving instance: 38...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.30961906004761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5629756928.0
		 entropy bonus: 0.2118149846792221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5483856896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6355550208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.30961906004761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.30961906004761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5629756928.0
		 entropy bonus: 0.2118149846792221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5483856896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6355550208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.30961906004761e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.30961906004761e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5629756928.0
		 entropy bonus: 0.2118149846792221
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5483856896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6355550208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.30961906004761e+18 - Differentiable computation graph = True!
PPO iteration: 843/1000:
	 start solving instance: 119...
	 start solving instance: 68...
	 start solving instance: 19...
	 start solving instance: 3...
	 start solving instance: 18...
	 start solving instance: 98...
	 start solving instance: 137...
	 start solving instance: 116...
	 start solving instance: 60...
	 start solving instance: 17...
	 start solving instance: 49...
	 start solving instance: 29...
	 start solving instance: 12...
	 start solving instance: 134...
	 start solving instance: 4...
	 start solving instance: 27...
	 start solving instance: 125...
	 start solving instance: 38...
	 start solving instance: 51...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5341811158813245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5640016896.0
		 entropy bonus: 0.20023921132087708
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5739837952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6316264960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5341811158813245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5341811158813245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5640016896.0
		 entropy bonus: 0.20023921132087708
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5739837952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6316264960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5341811158813245e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5341811158813245e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5640016896.0
		 entropy bonus: 0.20023921132087708
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5739837952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6316264960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5341811158813245e+18 - Differentiable computation graph = True!
PPO iteration: 844/1000:
	 start solving instance: 3...
	 start solving instance: 117...
	 start solving instance: 19...
	 start solving instance: 18...
	 start solving instance: 98...
	 start solving instance: 51...
	 start solving instance: 60...
	 start solving instance: 4...
	 start solving instance: 68...
	 start solving instance: 116...
	 start solving instance: 49...
	 start solving instance: 119...
	 start solving instance: 134...
	 start solving instance: 125...
	 start solving instance: 38...
	 start solving instance: 27...
	 start solving instance: 12...
	 start solving instance: 29...
	 start solving instance: 137...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.228190768210798e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5554791936.0
		 entropy bonus: 0.20825211703777313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5333376000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6188704256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.228190878161961e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.228190768210798e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5554791936.0
		 entropy bonus: 0.20825211703777313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5333376000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6188704256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.228190878161961e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.228190768210798e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5554791936.0
		 entropy bonus: 0.20825211703777313
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5333376000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6188704256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.228190878161961e+18 - Differentiable computation graph = True!
PPO iteration: 845/1000:
	 start solving instance: 18...
	 start solving instance: 117...
	 start solving instance: 38...
	 start solving instance: 116...
	 start solving instance: 29...
	 start solving instance: 19...
	 start solving instance: 137...
	 start solving instance: 4...
	 start solving instance: 3...
	 start solving instance: 119...
	 start solving instance: 134...
	 start solving instance: 12...
	 start solving instance: 125...
	 start solving instance: 49...
	 start solving instance: 27...
	 start solving instance: 17...
	 start solving instance: 68...
	 start solving instance: 51...
	 start solving instance: 98...
	 start solving instance: 60...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4674363620288102e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631412736.0
		 entropy bonus: 0.19537293910980225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5588722176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6498151936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.46743636202881e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4674363620288102e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631412736.0
		 entropy bonus: 0.19537293910980225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5588722176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6498151936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.46743636202881e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4674363620288102e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631412736.0
		 entropy bonus: 0.19537293910980225
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5588722176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6498151936.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.46743636202881e+18 - Differentiable computation graph = True!
PPO iteration: 846/1000:
	 start solving instance: 60...
	 start solving instance: 137...
	 start solving instance: 29...
	 start solving instance: 125...
	 start solving instance: 49...
	 start solving instance: 38...
	 start solving instance: 27...
	 start solving instance: 116...
	 start solving instance: 117...
	 start solving instance: 18...
	 start solving instance: 19...
	 start solving instance: 4...
	 start solving instance: 134...
	 start solving instance: 68...
	 start solving instance: 17...
	 start solving instance: 98...
	 start solving instance: 119...
	 start solving instance: 12...
	 start solving instance: 51...
	 start solving instance: 3...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.415009888397846e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5683279872.0
		 entropy bonus: 0.20079298317432404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5531951616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6512292352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.415009998349009e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.415009888397846e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5683279872.0
		 entropy bonus: 0.20079298317432404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5531951616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6512292352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.415009998349009e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.415009888397846e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5683279872.0
		 entropy bonus: 0.20079298317432404
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5531951616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6512292352.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.415009998349009e+18 - Differentiable computation graph = True!
PPO iteration: 847/1000:
	 start solving instance: 12...
	 start solving instance: 98...
	 start solving instance: 3...
	 start solving instance: 27...
	 start solving instance: 68...
	 start solving instance: 19...
	 start solving instance: 17...
	 start solving instance: 18...
	 start solving instance: 134...
	 start solving instance: 60...
	 start solving instance: 4...
	 start solving instance: 29...
	 start solving instance: 116...
	 start solving instance: 125...
	 start solving instance: 119...
	 start solving instance: 137...
	 start solving instance: 117...
	 start solving instance: 49...
	 start solving instance: 38...
	 start solving instance: 51...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5302556394678387e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5724303360.0
		 entropy bonus: 0.19772224128246307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657896960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6358177280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5302555844922573e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5302556394678387e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5724303360.0
		 entropy bonus: 0.19772224128246307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657896960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6358177280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5302555844922573e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5302556394678387e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5724303360.0
		 entropy bonus: 0.19772224128246307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5657896960.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6358177280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5302555844922573e+18 - Differentiable computation graph = True!
PPO iteration: 848/1000:
	 start solving instance: 119...
	 start solving instance: 38...
	 start solving instance: 116...
	 start solving instance: 27...
	 start solving instance: 17...
	 start solving instance: 12...
	 start solving instance: 4...
	 start solving instance: 137...
	 start solving instance: 51...
	 start solving instance: 60...
	 start solving instance: 134...
	 start solving instance: 117...
	 start solving instance: 49...
	 start solving instance: 3...
	 start solving instance: 98...
	 start solving instance: 29...
	 start solving instance: 19...
	 start solving instance: 18...
	 start solving instance: 68...
	 start solving instance: 125...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2725166998752854e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5528242688.0
		 entropy bonus: 0.20522117614746094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5421103616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6293579776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2725168648020296e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2725166998752854e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5528242688.0
		 entropy bonus: 0.20522117614746094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5421103616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6293579776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2725168648020296e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2725166998752854e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5528242688.0
		 entropy bonus: 0.20522117614746094
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5421103616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6293579776.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2725168648020296e+18 - Differentiable computation graph = True!
PPO iteration: 849/1000:
	 start solving instance: 49...
	 start solving instance: 3...
	 start solving instance: 60...
	 start solving instance: 98...
	 start solving instance: 137...
	 start solving instance: 119...
	 start solving instance: 18...
	 start solving instance: 4...
	 start solving instance: 38...
	 start solving instance: 51...
	 start solving instance: 29...
	 start solving instance: 27...
	 start solving instance: 17...
	 start solving instance: 68...
	 start solving instance: 12...
	 start solving instance: 19...
	 start solving instance: 117...
	 start solving instance: 125...
	 start solving instance: 134...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.639802181966417e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5720507904.0
		 entropy bonus: 0.21903324127197266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5887592448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662809600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6398021269908357e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.639802181966417e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5720507904.0
		 entropy bonus: 0.21903324127197266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5887592448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662809600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6398021269908357e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.639802181966417e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5720507904.0
		 entropy bonus: 0.21903324127197266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5887592448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662809600.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6398021269908357e+18 - Differentiable computation graph = True!
PPO iteration: 850/1000:
	 start solving instance: 68...
	 start solving instance: 19...
	 start solving instance: 4...
	 start solving instance: 38...
	 start solving instance: 29...
	 start solving instance: 98...
	 start solving instance: 17...
	 start solving instance: 3...
	 start solving instance: 134...
	 start solving instance: 125...
	 start solving instance: 119...
	 start solving instance: 116...
	 start solving instance: 137...
	 start solving instance: 60...
	 start solving instance: 27...
	 start solving instance: 51...
	 start solving instance: 49...
	 start solving instance: 117...
	 start solving instance: 18...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.341472791513583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631699968.0
		 entropy bonus: 0.1968204528093338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5393133056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369138688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3414727365380014e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.341472791513583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631699968.0
		 entropy bonus: 0.1968204528093338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5393133056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369138688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3414727365380014e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.341472791513583e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5631699968.0
		 entropy bonus: 0.1968204528093338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5393133056.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369138688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3414727365380014e+18 - Differentiable computation graph = True!
PPO iteration: 851/1000:
	 New training batch of size 20...
	 start solving instance: 84...
	 start solving instance: 17...
	 start solving instance: 44...
	 start solving instance: 135...
	 start solving instance: 47...
	 start solving instance: 11...
	 start solving instance: 77...
	 start solving instance: 62...
	 start solving instance: 22...
	 start solving instance: 58...
	 start solving instance: 86...
	 start solving instance: 13...
	 start solving instance: 112...
	 start solving instance: 26...
	 start solving instance: 97...
	 start solving instance: 74...
	 start solving instance: 30...
	 start solving instance: 46...
	 start solving instance: 65...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.393470343709196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149080064.0
		 entropy bonus: 0.22496230900287628
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270735872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779208704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3934703437091963e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.393470343709196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149080064.0
		 entropy bonus: 0.22496230900287628
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270735872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779208704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3934703437091963e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.393470343709196e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6149080064.0
		 entropy bonus: 0.22496230900287628
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270735872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6779208704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3934703437091963e+18 - Differentiable computation graph = True!
PPO iteration: 852/1000:
	 start solving instance: 135...
	 start solving instance: 84...
	 start solving instance: 13...
	 start solving instance: 22...
	 start solving instance: 112...
	 start solving instance: 74...
	 start solving instance: 47...
	 start solving instance: 26...
	 start solving instance: 86...
	 start solving instance: 58...
	 start solving instance: 77...
	 start solving instance: 44...
	 start solving instance: 106...
	 start solving instance: 11...
	 start solving instance: 17...
	 start solving instance: 62...
	 start solving instance: 30...
	 start solving instance: 65...
	 start solving instance: 46...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.071936200156801e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985893888.0
		 entropy bonus: 0.22385267913341522
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6009174528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6810043392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0719363101079634e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.071936200156801e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985893888.0
		 entropy bonus: 0.22385267913341522
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6009174528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6810043392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0719363101079634e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.071936200156801e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5985893888.0
		 entropy bonus: 0.22385267913341522
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6009174528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6810043392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0719363101079634e+18 - Differentiable computation graph = True!
PPO iteration: 853/1000:
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 65...
	 start solving instance: 62...
	 start solving instance: 46...
	 start solving instance: 13...
	 start solving instance: 58...
	 start solving instance: 86...
	 start solving instance: 26...
	 start solving instance: 74...
	 start solving instance: 30...
	 start solving instance: 84...
	 start solving instance: 17...
	 start solving instance: 97...
	 start solving instance: 112...
	 start solving instance: 135...
	 start solving instance: 77...
	 start solving instance: 11...
	 start solving instance: 106...
	 start solving instance: 47...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.271191456560972e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6159352832.0
		 entropy bonus: 0.2182958871126175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188004864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6851269120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.271191456560972e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.271191456560972e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6159352832.0
		 entropy bonus: 0.2182958871126175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188004864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6851269120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.271191456560972e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.271191456560972e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6159352832.0
		 entropy bonus: 0.2182958871126175
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6188004864.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6851269120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.271191456560972e+18 - Differentiable computation graph = True!
PPO iteration: 854/1000:
	 start solving instance: 62...
	 start solving instance: 17...
	 start solving instance: 112...
	 start solving instance: 84...
	 start solving instance: 77...
	 start solving instance: 30...
	 start solving instance: 11...
	 start solving instance: 47...
	 start solving instance: 97...
	 start solving instance: 65...
	 start solving instance: 106...
	 start solving instance: 46...
	 start solving instance: 22...
	 start solving instance: 44...
	 start solving instance: 135...
	 start solving instance: 74...
	 start solving instance: 26...
	 start solving instance: 58...
	 start solving instance: 86...
	 start solving instance: 13...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.575282947650329e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6291437056.0
		 entropy bonus: 0.21451786160469055
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6554694656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7313713152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.575283112577073e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.575282947650329e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6291437056.0
		 entropy bonus: 0.21451786160469055
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6554694656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7313713152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.575283112577073e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.575282947650329e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6291437056.0
		 entropy bonus: 0.21451786160469055
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6554694656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7313713152.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.575283112577073e+18 - Differentiable computation graph = True!
PPO iteration: 855/1000:
	 start solving instance: 77...
	 start solving instance: 106...
	 start solving instance: 97...
	 start solving instance: 112...
	 start solving instance: 22...
	 start solving instance: 58...
	 start solving instance: 62...
	 start solving instance: 17...
	 start solving instance: 135...
	 start solving instance: 46...
	 start solving instance: 65...
	 start solving instance: 11...
	 start solving instance: 84...
	 start solving instance: 44...
	 start solving instance: 47...
	 start solving instance: 86...
	 start solving instance: 13...
	 start solving instance: 30...
	 start solving instance: 26...
	 start solving instance: 74...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.310993337681812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203397632.0
		 entropy bonus: 0.21516409516334534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6190678528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967258624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.310993502608556e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.310993337681812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203397632.0
		 entropy bonus: 0.21516409516334534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6190678528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967258624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.310993502608556e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.310993337681812e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6203397632.0
		 entropy bonus: 0.21516409516334534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6190678528.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6967258624.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.310993502608556e+18 - Differentiable computation graph = True!
PPO iteration: 856/1000:
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 22...
	 start solving instance: 84...
	 start solving instance: 97...
	 start solving instance: 13...
	 start solving instance: 74...
	 start solving instance: 86...
	 start solving instance: 46...
	 start solving instance: 47...
	 start solving instance: 44...
	 start solving instance: 112...
	 start solving instance: 77...
	 start solving instance: 58...
	 start solving instance: 17...
	 start solving instance: 11...
	 start solving instance: 30...
	 start solving instance: 106...
	 start solving instance: 65...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.530111051739431e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6234206720.0
		 entropy bonus: 0.21978846192359924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6345793024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7194832896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.530111051739431e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.530111051739431e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6234206720.0
		 entropy bonus: 0.21978846192359924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6345793024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7194832896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.530111051739431e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.530111051739431e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6234206720.0
		 entropy bonus: 0.21978846192359924
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6345793024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7194832896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.530111051739431e+18 - Differentiable computation graph = True!
PPO iteration: 857/1000:
	 start solving instance: 13...
	 start solving instance: 46...
	 start solving instance: 47...
	 start solving instance: 17...
	 start solving instance: 26...
	 start solving instance: 74...
	 start solving instance: 86...
	 start solving instance: 135...
	 start solving instance: 97...
	 start solving instance: 22...
	 start solving instance: 11...
	 start solving instance: 106...
	 start solving instance: 58...
	 start solving instance: 62...
	 start solving instance: 77...
	 start solving instance: 30...
	 start solving instance: 65...
	 start solving instance: 44...
	 start solving instance: 84...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.454743927701897e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142875136.0
		 entropy bonus: 0.22460058331489563
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6245009920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7353933312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.454743927701897e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.454743927701897e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142875136.0
		 entropy bonus: 0.22460058331489563
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6245009920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7353933312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.454743927701897e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.454743927701897e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6142875136.0
		 entropy bonus: 0.22460058331489563
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6245009920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7353933312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.454743927701897e+18 - Differentiable computation graph = True!
PPO iteration: 858/1000:
	 start solving instance: 65...
	 start solving instance: 112...
	 start solving instance: 11...
	 start solving instance: 58...
	 start solving instance: 62...
	 start solving instance: 13...
	 start solving instance: 74...
	 start solving instance: 46...
	 start solving instance: 106...
	 start solving instance: 26...
	 start solving instance: 17...
	 start solving instance: 135...
	 start solving instance: 47...
	 start solving instance: 77...
	 start solving instance: 30...
	 start solving instance: 84...
	 start solving instance: 44...
	 start solving instance: 22...
	 start solving instance: 86...
	 start solving instance: 97...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5723371360971915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6248079872.0
		 entropy bonus: 0.22176750004291534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6340447744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7271032832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5723372460483543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5723371360971915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6248079872.0
		 entropy bonus: 0.22176750004291534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6340447744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7271032832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5723372460483543e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5723371360971915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6248079872.0
		 entropy bonus: 0.22176750004291534
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6340447744.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7271032832.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5723372460483543e+18 - Differentiable computation graph = True!
PPO iteration: 859/1000:
	 start solving instance: 97...
	 start solving instance: 22...
	 start solving instance: 135...
	 start solving instance: 13...
	 start solving instance: 11...
	 start solving instance: 47...
	 start solving instance: 17...
	 start solving instance: 30...
	 start solving instance: 74...
	 start solving instance: 62...
	 start solving instance: 44...
	 start solving instance: 58...
	 start solving instance: 106...
	 start solving instance: 86...
	 start solving instance: 84...
	 start solving instance: 46...
	 start solving instance: 65...
	 start solving instance: 77...
	 start solving instance: 26...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.164743337829466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048250368.0
		 entropy bonus: 0.2139405459165573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6078501888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6902653952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.164743337829466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.164743337829466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048250368.0
		 entropy bonus: 0.2139405459165573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6078501888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6902653952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.164743337829466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.164743337829466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6048250368.0
		 entropy bonus: 0.2139405459165573
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6078501888.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6902653952.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.164743337829466e+18 - Differentiable computation graph = True!
PPO iteration: 860/1000:
	 start solving instance: 77...
	 start solving instance: 74...
	 start solving instance: 46...
	 start solving instance: 62...
	 start solving instance: 112...
	 start solving instance: 58...
	 start solving instance: 135...
	 start solving instance: 86...
	 start solving instance: 47...
	 start solving instance: 26...
	 start solving instance: 11...
	 start solving instance: 22...
	 start solving instance: 65...
	 start solving instance: 13...
	 start solving instance: 106...
	 start solving instance: 84...
	 start solving instance: 44...
	 start solving instance: 97...
	 start solving instance: 30...
	 start solving instance: 17...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.500360905919719e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6138016768.0
		 entropy bonus: 0.22128169238567352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6379470336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6936303616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.500361015870882e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.500360905919719e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6138016768.0
		 entropy bonus: 0.22128169238567352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6379470336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6936303616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.500361015870882e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.500360905919719e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6138016768.0
		 entropy bonus: 0.22128169238567352
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6379470336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6936303616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.500361015870882e+18 - Differentiable computation graph = True!
PPO iteration: 861/1000:
	 New training batch of size 20...
	 start solving instance: 133...
	 start solving instance: 65...
	 start solving instance: 79...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 2...
	 start solving instance: 39...
	 start solving instance: 103...
	 start solving instance: 77...
	 start solving instance: 122...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 132...
	 start solving instance: 30...
	 start solving instance: 35...
	 start solving instance: 62...
	 start solving instance: 11...
	 start solving instance: 137...
	 start solving instance: 96...
	 start solving instance: 68...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.528767780333132e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5559367168.0
		 entropy bonus: 0.22261209785938263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593466368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6824142848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5287679452598764e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.528767780333132e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5559367168.0
		 entropy bonus: 0.22261209785938263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593466368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6824142848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5287679452598764e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.528767780333132e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5559367168.0
		 entropy bonus: 0.22261209785938263
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5593466368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6824142848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5287679452598764e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.7847561894124585e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5161944064.0
		 entropy bonus: 0.2029229700565338
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4917223424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5791569408.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2784756189412458496.0000
PPO iteration: 862/1000:
	 start solving instance: 68...
	 start solving instance: 35...
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 51...
	 start solving instance: 77...
	 start solving instance: 62...
	 start solving instance: 2...
	 start solving instance: 132...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 122...
	 start solving instance: 79...
	 start solving instance: 137...
	 start solving instance: 11...
	 start solving instance: 96...
	 start solving instance: 133...
	 start solving instance: 39...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.449629331412327e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5492330496.0
		 entropy bonus: 0.21290016174316406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5494712320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543632384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.449629496339071e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.449629331412327e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5492330496.0
		 entropy bonus: 0.21290016174316406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5494712320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543632384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.449629496339071e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.449629331412327e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5492330496.0
		 entropy bonus: 0.21290016174316406
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5494712320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6543632384.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.449629496339071e+18 - Differentiable computation graph = True!
PPO iteration: 863/1000:
	 start solving instance: 39...
	 start solving instance: 137...
	 start solving instance: 11...
	 start solving instance: 2...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 122...
	 start solving instance: 68...
	 start solving instance: 42...
	 start solving instance: 35...
	 start solving instance: 133...
	 start solving instance: 132...
	 start solving instance: 103...
	 start solving instance: 96...
	 start solving instance: 62...
	 start solving instance: 77...
	 start solving instance: 79...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.311259751298577e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5543374848.0
		 entropy bonus: 0.21196900308132172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5272199168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6194280448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3112598062741586e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.311259751298577e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5543374848.0
		 entropy bonus: 0.21196900308132172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5272199168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6194280448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3112598062741586e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.311259751298577e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5543374848.0
		 entropy bonus: 0.21196900308132172
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5272199168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6194280448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3112598062741586e+18 - Differentiable computation graph = True!
PPO iteration: 864/1000:
	 start solving instance: 132...
	 start solving instance: 11...
	 start solving instance: 62...
	 start solving instance: 96...
	 start solving instance: 39...
	 start solving instance: 107...
	 start solving instance: 30...
	 start solving instance: 103...
	 start solving instance: 150...
	 start solving instance: 68...
	 start solving instance: 137...
	 start solving instance: 51...
	 start solving instance: 77...
	 start solving instance: 35...
	 start solving instance: 133...
	 start solving instance: 2...
	 start solving instance: 65...
	 start solving instance: 42...
	 start solving instance: 79...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3427246954529686e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5506345472.0
		 entropy bonus: 0.20103493332862854
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5302204928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6393715200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3427248054041313e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3427246954529686e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5506345472.0
		 entropy bonus: 0.20103493332862854
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5302204928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6393715200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3427248054041313e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3427246954529686e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5506345472.0
		 entropy bonus: 0.20103493332862854
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5302204928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6393715200.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3427248054041313e+18 - Differentiable computation graph = True!
PPO iteration: 865/1000:
	 start solving instance: 137...
	 start solving instance: 77...
	 start solving instance: 68...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 133...
	 start solving instance: 30...
	 start solving instance: 2...
	 start solving instance: 65...
	 start solving instance: 132...
	 start solving instance: 122...
	 start solving instance: 39...
	 start solving instance: 96...
	 start solving instance: 11...
	 start solving instance: 35...
	 start solving instance: 42...
	 start solving instance: 62...
	 start solving instance: 103...
	 start solving instance: 79...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3932290028562547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5544982016.0
		 entropy bonus: 0.2063985913991928
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406605312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6225573888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3932289478806733e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3932290028562547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5544982016.0
		 entropy bonus: 0.2063985913991928
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406605312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6225573888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3932289478806733e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3932290028562547e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5544982016.0
		 entropy bonus: 0.2063985913991928
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406605312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6225573888.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3932289478806733e+18 - Differentiable computation graph = True!
PPO iteration: 866/1000:
	 start solving instance: 39...
	 start solving instance: 11...
	 start solving instance: 103...
	 start solving instance: 132...
	 start solving instance: 68...
	 start solving instance: 65...
	 start solving instance: 96...
	 start solving instance: 77...
	 start solving instance: 30...
	 start solving instance: 42...
	 start solving instance: 133...
	 start solving instance: 51...
	 start solving instance: 107...
	 start solving instance: 62...
	 start solving instance: 79...
	 start solving instance: 2...
	 start solving instance: 150...
	 start solving instance: 137...
	 start solving instance: 122...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.337733132565191e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5522644480.0
		 entropy bonus: 0.21310852468013763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5464293376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6380103168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.337733297491935e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.337733132565191e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5522644480.0
		 entropy bonus: 0.21310852468013763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5464293376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6380103168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.337733297491935e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.337733132565191e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5522644480.0
		 entropy bonus: 0.21310852468013763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5464293376.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6380103168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.337733297491935e+18 - Differentiable computation graph = True!
PPO iteration: 867/1000:
	 start solving instance: 51...
	 start solving instance: 77...
	 start solving instance: 42...
	 start solving instance: 150...
	 start solving instance: 103...
	 start solving instance: 30...
	 start solving instance: 122...
	 start solving instance: 79...
	 start solving instance: 133...
	 start solving instance: 107...
	 start solving instance: 96...
	 start solving instance: 137...
	 start solving instance: 132...
	 start solving instance: 35...
	 start solving instance: 11...
	 start solving instance: 62...
	 start solving instance: 65...
	 start solving instance: 68...
	 start solving instance: 2...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.348984435052223e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5511465984.0
		 entropy bonus: 0.20018158853054047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5398556672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6331695616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.348984599978967e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.348984435052223e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5511465984.0
		 entropy bonus: 0.20018158853054047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5398556672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6331695616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.348984599978967e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.348984435052223e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5511465984.0
		 entropy bonus: 0.20018158853054047
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5398556672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6331695616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.348984599978967e+18 - Differentiable computation graph = True!
PPO iteration: 868/1000:
	 start solving instance: 65...
	 start solving instance: 11...
	 start solving instance: 62...
	 start solving instance: 39...
	 start solving instance: 77...
	 start solving instance: 96...
	 start solving instance: 132...
	 start solving instance: 68...
	 start solving instance: 150...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 42...
	 start solving instance: 133...
	 start solving instance: 51...
	 start solving instance: 79...
	 start solving instance: 122...
	 start solving instance: 2...
	 start solving instance: 35...
	 start solving instance: 107...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.336482328137433e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5492004352.0
		 entropy bonus: 0.20441794395446777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5368944640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6088403968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.336482328137433e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.336482328137433e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5492004352.0
		 entropy bonus: 0.20441794395446777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5368944640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6088403968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.336482328137433e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.336482328137433e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5492004352.0
		 entropy bonus: 0.20441794395446777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5368944640.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6088403968.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.336482328137433e+18 - Differentiable computation graph = True!
PPO iteration: 869/1000:
	 start solving instance: 96...
	 start solving instance: 2...
	 start solving instance: 30...
	 start solving instance: 68...
	 start solving instance: 62...
	 start solving instance: 150...
	 start solving instance: 11...
	 start solving instance: 39...
	 start solving instance: 103...
	 start solving instance: 79...
	 start solving instance: 51...
	 start solving instance: 35...
	 start solving instance: 132...
	 start solving instance: 77...
	 start solving instance: 122...
	 start solving instance: 42...
	 start solving instance: 133...
	 start solving instance: 107...
	 start solving instance: 65...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.0933719509477884e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5443791360.0
		 entropy bonus: 0.20327062904834747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5200008704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6041622528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.093372060898951e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.0933719509477884e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5443791360.0
		 entropy bonus: 0.20327062904834747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5200008704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6041622528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.093372060898951e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.0933719509477884e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5443791360.0
		 entropy bonus: 0.20327062904834747
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5200008704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6041622528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.093372060898951e+18 - Differentiable computation graph = True!
PPO iteration: 870/1000:
	 start solving instance: 30...
	 start solving instance: 65...
	 start solving instance: 39...
	 start solving instance: 35...
	 start solving instance: 11...
	 start solving instance: 68...
	 start solving instance: 79...
	 start solving instance: 2...
	 start solving instance: 150...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 51...
	 start solving instance: 133...
	 start solving instance: 42...
	 start solving instance: 107...
	 start solving instance: 77...
	 start solving instance: 62...
	 start solving instance: 96...
	 start solving instance: 132...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.061078414830705e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5407374848.0
		 entropy bonus: 0.19854553043842316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5159808512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5929874432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.061078579757449e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.061078414830705e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5407374848.0
		 entropy bonus: 0.19854553043842316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5159808512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5929874432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.061078579757449e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.061078414830705e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5407374848.0
		 entropy bonus: 0.19854553043842316
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5159808512.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5929874432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.061078579757449e+18 - Differentiable computation graph = True!
PPO iteration: 871/1000:
	 New training batch of size 20...
	 start solving instance: 31...
	 start solving instance: 38...
	 start solving instance: 79...
	 start solving instance: 40...
	 start solving instance: 36...
	 start solving instance: 90...
	 start solving instance: 58...
	 start solving instance: 17...
	 start solving instance: 148...
	 start solving instance: 72...
	 start solving instance: 49...
	 start solving instance: 87...
	 start solving instance: 89...
	 start solving instance: 92...
	 start solving instance: 121...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 120...
	 start solving instance: 142...
	 start solving instance: 119...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.116348553435231e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5991035904.0
		 entropy bonus: 0.21900878846645355
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6143452672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662999040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1163486084108124e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.116348553435231e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5991035904.0
		 entropy bonus: 0.21900878846645355
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6143452672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662999040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1163486084108124e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.116348553435231e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5991035904.0
		 entropy bonus: 0.21900878846645355
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6143452672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6662999040.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1163486084108124e+18 - Differentiable computation graph = True!
PPO iteration: 872/1000:
	 start solving instance: 17...
	 start solving instance: 92...
	 start solving instance: 90...
	 start solving instance: 119...
	 start solving instance: 36...
	 start solving instance: 148...
	 start solving instance: 31...
	 start solving instance: 58...
	 start solving instance: 142...
	 start solving instance: 79...
	 start solving instance: 38...
	 start solving instance: 121...
	 start solving instance: 26...
	 start solving instance: 87...
	 start solving instance: 72...
	 start solving instance: 49...
	 start solving instance: 89...
	 start solving instance: 135...
	 start solving instance: 40...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.788093315204566e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5925914112.0
		 entropy bonus: 0.20438018441200256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5799086080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6421439488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.788093260228985e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.788093315204566e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5925914112.0
		 entropy bonus: 0.20438018441200256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5799086080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6421439488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.788093260228985e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.788093315204566e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5925914112.0
		 entropy bonus: 0.20438018441200256
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5799086080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6421439488.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.788093260228985e+18 - Differentiable computation graph = True!
PPO iteration: 873/1000:
	 start solving instance: 72...
	 start solving instance: 26...
	 start solving instance: 148...
	 start solving instance: 135...
	 start solving instance: 17...
	 start solving instance: 120...
	 start solving instance: 121...
	 start solving instance: 119...
	 start solving instance: 58...
	 start solving instance: 40...
	 start solving instance: 142...
	 start solving instance: 36...
	 start solving instance: 31...
	 start solving instance: 92...
	 start solving instance: 89...
	 start solving instance: 49...
	 start solving instance: 38...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 87...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.206310155015212e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079201280.0
		 entropy bonus: 0.2119196504354477
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6260610048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6742670848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.206310100039631e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.206310155015212e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079201280.0
		 entropy bonus: 0.2119196504354477
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6260610048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6742670848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.206310100039631e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.206310155015212e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6079201280.0
		 entropy bonus: 0.2119196504354477
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6260610048.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6742670848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.206310100039631e+18 - Differentiable computation graph = True!
PPO iteration: 874/1000:
	 start solving instance: 79...
	 start solving instance: 87...
	 start solving instance: 90...
	 start solving instance: 89...
	 start solving instance: 58...
	 start solving instance: 17...
	 start solving instance: 142...
	 start solving instance: 119...
	 start solving instance: 36...
	 start solving instance: 121...
	 start solving instance: 38...
	 start solving instance: 26...
	 start solving instance: 120...
	 start solving instance: 92...
	 start solving instance: 40...
	 start solving instance: 31...
	 start solving instance: 49...
	 start solving instance: 135...
	 start solving instance: 148...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2398584538019135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059189248.0
		 entropy bonus: 0.21572564542293549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6254583296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037800960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.239858398826332e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2398584538019135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059189248.0
		 entropy bonus: 0.21572564542293549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6254583296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037800960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.239858398826332e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2398584538019135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059189248.0
		 entropy bonus: 0.21572564542293549
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6254583296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037800960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.239858398826332e+18 - Differentiable computation graph = True!
PPO iteration: 875/1000:
	 start solving instance: 36...
	 start solving instance: 49...
	 start solving instance: 135...
	 start solving instance: 120...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 87...
	 start solving instance: 40...
	 start solving instance: 89...
	 start solving instance: 58...
	 start solving instance: 121...
	 start solving instance: 119...
	 start solving instance: 38...
	 start solving instance: 17...
	 start solving instance: 72...
	 start solving instance: 92...
	 start solving instance: 142...
	 start solving instance: 148...
	 start solving instance: 26...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.101704817771859e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6032314368.0
		 entropy bonus: 0.20363354682922363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053709312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6886519808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.101704762796278e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.101704817771859e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6032314368.0
		 entropy bonus: 0.20363354682922363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053709312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6886519808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.101704762796278e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.101704817771859e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6032314368.0
		 entropy bonus: 0.20363354682922363
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053709312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6886519808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.101704762796278e+18 - Differentiable computation graph = True!
PPO iteration: 876/1000:
	 start solving instance: 90...
	 start solving instance: 142...
	 start solving instance: 79...
	 start solving instance: 40...
	 start solving instance: 72...
	 start solving instance: 119...
	 start solving instance: 17...
	 start solving instance: 89...
	 start solving instance: 38...
	 start solving instance: 31...
	 start solving instance: 92...
	 start solving instance: 49...
	 start solving instance: 87...
	 start solving instance: 58...
	 start solving instance: 36...
	 start solving instance: 121...
	 start solving instance: 148...
	 start solving instance: 26...
	 start solving instance: 120...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.972655577824441e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998055424.0
		 entropy bonus: 0.20907309651374817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5950518272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6747516416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9726556328000225e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.972655577824441e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998055424.0
		 entropy bonus: 0.20907309651374817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5950518272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6747516416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9726556328000225e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.972655577824441e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5998055424.0
		 entropy bonus: 0.20907309651374817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5950518272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6747516416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9726556328000225e+18 - Differentiable computation graph = True!
PPO iteration: 877/1000:
	 start solving instance: 26...
	 start solving instance: 142...
	 start solving instance: 135...
	 start solving instance: 121...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 49...
	 start solving instance: 119...
	 start solving instance: 40...
	 start solving instance: 72...
	 start solving instance: 120...
	 start solving instance: 89...
	 start solving instance: 38...
	 start solving instance: 87...
	 start solving instance: 17...
	 start solving instance: 92...
	 start solving instance: 31...
	 start solving instance: 58...
	 start solving instance: 148...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.971145288652528e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5921832448.0
		 entropy bonus: 0.2169274389743805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935338496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6439566336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971145453579272e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.971145288652528e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5921832448.0
		 entropy bonus: 0.2169274389743805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935338496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6439566336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971145453579272e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.971145288652528e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5921832448.0
		 entropy bonus: 0.2169274389743805
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935338496.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6439566336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.971145453579272e+18 - Differentiable computation graph = True!
PPO iteration: 878/1000:
	 start solving instance: 142...
	 start solving instance: 120...
	 start solving instance: 40...
	 start solving instance: 36...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 38...
	 start solving instance: 92...
	 start solving instance: 148...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 31...
	 start solving instance: 121...
	 start solving instance: 17...
	 start solving instance: 58...
	 start solving instance: 87...
	 start solving instance: 49...
	 start solving instance: 119...
	 start solving instance: 89...
	 start solving instance: 72...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2577017683021136e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106334720.0
		 entropy bonus: 0.21371197700500488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6281605120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6918853632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257701823277695e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2577017683021136e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106334720.0
		 entropy bonus: 0.21371197700500488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6281605120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6918853632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257701823277695e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2577017683021136e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6106334720.0
		 entropy bonus: 0.21371197700500488
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6281605120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6918853632.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.257701823277695e+18 - Differentiable computation graph = True!
PPO iteration: 879/1000:
	 start solving instance: 17...
	 start solving instance: 89...
	 start solving instance: 90...
	 start solving instance: 148...
	 start solving instance: 87...
	 start solving instance: 36...
	 start solving instance: 38...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 119...
	 start solving instance: 79...
	 start solving instance: 26...
	 start solving instance: 72...
	 start solving instance: 40...
	 start solving instance: 31...
	 start solving instance: 120...
	 start solving instance: 92...
	 start solving instance: 121...
	 start solving instance: 49...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.079822777160512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083666432.0
		 entropy bonus: 0.207352876663208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6107574784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6478932480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0798228321360937e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.079822777160512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083666432.0
		 entropy bonus: 0.207352876663208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6107574784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6478932480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0798228321360937e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.079822777160512e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083666432.0
		 entropy bonus: 0.207352876663208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6107574784.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6478932480.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0798228321360937e+18 - Differentiable computation graph = True!
PPO iteration: 880/1000:
	 start solving instance: 119...
	 start solving instance: 72...
	 start solving instance: 26...
	 start solving instance: 58...
	 start solving instance: 92...
	 start solving instance: 142...
	 start solving instance: 120...
	 start solving instance: 40...
	 start solving instance: 148...
	 start solving instance: 17...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 87...
	 start solving instance: 49...
	 start solving instance: 89...
	 start solving instance: 36...
	 start solving instance: 121...
	 start solving instance: 135...
	 start solving instance: 38...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.130194483461489e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6020980224.0
		 entropy bonus: 0.2149352878332138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6182517248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6630202368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1301944834614886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.130194483461489e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6020980224.0
		 entropy bonus: 0.2149352878332138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6182517248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6630202368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1301944834614886e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.130194483461489e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6020980224.0
		 entropy bonus: 0.2149352878332138
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6182517248.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6630202368.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1301944834614886e+18 - Differentiable computation graph = True!
PPO iteration: 881/1000:
	 New training batch of size 20...
	 start solving instance: 99...
	 start solving instance: 69...
	 start solving instance: 136...
	 start solving instance: 34...
	 start solving instance: 140...
	 start solving instance: 19...
	 start solving instance: 106...
	 start solving instance: 3...
	 start solving instance: 32...
	 start solving instance: 38...
	 start solving instance: 102...
	 start solving instance: 86...
	 start solving instance: 53...
	 start solving instance: 62...
	 start solving instance: 44...
	 start solving instance: 104...
	 start solving instance: 142...
	 start solving instance: 57...
	 start solving instance: 43...
	 start solving instance: 52...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.336302448035129e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768801792.0
		 entropy bonus: 0.19300875067710876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5290707456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5917988864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3363025579862917e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.336302448035129e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768801792.0
		 entropy bonus: 0.19300875067710876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5290707456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5917988864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3363025579862917e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.336302448035129e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5768801792.0
		 entropy bonus: 0.19300875067710876
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5290707456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5917988864.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3363025579862917e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.2016692283348877e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5357436928.0
		 entropy bonus: 0.20493312180042267
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5326653952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6039406592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3201669283310469120.0000
PPO iteration: 882/1000:
	 start solving instance: 43...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 52...
	 start solving instance: 3...
	 start solving instance: 44...
	 start solving instance: 38...
	 start solving instance: 136...
	 start solving instance: 106...
	 start solving instance: 62...
	 start solving instance: 19...
	 start solving instance: 102...
	 start solving instance: 53...
	 start solving instance: 69...
	 start solving instance: 86...
	 start solving instance: 104...
	 start solving instance: 57...
	 start solving instance: 140...
	 start solving instance: 34...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5524433443117072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5788956160.0
		 entropy bonus: 0.19426164031028748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5661381632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6205842432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.55244345426287e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5524433443117072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5788956160.0
		 entropy bonus: 0.19426164031028748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5661381632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6205842432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.55244345426287e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5524433443117072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5788956160.0
		 entropy bonus: 0.19426164031028748
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5661381632.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6205842432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.55244345426287e+18 - Differentiable computation graph = True!
PPO iteration: 883/1000:
	 start solving instance: 99...
	 start solving instance: 52...
	 start solving instance: 32...
	 start solving instance: 62...
	 start solving instance: 102...
	 start solving instance: 106...
	 start solving instance: 44...
	 start solving instance: 38...
	 start solving instance: 53...
	 start solving instance: 3...
	 start solving instance: 86...
	 start solving instance: 136...
	 start solving instance: 19...
	 start solving instance: 43...
	 start solving instance: 57...
	 start solving instance: 140...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 69...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.70817025478618e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5840590848.0
		 entropy bonus: 0.20010828971862793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5737575936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529906688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7081703097617613e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.70817025478618e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5840590848.0
		 entropy bonus: 0.20010828971862793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5737575936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529906688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7081703097617613e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.70817025478618e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5840590848.0
		 entropy bonus: 0.20010828971862793
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5737575936.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6529906688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7081703097617613e+18 - Differentiable computation graph = True!
PPO iteration: 884/1000:
	 start solving instance: 38...
	 start solving instance: 32...
	 start solving instance: 104...
	 start solving instance: 86...
	 start solving instance: 62...
	 start solving instance: 142...
	 start solving instance: 53...
	 start solving instance: 57...
	 start solving instance: 69...
	 start solving instance: 136...
	 start solving instance: 106...
	 start solving instance: 99...
	 start solving instance: 43...
	 start solving instance: 52...
	 start solving instance: 19...
	 start solving instance: 44...
	 start solving instance: 34...
	 start solving instance: 102...
	 start solving instance: 3...
	 start solving instance: 140...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.621088274159344e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5845943808.0
		 entropy bonus: 0.19798636436462402
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723349504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6304074240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.621088439086088e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.621088274159344e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5845943808.0
		 entropy bonus: 0.19798636436462402
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723349504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6304074240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.621088439086088e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.621088274159344e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5834852864.0
		 entropy bonus: 0.18643391132354736
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723349504.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6304074240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.621088439086088e+18 - Differentiable computation graph = True!
PPO iteration: 885/1000:
	 start solving instance: 38...
	 start solving instance: 43...
	 start solving instance: 19...
	 start solving instance: 86...
	 start solving instance: 102...
	 start solving instance: 53...
	 start solving instance: 140...
	 start solving instance: 52...
	 start solving instance: 62...
	 start solving instance: 136...
	 start solving instance: 3...
	 start solving instance: 34...
	 start solving instance: 32...
	 start solving instance: 142...
	 start solving instance: 104...
	 start solving instance: 106...
	 start solving instance: 44...
	 start solving instance: 69...
	 start solving instance: 99...
	 start solving instance: 57...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6877888276444217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5804363776.0
		 entropy bonus: 0.19481968879699707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723415552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509922304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6877889375955845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6877888276444217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5804363776.0
		 entropy bonus: 0.19481968879699707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723415552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509922304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6877889375955845e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6877888276444217e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5804363776.0
		 entropy bonus: 0.19481968879699707
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5723415552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6509922304.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6877889375955845e+18 - Differentiable computation graph = True!
PPO iteration: 886/1000:
	 start solving instance: 53...
	 start solving instance: 69...
	 start solving instance: 44...
	 start solving instance: 52...
	 start solving instance: 32...
	 start solving instance: 99...
	 start solving instance: 106...
	 start solving instance: 19...
	 start solving instance: 142...
	 start solving instance: 102...
	 start solving instance: 86...
	 start solving instance: 57...
	 start solving instance: 62...
	 start solving instance: 3...
	 start solving instance: 43...
	 start solving instance: 34...
	 start solving instance: 136...
	 start solving instance: 140...
	 start solving instance: 104...
	 start solving instance: 38...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6360842933482553e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5840281600.0
		 entropy bonus: 0.2080589383840561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5709991424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369570816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.636084403299418e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6360842933482553e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5840281600.0
		 entropy bonus: 0.2080589383840561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5709991424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369570816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.636084403299418e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6360842933482553e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5840281600.0
		 entropy bonus: 0.2080589383840561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5709991424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6369570816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.636084403299418e+18 - Differentiable computation graph = True!
PPO iteration: 887/1000:
	 start solving instance: 38...
	 start solving instance: 43...
	 start solving instance: 34...
	 start solving instance: 3...
	 start solving instance: 106...
	 start solving instance: 32...
	 start solving instance: 57...
	 start solving instance: 69...
	 start solving instance: 104...
	 start solving instance: 140...
	 start solving instance: 62...
	 start solving instance: 99...
	 start solving instance: 86...
	 start solving instance: 136...
	 start solving instance: 52...
	 start solving instance: 44...
	 start solving instance: 19...
	 start solving instance: 102...
	 start solving instance: 142...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.685788815993497e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885488640.0
		 entropy bonus: 0.1981838047504425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5792671232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6261070336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.68578892594466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.685788815993497e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885488640.0
		 entropy bonus: 0.1981838047504425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5792671232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6261070336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.68578892594466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.685788815993497e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885488640.0
		 entropy bonus: 0.1981838047504425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5792671232.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6261070336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.68578892594466e+18 - Differentiable computation graph = True!
PPO iteration: 888/1000:
	 start solving instance: 102...
	 start solving instance: 34...
	 start solving instance: 62...
	 start solving instance: 3...
	 start solving instance: 99...
	 start solving instance: 104...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 38...
	 start solving instance: 57...
	 start solving instance: 140...
	 start solving instance: 19...
	 start solving instance: 53...
	 start solving instance: 43...
	 start solving instance: 86...
	 start solving instance: 69...
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 136...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4775756184555094e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5781636608.0
		 entropy bonus: 0.20308151841163635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5505679360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6128079360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4775757833822536e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4775756184555094e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5781636608.0
		 entropy bonus: 0.20308151841163635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5505679360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6128079360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4775757833822536e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4775756184555094e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5781636608.0
		 entropy bonus: 0.20308151841163635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5505679360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6128079360.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4775757833822536e+18 - Differentiable computation graph = True!
PPO iteration: 889/1000:
	 start solving instance: 99...
	 start solving instance: 69...
	 start solving instance: 140...
	 start solving instance: 3...
	 start solving instance: 106...
	 start solving instance: 32...
	 start solving instance: 44...
	 start solving instance: 86...
	 start solving instance: 34...
	 start solving instance: 43...
	 start solving instance: 62...
	 start solving instance: 136...
	 start solving instance: 104...
	 start solving instance: 57...
	 start solving instance: 19...
	 start solving instance: 52...
	 start solving instance: 102...
	 start solving instance: 142...
	 start solving instance: 38...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4681215776752402e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738503168.0
		 entropy bonus: 0.19421735405921936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5508898304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6331515904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4681216326508216e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4681215776752402e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738503168.0
		 entropy bonus: 0.19421735405921936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5508898304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6331515904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4681216326508216e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4681215776752402e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5738503168.0
		 entropy bonus: 0.19421735405921936
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5508898304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6331515904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4681216326508216e+18 - Differentiable computation graph = True!
PPO iteration: 890/1000:
	 start solving instance: 43...
	 start solving instance: 142...
	 start solving instance: 140...
	 start solving instance: 62...
	 start solving instance: 32...
	 start solving instance: 53...
	 start solving instance: 19...
	 start solving instance: 44...
	 start solving instance: 52...
	 start solving instance: 106...
	 start solving instance: 86...
	 start solving instance: 57...
	 start solving instance: 104...
	 start solving instance: 102...
	 start solving instance: 69...
	 start solving instance: 38...
	 start solving instance: 136...
	 start solving instance: 99...
	 start solving instance: 3...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.547059695577465e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5892849664.0
		 entropy bonus: 0.18846234679222107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5559271424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6133768704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.547059695577465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.547059695577465e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5892849664.0
		 entropy bonus: 0.18846234679222107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5559271424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6133768704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.547059695577465e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.547059695577465e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5892849664.0
		 entropy bonus: 0.18846234679222107
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5559271424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6133768704.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.547059695577465e+18 - Differentiable computation graph = True!
PPO iteration: 891/1000:
	 New training batch of size 20...
	 start solving instance: 114...
	 start solving instance: 133...
	 start solving instance: 84...
	 start solving instance: 79...
	 start solving instance: 64...
	 start solving instance: 35...
	 start solving instance: 148...
	 start solving instance: 101...
	 start solving instance: 54...
	 start solving instance: 131...
	 start solving instance: 99...
	 start solving instance: 87...
	 start solving instance: 41...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 76...
	 start solving instance: 91...
	 start solving instance: 65...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.016472435605268e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5933761024.0
		 entropy bonus: 0.2160869687795639
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6037429760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6465323008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.016472545556431e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.016472435605268e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5933761024.0
		 entropy bonus: 0.2160869687795639
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6037429760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6465323008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.016472545556431e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.016472435605268e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5933761024.0
		 entropy bonus: 0.2160869687795639
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6037429760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6465323008.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.016472545556431e+18 - Differentiable computation graph = True!
PPO iteration: 892/1000:
	 start solving instance: 87...
	 start solving instance: 148...
	 start solving instance: 133...
	 start solving instance: 114...
	 start solving instance: 84...
	 start solving instance: 41...
	 start solving instance: 43...
	 start solving instance: 64...
	 start solving instance: 118...
	 start solving instance: 9...
	 start solving instance: 131...
	 start solving instance: 101...
	 start solving instance: 65...
	 start solving instance: 79...
	 start solving instance: 91...
	 start solving instance: 10...
	 start solving instance: 54...
	 start solving instance: 76...
	 start solving instance: 99...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.940146977232965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5911088640.0
		 entropy bonus: 0.22929885983467102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004624896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6636310528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9401469222573834e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.940146977232965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5911088640.0
		 entropy bonus: 0.22929885983467102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004624896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6636310528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9401469222573834e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.940146977232965e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5911088640.0
		 entropy bonus: 0.22929885983467102
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6004624896.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6636310528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9401469222573834e+18 - Differentiable computation graph = True!
PPO iteration: 893/1000:
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 76...
	 start solving instance: 65...
	 start solving instance: 99...
	 start solving instance: 131...
	 start solving instance: 84...
	 start solving instance: 41...
	 start solving instance: 64...
	 start solving instance: 54...
	 start solving instance: 43...
	 start solving instance: 114...
	 start solving instance: 101...
	 start solving instance: 10...
	 start solving instance: 118...
	 start solving instance: 133...
	 start solving instance: 35...
	 start solving instance: 79...
	 start solving instance: 148...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.924909505290594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5987483136.0
		 entropy bonus: 0.21145346760749817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053681152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6667611648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9249096152417567e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.924909505290594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5987483136.0
		 entropy bonus: 0.21145346760749817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053681152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6667611648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9249096152417567e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.924909505290594e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5987483136.0
		 entropy bonus: 0.21145346760749817
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6053681152.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6667611648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9249096152417567e+18 - Differentiable computation graph = True!
PPO iteration: 894/1000:
	 start solving instance: 10...
	 start solving instance: 54...
	 start solving instance: 114...
	 start solving instance: 35...
	 start solving instance: 64...
	 start solving instance: 118...
	 start solving instance: 65...
	 start solving instance: 99...
	 start solving instance: 76...
	 start solving instance: 9...
	 start solving instance: 43...
	 start solving instance: 131...
	 start solving instance: 79...
	 start solving instance: 133...
	 start solving instance: 41...
	 start solving instance: 148...
	 start solving instance: 87...
	 start solving instance: 84...
	 start solving instance: 91...
	 start solving instance: 101...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.677863975985139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928961024.0
		 entropy bonus: 0.22209730744361877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5827280384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6359859712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6778639210095575e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.677863975985139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928961024.0
		 entropy bonus: 0.22209730744361877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5827280384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6359859712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6778639210095575e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.677863975985139e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5928961024.0
		 entropy bonus: 0.22209730744361877
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5827280384.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6359859712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6778639210095575e+18 - Differentiable computation graph = True!
PPO iteration: 895/1000:
	 start solving instance: 41...
	 start solving instance: 54...
	 start solving instance: 91...
	 start solving instance: 133...
	 start solving instance: 101...
	 start solving instance: 64...
	 start solving instance: 76...
	 start solving instance: 148...
	 start solving instance: 79...
	 start solving instance: 9...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 114...
	 start solving instance: 87...
	 start solving instance: 10...
	 start solving instance: 84...
	 start solving instance: 43...
	 start solving instance: 131...
	 start solving instance: 99...
	 start solving instance: 35...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.955010615221892e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5978800128.0
		 entropy bonus: 0.22181682288646698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5872188928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6632008192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9550106701974733e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.955010615221892e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5978800128.0
		 entropy bonus: 0.22181682288646698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5872188928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6632008192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9550106701974733e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.955010615221892e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5978800128.0
		 entropy bonus: 0.22181682288646698
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5872188928.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6632008192.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9550106701974733e+18 - Differentiable computation graph = True!
PPO iteration: 896/1000:
	 start solving instance: 131...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 114...
	 start solving instance: 64...
	 start solving instance: 148...
	 start solving instance: 43...
	 start solving instance: 101...
	 start solving instance: 84...
	 start solving instance: 10...
	 start solving instance: 35...
	 start solving instance: 87...
	 start solving instance: 9...
	 start solving instance: 76...
	 start solving instance: 54...
	 start solving instance: 133...
	 start solving instance: 41...
	 start solving instance: 99...
	 start solving instance: 79...
	 start solving instance: 91...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.865954131613896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5761082880.0
		 entropy bonus: 0.23750324547290802
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935369216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6427890688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8659540766383145e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.865954131613896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5761082880.0
		 entropy bonus: 0.23750324547290802
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935369216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6427890688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8659540766383145e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.865954131613896e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5761082880.0
		 entropy bonus: 0.23750324547290802
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5935369216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6427890688.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8659540766383145e+18 - Differentiable computation graph = True!
PPO iteration: 897/1000:
	 start solving instance: 87...
	 start solving instance: 64...
	 start solving instance: 76...
	 start solving instance: 148...
	 start solving instance: 41...
	 start solving instance: 118...
	 start solving instance: 10...
	 start solving instance: 35...
	 start solving instance: 79...
	 start solving instance: 91...
	 start solving instance: 84...
	 start solving instance: 114...
	 start solving instance: 133...
	 start solving instance: 54...
	 start solving instance: 43...
	 start solving instance: 9...
	 start solving instance: 65...
	 start solving instance: 131...
	 start solving instance: 101...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.785418863121164e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927196160.0
		 entropy bonus: 0.22497855126857758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865318912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6474249728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7854189730723267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.785418863121164e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927196160.0
		 entropy bonus: 0.22497855126857758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865318912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6474249728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7854189730723267e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.785418863121164e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5927196160.0
		 entropy bonus: 0.22497855126857758
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5865318912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6474249728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7854189730723267e+18 - Differentiable computation graph = True!
PPO iteration: 898/1000:
	 start solving instance: 148...
	 start solving instance: 118...
	 start solving instance: 10...
	 start solving instance: 87...
	 start solving instance: 84...
	 start solving instance: 54...
	 start solving instance: 64...
	 start solving instance: 101...
	 start solving instance: 65...
	 start solving instance: 131...
	 start solving instance: 41...
	 start solving instance: 91...
	 start solving instance: 114...
	 start solving instance: 35...
	 start solving instance: 9...
	 start solving instance: 99...
	 start solving instance: 76...
	 start solving instance: 133...
	 start solving instance: 79...
	 start solving instance: 43...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.085987958759778e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5971707904.0
		 entropy bonus: 0.2260047048330307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6117938176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6911138816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0859880687109407e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.085987958759778e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5971707904.0
		 entropy bonus: 0.2260047048330307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6117938176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6911138816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0859880687109407e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.085987958759778e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5971707904.0
		 entropy bonus: 0.2260047048330307
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6117938176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6911138816.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0859880687109407e+18 - Differentiable computation graph = True!
PPO iteration: 899/1000:
	 start solving instance: 41...
	 start solving instance: 64...
	 start solving instance: 79...
	 start solving instance: 76...
	 start solving instance: 65...
	 start solving instance: 91...
	 start solving instance: 101...
	 start solving instance: 114...
	 start solving instance: 131...
	 start solving instance: 43...
	 start solving instance: 35...
	 start solving instance: 9...
	 start solving instance: 54...
	 start solving instance: 10...
	 start solving instance: 87...
	 start solving instance: 148...
	 start solving instance: 84...
	 start solving instance: 118...
	 start solving instance: 133...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.881426899044611e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894061568.0
		 entropy bonus: 0.2317586988210678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5878136320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6604225536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.881426954020192e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.881426899044611e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894061568.0
		 entropy bonus: 0.2317586988210678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5878136320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6604225536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.881426954020192e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.881426899044611e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5894061568.0
		 entropy bonus: 0.2317586988210678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5878136320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6604225536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.881426954020192e+18 - Differentiable computation graph = True!
PPO iteration: 900/1000:
	 start solving instance: 131...
	 start solving instance: 35...
	 start solving instance: 43...
	 start solving instance: 76...
	 start solving instance: 148...
	 start solving instance: 10...
	 start solving instance: 9...
	 start solving instance: 84...
	 start solving instance: 99...
	 start solving instance: 101...
	 start solving instance: 114...
	 start solving instance: 54...
	 start solving instance: 87...
	 start solving instance: 65...
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 133...
	 start solving instance: 91...
	 start solving instance: 79...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.951376949194418e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5870499328.0
		 entropy bonus: 0.22865377366542816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6013990912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6552843264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9513770591455805e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.951376949194418e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5870499328.0
		 entropy bonus: 0.22865377366542816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6013990912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6552843264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9513770591455805e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.951376949194418e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5870499328.0
		 entropy bonus: 0.22865377366542816
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6013990912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6552843264.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9513770591455805e+18 - Differentiable computation graph = True!
PPO iteration: 901/1000:
	 New training batch of size 20...
	 start solving instance: 121...
	 start solving instance: 84...
	 start solving instance: 2...
	 start solving instance: 79...
	 start solving instance: 50...
	 start solving instance: 115...
	 start solving instance: 127...
	 start solving instance: 15...
	 start solving instance: 27...
	 start solving instance: 30...
	 start solving instance: 99...
	 start solving instance: 54...
	 start solving instance: 7...
	 start solving instance: 124...
	 start solving instance: 108...
	 start solving instance: 134...
	 start solving instance: 131...
	 start solving instance: 44...
	 start solving instance: 51...
	 start solving instance: 150...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.519428196763959e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6397914112.0
		 entropy bonus: 0.2317083179950714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6452751872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7093430784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5194281967639593e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.519428196763959e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6397914112.0
		 entropy bonus: 0.2317083179950714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6452751872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7093430784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5194281967639593e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.519428196763959e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6397914112.0
		 entropy bonus: 0.2317083179950714
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6452751872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7093430784.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5194281967639593e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.154757465224197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5234391040.0
		 entropy bonus: 0.21222005784511566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5216731136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6161289216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3154757520199778304.0000
PPO iteration: 902/1000:
	 start solving instance: 30...
	 start solving instance: 44...
	 start solving instance: 15...
	 start solving instance: 124...
	 start solving instance: 115...
	 start solving instance: 7...
	 start solving instance: 127...
	 start solving instance: 99...
	 start solving instance: 2...
	 start solving instance: 134...
	 start solving instance: 150...
	 start solving instance: 84...
	 start solving instance: 108...
	 start solving instance: 121...
	 start solving instance: 27...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 131...
	 start solving instance: 51...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.477152414480623e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6353963520.0
		 entropy bonus: 0.2135837823152542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6424054272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7004681728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.477152524431786e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.477152414480623e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6353963520.0
		 entropy bonus: 0.2135837823152542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6424054272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7004681728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.477152524431786e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.477152414480623e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6353963520.0
		 entropy bonus: 0.2135837823152542
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6424054272.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7004681728.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.477152524431786e+18 - Differentiable computation graph = True!
PPO iteration: 903/1000:
	 start solving instance: 108...
	 start solving instance: 15...
	 start solving instance: 30...
	 start solving instance: 51...
	 start solving instance: 127...
	 start solving instance: 27...
	 start solving instance: 50...
	 start solving instance: 54...
	 start solving instance: 99...
	 start solving instance: 115...
	 start solving instance: 121...
	 start solving instance: 2...
	 start solving instance: 84...
	 start solving instance: 7...
	 start solving instance: 124...
	 start solving instance: 150...
	 start solving instance: 131...
	 start solving instance: 44...
	 start solving instance: 134...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.461344076101111e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6301084672.0
		 entropy bonus: 0.22293220460414886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6476654592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7278787072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4613440211255296e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.461344076101111e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6301084672.0
		 entropy bonus: 0.22293220460414886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6476654592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7278787072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4613440211255296e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.461344076101111e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6301084672.0
		 entropy bonus: 0.22293220460414886
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6476654592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7278787072.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4613440211255296e+18 - Differentiable computation graph = True!
PPO iteration: 904/1000:
	 start solving instance: 30...
	 start solving instance: 121...
	 start solving instance: 99...
	 start solving instance: 124...
	 start solving instance: 27...
	 start solving instance: 131...
	 start solving instance: 108...
	 start solving instance: 150...
	 start solving instance: 15...
	 start solving instance: 50...
	 start solving instance: 44...
	 start solving instance: 54...
	 start solving instance: 51...
	 start solving instance: 127...
	 start solving instance: 2...
	 start solving instance: 134...
	 start solving instance: 115...
	 start solving instance: 84...
	 start solving instance: 7...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.509090148634958e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6414647808.0
		 entropy bonus: 0.22071433067321777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6533630464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7092778496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5090903135617024e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.509090148634958e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6414647808.0
		 entropy bonus: 0.22071433067321777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6533630464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7092778496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5090903135617024e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.509090148634958e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6414647808.0
		 entropy bonus: 0.22071433067321777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6533630464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7092778496.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5090903135617024e+18 - Differentiable computation graph = True!
PPO iteration: 905/1000:
	 start solving instance: 131...
	 start solving instance: 127...
	 start solving instance: 27...
	 start solving instance: 7...
	 start solving instance: 15...
	 start solving instance: 115...
	 start solving instance: 134...
	 start solving instance: 99...
	 start solving instance: 51...
	 start solving instance: 30...
	 start solving instance: 54...
	 start solving instance: 150...
	 start solving instance: 124...
	 start solving instance: 84...
	 start solving instance: 79...
	 start solving instance: 50...
	 start solving instance: 121...
	 start solving instance: 2...
	 start solving instance: 44...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.422324607454596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6333636608.0
		 entropy bonus: 0.21724501252174377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6317850624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7105851904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.422324552479015e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.422324607454596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6333636608.0
		 entropy bonus: 0.21724501252174377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6317850624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7105851904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.422324552479015e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.422324607454596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6333636608.0
		 entropy bonus: 0.21724501252174377
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6317850624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7105851904.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.422324552479015e+18 - Differentiable computation graph = True!
PPO iteration: 906/1000:
	 start solving instance: 15...
	 start solving instance: 50...
	 start solving instance: 134...
	 start solving instance: 121...
	 start solving instance: 27...
	 start solving instance: 108...
	 start solving instance: 84...
	 start solving instance: 51...
	 start solving instance: 2...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 30...
	 start solving instance: 127...
	 start solving instance: 7...
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 131...
	 start solving instance: 115...
	 start solving instance: 99...
	 start solving instance: 44...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.5820968411099824e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6353757696.0
		 entropy bonus: 0.23082514107227325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6501137920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7128240640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.582096786134401e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.5820968411099824e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6353757696.0
		 entropy bonus: 0.23082514107227325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6501137920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7128240640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.582096786134401e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.5820968411099824e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6353757696.0
		 entropy bonus: 0.23082514107227325
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6501137920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7128240640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.582096786134401e+18 - Differentiable computation graph = True!
PPO iteration: 907/1000:
	 start solving instance: 108...
	 start solving instance: 121...
	 start solving instance: 127...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 54...
	 start solving instance: 79...
	 start solving instance: 115...
	 start solving instance: 30...
	 start solving instance: 27...
	 start solving instance: 51...
	 start solving instance: 2...
	 start solving instance: 7...
	 start solving instance: 150...
	 start solving instance: 84...
	 start solving instance: 99...
	 start solving instance: 131...
	 start solving instance: 134...
	 start solving instance: 124...
	 start solving instance: 50...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.276510893816152e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6348692992.0
		 entropy bonus: 0.21336793899536133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6207325184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067035648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.276510893816152e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.276510893816152e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6348692992.0
		 entropy bonus: 0.21336793899536133
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6207325184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067035648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.276510893816152e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.276510893816152e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6342543360.0
		 entropy bonus: 0.21021728217601776
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6207325184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067035648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.276510893816152e+18 - Differentiable computation graph = True!
PPO iteration: 908/1000:
	 start solving instance: 150...
	 start solving instance: 50...
	 start solving instance: 84...
	 start solving instance: 15...
	 start solving instance: 127...
	 start solving instance: 2...
	 start solving instance: 27...
	 start solving instance: 7...
	 start solving instance: 99...
	 start solving instance: 54...
	 start solving instance: 131...
	 start solving instance: 115...
	 start solving instance: 124...
	 start solving instance: 121...
	 start solving instance: 79...
	 start solving instance: 134...
	 start solving instance: 51...
	 start solving instance: 30...
	 start solving instance: 44...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.400618488703694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6454563840.0
		 entropy bonus: 0.21457539498806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6355075584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6994628096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.400618543679275e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.400618488703694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6454563840.0
		 entropy bonus: 0.21457539498806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6355075584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6994628096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.400618543679275e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.400618488703694e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6454563840.0
		 entropy bonus: 0.21457539498806
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6355075584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6994628096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.400618543679275e+18 - Differentiable computation graph = True!
PPO iteration: 909/1000:
	 start solving instance: 30...
	 start solving instance: 15...
	 start solving instance: 54...
	 start solving instance: 84...
	 start solving instance: 115...
	 start solving instance: 108...
	 start solving instance: 44...
	 start solving instance: 2...
	 start solving instance: 134...
	 start solving instance: 121...
	 start solving instance: 131...
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 50...
	 start solving instance: 127...
	 start solving instance: 51...
	 start solving instance: 150...
	 start solving instance: 27...
	 start solving instance: 7...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4491241038700085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6362494464.0
		 entropy bonus: 0.21839821338653564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6447654912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067616256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.449124048894427e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4491241038700085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6362494464.0
		 entropy bonus: 0.21839821338653564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6447654912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067616256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.449124048894427e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4491241038700085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6362494464.0
		 entropy bonus: 0.21839821338653564
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6447654912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067616256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.449124048894427e+18 - Differentiable computation graph = True!
PPO iteration: 910/1000:
	 start solving instance: 131...
	 start solving instance: 50...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 7...
	 start solving instance: 121...
	 start solving instance: 79...
	 start solving instance: 108...
	 start solving instance: 51...
	 start solving instance: 15...
	 start solving instance: 44...
	 start solving instance: 134...
	 start solving instance: 99...
	 start solving instance: 127...
	 start solving instance: 150...
	 start solving instance: 27...
	 start solving instance: 124...
	 start solving instance: 2...
	 start solving instance: 84...
	 start solving instance: 54...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.340696424403855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6420441088.0
		 entropy bonus: 0.20827467739582062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325044736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7044696576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3406965343550177e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.340696424403855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6420441088.0
		 entropy bonus: 0.20827467739582062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325044736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7044696576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3406965343550177e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.340696424403855e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6420441088.0
		 entropy bonus: 0.20827467739582062
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6325044736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7044696576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3406965343550177e+18 - Differentiable computation graph = True!
PPO iteration: 911/1000:
	 New training batch of size 20...
	 start solving instance: 13...
	 start solving instance: 128...
	 start solving instance: 93...
	 start solving instance: 139...
	 start solving instance: 10...
	 start solving instance: 76...
	 start solving instance: 20...
	 start solving instance: 99...
	 start solving instance: 121...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 118...
	 start solving instance: 60...
	 start solving instance: 110...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 2...
	 start solving instance: 102...
	 start solving instance: 95...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.098574288265255e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6119627264.0
		 entropy bonus: 0.22585120797157288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6008059392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6695822336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0985744531919995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.098574288265255e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6119627264.0
		 entropy bonus: 0.22585120797157288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6008059392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6695822336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0985744531919995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.098574288265255e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6119627264.0
		 entropy bonus: 0.22585120797157288
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6008059392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6695822336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.0985744531919995e+18 - Differentiable computation graph = True!
PPO iteration: 912/1000:
	 start solving instance: 100...
	 start solving instance: 13...
	 start solving instance: 56...
	 start solving instance: 20...
	 start solving instance: 95...
	 start solving instance: 102...
	 start solving instance: 130...
	 start solving instance: 76...
	 start solving instance: 2...
	 start solving instance: 25...
	 start solving instance: 93...
	 start solving instance: 118...
	 start solving instance: 60...
	 start solving instance: 110...
	 start solving instance: 99...
	 start solving instance: 139...
	 start solving instance: 10...
	 start solving instance: 128...
	 start solving instance: 132...
	 start solving instance: 121...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.31237080584909e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059775488.0
		 entropy bonus: 0.22741590440273285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6177050624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7259313664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3123709158002524e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.31237080584909e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059775488.0
		 entropy bonus: 0.22741590440273285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6177050624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7259313664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3123709158002524e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.31237080584909e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6059775488.0
		 entropy bonus: 0.22741590440273285
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6177050624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7259313664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3123709158002524e+18 - Differentiable computation graph = True!
PPO iteration: 913/1000:
	 start solving instance: 100...
	 start solving instance: 56...
	 start solving instance: 95...
	 start solving instance: 118...
	 start solving instance: 110...
	 start solving instance: 25...
	 start solving instance: 2...
	 start solving instance: 20...
	 start solving instance: 132...
	 start solving instance: 128...
	 start solving instance: 93...
	 start solving instance: 121...
	 start solving instance: 10...
	 start solving instance: 102...
	 start solving instance: 13...
	 start solving instance: 139...
	 start solving instance: 130...
	 start solving instance: 60...
	 start solving instance: 99...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8584391895403725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063767040.0
		 entropy bonus: 0.21696864068508148
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5861469696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6287035392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8584391895403725e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8584391895403725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063767040.0
		 entropy bonus: 0.21696864068508148
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5861469696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6287035392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8584391895403725e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8584391895403725e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6063767040.0
		 entropy bonus: 0.21696864068508148
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5861469696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6287035392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8584391895403725e+18 - Differentiable computation graph = True!
PPO iteration: 914/1000:
	 start solving instance: 132...
	 start solving instance: 13...
	 start solving instance: 25...
	 start solving instance: 121...
	 start solving instance: 128...
	 start solving instance: 110...
	 start solving instance: 56...
	 start solving instance: 139...
	 start solving instance: 76...
	 start solving instance: 2...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 100...
	 start solving instance: 118...
	 start solving instance: 20...
	 start solving instance: 130...
	 start solving instance: 10...
	 start solving instance: 99...
	 start solving instance: 95...
	 start solving instance: 102...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.085646670350516e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6003857408.0
		 entropy bonus: 0.2176317274570465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5946651136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6780072960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.085646670350516e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.085646670350516e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6003857408.0
		 entropy bonus: 0.2176317274570465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5946651136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6780072960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.085646670350516e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.085646670350516e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6003857408.0
		 entropy bonus: 0.2176317274570465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5946651136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6780072960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.085646670350516e+18 - Differentiable computation graph = True!
PPO iteration: 915/1000:
	 start solving instance: 132...
	 start solving instance: 130...
	 start solving instance: 128...
	 start solving instance: 93...
	 start solving instance: 60...
	 start solving instance: 99...
	 start solving instance: 118...
	 start solving instance: 95...
	 start solving instance: 110...
	 start solving instance: 13...
	 start solving instance: 25...
	 start solving instance: 56...
	 start solving instance: 121...
	 start solving instance: 102...
	 start solving instance: 10...
	 start solving instance: 139...
	 start solving instance: 100...
	 start solving instance: 2...
	 start solving instance: 20...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.375732142520612e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083180544.0
		 entropy bonus: 0.2312217801809311
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6267565568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7033005568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.375732197496193e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.375732142520612e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083180544.0
		 entropy bonus: 0.2312217801809311
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6267565568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7033005568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.375732197496193e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.375732142520612e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6083180544.0
		 entropy bonus: 0.2312217801809311
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6267565568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7033005568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.375732197496193e+18 - Differentiable computation graph = True!
PPO iteration: 916/1000:
	 start solving instance: 56...
	 start solving instance: 99...
	 start solving instance: 132...
	 start solving instance: 13...
	 start solving instance: 25...
	 start solving instance: 93...
	 start solving instance: 10...
	 start solving instance: 121...
	 start solving instance: 76...
	 start solving instance: 60...
	 start solving instance: 100...
	 start solving instance: 2...
	 start solving instance: 102...
	 start solving instance: 110...
	 start solving instance: 128...
	 start solving instance: 130...
	 start solving instance: 139...
	 start solving instance: 20...
	 start solving instance: 95...
	 start solving instance: 118...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.434420994578737e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022332416.0
		 entropy bonus: 0.22657838463783264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6346305024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687984640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4344211045298995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.434420994578737e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022332416.0
		 entropy bonus: 0.22657838463783264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6346305024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687984640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4344211045298995e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.434420994578737e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6022332416.0
		 entropy bonus: 0.22657838463783264
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6346305024.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6687984640.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4344211045298995e+18 - Differentiable computation graph = True!
PPO iteration: 917/1000:
	 start solving instance: 100...
	 start solving instance: 121...
	 start solving instance: 76...
	 start solving instance: 110...
	 start solving instance: 20...
	 start solving instance: 93...
	 start solving instance: 2...
	 start solving instance: 13...
	 start solving instance: 25...
	 start solving instance: 130...
	 start solving instance: 95...
	 start solving instance: 10...
	 start solving instance: 56...
	 start solving instance: 128...
	 start solving instance: 60...
	 start solving instance: 139...
	 start solving instance: 102...
	 start solving instance: 132...
	 start solving instance: 118...
	 start solving instance: 99...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.395986026313548e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024491008.0
		 entropy bonus: 0.23513558506965637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6203315200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7075732992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.395986026313548e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.395986026313548e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024491008.0
		 entropy bonus: 0.23513558506965637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6203315200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7075732992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.395986026313548e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.395986026313548e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024491008.0
		 entropy bonus: 0.23513558506965637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6203315200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7075732992.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.395986026313548e+18 - Differentiable computation graph = True!
PPO iteration: 918/1000:
	 start solving instance: 110...
	 start solving instance: 139...
	 start solving instance: 130...
	 start solving instance: 20...
	 start solving instance: 56...
	 start solving instance: 100...
	 start solving instance: 128...
	 start solving instance: 95...
	 start solving instance: 60...
	 start solving instance: 13...
	 start solving instance: 121...
	 start solving instance: 102...
	 start solving instance: 76...
	 start solving instance: 132...
	 start solving instance: 25...
	 start solving instance: 99...
	 start solving instance: 2...
	 start solving instance: 93...
	 start solving instance: 118...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.305731075031276e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5992807424.0
		 entropy bonus: 0.22322475910186768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6223528448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067267584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.30573123995802e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.305731075031276e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5992807424.0
		 entropy bonus: 0.22322475910186768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6223528448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067267584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.30573123995802e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.305731075031276e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5992807424.0
		 entropy bonus: 0.22322475910186768
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6223528448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7067267584.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.30573123995802e+18 - Differentiable computation graph = True!
PPO iteration: 919/1000:
	 start solving instance: 102...
	 start solving instance: 93...
	 start solving instance: 76...
	 start solving instance: 60...
	 start solving instance: 95...
	 start solving instance: 121...
	 start solving instance: 2...
	 start solving instance: 99...
	 start solving instance: 118...
	 start solving instance: 110...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 128...
	 start solving instance: 25...
	 start solving instance: 56...
	 start solving instance: 10...
	 start solving instance: 139...
	 start solving instance: 13...
	 start solving instance: 20...
	 start solving instance: 132...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.315993916564937e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044296704.0
		 entropy bonus: 0.22749100625514984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198062592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6605709312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3159940814916813e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.315993916564937e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044296704.0
		 entropy bonus: 0.22749100625514984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198062592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6605709312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3159940814916813e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.315993916564937e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6044296704.0
		 entropy bonus: 0.22749100625514984
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6198062592.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6605709312.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3159940814916813e+18 - Differentiable computation graph = True!
PPO iteration: 920/1000:
	 start solving instance: 118...
	 start solving instance: 2...
	 start solving instance: 25...
	 start solving instance: 60...
	 start solving instance: 139...
	 start solving instance: 56...
	 start solving instance: 13...
	 start solving instance: 100...
	 start solving instance: 93...
	 start solving instance: 121...
	 start solving instance: 110...
	 start solving instance: 20...
	 start solving instance: 132...
	 start solving instance: 10...
	 start solving instance: 128...
	 start solving instance: 99...
	 start solving instance: 102...
	 start solving instance: 130...
	 start solving instance: 76...
	 start solving instance: 95...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.994008973245153e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6042547200.0
		 entropy bonus: 0.2072550505399704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5941113856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037124608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9940089732451533e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.994008973245153e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6042547200.0
		 entropy bonus: 0.2072550505399704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5941113856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037124608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9940089732451533e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.994008973245153e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6042547200.0
		 entropy bonus: 0.2072550505399704
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5941113856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7037124608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9940089732451533e+18 - Differentiable computation graph = True!
PPO iteration: 921/1000:
	 New training batch of size 20...
	 start solving instance: 56...
	 start solving instance: 90...
	 start solving instance: 79...
	 start solving instance: 115...
	 start solving instance: 5...
	 start solving instance: 103...
	 start solving instance: 116...
	 start solving instance: 137...
	 start solving instance: 29...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 25...
	 start solving instance: 66...
	 start solving instance: 147...
	 start solving instance: 64...
	 start solving instance: 24...
	 start solving instance: 12...
	 start solving instance: 59...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5743825595276984e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5606401536.0
		 entropy bonus: 0.21671031415462494
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5695375872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6446290432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5743825595276984e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5743825595276984e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5606401536.0
		 entropy bonus: 0.21671031415462494
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5695375872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6446290432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5743825595276984e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5743825595276984e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5606401536.0
		 entropy bonus: 0.21671031415462494
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5695375872.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6446290432.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5743825595276984e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.045760458637181e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5107619328.0
		 entropy bonus: 0.21851091086864471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5169933312.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6060870656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3045760458637180928.0000
PPO iteration: 922/1000:
	 start solving instance: 59...
	 start solving instance: 137...
	 start solving instance: 29...
	 start solving instance: 61...
	 start solving instance: 64...
	 start solving instance: 90...
	 start solving instance: 12...
	 start solving instance: 103...
	 start solving instance: 66...
	 start solving instance: 147...
	 start solving instance: 5...
	 start solving instance: 116...
	 start solving instance: 24...
	 start solving instance: 10...
	 start solving instance: 78...
	 start solving instance: 79...
	 start solving instance: 115...
	 start solving instance: 56...
	 start solving instance: 128...
	 start solving instance: 25...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.611464688686072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5659538432.0
		 entropy bonus: 0.20782864093780518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774004736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6432214528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.611464688686072e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.611464688686072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5659538432.0
		 entropy bonus: 0.20782864093780518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774004736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6432214528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.611464688686072e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.611464688686072e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5659538432.0
		 entropy bonus: 0.20782864093780518
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774004736.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6432214528.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.611464688686072e+18 - Differentiable computation graph = True!
PPO iteration: 923/1000:
	 start solving instance: 79...
	 start solving instance: 61...
	 start solving instance: 66...
	 start solving instance: 64...
	 start solving instance: 29...
	 start solving instance: 78...
	 start solving instance: 116...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 59...
	 start solving instance: 128...
	 start solving instance: 10...
	 start solving instance: 90...
	 start solving instance: 25...
	 start solving instance: 24...
	 start solving instance: 115...
	 start solving instance: 12...
	 start solving instance: 147...
	 start solving instance: 56...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.946664002553119e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5624530944.0
		 entropy bonus: 0.2343602180480957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6159351296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7090876416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9466640025531187e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.946664002553119e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5624530944.0
		 entropy bonus: 0.2343602180480957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6159351296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7090876416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9466640025531187e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.946664002553119e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5624530944.0
		 entropy bonus: 0.2343602180480957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6159351296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7090876416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9466640025531187e+18 - Differentiable computation graph = True!
PPO iteration: 924/1000:
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 12...
	 start solving instance: 29...
	 start solving instance: 103...
	 start solving instance: 115...
	 start solving instance: 147...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 56...
	 start solving instance: 59...
	 start solving instance: 25...
	 start solving instance: 116...
	 start solving instance: 66...
	 start solving instance: 90...
	 start solving instance: 64...
	 start solving instance: 24...
	 start solving instance: 137...
	 start solving instance: 79...
	 start solving instance: 5...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.842534533942267e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5652316672.0
		 entropy bonus: 0.22806334495544434
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970378752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6876286976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8425344789666857e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.842534533942267e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5652316672.0
		 entropy bonus: 0.22806334495544434
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970378752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6876286976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8425344789666857e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.842534533942267e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5652316672.0
		 entropy bonus: 0.22806334495544434
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5970378752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6876286976.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.8425344789666857e+18 - Differentiable computation graph = True!
PPO iteration: 925/1000:
	 start solving instance: 64...
	 start solving instance: 25...
	 start solving instance: 103...
	 start solving instance: 12...
	 start solving instance: 56...
	 start solving instance: 147...
	 start solving instance: 90...
	 start solving instance: 115...
	 start solving instance: 66...
	 start solving instance: 61...
	 start solving instance: 5...
	 start solving instance: 79...
	 start solving instance: 29...
	 start solving instance: 128...
	 start solving instance: 59...
	 start solving instance: 137...
	 start solving instance: 78...
	 start solving instance: 24...
	 start solving instance: 10...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.649026864621132e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5635198464.0
		 entropy bonus: 0.22216181457042694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5670263296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750041088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6490270295478764e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.649026864621132e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5635198464.0
		 entropy bonus: 0.22216181457042694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5670263296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750041088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6490270295478764e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.649026864621132e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5635198464.0
		 entropy bonus: 0.22216181457042694
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5670263296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750041088.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6490270295478764e+18 - Differentiable computation graph = True!
PPO iteration: 926/1000:
	 start solving instance: 25...
	 start solving instance: 90...
	 start solving instance: 29...
	 start solving instance: 24...
	 start solving instance: 10...
	 start solving instance: 116...
	 start solving instance: 59...
	 start solving instance: 147...
	 start solving instance: 137...
	 start solving instance: 56...
	 start solving instance: 12...
	 start solving instance: 64...
	 start solving instance: 128...
	 start solving instance: 115...
	 start solving instance: 103...
	 start solving instance: 78...
	 start solving instance: 61...
	 start solving instance: 66...
	 start solving instance: 5...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.452976684611928e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5648512512.0
		 entropy bonus: 0.20363548398017883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5549390336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6501528576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.452976684611928e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.452976684611928e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5648512512.0
		 entropy bonus: 0.20363548398017883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5549390336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6501528576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.452976684611928e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.452976684611928e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5648512512.0
		 entropy bonus: 0.20363548398017883
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5549390336.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6501528576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.452976684611928e+18 - Differentiable computation graph = True!
PPO iteration: 927/1000:
	 start solving instance: 103...
	 start solving instance: 24...
	 start solving instance: 147...
	 start solving instance: 79...
	 start solving instance: 25...
	 start solving instance: 5...
	 start solving instance: 56...
	 start solving instance: 59...
	 start solving instance: 90...
	 start solving instance: 116...
	 start solving instance: 29...
	 start solving instance: 66...
	 start solving instance: 128...
	 start solving instance: 78...
	 start solving instance: 115...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 64...
	 start solving instance: 61...
	 start solving instance: 12...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.915185424454543e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763551232.0
		 entropy bonus: 0.2322746366262436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018452992.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7175753216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9151855344057057e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.915185424454543e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763551232.0
		 entropy bonus: 0.2322746366262436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018452992.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7175753216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9151855344057057e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.915185424454543e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5763551232.0
		 entropy bonus: 0.2322746366262436
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6018452992.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7175753216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9151855344057057e+18 - Differentiable computation graph = True!
PPO iteration: 928/1000:
	 start solving instance: 29...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 10...
	 start solving instance: 147...
	 start solving instance: 24...
	 start solving instance: 137...
	 start solving instance: 64...
	 start solving instance: 59...
	 start solving instance: 5...
	 start solving instance: 78...
	 start solving instance: 25...
	 start solving instance: 66...
	 start solving instance: 12...
	 start solving instance: 116...
	 start solving instance: 79...
	 start solving instance: 90...
	 start solving instance: 56...
	 start solving instance: 115...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.775743600601386e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5698895360.0
		 entropy bonus: 0.2226153165102005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5999794688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6842127872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.775743545625805e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.775743600601386e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5698895360.0
		 entropy bonus: 0.2226153165102005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5999794688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6842127872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.775743545625805e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.775743600601386e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5698895360.0
		 entropy bonus: 0.2226153165102005
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5999794688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6842127872.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.775743545625805e+18 - Differentiable computation graph = True!
PPO iteration: 929/1000:
	 start solving instance: 12...
	 start solving instance: 64...
	 start solving instance: 66...
	 start solving instance: 25...
	 start solving instance: 116...
	 start solving instance: 115...
	 start solving instance: 147...
	 start solving instance: 137...
	 start solving instance: 78...
	 start solving instance: 24...
	 start solving instance: 10...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 5...
	 start solving instance: 29...
	 start solving instance: 59...
	 start solving instance: 56...
	 start solving instance: 103...
	 start solving instance: 61...
	 start solving instance: 79...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6373513705481044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5632073728.0
		 entropy bonus: 0.221575066447258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5873673216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622016000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.637351315572523e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6373513705481044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5632073728.0
		 entropy bonus: 0.221575066447258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5873673216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622016000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.637351315572523e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6373513705481044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5632073728.0
		 entropy bonus: 0.221575066447258
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5873673216.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6622016000.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.637351315572523e+18 - Differentiable computation graph = True!
PPO iteration: 930/1000:
	 start solving instance: 56...
	 start solving instance: 25...
	 start solving instance: 115...
	 start solving instance: 10...
	 start solving instance: 147...
	 start solving instance: 24...
	 start solving instance: 5...
	 start solving instance: 78...
	 start solving instance: 128...
	 start solving instance: 137...
	 start solving instance: 103...
	 start solving instance: 90...
	 start solving instance: 29...
	 start solving instance: 61...
	 start solving instance: 64...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 12...
	 start solving instance: 59...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.8304275915065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5696700416.0
		 entropy bonus: 0.21775327622890472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6024119808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6904375296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.830427756433244e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.8304275915065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5696700416.0
		 entropy bonus: 0.21775327622890472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6024119808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6904375296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.830427756433244e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.8304275915065e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5696700416.0
		 entropy bonus: 0.21775327622890472
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6024119808.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6904375296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.830427756433244e+18 - Differentiable computation graph = True!
PPO iteration: 931/1000:
	 New training batch of size 20...
	 start solving instance: 104...
	 start solving instance: 90...
	 start solving instance: 95...
	 start solving instance: 26...
	 start solving instance: 147...
	 start solving instance: 25...
	 start solving instance: 21...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 62...
	 start solving instance: 65...
	 start solving instance: 128...
	 start solving instance: 113...
	 start solving instance: 14...
	 start solving instance: 56...
	 start solving instance: 130...
	 start solving instance: 122...
	 start solving instance: 136...
	 start solving instance: 28...
	 start solving instance: 100...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.363345044522087e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6423451648.0
		 entropy bonus: 0.20445792376995087
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6302542848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7090811392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3633450994976686e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.363345044522087e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6423451648.0
		 entropy bonus: 0.20445792376995087
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6302542848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7090811392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3633450994976686e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.363345044522087e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6423451648.0
		 entropy bonus: 0.20445792376995087
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6302542848.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7090811392.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3633450994976686e+18 - Differentiable computation graph = True!
PPO iteration: 932/1000:
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 147...
	 start solving instance: 26...
	 start solving instance: 122...
	 start solving instance: 95...
	 start solving instance: 113...
	 start solving instance: 25...
	 start solving instance: 28...
	 start solving instance: 104...
	 start solving instance: 62...
	 start solving instance: 14...
	 start solving instance: 100...
	 start solving instance: 65...
	 start solving instance: 130...
	 start solving instance: 56...
	 start solving instance: 61...
	 start solving instance: 136...
	 start solving instance: 21...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.34673846070081e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6247749120.0
		 entropy bonus: 0.20378628373146057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6206013952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840416256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346738625627554e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.34673846070081e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6247749120.0
		 entropy bonus: 0.20378628373146057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6206013952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840416256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346738625627554e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.34673846070081e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6247749120.0
		 entropy bonus: 0.20378628373146057
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6206013952.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6840416256.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.346738625627554e+18 - Differentiable computation graph = True!
PPO iteration: 933/1000:
	 start solving instance: 147...
	 start solving instance: 90...
	 start solving instance: 28...
	 start solving instance: 1...
	 start solving instance: 128...
	 start solving instance: 104...
	 start solving instance: 61...
	 start solving instance: 122...
	 start solving instance: 21...
	 start solving instance: 130...
	 start solving instance: 56...
	 start solving instance: 65...
	 start solving instance: 25...
	 start solving instance: 100...
	 start solving instance: 62...
	 start solving instance: 113...
	 start solving instance: 95...
	 start solving instance: 26...
	 start solving instance: 136...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.8635405916904096e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6347035136.0
		 entropy bonus: 0.21814695000648499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6730018304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7591223296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.863540701641572e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.8635405916904096e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6347035136.0
		 entropy bonus: 0.21814695000648499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6730018304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7591223296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.863540701641572e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.8635405916904096e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6347035136.0
		 entropy bonus: 0.21814695000648499
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6730018304.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7591223296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.863540701641572e+18 - Differentiable computation graph = True!
PPO iteration: 934/1000:
	 start solving instance: 61...
	 start solving instance: 136...
	 start solving instance: 122...
	 start solving instance: 14...
	 start solving instance: 56...
	 start solving instance: 95...
	 start solving instance: 128...
	 start solving instance: 65...
	 start solving instance: 113...
	 start solving instance: 1...
	 start solving instance: 62...
	 start solving instance: 104...
	 start solving instance: 26...
	 start solving instance: 28...
	 start solving instance: 21...
	 start solving instance: 147...
	 start solving instance: 100...
	 start solving instance: 25...
	 start solving instance: 90...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.495623770022609e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6287802880.0
		 entropy bonus: 0.20904254913330078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359296000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7068700160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495623770022609e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.495623770022609e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6287802880.0
		 entropy bonus: 0.20904254913330078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359296000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7068700160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495623770022609e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.495623770022609e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6287802880.0
		 entropy bonus: 0.20904254913330078
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6359296000.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7068700160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.495623770022609e+18 - Differentiable computation graph = True!
PPO iteration: 935/1000:
	 start solving instance: 21...
	 start solving instance: 95...
	 start solving instance: 25...
	 start solving instance: 65...
	 start solving instance: 56...
	 start solving instance: 128...
	 start solving instance: 28...
	 start solving instance: 104...
	 start solving instance: 14...
	 start solving instance: 62...
	 start solving instance: 122...
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 136...
	 start solving instance: 147...
	 start solving instance: 113...
	 start solving instance: 90...
	 start solving instance: 1...
	 start solving instance: 26...
	 start solving instance: 61...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.4546696007158596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6331548672.0
		 entropy bonus: 0.21029849350452423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6301490688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7361972736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4546697106670223e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.4546696007158596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6331548672.0
		 entropy bonus: 0.21029849350452423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6301490688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7361972736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4546697106670223e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.4546696007158596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6331548672.0
		 entropy bonus: 0.21029849350452423
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6301490688.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7361972736.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4546697106670223e+18 - Differentiable computation graph = True!
PPO iteration: 936/1000:
	 start solving instance: 130...
	 start solving instance: 100...
	 start solving instance: 90...
	 start solving instance: 104...
	 start solving instance: 95...
	 start solving instance: 65...
	 start solving instance: 128...
	 start solving instance: 28...
	 start solving instance: 26...
	 start solving instance: 62...
	 start solving instance: 113...
	 start solving instance: 122...
	 start solving instance: 147...
	 start solving instance: 21...
	 start solving instance: 136...
	 start solving instance: 61...
	 start solving instance: 25...
	 start solving instance: 14...
	 start solving instance: 56...
	 start solving instance: 1...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3803219438596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6337035264.0
		 entropy bonus: 0.2057480365037918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6360023552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7360777216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380322108786344e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3803219438596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6337035264.0
		 entropy bonus: 0.2057480365037918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6360023552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7360777216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380322108786344e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3803219438596e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6337035264.0
		 entropy bonus: 0.2057480365037918
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6360023552.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7360777216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.380322108786344e+18 - Differentiable computation graph = True!
PPO iteration: 937/1000:
	 start solving instance: 130...
	 start solving instance: 28...
	 start solving instance: 147...
	 start solving instance: 21...
	 start solving instance: 113...
	 start solving instance: 26...
	 start solving instance: 25...
	 start solving instance: 61...
	 start solving instance: 128...
	 start solving instance: 104...
	 start solving instance: 62...
	 start solving instance: 90...
	 start solving instance: 56...
	 start solving instance: 100...
	 start solving instance: 136...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 122...
	 start solving instance: 95...
	 start solving instance: 14...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.733531697994269e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6279158784.0
		 entropy bonus: 0.21372662484645844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6610808832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7448272896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.733531697994269e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.733531697994269e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6279158784.0
		 entropy bonus: 0.21372662484645844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6610808832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7448272896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.733531697994269e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.733531697994269e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6279158784.0
		 entropy bonus: 0.21372662484645844
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6610808832.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7448272896.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.733531697994269e+18 - Differentiable computation graph = True!
PPO iteration: 938/1000:
	 start solving instance: 28...
	 start solving instance: 95...
	 start solving instance: 14...
	 start solving instance: 122...
	 start solving instance: 130...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 136...
	 start solving instance: 147...
	 start solving instance: 61...
	 start solving instance: 104...
	 start solving instance: 56...
	 start solving instance: 25...
	 start solving instance: 90...
	 start solving instance: 128...
	 start solving instance: 100...
	 start solving instance: 26...
	 start solving instance: 62...
	 start solving instance: 113...
	 start solving instance: 21...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.438217828131773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6307263488.0
		 entropy bonus: 0.2112353891134262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6343356416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6889133568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.438217993058517e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.438217828131773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6307263488.0
		 entropy bonus: 0.2112353891134262
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6343356416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6889133568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.438217993058517e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.438217828131773e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6386795008.0
		 entropy bonus: 0.20808470249176025
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6343356416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6889133568.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.438217993058517e+18 - Differentiable computation graph = True!
PPO iteration: 939/1000:
	 start solving instance: 62...
	 start solving instance: 65...
	 start solving instance: 1...
	 start solving instance: 104...
	 start solving instance: 147...
	 start solving instance: 21...
	 start solving instance: 61...
	 start solving instance: 14...
	 start solving instance: 128...
	 start solving instance: 26...
	 start solving instance: 122...
	 start solving instance: 100...
	 start solving instance: 130...
	 start solving instance: 28...
	 start solving instance: 25...
	 start solving instance: 95...
	 start solving instance: 136...
	 start solving instance: 56...
	 start solving instance: 113...
	 start solving instance: 90...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.428300233249233e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266249216.0
		 entropy bonus: 0.20646266639232635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6349848576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7170345984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4283003981759775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.428300233249233e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266249216.0
		 entropy bonus: 0.20646266639232635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6349848576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7170345984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4283003981759775e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.428300233249233e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6266249216.0
		 entropy bonus: 0.20646266639232635
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6349848576.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7170345984.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4283003981759775e+18 - Differentiable computation graph = True!
PPO iteration: 940/1000:
	 start solving instance: 14...
	 start solving instance: 147...
	 start solving instance: 100...
	 start solving instance: 113...
	 start solving instance: 128...
	 start solving instance: 21...
	 start solving instance: 104...
	 start solving instance: 28...
	 start solving instance: 95...
	 start solving instance: 122...
	 start solving instance: 1...
	 start solving instance: 61...
	 start solving instance: 90...
	 start solving instance: 56...
	 start solving instance: 62...
	 start solving instance: 65...
	 start solving instance: 25...
	 start solving instance: 26...
	 start solving instance: 136...
	 start solving instance: 130...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.338801745966871e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6310712832.0
		 entropy bonus: 0.20710325241088867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6313170432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7026743296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3388018009424527e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.338801745966871e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6310712832.0
		 entropy bonus: 0.20710325241088867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6313170432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7026743296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3388018009424527e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.338801745966871e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6310712832.0
		 entropy bonus: 0.20710325241088867
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6313170432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7026743296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.3388018009424527e+18 - Differentiable computation graph = True!
PPO iteration: 941/1000:
	 New training batch of size 20...
	 start solving instance: 76...
	 start solving instance: 66...
	 start solving instance: 31...
	 start solving instance: 3...
	 start solving instance: 81...
	 start solving instance: 60...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 46...
	 start solving instance: 45...
	 start solving instance: 100...
	 start solving instance: 29...
	 start solving instance: 17...
	 start solving instance: 135...
	 start solving instance: 62...
	 start solving instance: 103...
	 start solving instance: 142...
	 start solving instance: 37...
	 start solving instance: 110...
	 start solving instance: 30...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.562809208135536e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6176315904.0
		 entropy bonus: 0.20537681877613068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6302474240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7180960768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5628091531599544e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.562809208135536e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6176315904.0
		 entropy bonus: 0.20537681877613068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6302474240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7180960768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5628091531599544e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.562809208135536e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6176315904.0
		 entropy bonus: 0.20537681877613068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6302474240.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7180960768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.5628091531599544e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.242510147943976e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5348683264.0
		 entropy bonus: 0.2080087661743164
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5396514816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6252599808.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3242510092968394752.0000
PPO iteration: 942/1000:
	 start solving instance: 17...
	 start solving instance: 62...
	 start solving instance: 81...
	 start solving instance: 35...
	 start solving instance: 45...
	 start solving instance: 135...
	 start solving instance: 30...
	 start solving instance: 46...
	 start solving instance: 31...
	 start solving instance: 100...
	 start solving instance: 32...
	 start solving instance: 29...
	 start solving instance: 142...
	 start solving instance: 110...
	 start solving instance: 3...
	 start solving instance: 66...
	 start solving instance: 103...
	 start solving instance: 37...
	 start solving instance: 60...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.7361599705893044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6284658688.0
		 entropy bonus: 0.20892348885536194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6511004160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395270656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.736160080540467e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.7361599705893044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6284658688.0
		 entropy bonus: 0.20892348885536194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6511004160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395270656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.736160080540467e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.7361599705893044e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6284658688.0
		 entropy bonus: 0.20892348885536194
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6511004160.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7395270656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.736160080540467e+18 - Differentiable computation graph = True!
PPO iteration: 943/1000:
	 start solving instance: 37...
	 start solving instance: 110...
	 start solving instance: 62...
	 start solving instance: 60...
	 start solving instance: 29...
	 start solving instance: 135...
	 start solving instance: 45...
	 start solving instance: 30...
	 start solving instance: 103...
	 start solving instance: 3...
	 start solving instance: 31...
	 start solving instance: 76...
	 start solving instance: 32...
	 start solving instance: 35...
	 start solving instance: 81...
	 start solving instance: 142...
	 start solving instance: 17...
	 start solving instance: 100...
	 start solving instance: 46...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6703805879459774e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312467968.0
		 entropy bonus: 0.2156015932559967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6455975424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7429966336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.67038069789714e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6703805879459774e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312467968.0
		 entropy bonus: 0.2156015932559967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6455975424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7429966336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.67038069789714e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6703805879459774e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6312467968.0
		 entropy bonus: 0.2156015932559967
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6455975424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7429966336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.67038069789714e+18 - Differentiable computation graph = True!
PPO iteration: 944/1000:
	 start solving instance: 17...
	 start solving instance: 76...
	 start solving instance: 35...
	 start solving instance: 45...
	 start solving instance: 60...
	 start solving instance: 142...
	 start solving instance: 32...
	 start solving instance: 110...
	 start solving instance: 103...
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 62...
	 start solving instance: 31...
	 start solving instance: 37...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 100...
	 start solving instance: 30...
	 start solving instance: 46...
	 start solving instance: 29...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6598837703379255e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6199695872.0
		 entropy bonus: 0.21966126561164856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6459627008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7557993472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.659883660386763e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6598837703379255e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6199695872.0
		 entropy bonus: 0.21966126561164856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6459627008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7557993472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.659883660386763e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6598837703379255e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6199695872.0
		 entropy bonus: 0.21966126561164856
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6459627008.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7557993472.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.659883660386763e+18 - Differentiable computation graph = True!
PPO iteration: 945/1000:
	 start solving instance: 3...
	 start solving instance: 29...
	 start solving instance: 81...
	 start solving instance: 110...
	 start solving instance: 45...
	 start solving instance: 31...
	 start solving instance: 60...
	 start solving instance: 135...
	 start solving instance: 66...
	 start solving instance: 100...
	 start solving instance: 37...
	 start solving instance: 46...
	 start solving instance: 35...
	 start solving instance: 76...
	 start solving instance: 32...
	 start solving instance: 142...
	 start solving instance: 17...
	 start solving instance: 62...
	 start solving instance: 30...
	 start solving instance: 103...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.710002588964513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6275124736.0
		 entropy bonus: 0.21477623283863068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6486842368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7317659136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.710002698915676e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.710002588964513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6275124736.0
		 entropy bonus: 0.21477623283863068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6486842368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7317659136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.710002698915676e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.710002588964513e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6275124736.0
		 entropy bonus: 0.21477623283863068
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6486842368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7317659136.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.710002698915676e+18 - Differentiable computation graph = True!
PPO iteration: 946/1000:
	 start solving instance: 45...
	 start solving instance: 60...
	 start solving instance: 142...
	 start solving instance: 110...
	 start solving instance: 30...
	 start solving instance: 32...
	 start solving instance: 31...
	 start solving instance: 46...
	 start solving instance: 37...
	 start solving instance: 29...
	 start solving instance: 17...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 81...
	 start solving instance: 3...
	 start solving instance: 135...
	 start solving instance: 66...
	 start solving instance: 103...
	 start solving instance: 35...
	 start solving instance: 62...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.484959826647135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6256911360.0
		 entropy bonus: 0.19932201504707336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270899200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7167194112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4849598816227164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.484959826647135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6256911360.0
		 entropy bonus: 0.19932201504707336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270899200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7167194112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4849598816227164e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.484959826647135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6256911360.0
		 entropy bonus: 0.19932201504707336
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6270899200.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7167194112.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.4849598816227164e+18 - Differentiable computation graph = True!
PPO iteration: 947/1000:
	 start solving instance: 66...
	 start solving instance: 30...
	 start solving instance: 100...
	 start solving instance: 46...
	 start solving instance: 76...
	 start solving instance: 60...
	 start solving instance: 37...
	 start solving instance: 110...
	 start solving instance: 142...
	 start solving instance: 45...
	 start solving instance: 103...
	 start solving instance: 31...
	 start solving instance: 29...
	 start solving instance: 17...
	 start solving instance: 3...
	 start solving instance: 81...
	 start solving instance: 35...
	 start solving instance: 62...
	 start solving instance: 135...
	 start solving instance: 32...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.677120594224244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6224332288.0
		 entropy bonus: 0.21556822955608368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6463864320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7391246336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.677120704175407e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.677120594224244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6224332288.0
		 entropy bonus: 0.21556822955608368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6463864320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7391246336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.677120704175407e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.677120594224244e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6224332288.0
		 entropy bonus: 0.21556822955608368
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6463864320.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7391246336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.677120704175407e+18 - Differentiable computation graph = True!
PPO iteration: 948/1000:
	 start solving instance: 100...
	 start solving instance: 110...
	 start solving instance: 66...
	 start solving instance: 135...
	 start solving instance: 35...
	 start solving instance: 17...
	 start solving instance: 62...
	 start solving instance: 103...
	 start solving instance: 32...
	 start solving instance: 81...
	 start solving instance: 45...
	 start solving instance: 142...
	 start solving instance: 30...
	 start solving instance: 60...
	 start solving instance: 3...
	 start solving instance: 37...
	 start solving instance: 31...
	 start solving instance: 76...
	 start solving instance: 29...
	 start solving instance: 46...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.6264084791233085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6186477568.0
		 entropy bonus: 0.21135668456554413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6347075584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7491036672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.626408479123309e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.6264084791233085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6186477568.0
		 entropy bonus: 0.21135668456554413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6347075584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7491036672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.626408479123309e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.6264084791233085e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6186477568.0
		 entropy bonus: 0.21135668456554413
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6347075584.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7491036672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.626408479123309e+18 - Differentiable computation graph = True!
PPO iteration: 949/1000:
	 start solving instance: 103...
	 start solving instance: 3...
	 start solving instance: 100...
	 start solving instance: 45...
	 start solving instance: 35...
	 start solving instance: 135...
	 start solving instance: 31...
	 start solving instance: 32...
	 start solving instance: 110...
	 start solving instance: 30...
	 start solving instance: 60...
	 start solving instance: 62...
	 start solving instance: 81...
	 start solving instance: 66...
	 start solving instance: 37...
	 start solving instance: 29...
	 start solving instance: 17...
	 start solving instance: 76...
	 start solving instance: 46...
	 start solving instance: 142...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.50727683405843e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201561088.0
		 entropy bonus: 0.20537297427654266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6373455360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7363332608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.507276944009593e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.50727683405843e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201561088.0
		 entropy bonus: 0.20537297427654266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6373455360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7363332608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.507276944009593e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.50727683405843e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6201561088.0
		 entropy bonus: 0.20537297427654266
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6373455360.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7363332608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.507276944009593e+18 - Differentiable computation graph = True!
PPO iteration: 950/1000:
	 start solving instance: 46...
	 start solving instance: 135...
	 start solving instance: 76...
	 start solving instance: 81...
	 start solving instance: 100...
	 start solving instance: 37...
	 start solving instance: 31...
	 start solving instance: 29...
	 start solving instance: 142...
	 start solving instance: 110...
	 start solving instance: 103...
	 start solving instance: 35...
	 start solving instance: 30...
	 start solving instance: 60...
	 start solving instance: 3...
	 start solving instance: 17...
	 start solving instance: 62...
	 start solving instance: 32...
	 start solving instance: 66...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.624039251467777e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6229277184.0
		 entropy bonus: 0.217515230178833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6375614464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7547891712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.624039581321265e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.624039251467777e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6229277184.0
		 entropy bonus: 0.217515230178833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6375614464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7547891712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.624039581321265e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.624039251467777e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6229277184.0
		 entropy bonus: 0.217515230178833
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6375614464.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -7547891712.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.624039581321265e+18 - Differentiable computation graph = True!
PPO iteration: 951/1000:
	 New training batch of size 20...
	 start solving instance: 143...
	 start solving instance: 149...
	 start solving instance: 98...
	 start solving instance: 105...
	 start solving instance: 134...
	 start solving instance: 147...
	 start solving instance: 37...
	 start solving instance: 106...
	 start solving instance: 10...
	 start solving instance: 92...
	 start solving instance: 13...
	 start solving instance: 12...
	 start solving instance: 25...
	 start solving instance: 113...
	 start solving instance: 119...
	 start solving instance: 91...
	 start solving instance: 138...
	 start solving instance: 137...
	 start solving instance: 52...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.572779911379052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785581056.0
		 entropy bonus: 0.1927841156721115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5717759488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6598581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.572780021330215e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.572779911379052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785581056.0
		 entropy bonus: 0.1927841156721115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5717759488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6598581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.572780021330215e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.572779911379052e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5785581056.0
		 entropy bonus: 0.1927841156721115
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5717759488.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6598581760.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.572780021330215e+18 - Differentiable computation graph = True!
PPO iteration: 952/1000:
	 start solving instance: 147...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 12...
	 start solving instance: 149...
	 start solving instance: 13...
	 start solving instance: 134...
	 start solving instance: 25...
	 start solving instance: 37...
	 start solving instance: 52...
	 start solving instance: 143...
	 start solving instance: 105...
	 start solving instance: 119...
	 start solving instance: 98...
	 start solving instance: 138...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5290389199005417e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5910885376.0
		 entropy bonus: 0.20346783101558685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5602234880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6565257216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.529038974876123e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5290389199005417e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5910885376.0
		 entropy bonus: 0.20346783101558685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5602234880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6565257216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.529038974876123e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5290389199005417e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5910885376.0
		 entropy bonus: 0.20346783101558685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5602234880.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6565257216.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.529038974876123e+18 - Differentiable computation graph = True!
PPO iteration: 953/1000:
	 start solving instance: 134...
	 start solving instance: 37...
	 start solving instance: 25...
	 start solving instance: 137...
	 start solving instance: 149...
	 start solving instance: 12...
	 start solving instance: 113...
	 start solving instance: 52...
	 start solving instance: 147...
	 start solving instance: 10...
	 start solving instance: 9...
	 start solving instance: 106...
	 start solving instance: 98...
	 start solving instance: 91...
	 start solving instance: 119...
	 start solving instance: 13...
	 start solving instance: 138...
	 start solving instance: 92...
	 start solving instance: 143...
	 start solving instance: 105...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.704359347484308e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5814038016.0
		 entropy bonus: 0.2057199478149414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774042112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6411466752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7043594024598897e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.704359347484308e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5814038016.0
		 entropy bonus: 0.2057199478149414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774042112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6411466752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7043594024598897e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.704359347484308e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5814038016.0
		 entropy bonus: 0.2057199478149414
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5774042112.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6411466752.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7043594024598897e+18 - Differentiable computation graph = True!
PPO iteration: 954/1000:
	 start solving instance: 143...
	 start solving instance: 138...
	 start solving instance: 137...
	 start solving instance: 10...
	 start solving instance: 52...
	 start solving instance: 149...
	 start solving instance: 106...
	 start solving instance: 9...
	 start solving instance: 105...
	 start solving instance: 113...
	 start solving instance: 91...
	 start solving instance: 12...
	 start solving instance: 119...
	 start solving instance: 98...
	 start solving instance: 13...
	 start solving instance: 92...
	 start solving instance: 25...
	 start solving instance: 134...
	 start solving instance: 147...
	 start solving instance: 37...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6445648265332916e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5827131904.0
		 entropy bonus: 0.20045910775661469
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5704956416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6408132096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6445649364844544e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6445648265332916e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5827131904.0
		 entropy bonus: 0.20045910775661469
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5704956416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6408132096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6445649364844544e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6445648265332916e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5827131904.0
		 entropy bonus: 0.20045910775661469
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5704956416.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6408132096.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6445649364844544e+18 - Differentiable computation graph = True!
PPO iteration: 955/1000:
	 start solving instance: 134...
	 start solving instance: 143...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 98...
	 start solving instance: 91...
	 start solving instance: 113...
	 start solving instance: 12...
	 start solving instance: 119...
	 start solving instance: 138...
	 start solving instance: 106...
	 start solving instance: 25...
	 start solving instance: 149...
	 start solving instance: 147...
	 start solving instance: 92...
	 start solving instance: 52...
	 start solving instance: 105...
	 start solving instance: 13...
	 start solving instance: 37...
	 start solving instance: 9...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6748409787157316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5843879424.0
		 entropy bonus: 0.21473288536071777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5719983616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6600168448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6748410886668943e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6748409787157316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5843879424.0
		 entropy bonus: 0.21473288536071777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5719983616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6600168448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6748410886668943e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6748409787157316e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5843879424.0
		 entropy bonus: 0.21473288536071777
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5719983616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6600168448.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6748410886668943e+18 - Differentiable computation graph = True!
PPO iteration: 956/1000:
	 start solving instance: 98...
	 start solving instance: 106...
	 start solving instance: 13...
	 start solving instance: 9...
	 start solving instance: 12...
	 start solving instance: 119...
	 start solving instance: 10...
	 start solving instance: 25...
	 start solving instance: 138...
	 start solving instance: 149...
	 start solving instance: 134...
	 start solving instance: 37...
	 start solving instance: 92...
	 start solving instance: 105...
	 start solving instance: 143...
	 start solving instance: 137...
	 start solving instance: 147...
	 start solving instance: 91...
	 start solving instance: 52...
	 start solving instance: 113...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.789015145753294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5850131968.0
		 entropy bonus: 0.2044237107038498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5843474944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6526947840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.789015200728875e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.789015145753294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5850131968.0
		 entropy bonus: 0.2044237107038498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5843474944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6526947840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.789015200728875e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.789015145753294e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5850131968.0
		 entropy bonus: 0.2044237107038498
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5843474944.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6526947840.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.789015200728875e+18 - Differentiable computation graph = True!
PPO iteration: 957/1000:
	 start solving instance: 138...
	 start solving instance: 113...
	 start solving instance: 25...
	 start solving instance: 92...
	 start solving instance: 106...
	 start solving instance: 98...
	 start solving instance: 105...
	 start solving instance: 10...
	 start solving instance: 52...
	 start solving instance: 134...
	 start solving instance: 9...
	 start solving instance: 149...
	 start solving instance: 37...
	 start solving instance: 143...
	 start solving instance: 119...
	 start solving instance: 91...
	 start solving instance: 12...
	 start solving instance: 13...
	 start solving instance: 147...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6765269698457633e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832510464.0
		 entropy bonus: 0.2052111178636551
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5720505856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373767168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676526914870182e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6765269698457633e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832510464.0
		 entropy bonus: 0.2052111178636551
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5720505856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373767168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676526914870182e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6765269698457633e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5832510464.0
		 entropy bonus: 0.2052111178636551
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5720505856.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6373767168.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.676526914870182e+18 - Differentiable computation graph = True!
PPO iteration: 958/1000:
	 start solving instance: 106...
	 start solving instance: 52...
	 start solving instance: 134...
	 start solving instance: 10...
	 start solving instance: 137...
	 start solving instance: 113...
	 start solving instance: 13...
	 start solving instance: 105...
	 start solving instance: 119...
	 start solving instance: 91...
	 start solving instance: 37...
	 start solving instance: 9...
	 start solving instance: 98...
	 start solving instance: 149...
	 start solving instance: 147...
	 start solving instance: 12...
	 start solving instance: 92...
	 start solving instance: 143...
	 start solving instance: 25...
	 start solving instance: 138...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.706000258637601e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5846704128.0
		 entropy bonus: 0.20196712017059326
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5796969472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6470348800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7060004235643453e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.706000258637601e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5846704128.0
		 entropy bonus: 0.20196712017059326
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5796969472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6470348800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7060004235643453e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.706000258637601e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5846704128.0
		 entropy bonus: 0.20196712017059326
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5796969472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6470348800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7060004235643453e+18 - Differentiable computation graph = True!
PPO iteration: 959/1000:
	 start solving instance: 134...
	 start solving instance: 52...
	 start solving instance: 9...
	 start solving instance: 10...
	 start solving instance: 113...
	 start solving instance: 98...
	 start solving instance: 25...
	 start solving instance: 147...
	 start solving instance: 105...
	 start solving instance: 119...
	 start solving instance: 12...
	 start solving instance: 138...
	 start solving instance: 13...
	 start solving instance: 37...
	 start solving instance: 91...
	 start solving instance: 92...
	 start solving instance: 143...
	 start solving instance: 149...
	 start solving instance: 106...
	 start solving instance: 137...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6304136720791634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5792158208.0
		 entropy bonus: 0.19538277387619019
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5710048768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6553610240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6304136720791634e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6304136720791634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5792158208.0
		 entropy bonus: 0.19538277387619019
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5710048768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6553610240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6304136720791634e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6304136720791634e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5792158208.0
		 entropy bonus: 0.19538277387619019
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5710048768.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6553610240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.6304136720791634e+18 - Differentiable computation graph = True!
PPO iteration: 960/1000:
	 start solving instance: 106...
	 start solving instance: 119...
	 start solving instance: 149...
	 start solving instance: 137...
	 start solving instance: 25...
	 start solving instance: 52...
	 start solving instance: 147...
	 start solving instance: 10...
	 start solving instance: 138...
	 start solving instance: 12...
	 start solving instance: 92...
	 start solving instance: 91...
	 start solving instance: 143...
	 start solving instance: 13...
	 start solving instance: 98...
	 start solving instance: 105...
	 start solving instance: 113...
	 start solving instance: 134...
	 start solving instance: 9...
	 start solving instance: 37...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6831669205659025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5878560256.0
		 entropy bonus: 0.1984502226114273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5799306752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6538670592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.683166865590321e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6831669205659025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5878560256.0
		 entropy bonus: 0.1984502226114273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5799306752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6538670592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.683166865590321e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6831669205659025e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5878560256.0
		 entropy bonus: 0.1984502226114273
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5799306752.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6538670592.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.683166865590321e+18 - Differentiable computation graph = True!
PPO iteration: 961/1000:
	 New training batch of size 20...
	 start solving instance: 148...
	 start solving instance: 65...
	 start solving instance: 58...
	 start solving instance: 126...
	 start solving instance: 105...
	 start solving instance: 112...
	 start solving instance: 64...
	 start solving instance: 92...
	 start solving instance: 50...
	 start solving instance: 51...
	 start solving instance: 127...
	 start solving instance: 81...
	 start solving instance: 139...
	 start solving instance: 85...
	 start solving instance: 107...
	 start solving instance: 84...
	 start solving instance: 122...
	 start solving instance: 34...
	 start solving instance: 15...
	 start solving instance: 146...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.285634641303437e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060594176.0
		 entropy bonus: 0.2203456610441208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6279514624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6585341440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2856346413034373e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.285634641303437e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060594176.0
		 entropy bonus: 0.2203456610441208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6279514624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6585341440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2856346413034373e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.285634641303437e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6060594176.0
		 entropy bonus: 0.2203456610441208
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6279514624.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6585341440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2856346413034373e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 3.2988741926163317e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5305078272.0
		 entropy bonus: 0.21056972444057465
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5417647616.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6407324672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3298874357543075840.0000
PPO iteration: 962/1000:
	 start solving instance: 34...
	 start solving instance: 139...
	 start solving instance: 146...
	 start solving instance: 81...
	 start solving instance: 122...
	 start solving instance: 50...
	 start solving instance: 64...
	 start solving instance: 107...
	 start solving instance: 92...
	 start solving instance: 58...
	 start solving instance: 51...
	 start solving instance: 126...
	 start solving instance: 65...
	 start solving instance: 112...
	 start solving instance: 84...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 85...
	 start solving instance: 127...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.966646966680971e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885622784.0
		 entropy bonus: 0.2083018571138382
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5929891328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6318749184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9666470766321336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.966646966680971e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885622784.0
		 entropy bonus: 0.2083018571138382
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5929891328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6318749184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9666470766321336e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.966646966680971e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5885622784.0
		 entropy bonus: 0.2083018571138382
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5929891328.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6318749184.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.9666470766321336e+18 - Differentiable computation graph = True!
PPO iteration: 963/1000:
	 start solving instance: 146...
	 start solving instance: 81...
	 start solving instance: 112...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 15...
	 start solving instance: 51...
	 start solving instance: 50...
	 start solving instance: 58...
	 start solving instance: 127...
	 start solving instance: 122...
	 start solving instance: 34...
	 start solving instance: 92...
	 start solving instance: 105...
	 start solving instance: 148...
	 start solving instance: 126...
	 start solving instance: 64...
	 start solving instance: 85...
	 start solving instance: 139...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.226601422203493e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959137280.0
		 entropy bonus: 0.21860471367835999
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6245493760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6497440768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.226601587130237e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.226601422203493e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959137280.0
		 entropy bonus: 0.21860471367835999
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6245493760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6497440768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.226601587130237e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.226601422203493e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5959137280.0
		 entropy bonus: 0.21860471367835999
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6245493760.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6497440768.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.226601587130237e+18 - Differentiable computation graph = True!
PPO iteration: 964/1000:
	 start solving instance: 92...
	 start solving instance: 58...
	 start solving instance: 107...
	 start solving instance: 148...
	 start solving instance: 139...
	 start solving instance: 15...
	 start solving instance: 64...
	 start solving instance: 112...
	 start solving instance: 127...
	 start solving instance: 105...
	 start solving instance: 65...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 81...
	 start solving instance: 126...
	 start solving instance: 34...
	 start solving instance: 50...
	 start solving instance: 85...
	 start solving instance: 51...
	 start solving instance: 122...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.15153160611011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021519360.0
		 entropy bonus: 0.2206028252840042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6210027520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447041536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1515316061101097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.15153160611011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021519360.0
		 entropy bonus: 0.2206028252840042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6210027520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447041536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1515316061101097e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.15153160611011e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6021519360.0
		 entropy bonus: 0.2206028252840042
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6210027520.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6447041536.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.1515316061101097e+18 - Differentiable computation graph = True!
PPO iteration: 965/1000:
	 start solving instance: 50...
	 start solving instance: 84...
	 start solving instance: 146...
	 start solving instance: 139...
	 start solving instance: 112...
	 start solving instance: 105...
	 start solving instance: 81...
	 start solving instance: 58...
	 start solving instance: 64...
	 start solving instance: 51...
	 start solving instance: 122...
	 start solving instance: 92...
	 start solving instance: 107...
	 start solving instance: 148...
	 start solving instance: 34...
	 start solving instance: 85...
	 start solving instance: 15...
	 start solving instance: 65...
	 start solving instance: 127...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.3040281514221765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6071196672.0
		 entropy bonus: 0.2202303260564804
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6353057280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6735500800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304028096446595e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.3040281514221765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6071196672.0
		 entropy bonus: 0.2202303260564804
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6353057280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6735500800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304028096446595e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.3040281514221765e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6071196672.0
		 entropy bonus: 0.2202303260564804
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6353057280.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6735500800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.304028096446595e+18 - Differentiable computation graph = True!
PPO iteration: 966/1000:
	 start solving instance: 112...
	 start solving instance: 85...
	 start solving instance: 15...
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 127...
	 start solving instance: 81...
	 start solving instance: 92...
	 start solving instance: 146...
	 start solving instance: 126...
	 start solving instance: 139...
	 start solving instance: 50...
	 start solving instance: 84...
	 start solving instance: 148...
	 start solving instance: 65...
	 start solving instance: 105...
	 start solving instance: 64...
	 start solving instance: 34...
	 start solving instance: 122...
	 start solving instance: 58...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.2369064849836605e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009982464.0
		 entropy bonus: 0.22500894963741302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6196859904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707143680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2369064849836605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.2369064849836605e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009982464.0
		 entropy bonus: 0.22500894963741302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6196859904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707143680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2369064849836605e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.2369064849836605e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6009982464.0
		 entropy bonus: 0.22500894963741302
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6196859904.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6707143680.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2369064849836605e+18 - Differentiable computation graph = True!
PPO iteration: 967/1000:
	 start solving instance: 85...
	 start solving instance: 148...
	 start solving instance: 65...
	 start solving instance: 58...
	 start solving instance: 50...
	 start solving instance: 139...
	 start solving instance: 81...
	 start solving instance: 105...
	 start solving instance: 146...
	 start solving instance: 64...
	 start solving instance: 51...
	 start solving instance: 126...
	 start solving instance: 127...
	 start solving instance: 84...
	 start solving instance: 122...
	 start solving instance: 34...
	 start solving instance: 15...
	 start solving instance: 92...
	 start solving instance: 112...
	 start solving instance: 107...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.415020771613606e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6036419584.0
		 entropy bonus: 0.2211872637271881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6480359424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6777550848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.415020771613606e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.415020771613606e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6036419584.0
		 entropy bonus: 0.2211872637271881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6480359424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6777550848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.415020771613606e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.415020771613606e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6036419584.0
		 entropy bonus: 0.2211872637271881
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6480359424.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6777550848.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.415020771613606e+18 - Differentiable computation graph = True!
PPO iteration: 968/1000:
	 start solving instance: 148...
	 start solving instance: 64...
	 start solving instance: 58...
	 start solving instance: 105...
	 start solving instance: 146...
	 start solving instance: 126...
	 start solving instance: 85...
	 start solving instance: 34...
	 start solving instance: 122...
	 start solving instance: 65...
	 start solving instance: 107...
	 start solving instance: 50...
	 start solving instance: 92...
	 start solving instance: 15...
	 start solving instance: 139...
	 start solving instance: 51...
	 start solving instance: 81...
	 start solving instance: 127...
	 start solving instance: 84...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.1208517132579504e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024814080.0
		 entropy bonus: 0.22135646641254425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6195436032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400687616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.120851658282369e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.1208517132579504e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024814080.0
		 entropy bonus: 0.22135646641254425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6195436032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400687616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.120851658282369e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.1208517132579504e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6024814080.0
		 entropy bonus: 0.22135646641254425
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6195436032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6400687616.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.120851658282369e+18 - Differentiable computation graph = True!
PPO iteration: 969/1000:
	 start solving instance: 139...
	 start solving instance: 34...
	 start solving instance: 64...
	 start solving instance: 84...
	 start solving instance: 127...
	 start solving instance: 65...
	 start solving instance: 15...
	 start solving instance: 81...
	 start solving instance: 85...
	 start solving instance: 105...
	 start solving instance: 92...
	 start solving instance: 148...
	 start solving instance: 50...
	 start solving instance: 122...
	 start solving instance: 58...
	 start solving instance: 146...
	 start solving instance: 107...
	 start solving instance: 51...
	 start solving instance: 126...
	 start solving instance: 112...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.267928106049733e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6035125760.0
		 entropy bonus: 0.22274194657802582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276689920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6717061120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2679281060497326e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.267928106049733e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6035125760.0
		 entropy bonus: 0.22274194657802582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276689920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6717061120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2679281060497326e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.267928106049733e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6035125760.0
		 entropy bonus: 0.22274194657802582
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6276689920.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6717061120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.2679281060497326e+18 - Differentiable computation graph = True!
PPO iteration: 970/1000:
	 start solving instance: 139...
	 start solving instance: 92...
	 start solving instance: 34...
	 start solving instance: 148...
	 start solving instance: 50...
	 start solving instance: 51...
	 start solving instance: 122...
	 start solving instance: 84...
	 start solving instance: 81...
	 start solving instance: 15...
	 start solving instance: 65...
	 start solving instance: 58...
	 start solving instance: 146...
	 start solving instance: 112...
	 start solving instance: 127...
	 start solving instance: 85...
	 start solving instance: 105...
	 start solving instance: 64...
	 start solving instance: 107...
	 start solving instance: 126...
	 Optimization epoch: 1/3
		 value loss (over batch): 4.209508414438087e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023550976.0
		 entropy bonus: 0.22213196754455566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6215666176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6469514240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209508579364831e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 4.209508414438087e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023550976.0
		 entropy bonus: 0.22213196754455566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6215666176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6469514240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209508579364831e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 4.209508414438087e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -6023550976.0
		 entropy bonus: 0.22213196754455566
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -6215666176.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6469514240.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 4.209508579364831e+18 - Differentiable computation graph = True!
PPO iteration: 971/1000:
	 New training batch of size 20...
	 start solving instance: 12...
	 start solving instance: 66...
	 start solving instance: 11...
	 start solving instance: 14...
	 start solving instance: 37...
	 start solving instance: 52...
	 start solving instance: 64...
	 start solving instance: 145...
	 start solving instance: 106...
	 start solving instance: 116...
	 start solving instance: 24...
	 start solving instance: 84...
	 start solving instance: 36...
	 start solving instance: 108...
	 start solving instance: 62...
	 start solving instance: 148...
	 start solving instance: 110...
	 start solving instance: 39...
	 start solving instance: 51...
	 start solving instance: 111...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2208044689977246e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5430951424.0
		 entropy bonus: 0.20815983414649963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5355420672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859421696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2208046339244687e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2208044689977246e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5430951424.0
		 entropy bonus: 0.20815983414649963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5355420672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859421696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2208046339244687e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2208044689977246e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5430951424.0
		 entropy bonus: 0.20815983414649963
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5355420672.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859421696.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2208046339244687e+18 - Differentiable computation graph = True!
PPO iteration: 972/1000:
	 start solving instance: 110...
	 start solving instance: 145...
	 start solving instance: 84...
	 start solving instance: 12...
	 start solving instance: 14...
	 start solving instance: 37...
	 start solving instance: 148...
	 start solving instance: 62...
	 start solving instance: 51...
	 start solving instance: 64...
	 start solving instance: 39...
	 start solving instance: 52...
	 start solving instance: 106...
	 start solving instance: 66...
	 start solving instance: 24...
	 start solving instance: 111...
	 start solving instance: 116...
	 start solving instance: 11...
	 start solving instance: 36...
	 start solving instance: 108...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.443876026868826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5463723520.0
		 entropy bonus: 0.21832957863807678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718892032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6043937280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.443876026868826e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.443876026868826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5463723520.0
		 entropy bonus: 0.21832957863807678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718892032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6043937280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.443876026868826e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.443876026868826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5463723520.0
		 entropy bonus: 0.21832957863807678
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5718892032.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6043937280.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.443876026868826e+18 - Differentiable computation graph = True!
PPO iteration: 973/1000:
	 start solving instance: 52...
	 start solving instance: 62...
	 start solving instance: 108...
	 start solving instance: 24...
	 start solving instance: 36...
	 start solving instance: 148...
	 start solving instance: 51...
	 start solving instance: 39...
	 start solving instance: 66...
	 start solving instance: 111...
	 start solving instance: 11...
	 start solving instance: 37...
	 start solving instance: 84...
	 start solving instance: 145...
	 start solving instance: 12...
	 start solving instance: 14...
	 start solving instance: 64...
	 start solving instance: 110...
	 start solving instance: 106...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4944390481930355e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5592711168.0
		 entropy bonus: 0.2083146572113037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5668829184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5783185920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.494438993217454e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4944390481930355e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5592711168.0
		 entropy bonus: 0.2083146572113037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5668829184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5783185920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.494438993217454e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4944390481930355e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5592711168.0
		 entropy bonus: 0.2083146572113037
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5668829184.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5783185920.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.494438993217454e+18 - Differentiable computation graph = True!
PPO iteration: 974/1000:
	 start solving instance: 12...
	 start solving instance: 24...
	 start solving instance: 111...
	 start solving instance: 148...
	 start solving instance: 11...
	 start solving instance: 52...
	 start solving instance: 110...
	 start solving instance: 37...
	 start solving instance: 66...
	 start solving instance: 106...
	 start solving instance: 14...
	 start solving instance: 108...
	 start solving instance: 62...
	 start solving instance: 145...
	 start solving instance: 116...
	 start solving instance: 64...
	 start solving instance: 36...
	 start solving instance: 51...
	 start solving instance: 84...
	 start solving instance: 39...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1945848550148014e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5401647616.0
		 entropy bonus: 0.21513700485229492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406330368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5575565824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1945848550148014e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1945848550148014e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5401647616.0
		 entropy bonus: 0.21513700485229492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406330368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5575565824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1945848550148014e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1945848550148014e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5401647616.0
		 entropy bonus: 0.21513700485229492
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406330368.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5575565824.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1945848550148014e+18 - Differentiable computation graph = True!
PPO iteration: 975/1000:
	 start solving instance: 24...
	 start solving instance: 12...
	 start solving instance: 145...
	 start solving instance: 111...
	 start solving instance: 62...
	 start solving instance: 84...
	 start solving instance: 66...
	 start solving instance: 37...
	 start solving instance: 106...
	 start solving instance: 36...
	 start solving instance: 108...
	 start solving instance: 51...
	 start solving instance: 110...
	 start solving instance: 52...
	 start solving instance: 14...
	 start solving instance: 11...
	 start solving instance: 39...
	 start solving instance: 148...
	 start solving instance: 64...
	 start solving instance: 116...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4785579221437645e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5591009792.0
		 entropy bonus: 0.19532154500484467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5562695168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6214142464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4785579221437645e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4785579221437645e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5591009792.0
		 entropy bonus: 0.19532154500484467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5562695168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6214142464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4785579221437645e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4785579221437645e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5591009792.0
		 entropy bonus: 0.19532154500484467
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5562695168.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6214142464.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4785579221437645e+18 - Differentiable computation graph = True!
PPO iteration: 976/1000:
	 start solving instance: 51...
	 start solving instance: 64...
	 start solving instance: 37...
	 start solving instance: 62...
	 start solving instance: 66...
	 start solving instance: 39...
	 start solving instance: 106...
	 start solving instance: 116...
	 start solving instance: 14...
	 start solving instance: 84...
	 start solving instance: 11...
	 start solving instance: 108...
	 start solving instance: 148...
	 start solving instance: 111...
	 start solving instance: 12...
	 start solving instance: 36...
	 start solving instance: 24...
	 start solving instance: 145...
	 start solving instance: 52...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2558034634261135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5502590976.0
		 entropy bonus: 0.20613498985767365
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406024192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5564892672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2558034634261135e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2558034634261135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5502590976.0
		 entropy bonus: 0.20613498985767365
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406024192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5564892672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2558034634261135e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2558034634261135e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5502590976.0
		 entropy bonus: 0.20613498985767365
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5406024192.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5564892672.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2558034634261135e+18 - Differentiable computation graph = True!
PPO iteration: 977/1000:
	 start solving instance: 39...
	 start solving instance: 62...
	 start solving instance: 14...
	 start solving instance: 116...
	 start solving instance: 51...
	 start solving instance: 108...
	 start solving instance: 36...
	 start solving instance: 11...
	 start solving instance: 37...
	 start solving instance: 84...
	 start solving instance: 64...
	 start solving instance: 12...
	 start solving instance: 111...
	 start solving instance: 24...
	 start solving instance: 145...
	 start solving instance: 66...
	 start solving instance: 52...
	 start solving instance: 148...
	 start solving instance: 110...
	 start solving instance: 106...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4054740439524704e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530226688.0
		 entropy bonus: 0.20054426789283752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5503677440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6076288512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4054742088792146e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4054740439524704e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530226688.0
		 entropy bonus: 0.20054426789283752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5503677440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6076288512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4054742088792146e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4054740439524704e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5530226688.0
		 entropy bonus: 0.20054426789283752
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5503677440.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6076288512.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4054742088792146e+18 - Differentiable computation graph = True!
PPO iteration: 978/1000:
	 start solving instance: 62...
	 start solving instance: 14...
	 start solving instance: 39...
	 start solving instance: 11...
	 start solving instance: 108...
	 start solving instance: 106...
	 start solving instance: 66...
	 start solving instance: 52...
	 start solving instance: 12...
	 start solving instance: 148...
	 start solving instance: 116...
	 start solving instance: 51...
	 start solving instance: 37...
	 start solving instance: 110...
	 start solving instance: 145...
	 start solving instance: 111...
	 start solving instance: 24...
	 start solving instance: 36...
	 start solving instance: 64...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.274714403716884e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5482565632.0
		 entropy bonus: 0.2128220647573471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5435867136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5927735296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.274714513668047e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.274714403716884e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5482565632.0
		 entropy bonus: 0.2128220647573471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5435867136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5927735296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.274714513668047e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.274714403716884e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5482565632.0
		 entropy bonus: 0.2128220647573471
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5435867136.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5927735296.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.274714513668047e+18 - Differentiable computation graph = True!
PPO iteration: 979/1000:
	 start solving instance: 111...
	 start solving instance: 106...
	 start solving instance: 36...
	 start solving instance: 145...
	 start solving instance: 14...
	 start solving instance: 84...
	 start solving instance: 39...
	 start solving instance: 12...
	 start solving instance: 148...
	 start solving instance: 108...
	 start solving instance: 24...
	 start solving instance: 116...
	 start solving instance: 51...
	 start solving instance: 62...
	 start solving instance: 37...
	 start solving instance: 66...
	 start solving instance: 64...
	 start solving instance: 11...
	 start solving instance: 52...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.141796642058299e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5439789568.0
		 entropy bonus: 0.19959722459316254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5150510080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5858188800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.141796752009462e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.141796642058299e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5439789568.0
		 entropy bonus: 0.19959722459316254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5150510080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5858188800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.141796752009462e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.141796642058299e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5439789568.0
		 entropy bonus: 0.19959722459316254
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5150510080.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5858188800.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.141796752009462e+18 - Differentiable computation graph = True!
PPO iteration: 980/1000:
	 start solving instance: 110...
	 start solving instance: 24...
	 start solving instance: 36...
	 start solving instance: 106...
	 start solving instance: 37...
	 start solving instance: 111...
	 start solving instance: 62...
	 start solving instance: 12...
	 start solving instance: 39...
	 start solving instance: 116...
	 start solving instance: 52...
	 start solving instance: 108...
	 start solving instance: 11...
	 start solving instance: 66...
	 start solving instance: 14...
	 start solving instance: 51...
	 start solving instance: 148...
	 start solving instance: 64...
	 start solving instance: 145...
	 start solving instance: 84...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2198989112210883e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5501857280.0
		 entropy bonus: 0.20456407964229584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5263243776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5904125440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.219898911221088e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2198989112210883e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5501857280.0
		 entropy bonus: 0.20456407964229584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5263243776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5904125440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.219898911221088e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2198989112210883e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5501857280.0
		 entropy bonus: 0.20456407964229584
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5263243776.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5904125440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.219898911221088e+18 - Differentiable computation graph = True!
PPO iteration: 981/1000:
	 New training batch of size 20...
	 start solving instance: 82...
	 start solving instance: 67...
	 start solving instance: 144...
	 start solving instance: 103...
	 start solving instance: 136...
	 start solving instance: 10...
	 start solving instance: 32...
	 start solving instance: 63...
	 start solving instance: 78...
	 start solving instance: 2...
	 start solving instance: 26...
	 start solving instance: 29...
	 start solving instance: 24...
	 start solving instance: 64...
	 start solving instance: 34...
	 start solving instance: 110...
	 start solving instance: 44...
	 start solving instance: 124...
	 start solving instance: 12...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.222927186146309e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5488623616.0
		 entropy bonus: 0.20356528460979462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5167443968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6372870656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2229272411218903e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.222927186146309e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5488623616.0
		 entropy bonus: 0.20356528460979462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5167443968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6372870656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2229272411218903e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.222927186146309e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5488623616.0
		 entropy bonus: 0.20356528460979462
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5167443968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6372870656.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2229272411218903e+18 - Differentiable computation graph = True!
	 Validation stage...
	 start solving instance: 123...
	 start solving instance: 16...
	 start solving instance: 48...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 94...
	 start solving instance: 6...
	 start solving instance: 8...
	 start solving instance: 71...
	 start solving instance: 70...
		 value loss (over batch): 2.8156452093762208e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5216097280.0
		 entropy bonus: 0.19051796197891235
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -4908947456.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5634081792.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 2815645319327383552.0000
PPO iteration: 982/1000:
	 start solving instance: 24...
	 start solving instance: 67...
	 start solving instance: 34...
	 start solving instance: 63...
	 start solving instance: 103...
	 start solving instance: 144...
	 start solving instance: 2...
	 start solving instance: 32...
	 start solving instance: 136...
	 start solving instance: 64...
	 start solving instance: 85...
	 start solving instance: 124...
	 start solving instance: 26...
	 start solving instance: 44...
	 start solving instance: 78...
	 start solving instance: 82...
	 start solving instance: 29...
	 start solving instance: 12...
	 start solving instance: 110...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5188204986366427e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5594604544.0
		 entropy bonus: 0.20348219573497772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5491270656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6954344960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.518820663563387e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5188204986366427e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5594604544.0
		 entropy bonus: 0.20348219573497772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5491270656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6954344960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.518820663563387e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5188204986366427e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5594604544.0
		 entropy bonus: 0.20348219573497772
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5491270656.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6954344960.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.518820663563387e+18 - Differentiable computation graph = True!
PPO iteration: 983/1000:
	 start solving instance: 124...
	 start solving instance: 24...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 67...
	 start solving instance: 144...
	 start solving instance: 78...
	 start solving instance: 64...
	 start solving instance: 12...
	 start solving instance: 85...
	 start solving instance: 32...
	 start solving instance: 29...
	 start solving instance: 136...
	 start solving instance: 82...
	 start solving instance: 63...
	 start solving instance: 34...
	 start solving instance: 2...
	 start solving instance: 110...
	 start solving instance: 26...
	 start solving instance: 10...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.235604115409915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5427385344.0
		 entropy bonus: 0.22412045300006866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5365330432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6387821056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2356040604343337e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.235604115409915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5427385344.0
		 entropy bonus: 0.22412045300006866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5365330432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6387821056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2356040604343337e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.235604115409915e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5427385344.0
		 entropy bonus: 0.22412045300006866
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5365330432.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6387821056.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.2356040604343337e+18 - Differentiable computation graph = True!
PPO iteration: 984/1000:
	 start solving instance: 34...
	 start solving instance: 78...
	 start solving instance: 12...
	 start solving instance: 10...
	 start solving instance: 124...
	 start solving instance: 44...
	 start solving instance: 64...
	 start solving instance: 29...
	 start solving instance: 24...
	 start solving instance: 26...
	 start solving instance: 103...
	 start solving instance: 82...
	 start solving instance: 85...
	 start solving instance: 32...
	 start solving instance: 2...
	 start solving instance: 110...
	 start solving instance: 144...
	 start solving instance: 63...
	 start solving instance: 67...
	 start solving instance: 136...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.1624028093767746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5469824000.0
		 entropy bonus: 0.20275215804576874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5152980480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5839612416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1624029743035187e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.1624028093767746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5469824000.0
		 entropy bonus: 0.20275215804576874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5152980480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5839612416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1624029743035187e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.1624028093767746e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5469824000.0
		 entropy bonus: 0.20275215804576874
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5152980480.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5839612416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.1624029743035187e+18 - Differentiable computation graph = True!
PPO iteration: 985/1000:
	 start solving instance: 103...
	 start solving instance: 124...
	 start solving instance: 78...
	 start solving instance: 82...
	 start solving instance: 12...
	 start solving instance: 64...
	 start solving instance: 10...
	 start solving instance: 26...
	 start solving instance: 85...
	 start solving instance: 144...
	 start solving instance: 2...
	 start solving instance: 110...
	 start solving instance: 63...
	 start solving instance: 67...
	 start solving instance: 29...
	 start solving instance: 32...
	 start solving instance: 44...
	 start solving instance: 34...
	 start solving instance: 24...
	 start solving instance: 136...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.307322620061837e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5438330368.0
		 entropy bonus: 0.2036532461643219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5237563392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6416088576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3073227300129997e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.307322620061837e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5438330368.0
		 entropy bonus: 0.2036532461643219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5237563392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6416088576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3073227300129997e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.307322620061837e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5438330368.0
		 entropy bonus: 0.2036532461643219
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5237563392.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6416088576.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.3073227300129997e+18 - Differentiable computation graph = True!
PPO iteration: 986/1000:
	 start solving instance: 85...
	 start solving instance: 67...
	 start solving instance: 103...
	 start solving instance: 2...
	 start solving instance: 124...
	 start solving instance: 44...
	 start solving instance: 12...
	 start solving instance: 32...
	 start solving instance: 34...
	 start solving instance: 64...
	 start solving instance: 10...
	 start solving instance: 78...
	 start solving instance: 63...
	 start solving instance: 26...
	 start solving instance: 110...
	 start solving instance: 29...
	 start solving instance: 24...
	 start solving instance: 82...
	 start solving instance: 144...
	 start solving instance: 136...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4192095830112993e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5569406464.0
		 entropy bonus: 0.22188325226306915
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5516113408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6501478912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4192095830112993e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4192095830112993e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5569406464.0
		 entropy bonus: 0.22188325226306915
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5516113408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6501478912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4192095830112993e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4192095830112993e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5569406464.0
		 entropy bonus: 0.22188325226306915
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5516113408.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6501478912.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4192095830112993e+18 - Differentiable computation graph = True!
PPO iteration: 987/1000:
	 start solving instance: 26...
	 start solving instance: 24...
	 start solving instance: 32...
	 start solving instance: 144...
	 start solving instance: 29...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 67...
	 start solving instance: 10...
	 start solving instance: 82...
	 start solving instance: 110...
	 start solving instance: 78...
	 start solving instance: 34...
	 start solving instance: 63...
	 start solving instance: 12...
	 start solving instance: 64...
	 start solving instance: 85...
	 start solving instance: 124...
	 start solving instance: 136...
	 start solving instance: 2...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4251687161315197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5438082560.0
		 entropy bonus: 0.21190057694911957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5561864704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6358657024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4251686611559383e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4251687161315197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5438082560.0
		 entropy bonus: 0.21190057694911957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5561864704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6358657024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4251686611559383e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4251687161315197e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5438082560.0
		 entropy bonus: 0.21190057694911957
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5561864704.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6358657024.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4251686611559383e+18 - Differentiable computation graph = True!
PPO iteration: 988/1000:
	 start solving instance: 29...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 24...
	 start solving instance: 82...
	 start solving instance: 78...
	 start solving instance: 32...
	 start solving instance: 103...
	 start solving instance: 136...
	 start solving instance: 85...
	 start solving instance: 110...
	 start solving instance: 2...
	 start solving instance: 144...
	 start solving instance: 26...
	 start solving instance: 124...
	 start solving instance: 44...
	 start solving instance: 34...
	 start solving instance: 64...
	 start solving instance: 12...
	 start solving instance: 63...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.2784551621769036e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5429267968.0
		 entropy bonus: 0.2184222787618637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5371753472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5933437440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.278455327103648e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.2784551621769036e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5429267968.0
		 entropy bonus: 0.2184222787618637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5371753472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5933437440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.278455327103648e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.2784551621769036e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5429267968.0
		 entropy bonus: 0.2184222787618637
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5371753472.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5933437440.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.278455327103648e+18 - Differentiable computation graph = True!
PPO iteration: 989/1000:
	 start solving instance: 144...
	 start solving instance: 32...
	 start solving instance: 110...
	 start solving instance: 67...
	 start solving instance: 85...
	 start solving instance: 2...
	 start solving instance: 82...
	 start solving instance: 34...
	 start solving instance: 124...
	 start solving instance: 63...
	 start solving instance: 44...
	 start solving instance: 10...
	 start solving instance: 136...
	 start solving instance: 24...
	 start solving instance: 103...
	 start solving instance: 78...
	 start solving instance: 12...
	 start solving instance: 29...
	 start solving instance: 26...
	 start solving instance: 64...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4628058787595944e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503731712.0
		 entropy bonus: 0.20736847817897797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5483795968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6482610176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4628060436863386e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4628058787595944e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503731712.0
		 entropy bonus: 0.20736847817897797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5483795968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6482610176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4628060436863386e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4628058787595944e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5503731712.0
		 entropy bonus: 0.20736847817897797
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5483795968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6482610176.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4628060436863386e+18 - Differentiable computation graph = True!
PPO iteration: 990/1000:
	 start solving instance: 136...
	 start solving instance: 10...
	 start solving instance: 12...
	 start solving instance: 64...
	 start solving instance: 32...
	 start solving instance: 63...
	 start solving instance: 26...
	 start solving instance: 24...
	 start solving instance: 144...
	 start solving instance: 44...
	 start solving instance: 34...
	 start solving instance: 2...
	 start solving instance: 82...
	 start solving instance: 124...
	 start solving instance: 67...
	 start solving instance: 29...
	 start solving instance: 110...
	 start solving instance: 78...
	 start solving instance: 103...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.3350210771841188e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5478891520.0
		 entropy bonus: 0.21237896382808685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5377192448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6151275520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.335021077184119e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.3350210771841188e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5478891520.0
		 entropy bonus: 0.21237896382808685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5377192448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6151275520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.335021077184119e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.3350210771841188e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5478891520.0
		 entropy bonus: 0.21237896382808685
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5377192448.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6151275520.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.335021077184119e+18 - Differentiable computation graph = True!
PPO iteration: 991/1000:
	 New training batch of size 20...
	 start solving instance: 57...
	 start solving instance: 125...
	 start solving instance: 52...
	 start solving instance: 79...
	 start solving instance: 111...
	 start solving instance: 20...
	 start solving instance: 36...
	 start solving instance: 144...
	 start solving instance: 142...
	 start solving instance: 117...
	 start solving instance: 66...
	 start solving instance: 39...
	 start solving instance: 50...
	 start solving instance: 135...
	 start solving instance: 2...
	 start solving instance: 136...
	 start solving instance: 21...
	 start solving instance: 45...
	 start solving instance: 26...
	 start solving instance: 53...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.715634619324826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5719675392.0
		 entropy bonus: 0.20012064278125763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5734317568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268465664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7156346193248256e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.715634619324826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5719675392.0
		 entropy bonus: 0.20012064278125763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5734317568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268465664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7156346193248256e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.715634619324826e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5719675392.0
		 entropy bonus: 0.20012064278125763
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5734317568.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268465664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7156346193248256e+18 - Differentiable computation graph = True!
PPO iteration: 992/1000:
	 start solving instance: 2...
	 start solving instance: 45...
	 start solving instance: 111...
	 start solving instance: 142...
	 start solving instance: 136...
	 start solving instance: 125...
	 start solving instance: 39...
	 start solving instance: 20...
	 start solving instance: 53...
	 start solving instance: 52...
	 start solving instance: 50...
	 start solving instance: 36...
	 start solving instance: 21...
	 start solving instance: 117...
	 start solving instance: 26...
	 start solving instance: 135...
	 start solving instance: 144...
	 start solving instance: 57...
	 start solving instance: 79...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.440354071222734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5650595328.0
		 entropy bonus: 0.19753777980804443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5384645120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6118341120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4403540162471526e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.440354071222734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5650595328.0
		 entropy bonus: 0.19753777980804443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5384645120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6118341120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4403540162471526e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.440354071222734e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5650595328.0
		 entropy bonus: 0.19753777980804443
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5384645120.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6118341120.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4403540162471526e+18 - Differentiable computation graph = True!
PPO iteration: 993/1000:
	 start solving instance: 111...
	 start solving instance: 125...
	 start solving instance: 136...
	 start solving instance: 39...
	 start solving instance: 142...
	 start solving instance: 117...
	 start solving instance: 57...
	 start solving instance: 20...
	 start solving instance: 21...
	 start solving instance: 2...
	 start solving instance: 53...
	 start solving instance: 79...
	 start solving instance: 45...
	 start solving instance: 50...
	 start solving instance: 26...
	 start solving instance: 52...
	 start solving instance: 144...
	 start solving instance: 135...
	 start solving instance: 66...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6380979389433643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5704367104.0
		 entropy bonus: 0.19475798308849335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5632275968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6212089856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.638097883967783e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6380979389433643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5704367104.0
		 entropy bonus: 0.19475798308849335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5632275968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6212089856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.638097883967783e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6380979389433643e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5704367104.0
		 entropy bonus: 0.19475798308849335
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5632275968.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6212089856.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.638097883967783e+18 - Differentiable computation graph = True!
PPO iteration: 994/1000:
	 start solving instance: 125...
	 start solving instance: 20...
	 start solving instance: 142...
	 start solving instance: 57...
	 start solving instance: 39...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 79...
	 start solving instance: 53...
	 start solving instance: 50...
	 start solving instance: 36...
	 start solving instance: 136...
	 start solving instance: 111...
	 start solving instance: 66...
	 start solving instance: 135...
	 start solving instance: 2...
	 start solving instance: 52...
	 start solving instance: 45...
	 start solving instance: 21...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.6008132797431546e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5656673792.0
		 entropy bonus: 0.1960960477590561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5555590144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6160542208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.600813444669899e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.6008132797431546e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5656673792.0
		 entropy bonus: 0.1960960477590561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5555590144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6160542208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.600813444669899e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.6008132797431546e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5656673792.0
		 entropy bonus: 0.1960960477590561
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5555590144.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6160542208.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.600813444669899e+18 - Differentiable computation graph = True!
PPO iteration: 995/1000:
	 start solving instance: 111...
	 start solving instance: 26...
	 start solving instance: 142...
	 start solving instance: 2...
	 start solving instance: 21...
	 start solving instance: 135...
	 start solving instance: 50...
	 start solving instance: 36...
	 start solving instance: 52...
	 start solving instance: 125...
	 start solving instance: 117...
	 start solving instance: 39...
	 start solving instance: 45...
	 start solving instance: 57...
	 start solving instance: 20...
	 start solving instance: 144...
	 start solving instance: 66...
	 start solving instance: 53...
	 start solving instance: 79...
	 start solving instance: 136...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.705028730163298e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5674578944.0
		 entropy bonus: 0.20062576234340668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5679266816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6677564416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7050287301632983e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.705028730163298e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5674578944.0
		 entropy bonus: 0.20062576234340668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5679266816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6677564416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7050287301632983e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.705028730163298e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5674578944.0
		 entropy bonus: 0.20062576234340668
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5679266816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6677564416.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7050287301632983e+18 - Differentiable computation graph = True!
PPO iteration: 996/1000:
	 start solving instance: 142...
	 start solving instance: 45...
	 start solving instance: 21...
	 start solving instance: 53...
	 start solving instance: 136...
	 start solving instance: 135...
	 start solving instance: 79...
	 start solving instance: 125...
	 start solving instance: 20...
	 start solving instance: 52...
	 start solving instance: 2...
	 start solving instance: 57...
	 start solving instance: 117...
	 start solving instance: 26...
	 start solving instance: 144...
	 start solving instance: 39...
	 start solving instance: 50...
	 start solving instance: 36...
	 start solving instance: 111...
	 start solving instance: 66...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.580666488382764e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5678259712.0
		 entropy bonus: 0.1980544626712799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5478135296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268827648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.580666543358345e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.580666488382764e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5678259712.0
		 entropy bonus: 0.1980544626712799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5478135296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268827648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.580666543358345e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.580666488382764e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5678259712.0
		 entropy bonus: 0.1980544626712799
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5478135296.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6268827648.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.580666543358345e+18 - Differentiable computation graph = True!
PPO iteration: 997/1000:
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 135...
	 start solving instance: 53...
	 start solving instance: 111...
	 start solving instance: 45...
	 start solving instance: 21...
	 start solving instance: 52...
	 start solving instance: 117...
	 start solving instance: 136...
	 start solving instance: 50...
	 start solving instance: 79...
	 start solving instance: 20...
	 start solving instance: 39...
	 start solving instance: 57...
	 start solving instance: 66...
	 start solving instance: 36...
	 start solving instance: 2...
	 start solving instance: 142...
	 start solving instance: 26...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.4930769731885466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5734097920.0
		 entropy bonus: 0.2056177854537964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5435622912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859524608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4930769731885466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.4930769731885466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5734097920.0
		 entropy bonus: 0.2056177854537964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5435622912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859524608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4930769731885466e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.4930769731885466e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5734097920.0
		 entropy bonus: 0.2056177854537964
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5435622912.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5859524608.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.4930769731885466e+18 - Differentiable computation graph = True!
PPO iteration: 998/1000:
	 start solving instance: 66...
	 start solving instance: 117...
	 start solving instance: 125...
	 start solving instance: 39...
	 start solving instance: 50...
	 start solving instance: 142...
	 start solving instance: 53...
	 start solving instance: 52...
	 start solving instance: 2...
	 start solving instance: 136...
	 start solving instance: 111...
	 start solving instance: 144...
	 start solving instance: 79...
	 start solving instance: 26...
	 start solving instance: 57...
	 start solving instance: 36...
	 start solving instance: 20...
	 start solving instance: 45...
	 start solving instance: 21...
	 start solving instance: 135...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.422052920080728e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5609404928.0
		 entropy bonus: 0.20939791202545166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5475618816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5689521664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.422052920080728e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.422052920080728e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5609404928.0
		 entropy bonus: 0.20939791202545166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5475618816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5689521664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.422052920080728e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.422052920080728e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5609404928.0
		 entropy bonus: 0.20939791202545166
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5475618816.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -5689521664.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.422052920080728e+18 - Differentiable computation graph = True!
PPO iteration: 999/1000:
	 start solving instance: 135...
	 start solving instance: 39...
	 start solving instance: 125...
	 start solving instance: 136...
	 start solving instance: 142...
	 start solving instance: 111...
	 start solving instance: 52...
	 start solving instance: 2...
	 start solving instance: 21...
	 start solving instance: 20...
	 start solving instance: 50...
	 start solving instance: 144...
	 start solving instance: 79...
	 start solving instance: 26...
	 start solving instance: 66...
	 start solving instance: 53...
	 start solving instance: 36...
	 start solving instance: 57...
	 start solving instance: 117...
	 start solving instance: 45...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.5172574329065964e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682032128.0
		 entropy bonus: 0.18997104465961456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5475485696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6469838336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5172574329065964e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.5172574329065964e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682032128.0
		 entropy bonus: 0.18997104465961456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5475485696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6469838336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5172574329065964e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.5172574329065964e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5682032128.0
		 entropy bonus: 0.18997104465961456
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5475485696.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6469838336.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.5172574329065964e+18 - Differentiable computation graph = True!
PPO iteration: 1000/1000:
	 start solving instance: 144...
	 start solving instance: 53...
	 start solving instance: 79...
	 start solving instance: 39...
	 start solving instance: 20...
	 start solving instance: 136...
	 start solving instance: 135...
	 start solving instance: 142...
	 start solving instance: 45...
	 start solving instance: 125...
	 start solving instance: 50...
	 start solving instance: 111...
	 start solving instance: 2...
	 start solving instance: 57...
	 start solving instance: 66...
	 start solving instance: 117...
	 start solving instance: 52...
	 start solving instance: 26...
	 start solving instance: 21...
	 start solving instance: 36...
	 Optimization epoch: 1/3
		 value loss (over batch): 3.722507886412379e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5679142400.0
		 entropy bonus: 0.19232586026191711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5734212608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750364160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7225079413879603e+18 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 value loss (over batch): 3.722507886412379e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5679142400.0
		 entropy bonus: 0.19232586026191711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5734212608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750364160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7225079413879603e+18 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 value loss (over batch): 3.722507886412379e+19
		 -----------------
		 Computing losses for agent (over batch): outsourcing
		 policy loss: -5679142400.0
		 entropy bonus: 0.19232586026191711
		 -----------------
		 Computing losses for agent (over batch): scheduling
		 policy loss: -5734212608.0
		 entropy bonus: 0.0
		 -----------------
		 Computing losses for agent (over batch): material_use
		 policy loss: -6750364160.0
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 3.7225079413879603e+18 - Differentiable computation graph = True!
===* END OF FILE *===
