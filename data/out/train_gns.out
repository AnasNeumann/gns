created virtual environment CPython3.12.4.final.0-64 in 1212ms
  creator CPython3Posix(dest=/localscratch/aneumann.36689674.0/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/home/aneumann/.local/share/virtualenv)
    added seed packages: pip==24.0
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: pip in /localscratch/aneumann.36689674.0/env/lib/python3.12/site-packages (24.0)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pip-24.2+computecanada-py3-none-any.whl
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 24.0
    Uninstalling pip-24.0:
      Successfully uninstalled pip-24.0
Successfully installed pip-24.2+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/numpy-2.1.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 1))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/pandas-2.2.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/seaborn-0.13.2+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 3))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/plotly-5.24.1+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/matplotlib-3.9.2+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.5.1+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/torchvision-0.20.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torchaudio-2.5.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 8))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/torch_geometric-2.6.1+computecanada-py3-none-any.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/python_dateutil-2.9.0.post0+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pytz-2024.2+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tzdata-2024.2+computecanada-py2.py3-none-any.whl (from pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tenacity-9.0.0+computecanada-py3-none-any.whl (from plotly->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/packaging-24.1+computecanada-py3-none-any.whl (from plotly->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/contourpy-1.3.0+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cycler-0.12.1+computecanada-py3-none-any.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fonttools-4.54.1+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/kiwisolver-1.4.7+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/pillow-10.4.0+computecanada-cp312-cp312-linux_x86_64.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyparsing-3.2.0+computecanada-py3-none-any.whl (from matplotlib->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.16.1+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_extensions-4.12.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.4.2+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jinja2-3.1.4+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2024.10.0+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/setuptools-75.1.0+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sympy-1.13.1+computecanada-py3-none-any.whl (from torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/mpmath-1.3.0+computecanada-py3-none-any.whl (from sympy==1.13.1->torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.5.0+computecanada-cp312-cp312-linux_x86_64.whl (from -r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/Pillow_SIMD-9.5.0.post2+computecanada-cp312-cp312-linux_x86_64.whl (from torchvision->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/aiohttp-3.10.9+computecanada-cp312-cp312-linux_x86_64.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/psutil-5.9.8-cp310-abi3-linux_x86_64.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.32.3+computecanada-py3-none-any.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.0+computecanada-py3-none-any.whl (from torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/six-1.16.0+computecanada-py2.py3-none-any.whl (from python-dateutil>=2.8.2->pandas->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiohappyeyeballs-2.4.3+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiosignal-1.3.1+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/attrs-24.2.0+computecanada-py3-none-any.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/frozenlist-1.5.0+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/multidict-6.1.0+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/yarl-1.17.1+computecanada-cp312-cp312-linux_x86_64.whl (from aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-2.1.5+computecanada-cp312-cp312-linux_x86_64.whl (from jinja2->torch->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-3.4.0+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.10+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-2.2.3+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2024.8.30+computecanada-py3-none-any.whl (from requests->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/propcache-0.2.0+computecanada-cp312-cp312-linux_x86_64.whl (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric->-r /home/aneumann/projects/def-adhaj/aneumann/gns/requirements.txt (line 9))
Installing collected packages: pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, tenacity, sympy, six, setuptools, pyparsing, psutil, propcache, pillow-simd, pillow, packaging, numpy, networkx, multidict, MarkupSafe, kiwisolver, idna, fsspec, frozenlist, fonttools, filelock, cycler, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, plotly, jinja2, contourpy, aiosignal, torch, pandas, matplotlib, aiohttp, torchvision, torchaudio, torch_geometric, seaborn
Successfully installed MarkupSafe-2.1.5+computecanada aiohappyeyeballs-2.4.3+computecanada aiohttp-3.10.9+computecanada aiosignal-1.3.1+computecanada attrs-24.2.0+computecanada certifi-2024.8.30+computecanada charset-normalizer-3.4.0+computecanada contourpy-1.3.0+computecanada cycler-0.12.1+computecanada filelock-3.16.1+computecanada fonttools-4.54.1+computecanada frozenlist-1.5.0+computecanada fsspec-2024.10.0+computecanada idna-3.10+computecanada jinja2-3.1.4+computecanada kiwisolver-1.4.7+computecanada matplotlib-3.9.2+computecanada mpmath-1.3.0+computecanada multidict-6.1.0+computecanada networkx-3.4.2+computecanada numpy-2.1.1+computecanada packaging-24.1+computecanada pandas-2.2.2+computecanada pillow-10.4.0+computecanada pillow-simd-9.5.0.post2+computecanada plotly-5.24.1+computecanada propcache-0.2.0+computecanada psutil-5.9.8 pyparsing-3.2.0+computecanada python-dateutil-2.9.0.post0+computecanada pytz-2024.2+computecanada requests-2.32.3+computecanada seaborn-0.13.2+computecanada setuptools-75.1.0+computecanada six-1.16.0+computecanada sympy-1.13.1+computecanada tenacity-9.0.0+computecanada torch-2.5.0+computecanada torch_geometric-2.6.1+computecanada torchaudio-2.5.0+computecanada torchvision-0.20.0+computecanada tqdm-4.67.0+computecanada typing-extensions-4.12.2+computecanada tzdata-2024.2+computecanada urllib3-2.2.3+computecanada yarl-1.17.1+computecanada
/home/aneumann/projects/def-adhaj/aneumann/gns/gns_solver.py:576: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_GNN.load_state_dict(torch.load(model_path+'/gnn_weights_'+index+'.pth'))
/home/aneumann/projects/def-adhaj/aneumann/gns/gns_solver.py:578: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_critic.load_state_dict(torch.load(model_path+'/critic_weights_'+index+'.pth'))
/home/aneumann/projects/def-adhaj/aneumann/gns/gns_solver.py:582: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  outsourcing_actor.load_state_dict(torch.load(model_path+'/outsourcing_weights_'+index+'.pth'))
/home/aneumann/projects/def-adhaj/aneumann/gns/gns_solver.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  scheduling_actor.load_state_dict(torch.load(model_path+'/scheduling_weights_'+index+'.pth'))
/home/aneumann/projects/def-adhaj/aneumann/gns/gns_solver.py:584: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  material_actor.load_state_dict(torch.load(model_path+'/material_use_weights_'+index+'.pth'))
/localscratch/aneumann.36689674.0/env/lib/python3.12/site-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information
  return disable_fn(*args, **kwargs)
/home/aneumann/projects/def-adhaj/aneumann/gns/gns_solver.py:625: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  optimizer.load_state_dict(torch.load(args.path+directory.models+"/adam_"+str(previous_run)+".pth"))
Execution mode: prod...
Training models with MAPPO...
Loading dataset....
End of loading 900 instances!
Dataset loaded after 55.963836908340454 seconds!
PPO iteration: 1/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.302227020263672
		 value loss: 43.39358139038086
		 entropy bonus: 4.903338432312012
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.10595703125
		 value loss: 728.459228515625
		 entropy bonus: 2.8554043769836426
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.692904472351074
		 value loss: 25.417903900146484
		 entropy bonus: 0.3468749523162842
		 -----------------
	 Multi-agent batch loss: 114.99273681640625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.302207946777344
		 value loss: 43.39358139038086
		 entropy bonus: 4.903339385986328
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.10142517089844
		 value loss: 728.459228515625
		 entropy bonus: 2.8555784225463867
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.689269065856934
		 value loss: 25.417903900146484
		 entropy bonus: 0.3471224308013916
		 -----------------
	 Multi-agent batch loss: 114.98454284667969 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.302183151245117
		 value loss: 43.39358139038086
		 entropy bonus: 4.903340816497803
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.1021728515625
		 value loss: 728.459228515625
		 entropy bonus: 2.8557615280151367
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.684273719787598
		 value loss: 25.417903900146484
		 entropy bonus: 0.3475082516670227
		 -----------------
	 Multi-agent batch loss: 114.98027038574219 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: -8.261653900146484
		 value loss: 14.297807693481445
		 entropy bonus: 3.1909937858581543
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -25.611125946044922
		 value loss: 137.4086151123047
		 entropy bonus: 1.4363631010055542
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.454873561859131
		 value loss: 2.6249001026153564
		 entropy bonus: 0.07701428979635239
		 -----------------
	 Multi-agent batch loss: 38.8239
PPO iteration: 2/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.405193328857422
		 value loss: 55.141693115234375
		 entropy bonus: 4.804892063140869
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -83.81824493408203
		 value loss: 981.9688720703125
		 entropy bonus: 2.824981451034546
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.195022583007812
		 value loss: 34.714107513427734
		 entropy bonus: 0.3948126435279846
		 -----------------
	 Multi-agent batch loss: 130.05645751953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.405197143554688
		 value loss: 55.141693115234375
		 entropy bonus: 4.804893493652344
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -83.81649780273438
		 value loss: 981.9688720703125
		 entropy bonus: 2.825024366378784
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.195722579956055
		 value loss: 34.714107513427734
		 entropy bonus: 0.3948180377483368
		 -----------------
	 Multi-agent batch loss: 130.055419921875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.405202865600586
		 value loss: 55.141693115234375
		 entropy bonus: 4.804893970489502
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -83.81454467773438
		 value loss: 981.9688720703125
		 entropy bonus: 2.825049877166748
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.195762634277344
		 value loss: 34.714107513427734
		 entropy bonus: 0.3947488069534302
		 -----------------
	 Multi-agent batch loss: 130.0535125732422 - Differentiable computation graph = True!
PPO iteration: 3/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.302227020263672
		 value loss: 48.041683197021484
		 entropy bonus: 4.8263068199157715
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -71.65107727050781
		 value loss: 771.864013671875
		 entropy bonus: 2.7445931434631348
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.167162895202637
		 value loss: 25.669862747192383
		 entropy bonus: 0.2855357825756073
		 -----------------
	 Multi-agent batch loss: 111.49766540527344 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.302127838134766
		 value loss: 48.041683197021484
		 entropy bonus: 4.826309680938721
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -71.64804077148438
		 value loss: 771.864013671875
		 entropy bonus: 2.7446537017822266
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.16650676727295
		 value loss: 25.669862747192383
		 entropy bonus: 0.28526294231414795
		 -----------------
	 Multi-agent batch loss: 111.4938735961914 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.30196189880371
		 value loss: 48.041683197021484
		 entropy bonus: 4.826314926147461
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -71.64419555664062
		 value loss: 771.864013671875
		 entropy bonus: 2.744720697402954
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.165645599365234
		 value loss: 25.669862747192383
		 entropy bonus: 0.285003662109375
		 -----------------
	 Multi-agent batch loss: 111.48899841308594 - Differentiable computation graph = True!
PPO iteration: 4/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.681995391845703
		 value loss: 60.19218444824219
		 entropy bonus: 4.862186431884766
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -84.94483947753906
		 value loss: 950.203369140625
		 entropy bonus: 3.0232667922973633
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.870976448059082
		 value loss: 33.461830139160156
		 entropy bonus: 0.411296546459198
		 -----------------
	 Multi-agent batch loss: 132.85340881347656 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.682113647460938
		 value loss: 60.19218444824219
		 entropy bonus: 4.862188339233398
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -84.94232177734375
		 value loss: 950.203369140625
		 entropy bonus: 3.0233325958251953
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.86971664428711
		 value loss: 33.461830139160156
		 entropy bonus: 0.41101518273353577
		 -----------------
	 Multi-agent batch loss: 132.84976196289062 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.682159423828125
		 value loss: 60.19218444824219
		 entropy bonus: 4.862189292907715
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -84.93934631347656
		 value loss: 950.203369140625
		 entropy bonus: 3.0233700275421143
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.866697311401367
		 value loss: 33.461830139160156
		 entropy bonus: 0.4105263650417328
		 -----------------
	 Multi-agent batch loss: 132.84381103515625 - Differentiable computation graph = True!
PPO iteration: 5/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.0296630859375
		 value loss: 52.36260986328125
		 entropy bonus: 4.8905534744262695
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -76.75830078125
		 value loss: 788.29052734375
		 entropy bonus: 2.769108772277832
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.143539428710938
		 value loss: 29.532001495361328
		 entropy bonus: 0.3476002812385559
		 -----------------
	 Multi-agent batch loss: 119.55327606201172 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.029541015625
		 value loss: 52.36260986328125
		 entropy bonus: 4.8905487060546875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -76.75709533691406
		 value loss: 788.29052734375
		 entropy bonus: 2.769103527069092
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.139497756958008
		 value loss: 29.532001495361328
		 entropy bonus: 0.3470498323440552
		 -----------------
	 Multi-agent batch loss: 119.54791259765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.029325485229492
		 value loss: 52.36260986328125
		 entropy bonus: 4.89054012298584
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -76.75552368164062
		 value loss: 788.29052734375
		 entropy bonus: 2.769084930419922
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.134557723999023
		 value loss: 29.532001495361328
		 entropy bonus: 0.3463716506958008
		 -----------------
	 Multi-agent batch loss: 119.54119873046875 - Differentiable computation graph = True!
PPO iteration: 6/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.705615997314453
		 value loss: 54.73554992675781
		 entropy bonus: 4.803773880004883
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -82.3912353515625
		 value loss: 890.748046875
		 entropy bonus: 2.8765673637390137
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.81949234008789
		 value loss: 30.882057189941406
		 entropy bonus: 0.31125402450561523
		 -----------------
	 Multi-agent batch loss: 127.60008239746094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.705780029296875
		 value loss: 54.73554992675781
		 entropy bonus: 4.803771018981934
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -82.38533020019531
		 value loss: 890.748046875
		 entropy bonus: 2.876497268676758
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.816900253295898
		 value loss: 30.882057189941406
		 entropy bonus: 0.3107530474662781
		 -----------------
	 Multi-agent batch loss: 127.59175872802734 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.705814361572266
		 value loss: 54.73554992675781
		 entropy bonus: 4.803770065307617
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -82.37849426269531
		 value loss: 890.748046875
		 entropy bonus: 2.8764126300811768
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.814079284667969
		 value loss: 30.882057189941406
		 entropy bonus: 0.31019777059555054
		 -----------------
	 Multi-agent batch loss: 127.58213806152344 - Differentiable computation graph = True!
PPO iteration: 7/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.85158920288086
		 value loss: 42.333091735839844
		 entropy bonus: 4.890705108642578
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -67.74557495117188
		 value loss: 597.4172973632812
		 entropy bonus: 2.890717029571533
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.941844940185547
		 value loss: 22.371816635131836
		 entropy bonus: 0.38666319847106934
		 -----------------
	 Multi-agent batch loss: 105.07855224609375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.851593017578125
		 value loss: 42.333091735839844
		 entropy bonus: 4.8907060623168945
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -67.74777221679688
		 value loss: 597.4172973632812
		 entropy bonus: 2.890629768371582
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.94264030456543
		 value loss: 22.371816635131836
		 entropy bonus: 0.38616424798965454
		 -----------------
	 Multi-agent batch loss: 105.08155822753906 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.8515625
		 value loss: 42.333091735839844
		 entropy bonus: 4.8907060623168945
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -67.74789428710938
		 value loss: 597.4172973632812
		 entropy bonus: 2.8906073570251465
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.942636489868164
		 value loss: 22.371816635131836
		 entropy bonus: 0.38573798537254333
		 -----------------
	 Multi-agent batch loss: 105.08164978027344 - Differentiable computation graph = True!
PPO iteration: 8/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.602649688720703
		 value loss: 46.025997161865234
		 entropy bonus: 4.852709770202637
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.33128356933594
		 value loss: 739.3839111328125
		 entropy bonus: 2.9421932697296143
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.918220520019531
		 value loss: 26.685226440429688
		 entropy bonus: 0.5004618167877197
		 -----------------
	 Multi-agent batch loss: 115.89015197753906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.60265350341797
		 value loss: 46.025997161865234
		 entropy bonus: 4.852709770202637
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.32844543457031
		 value loss: 739.3839111328125
		 entropy bonus: 2.9422075748443604
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.914506912231445
		 value loss: 26.685226440429688
		 entropy bonus: 0.4991196393966675
		 -----------------
	 Multi-agent batch loss: 115.88362121582031 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.602643966674805
		 value loss: 46.025997161865234
		 entropy bonus: 4.852710247039795
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.32844543457031
		 value loss: 739.3839111328125
		 entropy bonus: 2.9421963691711426
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.9091796875
		 value loss: 26.685226440429688
		 entropy bonus: 0.4974544644355774
		 -----------------
	 Multi-agent batch loss: 115.8782958984375 - Differentiable computation graph = True!
PPO iteration: 9/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.278602600097656
		 value loss: 52.88157272338867
		 entropy bonus: 4.876943588256836
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -80.96422576904297
		 value loss: 930.8927001953125
		 entropy bonus: 2.948732852935791
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.744386672973633
		 value loss: 31.65298080444336
		 entropy bonus: 0.3888896405696869
		 -----------------
	 Multi-agent batch loss: 125.05934143066406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.278606414794922
		 value loss: 52.88157272338867
		 entropy bonus: 4.876943588256836
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -80.96403503417969
		 value loss: 930.8927001953125
		 entropy bonus: 2.9487204551696777
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.735159873962402
		 value loss: 31.65298080444336
		 entropy bonus: 0.3874804973602295
		 -----------------
	 Multi-agent batch loss: 125.04994201660156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.278581619262695
		 value loss: 52.88157272338867
		 entropy bonus: 4.876943111419678
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -80.96369934082031
		 value loss: 930.8927001953125
		 entropy bonus: 2.9487080574035645
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.724056243896484
		 value loss: 31.65298080444336
		 entropy bonus: 0.3858664035797119
		 -----------------
	 Multi-agent batch loss: 125.03849792480469 - Differentiable computation graph = True!
PPO iteration: 10/150:
	 start solving instance: 50...
	 start solving instance: 109...
	 start solving instance: 97...
	 start solving instance: 103...
	 start solving instance: 44...
	 start solving instance: 144...
	 start solving instance: 116...
	 start solving instance: 124...
	 start solving instance: 93...
	 start solving instance: 105...
	 start solving instance: 42...
	 start solving instance: 112...
	 start solving instance: 30...
	 start solving instance: 115...
	 start solving instance: 131...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.353710174560547
		 value loss: 48.590728759765625
		 entropy bonus: 4.801978588104248
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -77.13381958007812
		 value loss: 780.97607421875
		 entropy bonus: 2.7843801975250244
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.29375171661377
		 value loss: 28.29100227355957
		 entropy bonus: 0.2928386926651001
		 -----------------
	 Multi-agent batch loss: 119.28106689453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.35371971130371
		 value loss: 48.590728759765625
		 entropy bonus: 4.801977157592773
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -77.1314926147461
		 value loss: 780.97607421875
		 entropy bonus: 2.7844133377075195
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.289190292358398
		 value loss: 28.29100227355957
		 entropy bonus: 0.2930457890033722
		 -----------------
	 Multi-agent batch loss: 119.27418518066406 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.35372543334961
		 value loss: 48.590728759765625
		 entropy bonus: 4.801976203918457
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -77.1278076171875
		 value loss: 780.97607421875
		 entropy bonus: 2.7844815254211426
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.284513473510742
		 value loss: 28.29100227355957
		 entropy bonus: 0.29311075806617737
		 -----------------
	 Multi-agent batch loss: 119.26582336425781 - Differentiable computation graph = True!
PPO iteration: 11/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.195022583007812
		 value loss: 25.914304733276367
		 entropy bonus: 4.872432708740234
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.43909454345703
		 value loss: 305.8536682128906
		 entropy bonus: 2.471221923828125
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.9097466468811035
		 value loss: 10.033285140991211
		 entropy bonus: 0.12674503028392792
		 -----------------
	 Multi-agent batch loss: 69.88717651367188 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.194879531860352
		 value loss: 25.914304733276367
		 entropy bonus: 4.872435092926025
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.44075012207031
		 value loss: 305.8536682128906
		 entropy bonus: 2.4712700843811035
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.910579204559326
		 value loss: 10.033285140991211
		 entropy bonus: 0.1267170011997223
		 -----------------
	 Multi-agent batch loss: 69.88951873779297 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.194572448730469
		 value loss: 25.914304733276367
		 entropy bonus: 4.872440814971924
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.44161605834961
		 value loss: 305.8536682128906
		 entropy bonus: 2.471292018890381
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.911049842834473
		 value loss: 10.033285140991211
		 entropy bonus: 0.12664376199245453
		 -----------------
	 Multi-agent batch loss: 69.89054870605469 - Differentiable computation graph = True!
PPO iteration: 12/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.795870780944824
		 value loss: 31.871097564697266
		 entropy bonus: 4.9066290855407715
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -46.11505126953125
		 value loss: 354.0608215332031
		 entropy bonus: 2.6528196334838867
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.53421688079834
		 value loss: 10.292765617370605
		 entropy bonus: 0.16829900443553925
		 -----------------
	 Multi-agent batch loss: 71.33010864257812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.795980453491211
		 value loss: 31.871097564697266
		 entropy bonus: 4.9066362380981445
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -46.11296081542969
		 value loss: 354.0608215332031
		 entropy bonus: 2.6528406143188477
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.533254623413086
		 value loss: 10.292765617370605
		 entropy bonus: 0.16662421822547913
		 -----------------
	 Multi-agent batch loss: 71.32717895507812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.796060562133789
		 value loss: 31.871097564697266
		 entropy bonus: 4.906641483306885
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -46.11029052734375
		 value loss: 354.0608215332031
		 entropy bonus: 2.6528704166412354
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.531933784484863
		 value loss: 10.292765617370605
		 entropy bonus: 0.16501307487487793
		 -----------------
	 Multi-agent batch loss: 71.32328796386719 - Differentiable computation graph = True!
PPO iteration: 13/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.044811248779297
		 value loss: 28.900218963623047
		 entropy bonus: 4.912603378295898
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.38337707519531
		 value loss: 312.7355041503906
		 entropy bonus: 2.3524069786071777
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.783157825469971
		 value loss: 7.577611923217773
		 entropy bonus: 0.023005900904536247
		 -----------------
	 Multi-agent batch loss: 64.63059997558594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.044333457946777
		 value loss: 28.900218963623047
		 entropy bonus: 4.912610054016113
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.383514404296875
		 value loss: 312.7355041503906
		 entropy bonus: 2.352450370788574
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.783375263214111
		 value loss: 7.577611923217773
		 entropy bonus: 0.022965842857956886
		 -----------------
	 Multi-agent batch loss: 64.63047790527344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.043636322021484
		 value loss: 28.900218963623047
		 entropy bonus: 4.912619113922119
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.383209228515625
		 value loss: 312.7355041503906
		 entropy bonus: 2.352480173110962
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.7835612297058105
		 value loss: 7.577611923217773
		 entropy bonus: 0.022930895909667015
		 -----------------
	 Multi-agent batch loss: 64.62965393066406 - Differentiable computation graph = True!
PPO iteration: 14/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.570552825927734
		 value loss: 29.039365768432617
		 entropy bonus: 4.8861494064331055
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.936981201171875
		 value loss: 282.5228576660156
		 entropy bonus: 2.525214195251465
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.308899879455566
		 value loss: 7.671627044677734
		 entropy bonus: 0.16461989283561707
		 -----------------
	 Multi-agent batch loss: 67.93301391601562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.558683395385742
		 value loss: 29.039365768432617
		 entropy bonus: 4.885766983032227
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.93439865112305
		 value loss: 282.5228576660156
		 entropy bonus: 2.5252280235290527
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.309115409851074
		 value loss: 7.671627044677734
		 entropy bonus: 0.16464939713478088
		 -----------------
	 Multi-agent batch loss: 67.91877746582031 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.562019348144531
		 value loss: 29.039365768432617
		 entropy bonus: 4.885362148284912
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.928749084472656
		 value loss: 282.5228576660156
		 entropy bonus: 2.5252554416656494
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.309253215789795
		 value loss: 7.671627044677734
		 entropy bonus: 0.16466659307479858
		 -----------------
	 Multi-agent batch loss: 67.91661071777344 - Differentiable computation graph = True!
PPO iteration: 15/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.396718978881836
		 value loss: 30.321731567382812
		 entropy bonus: 4.910643577575684
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.76737976074219
		 value loss: 337.86767578125
		 entropy bonus: 2.460196018218994
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.233793258666992
		 value loss: 6.998480319976807
		 entropy bonus: 0.0476221889257431
		 -----------------
	 Multi-agent batch loss: 73.07559204101562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.387409210205078
		 value loss: 30.321731567382812
		 entropy bonus: 4.9108734130859375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.763633728027344
		 value loss: 337.86767578125
		 entropy bonus: 2.4602208137512207
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.233029842376709
		 value loss: 6.998480319976807
		 entropy bonus: 0.04747569188475609
		 -----------------
	 Multi-agent batch loss: 73.061767578125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.38499927520752
		 value loss: 30.321731567382812
		 entropy bonus: 4.910887718200684
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.759376525878906
		 value loss: 337.86767578125
		 entropy bonus: 2.4602394104003906
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.232102394104004
		 value loss: 6.998480319976807
		 entropy bonus: 0.04729510471224785
		 -----------------
	 Multi-agent batch loss: 73.0541763305664 - Differentiable computation graph = True!
PPO iteration: 16/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.870976448059082
		 value loss: 30.242755889892578
		 entropy bonus: 4.851429462432861
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.838253021240234
		 value loss: 319.28656005859375
		 entropy bonus: 2.5296974182128906
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.459111213684082
		 value loss: 8.611777305603027
		 entropy bonus: 0.1298159956932068
		 -----------------
	 Multi-agent batch loss: 69.67464447021484 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.870927810668945
		 value loss: 30.242755889892578
		 entropy bonus: 4.851430892944336
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.83978271484375
		 value loss: 319.28656005859375
		 entropy bonus: 2.5296475887298584
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.458975791931152
		 value loss: 8.611777305603027
		 entropy bonus: 0.12926006317138672
		 -----------------
	 Multi-agent batch loss: 69.67599487304688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.87311840057373
		 value loss: 30.242755889892578
		 entropy bonus: 4.851416110992432
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.85394287109375
		 value loss: 319.28656005859375
		 entropy bonus: 2.5298709869384766
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.458837032318115
		 value loss: 8.611777305603027
		 entropy bonus: 0.12876315414905548
		 -----------------
	 Multi-agent batch loss: 69.69220733642578 - Differentiable computation graph = True!
PPO iteration: 17/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.74438762664795
		 value loss: 22.086013793945312
		 entropy bonus: 4.907403945922852
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.75890350341797
		 value loss: 231.93896484375
		 entropy bonus: 2.6053411960601807
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.308899402618408
		 value loss: 6.964633941650391
		 entropy bonus: 0.252387136220932
		 -----------------
	 Multi-agent batch loss: 64.34443664550781 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.74779987335205
		 value loss: 22.086013793945312
		 entropy bonus: 4.907363414764404
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.75540542602539
		 value loss: 231.93896484375
		 entropy bonus: 2.6053013801574707
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.308541774749756
		 value loss: 6.964633941650391
		 entropy bonus: 0.2519669234752655
		 -----------------
	 Multi-agent batch loss: 64.343994140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.745742797851562
		 value loss: 22.086013793945312
		 entropy bonus: 4.907297134399414
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.75328063964844
		 value loss: 231.93896484375
		 entropy bonus: 2.6052305698394775
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.308159351348877
		 value loss: 6.964633941650391
		 entropy bonus: 0.2515779137611389
		 -----------------
	 Multi-agent batch loss: 64.33943939208984 - Differentiable computation graph = True!
PPO iteration: 18/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.143540382385254
		 value loss: 22.17626953125
		 entropy bonus: 4.927334785461426
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -40.25678253173828
		 value loss: 223.560302734375
		 entropy bonus: 2.534182548522949
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.783157825469971
		 value loss: 6.509601593017578
		 entropy bonus: 0.2610716223716736
		 -----------------
	 Multi-agent batch loss: 61.62871551513672 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.144896507263184
		 value loss: 22.17626953125
		 entropy bonus: 4.9272541999816895
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -40.25337600708008
		 value loss: 223.560302734375
		 entropy bonus: 2.5340328216552734
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.782224655151367
		 value loss: 6.509601593017578
		 entropy bonus: 0.26080724596977234
		 -----------------
	 Multi-agent batch loss: 61.625736236572266 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.13681697845459
		 value loss: 22.17626953125
		 entropy bonus: 4.927465438842773
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -40.239418029785156
		 value loss: 223.560302734375
		 entropy bonus: 2.5337328910827637
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.781879425048828
		 value loss: 6.509601593017578
		 entropy bonus: 0.2598292827606201
		 -----------------
	 Multi-agent batch loss: 61.60336685180664 - Differentiable computation graph = True!
PPO iteration: 19/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.345234870910645
		 value loss: 24.929027557373047
		 entropy bonus: 4.886295318603516
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.60869216918945
		 value loss: 225.22250366210938
		 entropy bonus: 2.5232222080230713
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.008475303649902
		 value loss: 5.956793308258057
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 64.44938659667969 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.346336364746094
		 value loss: 24.929027557373047
		 entropy bonus: 4.886214733123779
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.594722747802734
		 value loss: 225.22250366210938
		 entropy bonus: 2.5231149196624756
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.008475303649902
		 value loss: 5.956793308258057
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 64.4365234375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.346342086791992
		 value loss: 24.929027557373047
		 entropy bonus: 4.8862152099609375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.59757995605469
		 value loss: 225.22250366210938
		 entropy bonus: 2.522979259490967
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.008475303649902
		 value loss: 5.956793308258057
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 64.43938446044922 - Differentiable computation graph = True!
PPO iteration: 20/150:
	 start solving instance: 62...
	 start solving instance: 107...
	 start solving instance: 85...
	 start solving instance: 98...
	 start solving instance: 136...
	 start solving instance: 49...
	 start solving instance: 141...
	 start solving instance: 88...
	 start solving instance: 40...
	 start solving instance: 131...
	 start solving instance: 68...
	 start solving instance: 110...
	 start solving instance: 96...
	 start solving instance: 79...
	 start solving instance: 8...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.847354888916016
		 value loss: 33.427982330322266
		 entropy bonus: 4.875349044799805
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.88973617553711
		 value loss: 293.09014892578125
		 entropy bonus: 2.452530860900879
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.9848527908325195
		 value loss: 9.472954750061035
		 entropy bonus: 0.11950450390577316
		 -----------------
	 Multi-agent batch loss: 72.00738525390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.847135543823242
		 value loss: 33.427982330322266
		 entropy bonus: 4.8753533363342285
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.889404296875
		 value loss: 293.09014892578125
		 entropy bonus: 2.452406883239746
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.984806537628174
		 value loss: 9.472954750061035
		 entropy bonus: 0.11927884817123413
		 -----------------
	 Multi-agent batch loss: 72.00679016113281 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.848272323608398
		 value loss: 33.427982330322266
		 entropy bonus: 4.8753252029418945
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.889068603515625
		 value loss: 293.09014892578125
		 entropy bonus: 2.4522886276245117
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.984673500061035
		 value loss: 9.472954750061035
		 entropy bonus: 0.11909213662147522
		 -----------------
	 Multi-agent batch loss: 72.00745391845703 - Differentiable computation graph = True!
PPO iteration: 21/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.681991577148438
		 value loss: 53.18242645263672
		 entropy bonus: 4.895340919494629
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.02236938476562
		 value loss: 539.8760986328125
		 entropy bonus: 3.099492311477661
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.53845500946045
		 value loss: 12.910144805908203
		 entropy bonus: 0.29520443081855774
		 -----------------
	 Multi-agent batch loss: 107.21959686279297 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.677732467651367
		 value loss: 53.18242645263672
		 entropy bonus: 4.895371437072754
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.02438354492188
		 value loss: 539.8760986328125
		 entropy bonus: 3.099398136138916
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.539937973022461
		 value loss: 12.910144805908203
		 entropy bonus: 0.29508715867996216
		 -----------------
	 Multi-agent batch loss: 107.21884155273438 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.669456481933594
		 value loss: 53.18242645263672
		 entropy bonus: 4.895427227020264
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.02450561523438
		 value loss: 539.8760986328125
		 entropy bonus: 3.099242687225342
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.539754867553711
		 value loss: 12.910144805908203
		 entropy bonus: 0.29492613673210144
		 -----------------
	 Multi-agent batch loss: 107.21051025390625 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: -8.411865234375
		 value loss: 14.470795631408691
		 entropy bonus: 3.1966426372528076
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -23.05752182006836
		 value loss: 117.21420288085938
		 entropy bonus: 1.397256851196289
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.229555606842041
		 value loss: 2.6963517665863037
		 entropy bonus: 0.11205343157052994
		 -----------------
	 Multi-agent batch loss: 35.9957
PPO iteration: 22/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.330087661743164
		 value loss: 45.08209228515625
		 entropy bonus: 4.875528335571289
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -63.990264892578125
		 value loss: 441.16387939453125
		 entropy bonus: 3.138690948486328
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.562077522277832
		 value loss: 9.83021354675293
		 entropy bonus: 0.1786288022994995
		 -----------------
	 Multi-agent batch loss: 98.76126098632812 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.330244064331055
		 value loss: 45.08209228515625
		 entropy bonus: 4.875538349151611
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -63.9898567199707
		 value loss: 441.16387939453125
		 entropy bonus: 3.138607978820801
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.56147289276123
		 value loss: 9.83021354675293
		 entropy bonus: 0.17832502722740173
		 -----------------
	 Multi-agent batch loss: 98.76040649414062 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.33037567138672
		 value loss: 45.08209228515625
		 entropy bonus: 4.875546455383301
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -63.990089416503906
		 value loss: 441.16387939453125
		 entropy bonus: 3.138518810272217
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.560563087463379
		 value loss: 9.83021354675293
		 entropy bonus: 0.1779210865497589
		 -----------------
	 Multi-agent batch loss: 98.7598648071289 - Differentiable computation graph = True!
PPO iteration: 23/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.48029899597168
		 value loss: 46.69915008544922
		 entropy bonus: 4.89801025390625
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -66.01812744140625
		 value loss: 478.9693298339844
		 entropy bonus: 3.1599647998809814
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.388242721557617
		 value loss: 11.488639831542969
		 entropy bonus: 0.35734936594963074
		 -----------------
	 Multi-agent batch loss: 102.17408752441406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.480316162109375
		 value loss: 46.69915008544922
		 entropy bonus: 4.898012161254883
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -66.02095031738281
		 value loss: 478.9693298339844
		 entropy bonus: 3.1599209308624268
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.387794494628906
		 value loss: 11.488639831542969
		 entropy bonus: 0.3568347692489624
		 -----------------
	 Multi-agent batch loss: 102.17648315429688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.480331420898438
		 value loss: 46.69915008544922
		 entropy bonus: 4.898013114929199
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -66.01869201660156
		 value loss: 478.9693298339844
		 entropy bonus: 3.159898519515991
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.387199401855469
		 value loss: 11.488639831542969
		 entropy bonus: 0.35628020763397217
		 -----------------
	 Multi-agent batch loss: 102.17365264892578 - Differentiable computation graph = True!
PPO iteration: 24/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.104768753051758
		 value loss: 46.16138458251953
		 entropy bonus: 4.862321376800537
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.51600646972656
		 value loss: 460.79803466796875
		 entropy bonus: 3.160684108734131
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.162925720214844
		 value loss: 11.168988227844238
		 entropy bonus: 0.2795916497707367
		 -----------------
	 Multi-agent batch loss: 99.8819580078125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.104598999023438
		 value loss: 46.16138458251953
		 entropy bonus: 4.862322807312012
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.51451873779297
		 value loss: 460.79803466796875
		 entropy bonus: 3.160627841949463
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.163785934448242
		 value loss: 11.168988227844238
		 entropy bonus: 0.27926579117774963
		 -----------------
	 Multi-agent batch loss: 99.88116455078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.104412078857422
		 value loss: 46.16138458251953
		 entropy bonus: 4.8623247146606445
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.50822448730469
		 value loss: 460.79803466796875
		 entropy bonus: 3.1605987548828125
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.16352367401123
		 value loss: 11.168988227844238
		 entropy bonus: 0.27937257289886475
		 -----------------
	 Multi-agent batch loss: 99.87442016601562 - Differentiable computation graph = True!
PPO iteration: 25/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.804344177246094
		 value loss: 46.05608367919922
		 entropy bonus: 4.8721818923950195
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.93878936767578
		 value loss: 463.9908447265625
		 entropy bonus: 3.1928153038024902
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.31313705444336
		 value loss: 12.199392318725586
		 entropy bonus: 0.10859128087759018
		 -----------------
	 Multi-agent batch loss: 98.1969985961914 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.804344177246094
		 value loss: 46.05608367919922
		 entropy bonus: 4.8721818923950195
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.93810272216797
		 value loss: 463.9908447265625
		 entropy bonus: 3.19271183013916
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.312837600708008
		 value loss: 12.199392318725586
		 entropy bonus: 0.10875638574361801
		 -----------------
	 Multi-agent batch loss: 98.19601440429688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.804344177246094
		 value loss: 46.05608367919922
		 entropy bonus: 4.8721818923950195
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.93730163574219
		 value loss: 463.9908447265625
		 entropy bonus: 3.1926255226135254
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.312477111816406
		 value loss: 12.199392318725586
		 entropy bonus: 0.1089368537068367
		 -----------------
	 Multi-agent batch loss: 98.1948471069336 - Differentiable computation graph = True!
PPO iteration: 26/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.179874420166016
		 value loss: 48.955509185791016
		 entropy bonus: 4.883547782897949
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.34217834472656
		 value loss: 529.9066772460938
		 entropy bonus: 2.975046396255493
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.688667297363281
		 value loss: 14.482075691223145
		 entropy bonus: 0.2732044458389282
		 -----------------
	 Multi-agent batch loss: 102.06285095214844 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.179920196533203
		 value loss: 48.955509185791016
		 entropy bonus: 4.883549213409424
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.33848571777344
		 value loss: 529.9066772460938
		 entropy bonus: 2.9748764038085938
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.688204765319824
		 value loss: 14.482075691223145
		 entropy bonus: 0.27331259846687317
		 -----------------
	 Multi-agent batch loss: 102.05873107910156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.179956436157227
		 value loss: 48.955509185791016
		 entropy bonus: 4.883550643920898
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.33381652832031
		 value loss: 529.9066772460938
		 entropy bonus: 2.97464656829834
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.6864013671875
		 value loss: 14.482075691223145
		 entropy bonus: 0.2731969654560089
		 -----------------
	 Multi-agent batch loss: 102.05229949951172 - Differentiable computation graph = True!
PPO iteration: 27/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.405193328857422
		 value loss: 50.25291442871094
		 entropy bonus: 4.870815753936768
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -63.31431579589844
		 value loss: 468.21405029296875
		 entropy bonus: 3.1026482582092285
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.31313705444336
		 value loss: 13.116978645324707
		 entropy bonus: 0.31196099519729614
		 -----------------
	 Multi-agent batch loss: 99.26563262939453 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.40522003173828
		 value loss: 50.25291442871094
		 entropy bonus: 4.870816230773926
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -63.313926696777344
		 value loss: 468.21405029296875
		 entropy bonus: 3.1023383140563965
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.312734603881836
		 value loss: 13.116978645324707
		 entropy bonus: 0.31137728691101074
		 -----------------
	 Multi-agent batch loss: 99.26487731933594 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.405223846435547
		 value loss: 50.25291442871094
		 entropy bonus: 4.870816230773926
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -63.31293869018555
		 value loss: 468.21405029296875
		 entropy bonus: 3.10202693939209
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.312055587768555
		 value loss: 13.116978645324707
		 entropy bonus: 0.3108815848827362
		 -----------------
	 Multi-agent batch loss: 99.26321411132812 - Differentiable computation graph = True!
PPO iteration: 28/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.254981994628906
		 value loss: 47.02632141113281
		 entropy bonus: 4.8906569480896
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.938785552978516
		 value loss: 448.5572814941406
		 entropy bonus: 3.181377410888672
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.712289810180664
		 value loss: 10.589855194091797
		 entropy bonus: 0.27399078011512756
		 -----------------
	 Multi-agent batch loss: 97.88433837890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.254913330078125
		 value loss: 47.02632141113281
		 entropy bonus: 4.890657424926758
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.939666748046875
		 value loss: 448.5572814941406
		 entropy bonus: 3.1812000274658203
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.712017059326172
		 value loss: 10.589855194091797
		 entropy bonus: 0.2741217613220215
		 -----------------
	 Multi-agent batch loss: 97.88487243652344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.25474739074707
		 value loss: 47.02632141113281
		 entropy bonus: 4.890658855438232
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.940128326416016
		 value loss: 448.5572814941406
		 entropy bonus: 3.1810522079467773
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.71158218383789
		 value loss: 10.589855194091797
		 entropy bonus: 0.2741914689540863
		 -----------------
	 Multi-agent batch loss: 97.8847427368164 - Differentiable computation graph = True!
PPO iteration: 29/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.555404663085938
		 value loss: 50.93734359741211
		 entropy bonus: 4.892737865447998
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.19197082519531
		 value loss: 503.349365234375
		 entropy bonus: 3.052529811859131
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.862502098083496
		 value loss: 11.018563270568848
		 entropy bonus: 0.08617287874221802
		 -----------------
	 Multi-agent batch loss: 101.1826171875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.555355072021484
		 value loss: 50.93734359741211
		 entropy bonus: 4.892738342285156
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.19491577148438
		 value loss: 503.349365234375
		 entropy bonus: 3.0525293350219727
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.862420082092285
		 value loss: 11.018563270568848
		 entropy bonus: 0.0863025039434433
		 -----------------
	 Multi-agent batch loss: 101.1854248046875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.55530548095703
		 value loss: 50.93734359741211
		 entropy bonus: 4.892739295959473
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.19266510009766
		 value loss: 503.349365234375
		 entropy bonus: 3.0526163578033447
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.862323760986328
		 value loss: 11.018563270568848
		 entropy bonus: 0.08645428717136383
		 -----------------
	 Multi-agent batch loss: 101.18302917480469 - Differentiable computation graph = True!
PPO iteration: 30/150:
	 start solving instance: 45...
	 start solving instance: 43...
	 start solving instance: 90...
	 start solving instance: 32...
	 start solving instance: 78...
	 start solving instance: 111...
	 start solving instance: 23...
	 start solving instance: 140...
	 start solving instance: 50...
	 start solving instance: 67...
	 start solving instance: 121...
	 start solving instance: 61...
	 start solving instance: 147...
	 start solving instance: 145...
	 start solving instance: 86...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.353710174560547
		 value loss: 45.25131607055664
		 entropy bonus: 4.877249717712402
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.7413330078125
		 value loss: 493.41387939453125
		 entropy bonus: 3.0635151863098145
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.937606811523438
		 value loss: 11.180269241333008
		 entropy bonus: 0.15499372780323029
		 -----------------
	 Multi-agent batch loss: 99.45014953613281 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.35376739501953
		 value loss: 45.25131607055664
		 entropy bonus: 4.877251148223877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.74081420898438
		 value loss: 493.41387939453125
		 entropy bonus: 3.0636940002441406
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.937612533569336
		 value loss: 11.180269241333008
		 entropy bonus: 0.15519678592681885
		 -----------------
	 Multi-agent batch loss: 99.44967651367188 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.353809356689453
		 value loss: 45.25131607055664
		 entropy bonus: 4.877252578735352
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.74020385742188
		 value loss: 493.41387939453125
		 entropy bonus: 3.06386661529541
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.937585830688477
		 value loss: 11.180269241333008
		 entropy bonus: 0.1554376631975174
		 -----------------
	 Multi-agent batch loss: 99.44908142089844 - Differentiable computation graph = True!
PPO iteration: 31/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.804344177246094
		 value loss: 49.92198181152344
		 entropy bonus: 4.74570369720459
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -73.37852478027344
		 value loss: 766.4976806640625
		 entropy bonus: 2.8616600036621094
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.692904472351074
		 value loss: 28.892698287963867
		 entropy bonus: 0.2673457860946655
		 -----------------
	 Multi-agent batch loss: 115.25015258789062 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.804203033447266
		 value loss: 49.92198181152344
		 entropy bonus: 4.745704650878906
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -73.37770080566406
		 value loss: 766.4976806640625
		 entropy bonus: 2.861804723739624
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.69236946105957
		 value loss: 28.892698287963867
		 entropy bonus: 0.26737770438194275
		 -----------------
	 Multi-agent batch loss: 115.24864959716797 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.804000854492188
		 value loss: 49.92198181152344
		 entropy bonus: 4.745705604553223
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -73.3755874633789
		 value loss: 766.4976806640625
		 entropy bonus: 2.861936092376709
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.69162368774414
		 value loss: 28.892698287963867
		 entropy bonus: 0.26737913489341736
		 -----------------
	 Multi-agent batch loss: 115.24559020996094 - Differentiable computation graph = True!
PPO iteration: 32/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.85582733154297
		 value loss: 54.47230911254883
		 entropy bonus: 4.768187522888184
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -74.35490417480469
		 value loss: 722.40478515625
		 entropy bonus: 2.963341236114502
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.265890121459961
		 value loss: 21.18722915649414
		 entropy bonus: 0.14087873697280884
		 -----------------
	 Multi-agent batch loss: 115.3785400390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.85533332824707
		 value loss: 54.47230911254883
		 entropy bonus: 4.768190860748291
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -74.35441589355469
		 value loss: 722.40478515625
		 entropy bonus: 2.963383197784424
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.266149520874023
		 value loss: 21.18722915649414
		 entropy bonus: 0.14100131392478943
		 -----------------
	 Multi-agent batch loss: 115.37781524658203 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.8547306060791
		 value loss: 54.47230911254883
		 entropy bonus: 4.768194675445557
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -74.3533935546875
		 value loss: 722.40478515625
		 entropy bonus: 2.9633872509002686
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.266313552856445
		 value loss: 21.18722915649414
		 entropy bonus: 0.14111045002937317
		 -----------------
	 Multi-agent batch loss: 115.37635040283203 - Differentiable computation graph = True!
PPO iteration: 33/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.907310485839844
		 value loss: 60.241065979003906
		 entropy bonus: 4.796605110168457
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -77.6595687866211
		 value loss: 809.3048706054688
		 entropy bonus: 2.8778867721557617
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.941844940185547
		 value loss: 23.138980865478516
		 entropy bonus: 0.22625797986984253
		 -----------------
	 Multi-agent batch loss: 121.3565673828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.907915115356445
		 value loss: 60.241065979003906
		 entropy bonus: 4.796606063842773
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -77.65900421142578
		 value loss: 809.3048706054688
		 entropy bonus: 2.8778560161590576
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.941241264343262
		 value loss: 23.138980865478516
		 entropy bonus: 0.22644680738449097
		 -----------------
	 Multi-agent batch loss: 121.35600280761719 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.907833099365234
		 value loss: 60.241065979003906
		 entropy bonus: 4.796605587005615
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -77.65813446044922
		 value loss: 809.3048706054688
		 entropy bonus: 2.8778188228607178
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.940420150756836
		 value loss: 23.138980865478516
		 entropy bonus: 0.22671622037887573
		 -----------------
	 Multi-agent batch loss: 121.3542251586914 - Differentiable computation graph = True!
PPO iteration: 34/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.808582305908203
		 value loss: 61.940860748291016
		 entropy bonus: 4.74826192855835
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -74.73043823242188
		 value loss: 722.7169189453125
		 entropy bonus: 2.9244375228881836
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.96546745300293
		 value loss: 17.276203155517578
		 entropy bonus: 0.2500813603401184
		 -----------------
	 Multi-agent batch loss: 117.4446029663086 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.80872344970703
		 value loss: 61.940860748291016
		 entropy bonus: 4.748261451721191
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -74.72969055175781
		 value loss: 722.7169189453125
		 entropy bonus: 2.9244236946105957
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.96324348449707
		 value loss: 17.276203155517578
		 entropy bonus: 0.2503811717033386
		 -----------------
	 Multi-agent batch loss: 117.4417724609375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.808767318725586
		 value loss: 61.940860748291016
		 entropy bonus: 4.748261451721191
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -74.72854614257812
		 value loss: 722.7169189453125
		 entropy bonus: 2.92443585395813
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.960336685180664
		 value loss: 17.276203155517578
		 entropy bonus: 0.2507648468017578
		 -----------------
	 Multi-agent batch loss: 117.43775939941406 - Differentiable computation graph = True!
PPO iteration: 35/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.156251907348633
		 value loss: 55.99159240722656
		 entropy bonus: 4.762059211730957
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -73.52873229980469
		 value loss: 714.4886474609375
		 entropy bonus: 2.914252758026123
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.641420364379883
		 value loss: 21.92054557800293
		 entropy bonus: 0.14723332226276398
		 -----------------
	 Multi-agent batch loss: 115.17218017578125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.15599822998047
		 value loss: 55.99159240722656
		 entropy bonus: 4.762060642242432
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -73.52847290039062
		 value loss: 714.4886474609375
		 entropy bonus: 2.91424298286438
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.637725830078125
		 value loss: 21.92054557800293
		 entropy bonus: 0.14773498475551605
		 -----------------
	 Multi-agent batch loss: 115.16796875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.15558624267578
		 value loss: 55.99159240722656
		 entropy bonus: 4.762062072753906
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -73.52787780761719
		 value loss: 714.4886474609375
		 entropy bonus: 2.914205551147461
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.633462905883789
		 value loss: 21.92054557800293
		 entropy bonus: 0.14832475781440735
		 -----------------
	 Multi-agent batch loss: 115.16268920898438 - Differentiable computation graph = True!
PPO iteration: 36/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.05752182006836
		 value loss: 59.87253189086914
		 entropy bonus: 4.802514553070068
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -78.78614807128906
		 value loss: 795.4093017578125
		 entropy bonus: 3.0931143760681152
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.317375183105469
		 value loss: 23.827171325683594
		 entropy bonus: 0.18617799878120422
		 -----------------
	 Multi-agent batch loss: 122.87132263183594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.057422637939453
		 value loss: 59.87253189086914
		 entropy bonus: 4.802515983581543
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -78.78536987304688
		 value loss: 795.4093017578125
		 entropy bonus: 3.0931217670440674
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.312639236450195
		 value loss: 23.827171325683594
		 entropy bonus: 0.185936838388443
		 -----------------
	 Multi-agent batch loss: 122.86570739746094 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.057323455810547
		 value loss: 59.87253189086914
		 entropy bonus: 4.802516937255859
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -78.78350067138672
		 value loss: 795.4093017578125
		 entropy bonus: 3.093193531036377
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -12.307622909545898
		 value loss: 23.827171325683594
		 entropy bonus: 0.18563124537467957
		 -----------------
	 Multi-agent batch loss: 122.85872650146484 - Differentiable computation graph = True!
PPO iteration: 37/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.93093490600586
		 value loss: 55.88253402709961
		 entropy bonus: 4.743584156036377
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -72.852783203125
		 value loss: 758.3560791015625
		 entropy bonus: 3.0594887733459473
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.491209030151367
		 value loss: 24.605613708496094
		 entropy bonus: 0.10604911297559738
		 -----------------
	 Multi-agent batch loss: 114.58427429199219 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.930404663085938
		 value loss: 55.88253402709961
		 entropy bonus: 4.743584632873535
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -72.89696502685547
		 value loss: 758.3560791015625
		 entropy bonus: 3.0595149993896484
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.48409652709961
		 value loss: 24.605613708496094
		 entropy bonus: 0.10408270359039307
		 -----------------
	 Multi-agent batch loss: 114.62083435058594 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.92995834350586
		 value loss: 55.88253402709961
		 entropy bonus: 4.743585586547852
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -72.84754943847656
		 value loss: 758.3560791015625
		 entropy bonus: 3.0600781440734863
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.471220970153809
		 value loss: 24.605613708496094
		 entropy bonus: 0.11035741120576859
		 -----------------
	 Multi-agent batch loss: 114.55802917480469 - Differentiable computation graph = True!
PPO iteration: 38/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.081146240234375
		 value loss: 53.167381286621094
		 entropy bonus: 4.745492935180664
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.92364501953125
		 value loss: 636.7041625976562
		 entropy bonus: 2.9558722972869873
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.890361785888672
		 value loss: 20.829971313476562
		 entropy bonus: 0.3220095634460449
		 -----------------
	 Multi-agent batch loss: 109.92193603515625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.078704833984375
		 value loss: 53.167381286621094
		 entropy bonus: 4.745491027832031
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.8847427368164
		 value loss: 636.7041625976562
		 entropy bonus: 2.9559309482574463
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.909795761108398
		 value loss: 20.829971313476562
		 entropy bonus: 0.32018035650253296
		 -----------------
	 Multi-agent batch loss: 109.9000473022461 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.07493019104004
		 value loss: 53.167381286621094
		 entropy bonus: 4.745480060577393
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.87069702148438
		 value loss: 636.7041625976562
		 entropy bonus: 2.956064462661743
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.89312744140625
		 value loss: 20.829971313476562
		 entropy bonus: 0.32195866107940674
		 -----------------
	 Multi-agent batch loss: 109.86553192138672 - Differentiable computation graph = True!
PPO iteration: 39/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.987079620361328
		 value loss: 46.2215690612793
		 entropy bonus: 4.701527118682861
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.17001342773438
		 value loss: 583.839599609375
		 entropy bonus: 2.821328639984131
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.653070449829102
		 value loss: 19.584285736083984
		 entropy bonus: 0.0936228409409523
		 -----------------
	 Multi-agent batch loss: 102.23045349121094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.985851287841797
		 value loss: 46.2215690612793
		 entropy bonus: 4.701495170593262
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.16879272460938
		 value loss: 583.839599609375
		 entropy bonus: 2.821326732635498
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.654254913330078
		 value loss: 19.584285736083984
		 entropy bonus: 0.09387555718421936
		 -----------------
	 Multi-agent batch loss: 102.22918701171875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.98699378967285
		 value loss: 46.2215690612793
		 entropy bonus: 4.7014594078063965
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.14820861816406
		 value loss: 583.839599609375
		 entropy bonus: 2.8212790489196777
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.65516185760498
		 value loss: 19.584285736083984
		 entropy bonus: 0.09406319260597229
		 -----------------
	 Multi-agent batch loss: 102.21064758300781 - Differentiable computation graph = True!
PPO iteration: 40/150:
	 start solving instance: 122...
	 start solving instance: 47...
	 start solving instance: 128...
	 start solving instance: 124...
	 start solving instance: 128...
	 start solving instance: 144...
	 start solving instance: 18...
	 start solving instance: 41...
	 start solving instance: 123...
	 start solving instance: 134...
	 start solving instance: 122...
	 start solving instance: 23...
	 start solving instance: 60...
	 start solving instance: 36...
	 start solving instance: 96...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.836669921875
		 value loss: 27.649219512939453
		 entropy bonus: 4.759716987609863
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -52.834442138671875
		 value loss: 359.6443786621094
		 entropy bonus: 2.8599538803100586
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.193538665771484
		 value loss: 10.861621856689453
		 entropy bonus: 0.11797069013118744
		 -----------------
	 Multi-agent batch loss: 80.76882934570312 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.808074951171875
		 value loss: 27.649219512939453
		 entropy bonus: 4.759487152099609
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -52.8184814453125
		 value loss: 359.6443786621094
		 entropy bonus: 2.8593733310699463
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.187728881835938
		 value loss: 10.861621856689453
		 entropy bonus: 0.11826414614915848
		 -----------------
	 Multi-agent batch loss: 80.71846771240234 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.85903549194336
		 value loss: 27.649219512939453
		 entropy bonus: 4.759317398071289
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -52.799659729003906
		 value loss: 359.6443786621094
		 entropy bonus: 2.8603315353393555
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.18619155883789
		 value loss: 10.861621856689453
		 entropy bonus: 0.11870823800563812
		 -----------------
	 Multi-agent batch loss: 80.74905395507812 - Differentiable computation graph = True!
PPO iteration: 41/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.432741165161133
		 value loss: 56.21442413330078
		 entropy bonus: 4.818177223205566
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -80.86932373046875
		 value loss: 776.7186279296875
		 entropy bonus: 2.970796585083008
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.181831359863281
		 value loss: 23.969501495361328
		 entropy bonus: 0.6783769726753235
		 -----------------
	 Multi-agent batch loss: 124.96824645996094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.589670181274414
		 value loss: 56.21442413330078
		 entropy bonus: 4.816908836364746
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -80.79573059082031
		 value loss: 776.7186279296875
		 entropy bonus: 2.966458797454834
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.207221984863281
		 value loss: 23.969501495361328
		 entropy bonus: 0.6645680069923401
		 -----------------
	 Multi-agent batch loss: 125.0771713256836 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -22.403467178344727
		 value loss: 56.21442413330078
		 entropy bonus: 4.818192481994629
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -80.89932250976562
		 value loss: 776.7186279296875
		 entropy bonus: 2.9694695472717285
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -13.190299987792969
		 value loss: 23.969501495361328
		 entropy bonus: 0.6690355539321899
		 -----------------
	 Multi-agent batch loss: 124.97755432128906 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: -9.993487358093262
		 value loss: 20.41224479675293
		 entropy bonus: 3.1721677780151367
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -27.57818603515625
		 value loss: 145.84664916992188
		 entropy bonus: 1.467490792274475
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.131922721862793
		 value loss: 3.7241878509521484
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: 43.3570
PPO iteration: 42/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -31.229652404785156
		 value loss: 112.83985137939453
		 entropy bonus: 4.781750202178955
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -112.33068084716797
		 value loss: 1650.7274169921875
		 entropy bonus: 2.8906941413879395
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -18.737789154052734
		 value loss: 49.941062927246094
		 entropy bonus: 0.6226620674133301
		 -----------------
	 Multi-agent batch loss: 180.35025024414062 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -31.23751449584961
		 value loss: 112.83985137939453
		 entropy bonus: 4.781336307525635
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -112.30867004394531
		 value loss: 1650.7274169921875
		 entropy bonus: 2.890777587890625
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -18.721073150634766
		 value loss: 49.941062927246094
		 entropy bonus: 0.6172547936439514
		 -----------------
	 Multi-agent batch loss: 180.3194580078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -31.257226943969727
		 value loss: 112.83985137939453
		 entropy bonus: 4.78129243850708
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -112.24297332763672
		 value loss: 1650.7274169921875
		 entropy bonus: 2.891268253326416
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -18.6860294342041
		 value loss: 49.941062927246094
		 entropy bonus: 0.6119064092636108
		 -----------------
	 Multi-agent batch loss: 180.23846435546875 - Differentiable computation graph = True!
PPO iteration: 43/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -31.93118667602539
		 value loss: 115.45518493652344
		 entropy bonus: 4.793346405029297
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -105.99623107910156
		 value loss: 1379.890625
		 entropy bonus: 2.9549899101257324
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -19.47354507446289
		 value loss: 53.38077163696289
		 entropy bonus: 0.6140628457069397
		 -----------------
	 Multi-agent batch loss: 172.8046112060547 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -31.958847045898438
		 value loss: 115.45518493652344
		 entropy bonus: 4.79313325881958
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -105.97759246826172
		 value loss: 1379.890625
		 entropy bonus: 2.955429792404175
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -19.435914993286133
		 value loss: 53.38077163696289
		 entropy bonus: 0.6155951023101807
		 -----------------
	 Multi-agent batch loss: 172.77597045898438 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -31.92181396484375
		 value loss: 115.45518493652344
		 entropy bonus: 4.793312072753906
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -105.92790985107422
		 value loss: 1379.890625
		 entropy bonus: 2.956221580505371
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -19.44251823425293
		 value loss: 53.38077163696289
		 entropy bonus: 0.6180989742279053
		 -----------------
	 Multi-agent batch loss: 172.69583129882812 - Differentiable computation graph = True!
PPO iteration: 44/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -29.525333404541016
		 value loss: 110.9474868774414
		 entropy bonus: 4.800858497619629
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -99.22892761230469
		 value loss: 1402.47265625
		 entropy bonus: 2.874690532684326
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.9107608795166
		 value loss: 45.393375396728516
		 entropy bonus: 0.403878390789032
		 -----------------
	 Multi-agent batch loss: 161.17236328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -29.5678768157959
		 value loss: 110.9474868774414
		 entropy bonus: 4.801665306091309
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -99.25358581542969
		 value loss: 1402.47265625
		 entropy bonus: 2.8747639656066895
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.902599334716797
		 value loss: 45.393375396728516
		 entropy bonus: 0.4047524929046631
		 -----------------
	 Multi-agent batch loss: 161.23138427734375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -29.543067932128906
		 value loss: 110.9474868774414
		 entropy bonus: 4.801814556121826
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -99.28443145751953
		 value loss: 1402.47265625
		 entropy bonus: 2.875070571899414
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.888427734375
		 value loss: 45.393375396728516
		 entropy bonus: 0.40597105026245117
		 -----------------
	 Multi-agent batch loss: 161.22323608398438 - Differentiable computation graph = True!
PPO iteration: 45/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -36.224464416503906
		 value loss: 150.54751586914062
		 entropy bonus: 4.7938995361328125
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -133.87692260742188
		 value loss: 2271.427978515625
		 entropy bonus: 2.9207208156585693
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -23.364044189453125
		 value loss: 77.0843505859375
		 entropy bonus: 0.5903211236000061
		 -----------------
	 Multi-agent batch loss: 218.37298583984375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -36.22709274291992
		 value loss: 150.54751586914062
		 entropy bonus: 4.79387092590332
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -133.87698364257812
		 value loss: 2271.427978515625
		 entropy bonus: 2.920989751815796
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -23.352933883666992
		 value loss: 77.0843505859375
		 entropy bonus: 0.5906995534896851
		 -----------------
	 Multi-agent batch loss: 218.36456298828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -36.24192810058594
		 value loss: 150.54751586914062
		 entropy bonus: 4.793961524963379
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -133.96072387695312
		 value loss: 2271.427978515625
		 entropy bonus: 2.9210872650146484
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -23.375080108642578
		 value loss: 77.0843505859375
		 entropy bonus: 0.5899664163589478
		 -----------------
	 Multi-agent batch loss: 218.48529052734375 - Differentiable computation graph = True!
PPO iteration: 46/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -24.617158889770508
		 value loss: 72.82481384277344
		 entropy bonus: 4.796045303344727
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -83.35545349121094
		 value loss: 982.75390625
		 entropy bonus: 2.7680625915527344
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -15.104696273803711
		 value loss: 35.9686279296875
		 entropy bonus: 0.5850593447685242
		 -----------------
	 Multi-agent batch loss: 133.91128540039062 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -24.61686897277832
		 value loss: 72.82481384277344
		 entropy bonus: 4.796067714691162
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -83.3598861694336
		 value loss: 982.75390625
		 entropy bonus: 2.768065929412842
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -15.097094535827637
		 value loss: 35.9686279296875
		 entropy bonus: 0.5814605355262756
		 -----------------
	 Multi-agent batch loss: 133.90786743164062 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -24.616527557373047
		 value loss: 72.82481384277344
		 entropy bonus: 4.796083927154541
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -83.37274169921875
		 value loss: 982.75390625
		 entropy bonus: 2.768049955368042
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -15.075135231018066
		 value loss: 35.9686279296875
		 entropy bonus: 0.5775383710861206
		 -----------------
	 Multi-agent batch loss: 133.89846801757812 - Differentiable computation graph = True!
PPO iteration: 47/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -25.45620346069336
		 value loss: 74.90200805664062
		 entropy bonus: 4.798553466796875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -88.72087097167969
		 value loss: 1018.1469116210938
		 entropy bonus: 2.9109463691711426
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.43364715576172
		 value loss: 39.25852966308594
		 entropy bonus: 0.5022355318069458
		 -----------------
	 Multi-agent batch loss: 141.8516845703125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -25.45620346069336
		 value loss: 74.90200805664062
		 entropy bonus: 4.798553466796875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -88.71961975097656
		 value loss: 1018.1469116210938
		 entropy bonus: 2.9109582901000977
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.445451736450195
		 value loss: 39.25852966308594
		 entropy bonus: 0.49852967262268066
		 -----------------
	 Multi-agent batch loss: 141.86227416992188 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -25.45620346069336
		 value loss: 74.90200805664062
		 entropy bonus: 4.798553466796875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -88.71782684326172
		 value loss: 1018.1469116210938
		 entropy bonus: 2.910978317260742
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.441831588745117
		 value loss: 39.25852966308594
		 entropy bonus: 0.49745866656303406
		 -----------------
	 Multi-agent batch loss: 141.85687255859375 - Differentiable computation graph = True!
PPO iteration: 48/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -25.2579402923584
		 value loss: 78.61375427246094
		 entropy bonus: 4.75863790512085
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -91.34480285644531
		 value loss: 1176.3822021484375
		 entropy bonus: 2.8089828491210938
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.48055648803711
		 value loss: 44.21889877319336
		 entropy bonus: 0.3189074993133545
		 -----------------
	 Multi-agent batch loss: 145.99658203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -25.257946014404297
		 value loss: 78.61375427246094
		 entropy bonus: 4.75863790512085
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -91.33434295654297
		 value loss: 1176.3822021484375
		 entropy bonus: 2.8088297843933105
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.478803634643555
		 value loss: 44.21889877319336
		 entropy bonus: 0.31880462169647217
		 -----------------
	 Multi-agent batch loss: 145.984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -25.257427215576172
		 value loss: 78.61375427246094
		 entropy bonus: 4.758654594421387
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -91.38175201416016
		 value loss: 1176.3822021484375
		 entropy bonus: 2.8090245723724365
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -16.482885360717773
		 value loss: 44.21889877319336
		 entropy bonus: 0.31712794303894043
		 -----------------
	 Multi-agent batch loss: 146.03536987304688 - Differentiable computation graph = True!
PPO iteration: 49/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.487415313720703
		 value loss: 69.34054565429688
		 entropy bonus: 4.784386157989502
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -78.25839233398438
		 value loss: 863.7899780273438
		 entropy bonus: 2.905942440032959
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.421131134033203
		 value loss: 31.473285675048828
		 entropy bonus: 0.4983724355697632
		 -----------------
	 Multi-agent batch loss: 125.73109436035156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.487415313720703
		 value loss: 69.34054565429688
		 entropy bonus: 4.784386157989502
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -78.25030517578125
		 value loss: 863.7899780273438
		 entropy bonus: 2.905792236328125
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.408403396606445
		 value loss: 31.473285675048828
		 entropy bonus: 0.49551233649253845
		 -----------------
	 Multi-agent batch loss: 125.7103042602539 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -23.487415313720703
		 value loss: 69.34054565429688
		 entropy bonus: 4.784386157989502
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -78.18983459472656
		 value loss: 863.7899780273438
		 entropy bonus: 2.9053468704223633
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -14.409488677978516
		 value loss: 31.473285675048828
		 entropy bonus: 0.49450623989105225
		 -----------------
	 Multi-agent batch loss: 125.65093994140625 - Differentiable computation graph = True!
PPO iteration: 50/150:
	 start solving instance: 85...
	 start solving instance: 121...
	 start solving instance: 51...
	 start solving instance: 36...
	 start solving instance: 46...
	 start solving instance: 91...
	 start solving instance: 80...
	 start solving instance: 55...
	 start solving instance: 120...
	 start solving instance: 108...
	 start solving instance: 137...
	 start solving instance: 62...
	 start solving instance: 147...
	 start solving instance: 22...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -28.272354125976562
		 value loss: 97.861328125
		 entropy bonus: 4.793529033660889
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -103.97747039794922
		 value loss: 1517.19482421875
		 entropy bonus: 2.992361545562744
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -18.532062530517578
		 value loss: 53.09025573730469
		 entropy bonus: 0.5044386982917786
		 -----------------
	 Multi-agent batch loss: 167.3804473876953 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -28.272354125976562
		 value loss: 97.861328125
		 entropy bonus: 4.793529033660889
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -103.98930358886719
		 value loss: 1517.19482421875
		 entropy bonus: 2.9922237396240234
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -18.52219009399414
		 value loss: 53.09025573730469
		 entropy bonus: 0.5038320422172546
		 -----------------
	 Multi-agent batch loss: 167.38241577148438 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -28.272354125976562
		 value loss: 97.861328125
		 entropy bonus: 4.793529033660889
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -104.0035171508789
		 value loss: 1517.19482421875
		 entropy bonus: 2.9921207427978516
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -18.520328521728516
		 value loss: 53.09025573730469
		 entropy bonus: 0.5045372843742371
		 -----------------
	 Multi-agent batch loss: 167.39476013183594 - Differentiable computation graph = True!
PPO iteration: 51/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.840368270874023
		 value loss: 55.239013671875
		 entropy bonus: 4.814507007598877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.84050750732422
		 value loss: 746.8838500976562
		 entropy bonus: 2.8934664726257324
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.348946571350098
		 value loss: 21.35204315185547
		 entropy bonus: 0.2672702670097351
		 -----------------
	 Multi-agent batch loss: 108.184814453125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.840368270874023
		 value loss: 55.239013671875
		 entropy bonus: 4.814507007598877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.86153411865234
		 value loss: 746.8838500976562
		 entropy bonus: 2.8932406902313232
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.343941688537598
		 value loss: 21.35204315185547
		 entropy bonus: 0.2678292989730835
		 -----------------
	 Multi-agent batch loss: 108.20083618164062 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.840368270874023
		 value loss: 55.239013671875
		 entropy bonus: 4.814507007598877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -69.8547592163086
		 value loss: 746.8838500976562
		 entropy bonus: 2.8930959701538086
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.335811614990234
		 value loss: 21.35204315185547
		 entropy bonus: 0.2689617872238159
		 -----------------
	 Multi-agent batch loss: 108.18592834472656 - Differentiable computation graph = True!
PPO iteration: 52/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.771772384643555
		 value loss: 51.302650451660156
		 entropy bonus: 4.843542575836182
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.08119201660156
		 value loss: 628.9052734375
		 entropy bonus: 2.8152143955230713
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.826652526855469
		 value loss: 19.080402374267578
		 entropy bonus: 0.21716751158237457
		 -----------------
	 Multi-agent batch loss: 100.59374237060547 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.772605895996094
		 value loss: 51.302650451660156
		 entropy bonus: 4.843541622161865
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.08306884765625
		 value loss: 628.9052734375
		 entropy bonus: 2.815034866333008
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.827950477600098
		 value loss: 19.080402374267578
		 entropy bonus: 0.21803897619247437
		 -----------------
	 Multi-agent batch loss: 100.59774780273438 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.775371551513672
		 value loss: 51.302650451660156
		 entropy bonus: 4.843541145324707
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.0801773071289
		 value loss: 628.9052734375
		 entropy bonus: 2.8149213790893555
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.828761100769043
		 value loss: 19.080402374267578
		 entropy bonus: 0.2187349796295166
		 -----------------
	 Multi-agent batch loss: 100.59841918945312 - Differentiable computation graph = True!
PPO iteration: 53/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.058412551879883
		 value loss: 58.32867431640625
		 entropy bonus: 4.8685503005981445
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -70.79902648925781
		 value loss: 1005.2894287109375
		 entropy bonus: 2.6535229682922363
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.965742111206055
		 value loss: 29.094440460205078
		 entropy bonus: 0.130021333694458
		 -----------------
	 Multi-agent batch loss: 111.67378234863281 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.05846405029297
		 value loss: 58.32867431640625
		 entropy bonus: 4.868551254272461
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -70.79662322998047
		 value loss: 1005.2894287109375
		 entropy bonus: 2.653459072113037
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.966484069824219
		 value loss: 29.094440460205078
		 entropy bonus: 0.13026736676692963
		 -----------------
	 Multi-agent batch loss: 111.67217254638672 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.058496475219727
		 value loss: 58.32867431640625
		 entropy bonus: 4.868552207946777
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -70.79661560058594
		 value loss: 1005.2894287109375
		 entropy bonus: 2.653411388397217
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.96690559387207
		 value loss: 29.094440460205078
		 entropy bonus: 0.13043440878391266
		 -----------------
	 Multi-agent batch loss: 111.67262268066406 - Differentiable computation graph = True!
PPO iteration: 54/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.79547119140625
		 value loss: 60.94416046142578
		 entropy bonus: 4.8792290687561035
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -72.01409912109375
		 value loss: 874.7099609375
		 entropy bonus: 2.7872209548950195
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.655590057373047
		 value loss: 27.7324161529541
		 entropy bonus: 0.21301323175430298
		 -----------------
	 Multi-agent batch loss: 114.02023315429688 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.796810150146484
		 value loss: 60.94416046142578
		 entropy bonus: 4.8792219161987305
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -72.01982116699219
		 value loss: 874.7099609375
		 entropy bonus: 2.7871742248535156
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.650087356567383
		 value loss: 27.7324161529541
		 entropy bonus: 0.21540270745754242
		 -----------------
	 Multi-agent batch loss: 114.02176666259766 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.794998168945312
		 value loss: 60.94416046142578
		 entropy bonus: 4.879232406616211
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -72.02804565429688
		 value loss: 874.7099609375
		 entropy bonus: 2.7871594429016113
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -10.648366928100586
		 value loss: 27.7324161529541
		 entropy bonus: 0.21639463305473328
		 -----------------
	 Multi-agent batch loss: 114.02645111083984 - Differentiable computation graph = True!
PPO iteration: 55/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.291034698486328
		 value loss: 50.673553466796875
		 entropy bonus: 4.8581390380859375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -61.43312072753906
		 value loss: 652.5269165039062
		 entropy bonus: 2.7689356803894043
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.935604095458984
		 value loss: 21.33016586303711
		 entropy bonus: 0.10020279139280319
		 -----------------
	 Multi-agent batch loss: 96.82778930664062 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.29204559326172
		 value loss: 50.673553466796875
		 entropy bonus: 4.858132362365723
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -61.4295654296875
		 value loss: 652.5269165039062
		 entropy bonus: 2.768909454345703
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.935609817504883
		 value loss: 21.33016586303711
		 entropy bonus: 0.10020270943641663
		 -----------------
	 Multi-agent batch loss: 96.82525634765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.289005279541016
		 value loss: 50.673553466796875
		 entropy bonus: 4.858126640319824
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -61.43492126464844
		 value loss: 652.5269165039062
		 entropy bonus: 2.7689080238342285
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.935489654541016
		 value loss: 21.33016586303711
		 entropy bonus: 0.10021936893463135
		 -----------------
	 Multi-agent batch loss: 96.82745361328125 - Differentiable computation graph = True!
PPO iteration: 56/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.331649780273438
		 value loss: 46.62586212158203
		 entropy bonus: 4.865135192871094
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.255615234375
		 value loss: 559.4383544921875
		 entropy bonus: 3.090306043624878
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.425689697265625
		 value loss: 18.172954559326172
		 entropy bonus: 0.2647440433502197
		 -----------------
	 Multi-agent batch loss: 91.17312622070312 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.33034896850586
		 value loss: 46.62586212158203
		 entropy bonus: 4.8651227951049805
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.25299835205078
		 value loss: 559.4383544921875
		 entropy bonus: 3.09022855758667
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.424135208129883
		 value loss: 18.172954559326172
		 entropy bonus: 0.26530778408050537
		 -----------------
	 Multi-agent batch loss: 91.16764831542969 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.328838348388672
		 value loss: 46.62586212158203
		 entropy bonus: 4.865106582641602
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.246864318847656
		 value loss: 559.4383544921875
		 entropy bonus: 3.09004807472229
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.422086715698242
		 value loss: 18.172954559326172
		 entropy bonus: 0.26594382524490356
		 -----------------
	 Multi-agent batch loss: 91.15795135498047 - Differentiable computation graph = True!
PPO iteration: 57/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -17.843738555908203
		 value loss: 55.357635498046875
		 entropy bonus: 4.896254062652588
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.608280181884766
		 value loss: 761.7158813476562
		 entropy bonus: 2.9390578269958496
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.917046546936035
		 value loss: 21.064918518066406
		 entropy bonus: 0.1156056821346283
		 -----------------
	 Multi-agent batch loss: 92.67094421386719 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -17.844308853149414
		 value loss: 55.357635498046875
		 entropy bonus: 4.896240234375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.59856033325195
		 value loss: 761.7158813476562
		 entropy bonus: 2.9389259815216064
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.918072700500488
		 value loss: 21.064918518066406
		 entropy bonus: 0.11565352976322174
		 -----------------
	 Multi-agent batch loss: 92.6628189086914 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -17.84474754333496
		 value loss: 55.357635498046875
		 entropy bonus: 4.896228790283203
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.58604431152344
		 value loss: 761.7158813476562
		 entropy bonus: 2.938775062561035
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.918514251708984
		 value loss: 21.064918518066406
		 entropy bonus: 0.11568542569875717
		 -----------------
	 Multi-agent batch loss: 92.65118408203125 - Differentiable computation graph = True!
PPO iteration: 58/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.473236083984375
		 value loss: 59.43929672241211
		 entropy bonus: 4.825669288635254
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.68411254882812
		 value loss: 925.0174560546875
		 entropy bonus: 2.8098373413085938
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.55889892578125
		 value loss: 26.348527908325195
		 entropy bonus: 0.24488094449043274
		 -----------------
	 Multi-agent batch loss: 104.74549865722656 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.484378814697266
		 value loss: 59.43929672241211
		 entropy bonus: 4.825146198272705
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.64324188232422
		 value loss: 925.0174560546875
		 entropy bonus: 2.8098983764648438
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.558938980102539
		 value loss: 26.348527908325195
		 entropy bonus: 0.24495553970336914
		 -----------------
	 Multi-agent batch loss: 104.71581268310547 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -19.48085594177246
		 value loss: 59.43929672241211
		 entropy bonus: 4.825024604797363
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -65.63978576660156
		 value loss: 925.0174560546875
		 entropy bonus: 2.809617042541504
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.558762550354004
		 value loss: 26.348527908325195
		 entropy bonus: 0.24501395225524902
		 -----------------
	 Multi-agent batch loss: 104.70865631103516 - Differentiable computation graph = True!
PPO iteration: 59/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.730606079101562
		 value loss: 52.4220085144043
		 entropy bonus: 4.8785176277160645
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.70907211303711
		 value loss: 737.610595703125
		 entropy bonus: 3.1767702102661133
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.860112190246582
		 value loss: 20.863826751708984
		 entropy bonus: 0.24251072108745575
		 -----------------
	 Multi-agent batch loss: 98.32577514648438 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.732988357543945
		 value loss: 52.4220085144043
		 entropy bonus: 4.878763675689697
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.705265045166016
		 value loss: 737.610595703125
		 entropy bonus: 3.1765055656433105
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.85982894897461
		 value loss: 20.863826751708984
		 entropy bonus: 0.2424243539571762
		 -----------------
	 Multi-agent batch loss: 98.32406616210938 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.740678787231445
		 value loss: 52.4220085144043
		 entropy bonus: 4.878834247589111
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -62.70067596435547
		 value loss: 737.610595703125
		 entropy bonus: 3.1762313842773438
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.859169960021973
		 value loss: 20.863826751708984
		 entropy bonus: 0.24231642484664917
		 -----------------
	 Multi-agent batch loss: 98.3265151977539 - Differentiable computation graph = True!
PPO iteration: 60/150:
	 start solving instance: 56...
	 start solving instance: 35...
	 start solving instance: 32...
	 start solving instance: 146...
	 start solving instance: 30...
	 start solving instance: 72...
	 start solving instance: 10...
	 start solving instance: 67...
	 start solving instance: 80...
	 start solving instance: 2...
	 start solving instance: 41...
	 start solving instance: 55...
	 start solving instance: 136...
	 start solving instance: 148...
	 start solving instance: 85...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -17.940134048461914
		 value loss: 56.43321228027344
		 entropy bonus: 4.902163505554199
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.99525451660156
		 value loss: 755.009765625
		 entropy bonus: 2.7714040279388428
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.255459785461426
		 value loss: 23.095579147338867
		 entropy bonus: 0.18334117531776428
		 -----------------
	 Multi-agent batch loss: 93.45765686035156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -17.93699073791504
		 value loss: 56.43321228027344
		 entropy bonus: 4.902290344238281
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.99761962890625
		 value loss: 755.009765625
		 entropy bonus: 2.7712676525115967
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.255631446838379
		 value loss: 23.095579147338867
		 entropy bonus: 0.1833077222108841
		 -----------------
	 Multi-agent batch loss: 93.45706176757812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -17.93699073791504
		 value loss: 56.43321228027344
		 entropy bonus: 4.902290344238281
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -58.999542236328125
		 value loss: 755.009765625
		 entropy bonus: 2.7711663246154785
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.25560188293457
		 value loss: 23.095579147338867
		 entropy bonus: 0.18330763280391693
		 -----------------
	 Multi-agent batch loss: 93.45895385742188 - Differentiable computation graph = True!
PPO iteration: 61/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.476043701171875
		 value loss: 44.036766052246094
		 entropy bonus: 4.940305709838867
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -61.739410400390625
		 value loss: 562.6007080078125
		 entropy bonus: 2.612057685852051
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.811070442199707
		 value loss: 18.8487491607666
		 entropy bonus: 0.025297220796346664
		 -----------------
	 Multi-agent batch loss: 96.20561218261719 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.476043701171875
		 value loss: 44.036766052246094
		 entropy bonus: 4.940305709838867
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -61.73948287963867
		 value loss: 562.6007080078125
		 entropy bonus: 2.6119766235351562
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.811078071594238
		 value loss: 18.8487491607666
		 entropy bonus: 0.02529648318886757
		 -----------------
	 Multi-agent batch loss: 96.2056884765625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -18.476043701171875
		 value loss: 44.036766052246094
		 entropy bonus: 4.940305709838867
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -61.738529205322266
		 value loss: 562.6007080078125
		 entropy bonus: 2.6119461059570312
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.81103229522705
		 value loss: 18.8487491607666
		 entropy bonus: 0.025300640612840652
		 -----------------
	 Multi-agent batch loss: 96.20468139648438 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: -10.41878890991211
		 value loss: 21.37574005126953
		 entropy bonus: 3.2474899291992188
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -31.710371017456055
		 value loss: 194.61688232421875
		 entropy bonus: 1.523069143295288
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.104229927062988
		 value loss: 3.560016632080078
		 entropy bonus: 0.14925608038902283
		 -----------------
	 Multi-agent batch loss: 48.3797
PPO iteration: 62/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.505165100097656
		 value loss: 57.915313720703125
		 entropy bonus: 4.935497283935547
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.05860900878906
		 value loss: 817.7923583984375
		 entropy bonus: 2.638948917388916
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.496225357055664
		 value loss: 22.077350616455078
		 entropy bonus: 0.23792320489883423
		 -----------------
	 Multi-agent batch loss: 116.95973205566406 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.505146026611328
		 value loss: 57.915313720703125
		 entropy bonus: 4.935327529907227
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.05390930175781
		 value loss: 817.7923583984375
		 entropy bonus: 2.6396868228912354
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.460848808288574
		 value loss: 22.077350616455078
		 entropy bonus: 0.24008487164974213
		 -----------------
	 Multi-agent batch loss: 116.91960144042969 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -21.509784698486328
		 value loss: 57.915313720703125
		 entropy bonus: 4.935194969177246
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -75.05183410644531
		 value loss: 817.7923583984375
		 entropy bonus: 2.6395654678344727
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -11.46422004699707
		 value loss: 22.077350616455078
		 entropy bonus: 0.24026058614253998
		 -----------------
	 Multi-agent batch loss: 116.925537109375 - Differentiable computation graph = True!
PPO iteration: 63/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.231414794921875
		 value loss: 49.081565856933594
		 entropy bonus: 4.955540657043457
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.42463684082031
		 value loss: 572.7139892578125
		 entropy bonus: 2.562718391418457
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.609647750854492
		 value loss: 15.815557479858398
		 entropy bonus: 0.13822361826896667
		 -----------------
	 Multi-agent batch loss: 100.56524658203125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.22537612915039
		 value loss: 49.081565856933594
		 entropy bonus: 4.955432415008545
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.4261474609375
		 value loss: 572.7139892578125
		 entropy bonus: 2.5627083778381348
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.609572410583496
		 value loss: 15.815557479858398
		 entropy bonus: 0.13847002387046814
		 -----------------
	 Multi-agent batch loss: 100.56063842773438 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -20.223705291748047
		 value loss: 49.081565856933594
		 entropy bonus: 4.955377578735352
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -64.43350219726562
		 value loss: 572.7139892578125
		 entropy bonus: 2.5626773834228516
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -9.607836723327637
		 value loss: 15.815557479858398
		 entropy bonus: 0.13735999166965485
		 -----------------
	 Multi-agent batch loss: 100.56460571289062 - Differentiable computation graph = True!
PPO iteration: 64/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.041152954101562
		 value loss: 24.95210075378418
		 entropy bonus: 4.913082122802734
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.787654876708984
		 value loss: 334.443359375
		 entropy bonus: 2.637118339538574
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.749116897583008
		 value loss: 10.507943153381348
		 entropy bonus: 0.26314935088157654
		 -----------------
	 Multi-agent batch loss: 73.19882202148438 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.041528701782227
		 value loss: 24.95210075378418
		 entropy bonus: 4.913015365600586
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.78562927246094
		 value loss: 334.443359375
		 entropy bonus: 2.6370863914489746
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.749108791351318
		 value loss: 10.507943153381348
		 entropy bonus: 0.26351338624954224
		 -----------------
	 Multi-agent batch loss: 73.1971664428711 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.041793823242188
		 value loss: 24.95210075378418
		 entropy bonus: 4.913002014160156
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.78533935546875
		 value loss: 334.443359375
		 entropy bonus: 2.6370811462402344
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.744871616363525
		 value loss: 10.507943153381348
		 entropy bonus: 0.26303163170814514
		 -----------------
	 Multi-agent batch loss: 73.19290924072266 - Differentiable computation graph = True!
PPO iteration: 65/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.901037216186523
		 value loss: 25.94042205810547
		 entropy bonus: 4.922535419464111
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.64310073852539
		 value loss: 318.4465637207031
		 entropy bonus: 2.6279444694519043
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.4617204666137695
		 value loss: 10.18350601196289
		 entropy bonus: 0.28178730607032776
		 -----------------
	 Multi-agent batch loss: 70.4732437133789 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.903675079345703
		 value loss: 25.94042205810547
		 entropy bonus: 4.922533988952637
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.64118194580078
		 value loss: 318.4465637207031
		 entropy bonus: 2.6278843879699707
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.460874080657959
		 value loss: 10.18350601196289
		 entropy bonus: 0.2820334732532501
		 -----------------
	 Multi-agent batch loss: 70.47311401367188 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.904111862182617
		 value loss: 25.94042205810547
		 entropy bonus: 4.922560691833496
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.64039611816406
		 value loss: 318.4465637207031
		 entropy bonus: 2.6279284954071045
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.4598388671875
		 value loss: 10.18350601196289
		 entropy bonus: 0.28232547640800476
		 -----------------
	 Multi-agent batch loss: 70.47172546386719 - Differentiable computation graph = True!
PPO iteration: 66/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -11.907052993774414
		 value loss: 18.378440856933594
		 entropy bonus: 4.9181952476501465
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -40.211483001708984
		 value loss: 250.10122680664062
		 entropy bonus: 2.6675477027893066
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.971677780151367
		 value loss: 8.933223724365234
		 entropy bonus: 0.12188276648521423
		 -----------------
	 Multi-agent batch loss: 61.787261962890625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -11.904975891113281
		 value loss: 18.378440856933594
		 entropy bonus: 4.918169975280762
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -40.21104431152344
		 value loss: 250.10122680664062
		 entropy bonus: 2.6675491333007812
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.970938682556152
		 value loss: 8.933223724365234
		 entropy bonus: 0.12219341844320297
		 -----------------
	 Multi-agent batch loss: 61.78400421142578 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -11.904960632324219
		 value loss: 18.378440856933594
		 entropy bonus: 4.918176651000977
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -40.20407485961914
		 value loss: 250.10122680664062
		 entropy bonus: 2.66762113571167
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.970150947570801
		 value loss: 8.933223724365234
		 entropy bonus: 0.12251082062721252
		 -----------------
	 Multi-agent batch loss: 61.77622985839844 - Differentiable computation graph = True!
PPO iteration: 67/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.369988441467285
		 value loss: 24.151138305664062
		 entropy bonus: 4.950098037719727
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.92243194580078
		 value loss: 316.46673583984375
		 entropy bonus: 2.58140230178833
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.674017906188965
		 value loss: 10.786564826965332
		 entropy bonus: 0.11336996406316757
		 -----------------
	 Multi-agent batch loss: 69.40403747558594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.370409965515137
		 value loss: 24.151138305664062
		 entropy bonus: 4.9501118659973145
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.922401428222656
		 value loss: 316.46673583984375
		 entropy bonus: 2.5814356803894043
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.674612998962402
		 value loss: 10.786564826965332
		 entropy bonus: 0.1134372130036354
		 -----------------
	 Multi-agent batch loss: 69.40502166748047 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.3688325881958
		 value loss: 24.151138305664062
		 entropy bonus: 4.950132369995117
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.92204666137695
		 value loss: 316.46673583984375
		 entropy bonus: 2.581468343734741
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.6748576164245605
		 value loss: 10.786564826965332
		 entropy bonus: 0.11350454390048981
		 -----------------
	 Multi-agent batch loss: 69.40333557128906 - Differentiable computation graph = True!
PPO iteration: 68/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.415962219238281
		 value loss: 26.639005661010742
		 entropy bonus: 4.95301628112793
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -49.164459228515625
		 value loss: 376.9239501953125
		 entropy bonus: 2.6391546726226807
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.102603912353516
		 value loss: 11.855712890625
		 entropy bonus: 0.1616118848323822
		 -----------------
	 Multi-agent batch loss: 75.75967407226562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.412395477294922
		 value loss: 26.639005661010742
		 entropy bonus: 4.9530839920043945
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -49.162811279296875
		 value loss: 376.9239501953125
		 entropy bonus: 2.639176845550537
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.102385520935059
		 value loss: 11.855712890625
		 entropy bonus: 0.16167834401130676
		 -----------------
	 Multi-agent batch loss: 75.75424194335938 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.411020278930664
		 value loss: 26.639005661010742
		 entropy bonus: 4.953137397766113
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -49.162132263183594
		 value loss: 376.9239501953125
		 entropy bonus: 2.6391971111297607
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.102143287658691
		 value loss: 11.855712890625
		 entropy bonus: 0.16174685955047607
		 -----------------
	 Multi-agent batch loss: 75.75194549560547 - Differentiable computation graph = True!
PPO iteration: 69/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.165396690368652
		 value loss: 24.04144859313965
		 entropy bonus: 4.913699150085449
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.50788497924805
		 value loss: 334.3592224121094
		 entropy bonus: 2.7478933334350586
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.5351457595825195
		 value loss: 10.800552368164062
		 entropy bonus: 0.0953657254576683
		 -----------------
	 Multi-agent batch loss: 69.8228759765625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.163756370544434
		 value loss: 24.04144859313965
		 entropy bonus: 4.913755893707275
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.50759506225586
		 value loss: 334.3592224121094
		 entropy bonus: 2.7479238510131836
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.534963130950928
		 value loss: 10.800552368164062
		 entropy bonus: 0.0954442173242569
		 -----------------
	 Multi-agent batch loss: 69.82075500488281 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.162652969360352
		 value loss: 24.04144859313965
		 entropy bonus: 4.913796424865723
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.50714874267578
		 value loss: 334.3592224121094
		 entropy bonus: 2.7479443550109863
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.534681797027588
		 value loss: 10.800552368164062
		 entropy bonus: 0.0955447182059288
		 -----------------
	 Multi-agent batch loss: 69.81892395019531 - Differentiable computation graph = True!
PPO iteration: 70/150:
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 86...
	 start solving instance: 103...
	 start solving instance: 16...
	 start solving instance: 59...
	 start solving instance: 150...
	 start solving instance: 54...
	 start solving instance: 147...
	 start solving instance: 89...
	 start solving instance: 51...
	 start solving instance: 130...
	 start solving instance: 25...
	 start solving instance: 79...
	 start solving instance: 117...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.506124496459961
		 value loss: 24.978317260742188
		 entropy bonus: 4.962089538574219
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.66717529296875
		 value loss: 356.7944030761719
		 entropy bonus: 2.6548984050750732
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.055356979370117
		 value loss: 12.056058883666992
		 entropy bonus: 0.09717997908592224
		 -----------------
	 Multi-agent batch loss: 73.08979797363281 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.505390167236328
		 value loss: 24.978317260742188
		 entropy bonus: 4.962154865264893
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.6651611328125
		 value loss: 356.7944030761719
		 entropy bonus: 2.654898166656494
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.05532455444336
		 value loss: 12.056058883666992
		 entropy bonus: 0.09722462296485901
		 -----------------
	 Multi-agent batch loss: 73.08702087402344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.504741668701172
		 value loss: 24.978317260742188
		 entropy bonus: 4.962197303771973
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.66249084472656
		 value loss: 356.7944030761719
		 entropy bonus: 2.6548943519592285
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.055286407470703
		 value loss: 12.056058883666992
		 entropy bonus: 0.09726491570472717
		 -----------------
	 Multi-agent batch loss: 73.08366394042969 - Differentiable computation graph = True!
PPO iteration: 71/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.199370384216309
		 value loss: 20.479230880737305
		 entropy bonus: 4.846690654754639
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.08103942871094
		 value loss: 212.43148803710938
		 entropy bonus: 2.972572088241577
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.314915657043457
		 value loss: 6.75161075592041
		 entropy bonus: 0.38635310530662537
		 -----------------
	 Multi-agent batch loss: 60.90989303588867 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.199907302856445
		 value loss: 20.479230880737305
		 entropy bonus: 4.846722602844238
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.0787239074707
		 value loss: 212.43148803710938
		 entropy bonus: 2.9725334644317627
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.313878059387207
		 value loss: 6.75161075592041
		 entropy bonus: 0.3865491449832916
		 -----------------
	 Multi-agent batch loss: 60.907073974609375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.20075798034668
		 value loss: 20.479230880737305
		 entropy bonus: 4.846775531768799
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.0761604309082
		 value loss: 212.43148803710938
		 entropy bonus: 2.9724769592285156
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.312358856201172
		 value loss: 6.75161075592041
		 entropy bonus: 0.3868037760257721
		 -----------------
	 Multi-agent batch loss: 60.903839111328125 - Differentiable computation graph = True!
PPO iteration: 72/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.479440689086914
		 value loss: 20.44341278076172
		 entropy bonus: 4.807044982910156
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -38.86098861694336
		 value loss: 190.04066467285156
		 entropy bonus: 3.037954092025757
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.123535633087158
		 value loss: 5.5673322677612305
		 entropy bonus: 0.317864328622818
		 -----------------
	 Multi-agent batch loss: 60.5428466796875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.479532241821289
		 value loss: 20.44341278076172
		 entropy bonus: 4.807046890258789
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -38.85810852050781
		 value loss: 190.04066467285156
		 entropy bonus: 3.037893295288086
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.124016761779785
		 value loss: 5.5673322677612305
		 entropy bonus: 0.31788283586502075
		 -----------------
	 Multi-agent batch loss: 60.54054260253906 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.479576110839844
		 value loss: 20.44341278076172
		 entropy bonus: 4.807048320770264
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -38.857139587402344
		 value loss: 190.04066467285156
		 entropy bonus: 3.0378284454345703
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.124299049377441
		 value loss: 5.5673322677612305
		 entropy bonus: 0.3178951144218445
		 -----------------
	 Multi-agent batch loss: 60.53990173339844 - Differentiable computation graph = True!
PPO iteration: 73/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -12.597190856933594
		 value loss: 19.306079864501953
		 entropy bonus: 4.780196189880371
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.49233627319336
		 value loss: 233.09573364257812
		 entropy bonus: 2.8818511962890625
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.564999580383301
		 value loss: 8.071977615356445
		 entropy bonus: 0.5163472890853882
		 -----------------
	 Multi-agent batch loss: 61.17747497558594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -12.59714412689209
		 value loss: 19.306079864501953
		 entropy bonus: 4.780195236206055
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.49268341064453
		 value loss: 233.09573364257812
		 entropy bonus: 2.8817813396453857
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.564655303955078
		 value loss: 8.071977615356445
		 entropy bonus: 0.5164648294448853
		 -----------------
	 Multi-agent batch loss: 61.17743682861328 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -12.597038269042969
		 value loss: 19.306079864501953
		 entropy bonus: 4.7801923751831055
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.49285888671875
		 value loss: 233.09573364257812
		 entropy bonus: 2.8817155361175537
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.564209938049316
		 value loss: 8.071977615356445
		 entropy bonus: 0.5165612697601318
		 -----------------
	 Multi-agent batch loss: 61.177059173583984 - Differentiable computation graph = True!
PPO iteration: 74/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.680721282958984
		 value loss: 23.50828742980957
		 entropy bonus: 4.861910820007324
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -42.047584533691406
		 value loss: 254.94284057617188
		 entropy bonus: 2.9941487312316895
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.460038185119629
		 value loss: 7.290024280548096
		 entropy bonus: 0.3769780397415161
		 -----------------
	 Multi-agent batch loss: 64.96342468261719 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.680717468261719
		 value loss: 23.50828742980957
		 entropy bonus: 4.861908912658691
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -42.04827880859375
		 value loss: 254.94284057617188
		 entropy bonus: 2.994074821472168
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.460460186004639
		 value loss: 7.290024280548096
		 entropy bonus: 0.3771505653858185
		 -----------------
	 Multi-agent batch loss: 64.96453857421875 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.680646896362305
		 value loss: 23.50828742980957
		 entropy bonus: 4.861907482147217
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -42.04772186279297
		 value loss: 254.94284057617188
		 entropy bonus: 2.9940218925476074
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.460593223571777
		 value loss: 7.290024280548096
		 entropy bonus: 0.3772122263908386
		 -----------------
	 Multi-agent batch loss: 64.96403503417969 - Differentiable computation graph = True!
PPO iteration: 75/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.266082763671875
		 value loss: 21.114185333251953
		 entropy bonus: 4.809658050537109
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.76942825317383
		 value loss: 278.8468322753906
		 entropy bonus: 2.9751548767089844
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.914801597595215
		 value loss: 8.082650184631348
		 entropy bonus: 0.13999421894550323
		 -----------------
	 Multi-agent batch loss: 66.95149993896484 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.265419006347656
		 value loss: 21.114185333251953
		 entropy bonus: 4.809665203094482
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.76923751831055
		 value loss: 278.8468322753906
		 entropy bonus: 2.9751203060150146
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.9146575927734375
		 value loss: 8.082650184631348
		 entropy bonus: 0.14000669121742249
		 -----------------
	 Multi-agent batch loss: 66.95050048828125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.26416015625
		 value loss: 21.114185333251953
		 entropy bonus: 4.8096771240234375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.76892852783203
		 value loss: 278.8468322753906
		 entropy bonus: 2.9750890731811523
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.914375305175781
		 value loss: 8.082650184631348
		 entropy bonus: 0.14003343880176544
		 -----------------
	 Multi-agent batch loss: 66.94865417480469 - Differentiable computation graph = True!
PPO iteration: 76/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -12.955024719238281
		 value loss: 20.10189437866211
		 entropy bonus: 4.79654598236084
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -42.528568267822266
		 value loss: 269.8932189941406
		 entropy bonus: 3.0024731159210205
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.643326282501221
		 value loss: 8.49606704711914
		 entropy bonus: 0.17888414859771729
		 -----------------
	 Multi-agent batch loss: 65.03205108642578 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -12.955422401428223
		 value loss: 20.10189437866211
		 entropy bonus: 4.7965521812438965
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -42.528282165527344
		 value loss: 269.8932189941406
		 entropy bonus: 3.0024173259735107
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.643042087554932
		 value loss: 8.49606704711914
		 entropy bonus: 0.1788615584373474
		 -----------------
	 Multi-agent batch loss: 65.03187561035156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -12.955643653869629
		 value loss: 20.10189437866211
		 entropy bonus: 4.796555519104004
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -42.5272216796875
		 value loss: 269.8932189941406
		 entropy bonus: 3.002340793609619
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.6426286697387695
		 value loss: 8.49606704711914
		 entropy bonus: 0.17882391810417175
		 -----------------
	 Multi-agent batch loss: 65.03063201904297 - Differentiable computation graph = True!
PPO iteration: 77/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.116440773010254
		 value loss: 23.338233947753906
		 entropy bonus: 4.830530166625977
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.71144104003906
		 value loss: 335.6671142578125
		 entropy bonus: 2.9957871437072754
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.82133674621582
		 value loss: 11.832181930541992
		 entropy bonus: 0.34878191351890564
		 -----------------
	 Multi-agent batch loss: 73.27584075927734 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.116403579711914
		 value loss: 23.338233947753906
		 entropy bonus: 4.830531120300293
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.71101760864258
		 value loss: 335.6671142578125
		 entropy bonus: 2.9956698417663574
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.821405410766602
		 value loss: 11.832181930541992
		 entropy bonus: 0.34872961044311523
		 -----------------
	 Multi-agent batch loss: 73.27545166015625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.116360664367676
		 value loss: 23.338233947753906
		 entropy bonus: 4.830531597137451
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -47.710205078125
		 value loss: 335.6671142578125
		 entropy bonus: 2.9955506324768066
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.821300029754639
		 value loss: 11.832181930541992
		 entropy bonus: 0.3486652374267578
		 -----------------
	 Multi-agent batch loss: 73.27449035644531 - Differentiable computation graph = True!
PPO iteration: 78/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.77628231048584
		 value loss: 24.5833683013916
		 entropy bonus: 4.829776287078857
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.55579376220703
		 value loss: 299.4775695800781
		 entropy bonus: 3.052374839782715
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.239278793334961
		 value loss: 10.065138816833496
		 entropy bonus: 0.18146774172782898
		 -----------------
	 Multi-agent batch loss: 67.83197784423828 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.776315689086914
		 value loss: 24.5833683013916
		 entropy bonus: 4.829776763916016
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.55541229248047
		 value loss: 299.4775695800781
		 entropy bonus: 3.0522561073303223
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.239387035369873
		 value loss: 10.065138816833496
		 entropy bonus: 0.1814577877521515
		 -----------------
	 Multi-agent batch loss: 67.83174133300781 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.776335716247559
		 value loss: 24.5833683013916
		 entropy bonus: 4.829776763916016
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.55474853515625
		 value loss: 299.4775695800781
		 entropy bonus: 3.05214786529541
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.239330291748047
		 value loss: 10.065138816833496
		 entropy bonus: 0.1814831644296646
		 -----------------
	 Multi-agent batch loss: 67.83103942871094 - Differentiable computation graph = True!
PPO iteration: 79/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.846124649047852
		 value loss: 21.243497848510742
		 entropy bonus: 4.86395263671875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.97368621826172
		 value loss: 233.91879272460938
		 entropy bonus: 2.9554457664489746
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.083198070526123
		 value loss: 8.113998413085938
		 entropy bonus: 0.1712334156036377
		 -----------------
	 Multi-agent batch loss: 65.45586395263672 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.846012115478516
		 value loss: 21.243497848510742
		 entropy bonus: 4.863954544067383
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.974159240722656
		 value loss: 233.91879272460938
		 entropy bonus: 2.955368995666504
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.08323860168457
		 value loss: 8.113998413085938
		 entropy bonus: 0.1712338626384735
		 -----------------
	 Multi-agent batch loss: 65.45626831054688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.84585952758789
		 value loss: 21.243497848510742
		 entropy bonus: 4.863955497741699
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.97442626953125
		 value loss: 233.91879272460938
		 entropy bonus: 2.9553041458129883
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.083238124847412
		 value loss: 8.113998413085938
		 entropy bonus: 0.1712297797203064
		 -----------------
	 Multi-agent batch loss: 65.45638275146484 - Differentiable computation graph = True!
PPO iteration: 80/150:
	 start solving instance: 118...
	 start solving instance: 41...
	 start solving instance: 147...
	 start solving instance: 108...
	 start solving instance: 7...
	 start solving instance: 18...
	 start solving instance: 131...
	 start solving instance: 92...
	 start solving instance: 9...
	 start solving instance: 40...
	 start solving instance: 103...
	 start solving instance: 146...
	 start solving instance: 1...
	 start solving instance: 19...
	 start solving instance: 15...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.048514366149902
		 value loss: 20.927566528320312
		 entropy bonus: 4.818644046783447
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.17488479614258
		 value loss: 217.70428466796875
		 entropy bonus: 3.071075677871704
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.092028617858887
		 value loss: 6.312736988067627
		 entropy bonus: 0.45281410217285156
		 -----------------
	 Multi-agent batch loss: 60.68144989013672 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.048656463623047
		 value loss: 20.927566528320312
		 entropy bonus: 4.818645000457764
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.17469787597656
		 value loss: 217.70428466796875
		 entropy bonus: 3.071030855178833
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.091958045959473
		 value loss: 6.312736988067627
		 entropy bonus: 0.4527971148490906
		 -----------------
	 Multi-agent batch loss: 60.681331634521484 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.048563003540039
		 value loss: 20.927566528320312
		 entropy bonus: 4.818644046783447
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -39.174095153808594
		 value loss: 217.70428466796875
		 entropy bonus: 3.071007251739502
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.091818809509277
		 value loss: 6.312736988067627
		 entropy bonus: 0.45277026295661926
		 -----------------
	 Multi-agent batch loss: 60.680503845214844 - Differentiable computation graph = True!
PPO iteration: 81/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.300602912902832
		 value loss: 20.080215454101562
		 entropy bonus: 4.931790351867676
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.165870666503906
		 value loss: 223.12826538085938
		 entropy bonus: 2.8911447525024414
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.739114284515381
		 value loss: 6.994911193847656
		 entropy bonus: 0.46944570541381836
		 -----------------
	 Multi-agent batch loss: 65.62469482421875 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.300443649291992
		 value loss: 20.080215454101562
		 entropy bonus: 4.931790351867676
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.16587448120117
		 value loss: 223.12826538085938
		 entropy bonus: 2.8911280632019043
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.739119529724121
		 value loss: 6.994911193847656
		 entropy bonus: 0.4694475829601288
		 -----------------
	 Multi-agent batch loss: 65.62454223632812 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.300261497497559
		 value loss: 20.080215454101562
		 entropy bonus: 4.931788444519043
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -43.165706634521484
		 value loss: 223.12826538085938
		 entropy bonus: 2.8911290168762207
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.738826751708984
		 value loss: 6.994911193847656
		 entropy bonus: 0.4694531559944153
		 -----------------
	 Multi-agent batch loss: 65.6239013671875 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: -5.516725063323975
		 value loss: 6.773313045501709
		 entropy bonus: 3.1359715461730957
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -16.93762969970703
		 value loss: 73.5429916381836
		 entropy bonus: 1.3151673078536987
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.203266143798828
		 value loss: 1.2843472957611084
		 entropy bonus: 0.1681966632604599
		 -----------------
	 Multi-agent batch loss: 25.4274
PPO iteration: 82/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.704730987548828
		 value loss: 25.027572631835938
		 entropy bonus: 4.939725875854492
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.74174499511719
		 value loss: 251.357666015625
		 entropy bonus: 2.774655818939209
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.325717449188232
		 value loss: 8.620955467224121
		 entropy bonus: 0.29197853803634644
		 -----------------
	 Multi-agent batch loss: 69.54219055175781 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.704833030700684
		 value loss: 25.027572631835938
		 entropy bonus: 4.939725399017334
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.741127014160156
		 value loss: 251.357666015625
		 entropy bonus: 2.7746949195861816
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.325872898101807
		 value loss: 8.620955467224121
		 entropy bonus: 0.2919909656047821
		 -----------------
	 Multi-agent batch loss: 69.54183197021484 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.704900741577148
		 value loss: 25.027572631835938
		 entropy bonus: 4.939724445343018
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.739959716796875
		 value loss: 251.357666015625
		 entropy bonus: 2.774749755859375
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.325803756713867
		 value loss: 8.620955467224121
		 entropy bonus: 0.29199352860450745
		 -----------------
	 Multi-agent batch loss: 69.54066467285156 - Differentiable computation graph = True!
PPO iteration: 83/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.721203804016113
		 value loss: 21.61181640625
		 entropy bonus: 4.933103561401367
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.15833282470703
		 value loss: 242.74014282226562
		 entropy bonus: 2.93937611579895
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.098941326141357
		 value loss: 7.4197678565979
		 entropy bonus: 0.1812829077243805
		 -----------------
	 Multi-agent batch loss: 68.61566162109375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.721122741699219
		 value loss: 21.61181640625
		 entropy bonus: 4.933102607727051
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.1583251953125
		 value loss: 242.74014282226562
		 entropy bonus: 2.9394423961639404
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.098909378051758
		 value loss: 7.4197678565979
		 entropy bonus: 0.18129557371139526
		 -----------------
	 Multi-agent batch loss: 68.61553955078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -13.72102165222168
		 value loss: 21.61181640625
		 entropy bonus: 4.933101177215576
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.15821838378906
		 value loss: 242.74014282226562
		 entropy bonus: 2.9394989013671875
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.098745346069336
		 value loss: 7.4197678565979
		 entropy bonus: 0.18132539093494415
		 -----------------
	 Multi-agent batch loss: 68.61516571044922 - Differentiable computation graph = True!
PPO iteration: 84/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.419654846191406
		 value loss: 24.44304847717285
		 entropy bonus: 4.931516647338867
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.347557067871094
		 value loss: 265.9117431640625
		 entropy bonus: 2.7668566703796387
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.196229457855225
		 value loss: 8.84115982055664
		 entropy bonus: 0.39611878991127014
		 -----------------
	 Multi-agent batch loss: 69.87445831298828 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.419611930847168
		 value loss: 24.44304847717285
		 entropy bonus: 4.931511878967285
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.345367431640625
		 value loss: 265.9117431640625
		 entropy bonus: 2.7665460109710693
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.1928629875183105
		 value loss: 8.84115982055664
		 entropy bonus: 0.3965315520763397
		 -----------------
	 Multi-agent batch loss: 69.86885833740234 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.42005443572998
		 value loss: 24.44304847717285
		 entropy bonus: 4.931500434875488
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.34458923339844
		 value loss: 265.9117431640625
		 entropy bonus: 2.7664268016815186
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.192553520202637
		 value loss: 8.84115982055664
		 entropy bonus: 0.3965696394443512
		 -----------------
	 Multi-agent batch loss: 69.86820983886719 - Differentiable computation graph = True!
PPO iteration: 85/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.706871032714844
		 value loss: 26.094987869262695
		 entropy bonus: 4.9395599365234375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.16885757446289
		 value loss: 273.92578125
		 entropy bonus: 2.8308305740356445
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.792571067810059
		 value loss: 7.752279281616211
		 entropy bonus: 0.3145548105239868
		 -----------------
	 Multi-agent batch loss: 69.66517639160156 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.706875801086426
		 value loss: 26.094987869262695
		 entropy bonus: 4.939558982849121
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.15801239013672
		 value loss: 273.92578125
		 entropy bonus: 2.8306961059570312
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.7924628257751465
		 value loss: 7.752279281616211
		 entropy bonus: 0.31460219621658325
		 -----------------
	 Multi-agent batch loss: 69.65423583984375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.706879615783691
		 value loss: 26.094987869262695
		 entropy bonus: 4.939558029174805
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -45.157745361328125
		 value loss: 273.92578125
		 entropy bonus: 2.8304266929626465
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.792302131652832
		 value loss: 7.752279281616211
		 entropy bonus: 0.3146367073059082
		 -----------------
	 Multi-agent batch loss: 69.65380859375 - Differentiable computation graph = True!
PPO iteration: 86/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.119746208190918
		 value loss: 27.46381187438965
		 entropy bonus: 4.947256088256836
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -49.718589782714844
		 value loss: 310.83148193359375
		 entropy bonus: 2.959848403930664
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.026011943817139
		 value loss: 8.209271430969238
		 entropy bonus: 0.32332366704940796
		 -----------------
	 Multi-agent batch loss: 75.24708557128906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.119705200195312
		 value loss: 27.46381187438965
		 entropy bonus: 4.947253227233887
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -49.71562576293945
		 value loss: 310.83148193359375
		 entropy bonus: 2.9598536491394043
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.025999069213867
		 value loss: 8.209271430969238
		 entropy bonus: 0.3234547972679138
		 -----------------
	 Multi-agent batch loss: 75.24407196044922 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -15.121822357177734
		 value loss: 27.46381187438965
		 entropy bonus: 4.946916580200195
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -49.73954772949219
		 value loss: 310.83148193359375
		 entropy bonus: 2.9594573974609375
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -7.0282464027404785
		 value loss: 8.209271430969238
		 entropy bonus: 0.3263532519340515
		 -----------------
	 Multi-agent batch loss: 75.2723388671875 - Differentiable computation graph = True!
PPO iteration: 87/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.7431491613388062
		 value loss: 1.2453291416168213
		 entropy bonus: 4.9533562660217285
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.042275428771973
		 value loss: 13.787996292114258
		 entropy bonus: 2.8085274696350098
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2359381914138794
		 value loss: 0.30933868885040283
		 entropy bonus: 0.23891983926296234
		 -----------------
	 Multi-agent batch loss: -9.947944641113281 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.7424348592758179
		 value loss: 1.2453291416168213
		 entropy bonus: 4.953447341918945
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.054919242858887
		 value loss: 13.787996292114258
		 entropy bonus: 2.807990550994873
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2379761934280396
		 value loss: 0.30933868885040283
		 entropy bonus: 0.24202881753444672
		 -----------------
	 Multi-agent batch loss: -9.961938858032227 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.7393903732299805
		 value loss: 1.2453291416168213
		 entropy bonus: 4.953310966491699
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.054344654083252
		 value loss: 13.787996292114258
		 entropy bonus: 2.808046817779541
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.239310622215271
		 value loss: 0.30933868885040283
		 entropy bonus: 0.24194121360778809
		 -----------------
	 Multi-agent batch loss: -9.959651947021484 - Differentiable computation graph = True!
PPO iteration: 88/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -2.4489316940307617
		 value loss: 1.4951249361038208
		 entropy bonus: 4.933053493499756
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -4.53507137298584
		 value loss: 15.079561233520508
		 entropy bonus: 2.6814632415771484
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -0.5788460373878479
		 value loss: 0.44028836488723755
		 entropy bonus: 0.26572611927986145
		 -----------------
	 Multi-agent batch loss: 7.654196739196777 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -2.4505395889282227
		 value loss: 1.4951249361038208
		 entropy bonus: 4.932744979858398
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -4.544074058532715
		 value loss: 15.079561233520508
		 entropy bonus: 2.6819963455200195
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -0.5788540840148926
		 value loss: 0.44028836488723755
		 entropy bonus: 0.2656717896461487
		 -----------------
	 Multi-agent batch loss: 7.664813041687012 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -2.454176902770996
		 value loss: 1.4951249361038208
		 entropy bonus: 4.933030128479004
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -4.548573017120361
		 value loss: 15.079561233520508
		 entropy bonus: 2.6820831298828125
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -0.5792144536972046
		 value loss: 0.44028836488723755
		 entropy bonus: 0.2647314965724945
		 -----------------
	 Multi-agent batch loss: 7.67331600189209 - Differentiable computation graph = True!
PPO iteration: 89/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 0.5146821737289429
		 value loss: 1.3887219429016113
		 entropy bonus: 4.946196556091309
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 3.291060209274292
		 value loss: 15.455549240112305
		 entropy bonus: 2.868804693222046
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.775243878364563
		 value loss: 0.5087562799453735
		 entropy bonus: 0.16931366920471191
		 -----------------
	 Multi-agent batch loss: -4.487298965454102 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 0.5147771835327148
		 value loss: 1.3887219429016113
		 entropy bonus: 4.946205139160156
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 3.290590286254883
		 value loss: 15.455549240112305
		 entropy bonus: 2.868882179260254
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.7752315402030945
		 value loss: 0.5087562799453735
		 entropy bonus: 0.16927528381347656
		 -----------------
	 Multi-agent batch loss: -4.486912250518799 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 0.5127370357513428
		 value loss: 1.3887219429016113
		 entropy bonus: 4.9462175369262695
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 3.2910804748535156
		 value loss: 15.455549240112305
		 entropy bonus: 2.868913412094116
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.775221049785614
		 value loss: 0.5087562799453735
		 entropy bonus: 0.16924211382865906
		 -----------------
	 Multi-agent batch loss: -4.485352039337158 - Differentiable computation graph = True!
PPO iteration: 90/150:
	 start solving instance: 79...
	 start solving instance: 101...
	 start solving instance: 67...
	 start solving instance: 138...
	 start solving instance: 142...
	 start solving instance: 99...
	 start solving instance: 55...
	 start solving instance: 114...
	 start solving instance: 122...
	 start solving instance: 117...
	 start solving instance: 103...
	 start solving instance: 140...
	 start solving instance: 84...
	 start solving instance: 143...
	 start solving instance: 34...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 0.8045052289962769
		 value loss: 1.791150450706482
		 entropy bonus: 4.918492317199707
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 5.525210380554199
		 value loss: 15.65080738067627
		 entropy bonus: 2.7616724967956543
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.19478178024292
		 value loss: 0.4121507406234741
		 entropy bonus: 0.19005754590034485
		 -----------------
	 Multi-agent batch loss: -7.424658298492432 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 0.8064940571784973
		 value loss: 1.791150450706482
		 entropy bonus: 4.918504238128662
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 5.524988174438477
		 value loss: 15.65080738067627
		 entropy bonus: 2.762117624282837
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.1922862529754639
		 value loss: 0.4121507406234741
		 entropy bonus: 0.18845975399017334
		 -----------------
	 Multi-agent batch loss: -7.4239182472229 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 0.808077335357666
		 value loss: 1.791150450706482
		 entropy bonus: 4.918272018432617
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 5.522340774536133
		 value loss: 15.65080738067627
		 entropy bonus: 2.7618885040283203
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.1923081874847412
		 value loss: 0.4121507406234741
		 entropy bonus: 0.18848204612731934
		 -----------------
	 Multi-agent batch loss: -7.4228715896606445 - Differentiable computation graph = True!
PPO iteration: 91/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -11.113271713256836
		 value loss: 25.736032485961914
		 entropy bonus: 4.853399276733398
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.70830535888672
		 value loss: 435.1246337890625
		 entropy bonus: 2.628994941711426
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.716964721679688
		 value loss: 17.80317497253418
		 entropy bonus: 0.4934368431568146
		 -----------------
	 Multi-agent batch loss: 69.24542236328125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -11.11470890045166
		 value loss: 25.736032485961914
		 entropy bonus: 4.8533782958984375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.699066162109375
		 value loss: 435.1246337890625
		 entropy bonus: 2.628981113433838
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.713483810424805
		 value loss: 17.80317497253418
		 entropy bonus: 0.4937807321548462
		 -----------------
	 Multi-agent batch loss: 69.234130859375 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -11.107452392578125
		 value loss: 25.736032485961914
		 entropy bonus: 4.853317737579346
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -44.702903747558594
		 value loss: 435.1246337890625
		 entropy bonus: 2.629082441329956
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -8.714109420776367
		 value loss: 17.80317497253418
		 entropy bonus: 0.49384355545043945
		 -----------------
	 Multi-agent batch loss: 69.23133850097656 - Differentiable computation graph = True!
PPO iteration: 92/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -8.507113456726074
		 value loss: 13.055264472961426
		 entropy bonus: 4.859814643859863
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -35.95380401611328
		 value loss: 269.9505310058594
		 entropy bonus: 2.635786533355713
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.4046478271484375
		 value loss: 9.516562461853027
		 entropy bonus: 0.38945457339286804
		 -----------------
	 Multi-agent batch loss: 53.711936950683594 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -8.509377479553223
		 value loss: 13.055264472961426
		 entropy bonus: 4.859569072723389
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -35.957427978515625
		 value loss: 269.9505310058594
		 entropy bonus: 2.6357505321502686
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.404344081878662
		 value loss: 9.516562461853027
		 entropy bonus: 0.38969194889068604
		 -----------------
	 Multi-agent batch loss: 53.717525482177734 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -8.504396438598633
		 value loss: 13.055264472961426
		 entropy bonus: 4.859827995300293
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -35.97200012207031
		 value loss: 269.9505310058594
		 entropy bonus: 2.6354684829711914
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -6.405022144317627
		 value loss: 9.516562461853027
		 entropy bonus: 0.3892286419868469
		 -----------------
	 Multi-agent batch loss: 53.7277946472168 - Differentiable computation graph = True!
PPO iteration: 93/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -7.284303188323975
		 value loss: 7.086538314819336
		 entropy bonus: 4.860140323638916
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -29.60019302368164
		 value loss: 142.65533447265625
		 entropy bonus: 2.6677119731903076
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.528559684753418
		 value loss: 6.02468204498291
		 entropy bonus: 0.37874090671539307
		 -----------------
	 Multi-agent batch loss: 43.89165496826172 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -7.2712907791137695
		 value loss: 7.086538314819336
		 entropy bonus: 4.860025405883789
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -29.596336364746094
		 value loss: 142.65533447265625
		 entropy bonus: 2.6676673889160156
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.528853893280029
		 value loss: 6.02468204498291
		 entropy bonus: 0.37887728214263916
		 -----------------
	 Multi-agent batch loss: 43.875083923339844 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -7.2777419090271
		 value loss: 7.086538314819336
		 entropy bonus: 4.8599700927734375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -29.595104217529297
		 value loss: 142.65533447265625
		 entropy bonus: 2.667348861694336
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.529128074645996
		 value loss: 6.02468204498291
		 entropy bonus: 0.37890762090682983
		 -----------------
	 Multi-agent batch loss: 43.880577087402344 - Differentiable computation graph = True!
PPO iteration: 94/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.716175079345703
		 value loss: 6.530399799346924
		 entropy bonus: 4.87394380569458
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -24.512216567993164
		 value loss: 107.76742553710938
		 entropy bonus: 2.6310524940490723
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.503783702850342
		 value loss: 3.832914352416992
		 entropy bonus: 0.5031791925430298
		 -----------------
	 Multi-agent batch loss: 36.833404541015625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.717322826385498
		 value loss: 6.530399799346924
		 entropy bonus: 4.873786926269531
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -24.514598846435547
		 value loss: 107.76742553710938
		 entropy bonus: 2.6308348178863525
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.502516746520996
		 value loss: 3.832914352416992
		 entropy bonus: 0.5017417669296265
		 -----------------
	 Multi-agent batch loss: 36.8356819152832 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.713443756103516
		 value loss: 6.530399799346924
		 entropy bonus: 4.8737993240356445
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -24.51923179626465
		 value loss: 107.76742553710938
		 entropy bonus: 2.6304802894592285
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.5012383460998535
		 value loss: 3.832914352416992
		 entropy bonus: 0.5013250112533569
		 -----------------
	 Multi-agent batch loss: 36.835166931152344 - Differentiable computation graph = True!
PPO iteration: 95/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.0112714767456055
		 value loss: 4.627542018890381
		 entropy bonus: 4.814856052398682
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -21.984092712402344
		 value loss: 68.41276550292969
		 entropy bonus: 2.7309179306030273
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.143484115600586
		 value loss: 2.798341751098633
		 entropy bonus: 0.5799579620361328
		 -----------------
	 Multi-agent batch loss: 32.81597900390625 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.011866569519043
		 value loss: 4.627542018890381
		 entropy bonus: 4.815074920654297
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -21.984054565429688
		 value loss: 68.41276550292969
		 entropy bonus: 2.730989933013916
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.141839504241943
		 value loss: 2.798341751098633
		 entropy bonus: 0.5795795917510986
		 -----------------
	 Multi-agent batch loss: 32.81489181518555 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.0004682540893555
		 value loss: 4.627542018890381
		 entropy bonus: 4.815280914306641
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -21.983823776245117
		 value loss: 68.41276550292969
		 entropy bonus: 2.730940103530884
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.1402587890625
		 value loss: 2.798341751098633
		 entropy bonus: 0.57912278175354
		 -----------------
	 Multi-agent batch loss: 32.80168151855469 - Differentiable computation graph = True!
PPO iteration: 96/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.183022499084473
		 value loss: 4.917608261108398
		 entropy bonus: 4.871431350708008
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -22.327594757080078
		 value loss: 69.82869720458984
		 entropy bonus: 2.9186832904815674
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.036139965057373
		 value loss: 2.5798702239990234
		 entropy bonus: 0.6732887029647827
		 -----------------
	 Multi-agent batch loss: 33.23538589477539 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.160451889038086
		 value loss: 4.917608261108398
		 entropy bonus: 4.8723249435424805
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -22.32516098022461
		 value loss: 69.82869720458984
		 entropy bonus: 2.9187698364257812
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.034607410430908
		 value loss: 2.5798702239990234
		 entropy bonus: 0.6730712652206421
		 -----------------
	 Multi-agent batch loss: 33.208839416503906 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.160083770751953
		 value loss: 4.917608261108398
		 entropy bonus: 4.872438430786133
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -22.325206756591797
		 value loss: 69.82869720458984
		 entropy bonus: 2.9184508323669434
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.0340447425842285
		 value loss: 2.5798702239990234
		 entropy bonus: 0.6716482639312744
		 -----------------
	 Multi-agent batch loss: 33.207969665527344 - Differentiable computation graph = True!
PPO iteration: 97/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.560426712036133
		 value loss: 3.94815993309021
		 entropy bonus: 4.907147407531738
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -19.47223663330078
		 value loss: 54.010501861572266
		 entropy bonus: 2.486697196960449
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.799983024597168
		 value loss: 2.4750900268554688
		 entropy bonus: 0.5936622619628906
		 -----------------
	 Multi-agent batch loss: 29.35711097717285 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.562034606933594
		 value loss: 3.94815993309021
		 entropy bonus: 4.907217025756836
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -19.470224380493164
		 value loss: 54.010501861572266
		 entropy bonus: 2.4867324829101562
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.8016252517700195
		 value loss: 2.4750900268554688
		 entropy bonus: 0.5935955047607422
		 -----------------
	 Multi-agent batch loss: 29.358346939086914 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.559179782867432
		 value loss: 3.94815993309021
		 entropy bonus: 4.907224178314209
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -19.47079849243164
		 value loss: 54.010501861572266
		 entropy bonus: 2.486607074737549
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.801774501800537
		 value loss: 2.4750900268554688
		 entropy bonus: 0.5933436155319214
		 -----------------
	 Multi-agent batch loss: 29.356220245361328 - Differentiable computation graph = True!
PPO iteration: 98/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.032740592956543
		 value loss: 4.426892280578613
		 entropy bonus: 4.872917175292969
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -22.02703094482422
		 value loss: 65.70198822021484
		 entropy bonus: 2.515369176864624
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.057608604431152
		 value loss: 2.67911958694458
		 entropy bonus: 0.6088184714317322
		 -----------------
	 Multi-agent batch loss: 32.76548767089844 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.033044338226318
		 value loss: 4.426892280578613
		 entropy bonus: 4.8729095458984375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -22.03113555908203
		 value loss: 65.70198822021484
		 entropy bonus: 2.5148792266845703
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.048489570617676
		 value loss: 2.67911958694458
		 entropy bonus: 0.6101441979408264
		 -----------------
	 Multi-agent batch loss: 32.760772705078125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.036901473999023
		 value loss: 4.426892280578613
		 entropy bonus: 4.872900009155273
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -22.01463508605957
		 value loss: 65.70198822021484
		 entropy bonus: 2.5134477615356445
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.0430803298950195
		 value loss: 2.67911958694458
		 entropy bonus: 0.6097255945205688
		 -----------------
	 Multi-agent batch loss: 32.74273681640625 - Differentiable computation graph = True!
PPO iteration: 99/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.925396919250488
		 value loss: 4.354682922363281
		 entropy bonus: 4.866860389709473
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -21.425899505615234
		 value loss: 60.58893585205078
		 entropy bonus: 2.605959892272949
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.92879581451416
		 value loss: 2.320838689804077
		 entropy bonus: 0.45138758420944214
		 -----------------
	 Multi-agent batch loss: 31.873493194580078 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.92503547668457
		 value loss: 4.354682922363281
		 entropy bonus: 4.866876602172852
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -21.43252182006836
		 value loss: 60.58893585205078
		 entropy bonus: 2.6051557064056396
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.9287304878234863
		 value loss: 2.320838689804077
		 entropy bonus: 0.4514922499656677
		 -----------------
	 Multi-agent batch loss: 31.879695892333984 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.9243974685668945
		 value loss: 4.354682922363281
		 entropy bonus: 4.866883277893066
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -21.403759002685547
		 value loss: 60.58893585205078
		 entropy bonus: 2.60505747795105
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.9298388957977295
		 value loss: 2.320838689804077
		 entropy bonus: 0.44975560903549194
		 -----------------
	 Multi-agent batch loss: 31.851421356201172 - Differentiable computation graph = True!
PPO iteration: 100/150:
	 start solving instance: 70...
	 start solving instance: 142...
	 start solving instance: 118...
	 start solving instance: 94...
	 start solving instance: 20...
	 start solving instance: 12...
	 start solving instance: 100...
	 start solving instance: 76...
	 start solving instance: 7...
	 start solving instance: 141...
	 start solving instance: 103...
	 start solving instance: 106...
	 start solving instance: 109...
	 start solving instance: 95...
	 start solving instance: 120...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.397710800170898
		 value loss: 5.181248664855957
		 entropy bonus: 4.923497676849365
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -23.701601028442383
		 value loss: 79.38370513916016
		 entropy bonus: 2.544769048690796
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.379641056060791
		 value loss: 3.019886016845703
		 entropy bonus: 0.46052128076553345
		 -----------------
	 Multi-agent batch loss: 35.2755126953125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.398344039916992
		 value loss: 5.181248664855957
		 entropy bonus: 4.923573017120361
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -23.73345184326172
		 value loss: 79.38370513916016
		 entropy bonus: 2.544640064239502
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.379458427429199
		 value loss: 3.019886016845703
		 entropy bonus: 0.4608840346336365
		 -----------------
	 Multi-agent batch loss: 35.30781173706055 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -6.39868688583374
		 value loss: 5.181248664855957
		 entropy bonus: 4.923595905303955
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -23.728412628173828
		 value loss: 79.38370513916016
		 entropy bonus: 2.5444068908691406
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -4.380249977111816
		 value loss: 3.019886016845703
		 entropy bonus: 0.46095696091651917
		 -----------------
	 Multi-agent batch loss: 35.30390930175781 - Differentiable computation graph = True!
PPO iteration: 101/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.937830924987793
		 value loss: 2.887758731842041
		 entropy bonus: 4.783332824707031
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.083553314208984
		 value loss: 24.90884780883789
		 entropy bonus: 2.7263739109039307
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.867788314819336
		 value loss: 0.6062512397766113
		 entropy bonus: 0.1941801756620407
		 -----------------
	 Multi-agent batch loss: 21.096162796020508 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.937863349914551
		 value loss: 2.887758731842041
		 entropy bonus: 4.783331871032715
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.09083366394043
		 value loss: 24.90884780883789
		 entropy bonus: 2.7263848781585693
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.8676848411560059
		 value loss: 0.6062512397766113
		 entropy bonus: 0.19432812929153442
		 -----------------
	 Multi-agent batch loss: 21.103370666503906 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.93789005279541
		 value loss: 2.887758731842041
		 entropy bonus: 4.783330917358398
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.082983016967773
		 value loss: 24.90884780883789
		 entropy bonus: 2.72635555267334
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.8675813674926758
		 value loss: 0.6062512397766113
		 entropy bonus: 0.19446659088134766
		 -----------------
	 Multi-agent batch loss: 21.095441818237305 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: -2.447446823120117
		 value loss: 1.1952950954437256
		 entropy bonus: 3.1850318908691406
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -6.870025157928467
		 value loss: 9.42592716217041
		 entropy bonus: 1.3664010763168335
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -0.9875662922859192
		 value loss: 0.23168450593948364
		 entropy bonus: 0.138136088848114
		 -----------------
	 Multi-agent batch loss: 10.3667
PPO iteration: 102/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.937830924987793
		 value loss: 2.9098823070526123
		 entropy bonus: 4.815762996673584
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.114058494567871
		 value loss: 29.573278427124023
		 entropy bonus: 2.735720157623291
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.0824766159057617
		 value loss: 0.751899003982544
		 entropy bonus: 0.2010325938463211
		 -----------------
	 Multi-agent batch loss: 22.389190673828125 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.938011646270752
		 value loss: 2.9098823070526123
		 entropy bonus: 4.815758228302002
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.12309455871582
		 value loss: 29.573278427124023
		 entropy bonus: 2.7356743812561035
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.082412004470825
		 value loss: 0.751899003982544
		 entropy bonus: 0.20105306804180145
		 -----------------
	 Multi-agent batch loss: 22.39834213256836 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.937967777252197
		 value loss: 2.9098823070526123
		 entropy bonus: 4.815756320953369
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.116325378417969
		 value loss: 29.573278427124023
		 entropy bonus: 2.735734701156616
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.0823440551757812
		 value loss: 0.751899003982544
		 entropy bonus: 0.20107446610927582
		 -----------------
	 Multi-agent batch loss: 22.391462326049805 - Differentiable computation graph = True!
PPO iteration: 103/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.98076868057251
		 value loss: 3.231290340423584
		 entropy bonus: 4.7937421798706055
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.448524475097656
		 value loss: 29.377548217773438
		 entropy bonus: 2.7841148376464844
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.8248507976531982
		 value loss: 0.6461968421936035
		 entropy bonus: 0.1330946981906891
		 -----------------
	 Multi-agent batch loss: 21.509584426879883 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.9807610511779785
		 value loss: 3.231290340423584
		 entropy bonus: 4.7937421798706055
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.450037002563477
		 value loss: 29.377548217773438
		 entropy bonus: 2.7841334342956543
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.8247524499893188
		 value loss: 0.6461968421936035
		 entropy bonus: 0.1331813484430313
		 -----------------
	 Multi-agent batch loss: 21.510990142822266 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.980746269226074
		 value loss: 3.231290340423584
		 entropy bonus: 4.7937421798706055
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.453668594360352
		 value loss: 29.377548217773438
		 entropy bonus: 2.7842354774475098
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.824650764465332
		 value loss: 0.6461968421936035
		 entropy bonus: 0.1332685500383377
		 -----------------
	 Multi-agent batch loss: 21.514503479003906 - Differentiable computation graph = True!
PPO iteration: 104/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.401110649108887
		 value loss: 2.2157511711120605
		 entropy bonus: 4.776166915893555
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -13.117454528808594
		 value loss: 21.04733657836914
		 entropy bonus: 2.7526400089263916
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.7389752864837646
		 value loss: 0.555243730545044
		 entropy bonus: 0.12609197199344635
		 -----------------
	 Multi-agent batch loss: 19.419174194335938 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.40111780166626
		 value loss: 2.2157511711120605
		 entropy bonus: 4.776166915893555
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -13.118522644042969
		 value loss: 21.04733657836914
		 entropy bonus: 2.752647638320923
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.7390990257263184
		 value loss: 0.555243730545044
		 entropy bonus: 0.12618520855903625
		 -----------------
	 Multi-agent batch loss: 19.420372009277344 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.401121616363525
		 value loss: 2.2157511711120605
		 entropy bonus: 4.776167392730713
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -13.118303298950195
		 value loss: 21.04733657836914
		 entropy bonus: 2.752694606781006
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.7391846179962158
		 value loss: 0.555243730545044
		 entropy bonus: 0.1262495368719101
		 -----------------
	 Multi-agent batch loss: 19.420242309570312 - Differentiable computation graph = True!
PPO iteration: 105/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.1954569816589355
		 value loss: 3.136035919189453
		 entropy bonus: 4.803048133850098
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.07111930847168
		 value loss: 28.234172821044922
		 entropy bonus: 2.825740337371826
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.9107260704040527
		 value loss: 0.6781532764434814
		 entropy bonus: 0.2882418632507324
		 -----------------
	 Multi-agent batch loss: 22.418615341186523 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.195445537567139
		 value loss: 3.136035919189453
		 entropy bonus: 4.803049087524414
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.071344375610352
		 value loss: 28.234172821044922
		 entropy bonus: 2.8258368968963623
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.9107378721237183
		 value loss: 0.6781532764434814
		 entropy bonus: 0.28827160596847534
		 -----------------
	 Multi-agent batch loss: 22.418840408325195 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.195433616638184
		 value loss: 3.136035919189453
		 entropy bonus: 4.8030500411987305
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.074806213378906
		 value loss: 28.234172821044922
		 entropy bonus: 2.8258473873138428
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.910738229751587
		 value loss: 0.6781532764434814
		 entropy bonus: 0.2882978916168213
		 -----------------
	 Multi-agent batch loss: 22.422290802001953 - Differentiable computation graph = True!
PPO iteration: 106/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.388676166534424
		 value loss: 3.565911293029785
		 entropy bonus: 4.757815837860107
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.77055549621582
		 value loss: 29.472488403320312
		 entropy bonus: 2.638042449951172
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.9536638259887695
		 value loss: 0.657873272895813
		 entropy bonus: 0.2714634835720062
		 -----------------
	 Multi-agent batch loss: 22.373184204101562 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.388621807098389
		 value loss: 3.565911293029785
		 entropy bonus: 4.757817268371582
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.77039623260498
		 value loss: 29.472488403320312
		 entropy bonus: 2.638106346130371
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.9536447525024414
		 value loss: 0.657873272895813
		 entropy bonus: 0.2714572846889496
		 -----------------
	 Multi-agent batch loss: 22.37295150756836 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.388489723205566
		 value loss: 3.565911293029785
		 entropy bonus: 4.757818698883057
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.770719528198242
		 value loss: 29.472488403320312
		 entropy bonus: 2.638216018676758
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -1.9535844326019287
		 value loss: 0.657873272895813
		 entropy bonus: 0.27142393589019775
		 -----------------
	 Multi-agent batch loss: 22.37308120727539 - Differentiable computation graph = True!
PPO iteration: 107/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.173987865447998
		 value loss: 3.112990140914917
		 entropy bonus: 4.811866760253906
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.801061630249023
		 value loss: 33.657569885253906
		 entropy bonus: 2.732912063598633
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.0824766159057617
		 value loss: 0.8207282423973083
		 entropy bonus: 0.2978283166885376
		 -----------------
	 Multi-agent batch loss: 23.35501480102539 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.173999786376953
		 value loss: 3.112990140914917
		 entropy bonus: 4.811868667602539
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.802421569824219
		 value loss: 33.657569885253906
		 entropy bonus: 2.733008861541748
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.08249568939209
		 value loss: 0.8207282423973083
		 entropy bonus: 0.2978268265724182
		 -----------------
	 Multi-agent batch loss: 23.356403350830078 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.174009323120117
		 value loss: 3.112990140914917
		 entropy bonus: 4.8118696212768555
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.797975540161133
		 value loss: 33.657569885253906
		 entropy bonus: 2.733093738555908
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.082486629486084
		 value loss: 0.8207282423973083
		 entropy bonus: 0.2978351414203644
		 -----------------
	 Multi-agent batch loss: 23.351957321166992 - Differentiable computation graph = True!
PPO iteration: 108/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.959299564361572
		 value loss: 3.0509209632873535
		 entropy bonus: 4.766907691955566
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.963775634765625
		 value loss: 28.87729835510254
		 entropy bonus: 2.7310383319854736
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.0610079765319824
		 value loss: 0.7153334617614746
		 entropy bonus: 0.276183545589447
		 -----------------
	 Multi-agent batch loss: 22.232776641845703 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.959249496459961
		 value loss: 3.0509209632873535
		 entropy bonus: 4.766908645629883
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.963970184326172
		 value loss: 28.87729835510254
		 entropy bonus: 2.7311208248138428
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.060972213745117
		 value loss: 0.7153334617614746
		 entropy bonus: 0.27621933817863464
		 -----------------
	 Multi-agent batch loss: 22.23288345336914 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.959195137023926
		 value loss: 3.0509209632873535
		 entropy bonus: 4.766909599304199
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.964410781860352
		 value loss: 28.87729835510254
		 entropy bonus: 2.731544017791748
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.0609264373779297
		 value loss: 0.7153334617614746
		 entropy bonus: 0.27626317739486694
		 -----------------
	 Multi-agent batch loss: 22.23322105407715 - Differentiable computation graph = True!
PPO iteration: 109/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.131050109863281
		 value loss: 3.1787467002868652
		 entropy bonus: 4.810621738433838
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.7490873336792
		 value loss: 28.54360008239746
		 entropy bonus: 2.7278213500976562
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.039539098739624
		 value loss: 0.7426807880401611
		 entropy bonus: 0.3209976255893707
		 -----------------
	 Multi-agent batch loss: 22.165733337402344 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.130046844482422
		 value loss: 3.1787467002868652
		 entropy bonus: 4.810635566711426
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.760931015014648
		 value loss: 28.54360008239746
		 entropy bonus: 2.728013515472412
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.041111469268799
		 value loss: 0.7426807880401611
		 entropy bonus: 0.3187306523323059
		 -----------------
	 Multi-agent batch loss: 22.178165435791016 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.130073547363281
		 value loss: 3.1787467002868652
		 entropy bonus: 4.810643196105957
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -14.759096145629883
		 value loss: 28.54360008239746
		 entropy bonus: 2.7271878719329834
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.042970895767212
		 value loss: 0.7426807880401611
		 entropy bonus: 0.3167153000831604
		 -----------------
	 Multi-agent batch loss: 22.178245544433594 - Differentiable computation graph = True!
PPO iteration: 110/150:
	 start solving instance: 95...
	 start solving instance: 75...
	 start solving instance: 109...
	 start solving instance: 122...
	 start solving instance: 55...
	 start solving instance: 51...
	 start solving instance: 128...
	 start solving instance: 61...
	 start solving instance: 24...
	 start solving instance: 127...
	 start solving instance: 13...
	 start solving instance: 34...
	 start solving instance: 59...
	 start solving instance: 134...
	 start solving instance: 94...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.085864067077637
		 value loss: 23.958965301513672
		 entropy bonus: 4.762425422668457
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.47503662109375
		 value loss: 219.11160278320312
		 entropy bonus: 2.900388240814209
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.477835178375244
		 value loss: 5.336291790008545
		 entropy bonus: 0.2475208044052124
		 -----------------
	 Multi-agent batch loss: 63.443702697753906 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.056755065917969
		 value loss: 23.958965301513672
		 entropy bonus: 4.762261390686035
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.44646453857422
		 value loss: 219.11160278320312
		 entropy bonus: 2.899965763092041
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.475574016571045
		 value loss: 5.336291790008545
		 entropy bonus: 0.2476537823677063
		 -----------------
	 Multi-agent batch loss: 63.383766174316406 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -14.057822227478027
		 value loss: 23.958965301513672
		 entropy bonus: 4.762043476104736
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -41.4400634765625
		 value loss: 219.11160278320312
		 entropy bonus: 2.899982452392578
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -5.468012809753418
		 value loss: 5.336291790008545
		 entropy bonus: 0.24830511212348938
		 -----------------
	 Multi-agent batch loss: 63.37086486816406 - Differentiable computation graph = True!
PPO iteration: 111/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.229175567626953
		 value loss: 3.7405507564544678
		 entropy bonus: 4.895177364349365
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.803525924682617
		 value loss: 50.393592834472656
		 entropy bonus: 2.336897373199463
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.6510705947875977
		 value loss: 1.3925024271011353
		 entropy bonus: 0.283780038356781
		 -----------------
	 Multi-agent batch loss: 26.163881301879883 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.235743522644043
		 value loss: 3.7405507564544678
		 entropy bonus: 4.89606237411499
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.797395706176758
		 value loss: 50.393592834472656
		 entropy bonus: 2.3354246616363525
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.6509859561920166
		 value loss: 1.3925024271011353
		 entropy bonus: 0.28388965129852295
		 -----------------
	 Multi-agent batch loss: 26.16423988342285 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.235743522644043
		 value loss: 3.7405507564544678
		 entropy bonus: 4.89606237411499
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.797731399536133
		 value loss: 50.393592834472656
		 entropy bonus: 2.3354179859161377
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.650881767272949
		 value loss: 1.3925024271011353
		 entropy bonus: 0.2839227318763733
		 -----------------
	 Multi-agent batch loss: 26.164470672607422 - Differentiable computation graph = True!
PPO iteration: 112/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.864349365234375
		 value loss: 3.4719882011413574
		 entropy bonus: 4.863753795623779
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.614566802978516
		 value loss: 40.155067443847656
		 entropy bonus: 2.2098746299743652
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.5781054496765137
		 value loss: 1.3148126602172852
		 entropy bonus: 0.27355262637138367
		 -----------------
	 Multi-agent batch loss: 23.432968139648438 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.864349365234375
		 value loss: 3.4719882011413574
		 entropy bonus: 4.863753795623779
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.614368438720703
		 value loss: 40.155067443847656
		 entropy bonus: 2.209892511367798
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.578144073486328
		 value loss: 1.3148126602172852
		 entropy bonus: 0.27336370944976807
		 -----------------
	 Multi-agent batch loss: 23.432811737060547 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.864349365234375
		 value loss: 3.4719882011413574
		 entropy bonus: 4.863753795623779
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.614045143127441
		 value loss: 40.155067443847656
		 entropy bonus: 2.2099287509918213
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.578174114227295
		 value loss: 1.3148126602172852
		 entropy bonus: 0.2731967568397522
		 -----------------
	 Multi-agent batch loss: 23.432518005371094 - Differentiable computation graph = True!
PPO iteration: 113/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.2048540115356445
		 value loss: 3.7646069526672363
		 entropy bonus: 4.951427459716797
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -18.071063995361328
		 value loss: 52.55353546142578
		 entropy bonus: 2.4035348892211914
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.064540147781372
		 value loss: 1.8495711088180542
		 entropy bonus: 0.30235451459884644
		 -----------------
	 Multi-agent batch loss: 26.845563888549805 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.2048540115356445
		 value loss: 3.7646069526672363
		 entropy bonus: 4.951427459716797
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -18.070850372314453
		 value loss: 52.55353546142578
		 entropy bonus: 2.4035756587982178
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.0645289421081543
		 value loss: 1.8495711088180542
		 entropy bonus: 0.30231940746307373
		 -----------------
	 Multi-agent batch loss: 26.8453369140625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.2048540115356445
		 value loss: 3.7646069526672363
		 entropy bonus: 4.951427459716797
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -18.06998062133789
		 value loss: 52.55353546142578
		 entropy bonus: 2.4036126136779785
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -3.0644726753234863
		 value loss: 1.8495711088180542
		 entropy bonus: 0.3023129105567932
		 -----------------
	 Multi-agent batch loss: 26.844409942626953 - Differentiable computation graph = True!
PPO iteration: 114/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.4237494468688965
		 value loss: 4.051310062408447
		 entropy bonus: 4.980435371398926
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.779203414916992
		 value loss: 50.338768005371094
		 entropy bonus: 2.234978199005127
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.797001361846924
		 value loss: 1.443769931793213
		 entropy bonus: 0.4031803607940674
		 -----------------
	 Multi-agent batch loss: 26.482105255126953 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.4237494468688965
		 value loss: 4.051310062408447
		 entropy bonus: 4.980435371398926
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.77668571472168
		 value loss: 50.338768005371094
		 entropy bonus: 2.235034465789795
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.7970032691955566
		 value loss: 1.443769931793213
		 entropy bonus: 0.40323781967163086
		 -----------------
	 Multi-agent batch loss: 26.479589462280273 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.4237494468688965
		 value loss: 4.051310062408447
		 entropy bonus: 4.980435371398926
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.77627182006836
		 value loss: 50.338768005371094
		 entropy bonus: 2.2350921630859375
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.7969908714294434
		 value loss: 1.443769931793213
		 entropy bonus: 0.4032989740371704
		 -----------------
	 Multi-agent batch loss: 26.479162216186523 - Differentiable computation graph = True!
PPO iteration: 115/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.375105857849121
		 value loss: 3.965338706970215
		 entropy bonus: 4.915248870849609
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.41437530517578
		 value loss: 49.265708923339844
		 entropy bonus: 2.272308826446533
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.9429314136505127
		 value loss: 1.5991497039794922
		 entropy bonus: 0.23376935720443726
		 -----------------
	 Multi-agent batch loss: 26.206501007080078 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.375105857849121
		 value loss: 3.965338706970215
		 entropy bonus: 4.915248870849609
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.414432525634766
		 value loss: 49.265708923339844
		 entropy bonus: 2.272357940673828
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.9429445266723633
		 value loss: 1.5991497039794922
		 entropy bonus: 0.23378834128379822
		 -----------------
	 Multi-agent batch loss: 26.20656967163086 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.375105857849121
		 value loss: 3.965338706970215
		 entropy bonus: 4.915248870849609
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.414453506469727
		 value loss: 49.265708923339844
		 entropy bonus: 2.2723960876464844
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.9429519176483154
		 value loss: 1.5991497039794922
		 entropy bonus: 0.23380190134048462
		 -----------------
	 Multi-agent batch loss: 26.20659828186035 - Differentiable computation graph = True!
PPO iteration: 116/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.107566833496094
		 value loss: 3.4254531860351562
		 entropy bonus: 4.8881072998046875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.882104873657227
		 value loss: 35.92154312133789
		 entropy bonus: 2.3709917068481445
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.383531093597412
		 value loss: 0.9709265232086182
		 entropy bonus: 0.403186559677124
		 -----------------
	 Multi-agent batch loss: 23.699758529663086 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.107566833496094
		 value loss: 3.4254531860351562
		 entropy bonus: 4.8881072998046875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.882183074951172
		 value loss: 35.92154312133789
		 entropy bonus: 2.3710169792175293
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.3834619522094727
		 value loss: 0.9709265232086182
		 entropy bonus: 0.40318918228149414
		 -----------------
	 Multi-agent batch loss: 23.69976806640625 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.107566833496094
		 value loss: 3.4254531860351562
		 entropy bonus: 4.8881072998046875
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.882192611694336
		 value loss: 35.92154312133789
		 entropy bonus: 2.371041774749756
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.383333921432495
		 value loss: 0.9709265232086182
		 entropy bonus: 0.4031912088394165
		 -----------------
	 Multi-agent batch loss: 23.699649810791016 - Differentiable computation graph = True!
PPO iteration: 117/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.767062664031982
		 value loss: 3.0555388927459717
		 entropy bonus: 4.984109878540039
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.298381805419922
		 value loss: 33.574283599853516
		 entropy bonus: 2.4358952045440674
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.480818271636963
		 value loss: 1.3132351636886597
		 entropy bonus: 0.3691736161708832
		 -----------------
	 Multi-agent batch loss: 22.847801208496094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.767062664031982
		 value loss: 3.0555388927459717
		 entropy bonus: 4.984109878540039
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.294163703918457
		 value loss: 33.574283599853516
		 entropy bonus: 2.4360170364379883
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.480876922607422
		 value loss: 1.3132351636886597
		 entropy bonus: 0.3691736161708832
		 -----------------
	 Multi-agent batch loss: 22.84364128112793 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -4.767062664031982
		 value loss: 3.0555388927459717
		 entropy bonus: 4.984109878540039
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -15.293859481811523
		 value loss: 33.574283599853516
		 entropy bonus: 2.4360692501068115
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.48089337348938
		 value loss: 1.3132351636886597
		 entropy bonus: 0.36917242407798767
		 -----------------
	 Multi-agent batch loss: 22.843353271484375 - Differentiable computation graph = True!
PPO iteration: 118/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.083245277404785
		 value loss: 3.8186347484588623
		 entropy bonus: 4.88706111907959
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.7548828125
		 value loss: 52.647003173828125
		 entropy bonus: 2.393991231918335
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.991574764251709
		 value loss: 1.8775709867477417
		 entropy bonus: 0.2219083309173584
		 -----------------
	 Multi-agent batch loss: 26.338106155395508 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.083245277404785
		 value loss: 3.8186347484588623
		 entropy bonus: 4.88706111907959
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.754730224609375
		 value loss: 52.647003173828125
		 entropy bonus: 2.394017457962036
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.991567611694336
		 value loss: 1.8775709867477417
		 entropy bonus: 0.22192448377609253
		 -----------------
	 Multi-agent batch loss: 26.33794403076172 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.083245277404785
		 value loss: 3.8186347484588623
		 entropy bonus: 4.88706111907959
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.754724502563477
		 value loss: 52.647003173828125
		 entropy bonus: 2.394043445587158
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.9915554523468018
		 value loss: 1.8775709867477417
		 entropy bonus: 0.2219453752040863
		 -----------------
	 Multi-agent batch loss: 26.337926864624023 - Differentiable computation graph = True!
PPO iteration: 119/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.691288948059082
		 value loss: 4.220492839813232
		 entropy bonus: 4.990505695343018
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.341411590576172
		 value loss: 45.02824401855469
		 entropy bonus: 2.317629814147949
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.7483575344085693
		 value loss: 1.4761078357696533
		 entropy bonus: 0.2957528233528137
		 -----------------
	 Multi-agent batch loss: 26.212268829345703 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.691288948059082
		 value loss: 4.220492839813232
		 entropy bonus: 4.990505695343018
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.341365814208984
		 value loss: 45.02824401855469
		 entropy bonus: 2.3176541328430176
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.748256206512451
		 value loss: 1.4761078357696533
		 entropy bonus: 0.2957363724708557
		 -----------------
	 Multi-agent batch loss: 26.212121963500977 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.691288948059082
		 value loss: 4.220492839813232
		 entropy bonus: 4.990505695343018
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.341272354125977
		 value loss: 45.02824401855469
		 entropy bonus: 2.3176865577697754
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.748054027557373
		 value loss: 1.4761078357696533
		 entropy bonus: 0.2956918478012085
		 -----------------
	 Multi-agent batch loss: 26.21182632446289 - Differentiable computation graph = True!
PPO iteration: 120/150:
	 start solving instance: 62...
	 start solving instance: 59...
	 start solving instance: 110...
	 start solving instance: 89...
	 start solving instance: 149...
	 start solving instance: 67...
	 start solving instance: 43...
	 start solving instance: 12...
	 start solving instance: 71...
	 start solving instance: 114...
	 start solving instance: 142...
	 start solving instance: 93...
	 start solving instance: 107...
	 start solving instance: 42...
	 start solving instance: 76...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.253497123718262
		 value loss: 4.099816799163818
		 entropy bonus: 4.864832401275635
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -18.022422790527344
		 value loss: 55.66034698486328
		 entropy bonus: 2.2537028789520264
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.9672532081604004
		 value loss: 1.7470364570617676
		 entropy bonus: 0.37844958901405334
		 -----------------
	 Multi-agent batch loss: 26.783273696899414 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.253497123718262
		 value loss: 4.099816799163818
		 entropy bonus: 4.864832401275635
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -18.022369384765625
		 value loss: 55.66034698486328
		 entropy bonus: 2.253757953643799
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.967311382293701
		 value loss: 1.7470364570617676
		 entropy bonus: 0.3784674406051636
		 -----------------
	 Multi-agent batch loss: 26.783279418945312 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.253497123718262
		 value loss: 4.099816799163818
		 entropy bonus: 4.864832401275635
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -18.022293090820312
		 value loss: 55.66034698486328
		 entropy bonus: 2.25380802154541
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.967334270477295
		 value loss: 1.7470364570617676
		 entropy bonus: 0.3784785866737366
		 -----------------
	 Multi-agent batch loss: 26.783226013183594 - Differentiable computation graph = True!
PPO iteration: 121/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.642645359039307
		 value loss: 4.2086615562438965
		 entropy bonus: 4.805053234100342
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.633304595947266
		 value loss: 47.594783782958984
		 entropy bonus: 2.6587140560150146
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.7483575344085693
		 value loss: 1.5376286506652832
		 entropy bonus: 0.19157423079013824
		 -----------------
	 Multi-agent batch loss: 26.48116683959961 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.642645359039307
		 value loss: 4.2086615562438965
		 entropy bonus: 4.805053234100342
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.624549865722656
		 value loss: 47.594783782958984
		 entropy bonus: 2.658787727355957
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.7471508979797363
		 value loss: 1.5376286506652832
		 entropy bonus: 0.19128063321113586
		 -----------------
	 Multi-agent batch loss: 26.471206665039062 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: -5.642645359039307
		 value loss: 4.2086615562438965
		 entropy bonus: 4.805053234100342
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: -17.62112045288086
		 value loss: 47.594783782958984
		 entropy bonus: 2.658133029937744
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: -2.748708724975586
		 value loss: 1.5376286506652832
		 entropy bonus: 0.19168275594711304
		 -----------------
	 Multi-agent batch loss: 26.469337463378906 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: 4.091368675231934
		 value loss: 3.379502773284912
		 entropy bonus: 3.187406539916992
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.349098205566406
		 value loss: 24.269115447998047
		 entropy bonus: 1.3924665451049805
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4586617946624756
		 value loss: 0.481821745634079
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -16.6636
PPO iteration: 122/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 7.07834529876709
		 value loss: 6.838581085205078
		 entropy bonus: 4.873876571655273
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 23.879566192626953
		 value loss: 86.49263000488281
		 entropy bonus: 2.654862642288208
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 3.5556561946868896
		 value loss: 2.45304799079895
		 entropy bonus: 0.0915251076221466
		 -----------------
	 Multi-agent batch loss: -33.631927490234375 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 7.076385498046875
		 value loss: 6.838581085205078
		 entropy bonus: 4.873870849609375
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 23.835798263549805
		 value loss: 86.49263000488281
		 entropy bonus: 2.652947425842285
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 3.5546441078186035
		 value loss: 2.45304799079895
		 entropy bonus: 0.09151779860258102
		 -----------------
	 Multi-agent batch loss: -33.58517074584961 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 7.073836803436279
		 value loss: 6.838581085205078
		 entropy bonus: 4.873834609985352
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 23.81214141845703
		 value loss: 86.49263000488281
		 entropy bonus: 2.6527137756347656
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 3.553842544555664
		 value loss: 2.45304799079895
		 entropy bonus: 0.09177194535732269
		 -----------------
	 Multi-agent batch loss: -33.558162689208984 - Differentiable computation graph = True!
PPO iteration: 123/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 5.639841079711914
		 value loss: 4.036975860595703
		 entropy bonus: 4.82790470123291
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 19.56972312927246
		 value loss: 56.13783264160156
		 entropy bonus: 2.6937124729156494
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.76053524017334
		 value loss: 1.4805326461791992
		 entropy bonus: 0.120674267411232
		 -----------------
	 Multi-agent batch loss: -27.429969787597656 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 5.639064788818359
		 value loss: 4.036975860595703
		 entropy bonus: 4.827892303466797
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 19.56656265258789
		 value loss: 56.13783264160156
		 entropy bonus: 2.6937997341156006
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.760632038116455
		 value loss: 1.4805326461791992
		 entropy bonus: 0.12070515751838684
		 -----------------
	 Multi-agent batch loss: -27.426128387451172 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 5.643777847290039
		 value loss: 4.036975860595703
		 entropy bonus: 4.828028678894043
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 19.556785583496094
		 value loss: 56.13783264160156
		 entropy bonus: 2.6951310634613037
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.762509822845459
		 value loss: 1.4805326461791992
		 entropy bonus: 0.12047100067138672
		 -----------------
	 Multi-agent batch loss: -27.422954559326172 - Differentiable computation graph = True!
PPO iteration: 124/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 4.058444976806641
		 value loss: 3.5981364250183105
		 entropy bonus: 4.816418647766113
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 15.344191551208496
		 value loss: 57.98037338256836
		 entropy bonus: 2.7240538597106934
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.3806121349334717
		 value loss: 1.7411448955535889
		 entropy bonus: 0.19816547632217407
		 -----------------
	 Multi-agent batch loss: -21.227439880371094 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 4.0552659034729
		 value loss: 3.5981364250183105
		 entropy bonus: 4.816400051116943
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 15.377059936523438
		 value loss: 57.98037338256836
		 entropy bonus: 2.724149465560913
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.3805947303771973
		 value loss: 1.7411448955535889
		 entropy bonus: 0.1981627345085144
		 -----------------
	 Multi-agent batch loss: -21.257110595703125 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 4.052438259124756
		 value loss: 3.5981364250183105
		 entropy bonus: 4.816378593444824
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 15.37984848022461
		 value loss: 57.98037338256836
		 entropy bonus: 2.723961353302002
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.3810713291168213
		 value loss: 1.7411448955535889
		 entropy bonus: 0.19816488027572632
		 -----------------
	 Multi-agent batch loss: -21.25754737854004 - Differentiable computation graph = True!
PPO iteration: 125/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.773592233657837
		 value loss: 1.5880311727523804
		 entropy bonus: 4.842280864715576
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.739495754241943
		 value loss: 22.08115577697754
		 entropy bonus: 2.6991376876831055
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.9838093519210815
		 value loss: 0.5088947415351868
		 entropy bonus: 0.13360604643821716
		 -----------------
	 Multi-agent batch loss: -9.331867218017578 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.7743464708328247
		 value loss: 1.5880311727523804
		 entropy bonus: 4.842278480529785
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.741263389587402
		 value loss: 22.08115577697754
		 entropy bonus: 2.699253559112549
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.9838377237319946
		 value loss: 0.5088947415351868
		 entropy bonus: 0.13357873260974884
		 -----------------
	 Multi-agent batch loss: -9.334417343139648 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.774593472480774
		 value loss: 1.5880311727523804
		 entropy bonus: 4.842268943786621
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.743589401245117
		 value loss: 22.08115577697754
		 entropy bonus: 2.699105739593506
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.9838697910308838
		 value loss: 0.5088947415351868
		 entropy bonus: 0.1335483342409134
		 -----------------
	 Multi-agent batch loss: -9.337020874023438 - Differentiable computation graph = True!
PPO iteration: 126/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.959989070892334
		 value loss: 2.1429126262664795
		 entropy bonus: 4.868999004364014
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.404388427734375
		 value loss: 36.94561767578125
		 entropy bonus: 2.83107852935791
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3624660968780518
		 value loss: 1.1686054468154907
		 entropy bonus: 0.21825352311134338
		 -----------------
	 Multi-agent batch loss: -11.40345573425293 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.960194706916809
		 value loss: 2.1429126262664795
		 entropy bonus: 4.868968963623047
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.404547691345215
		 value loss: 36.94561767578125
		 entropy bonus: 2.831303834915161
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3625199794769287
		 value loss: 1.1686054468154907
		 entropy bonus: 0.2182588279247284
		 -----------------
	 Multi-agent batch loss: -11.403875350952148 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.960456132888794
		 value loss: 2.1429126262664795
		 entropy bonus: 4.868929862976074
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.404730796813965
		 value loss: 36.94561767578125
		 entropy bonus: 2.8313515186309814
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.362588882446289
		 value loss: 1.1686054468154907
		 entropy bonus: 0.218263179063797
		 -----------------
	 Multi-agent batch loss: -11.404390335083008 - Differentiable computation graph = True!
PPO iteration: 127/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.781371831893921
		 value loss: 1.467654824256897
		 entropy bonus: 4.809721946716309
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.217897415161133
		 value loss: 26.986719131469727
		 entropy bonus: 2.7133407592773438
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.1759308576583862
		 value loss: 0.8161017894744873
		 entropy bonus: 0.1037895530462265
		 -----------------
	 Multi-agent batch loss: -9.95876407623291 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.781624674797058
		 value loss: 1.467654824256897
		 entropy bonus: 4.8096795082092285
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.218116283416748
		 value loss: 26.986719131469727
		 entropy bonus: 2.7133686542510986
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.176023244857788
		 value loss: 0.8161017894744873
		 entropy bonus: 0.10378661751747131
		 -----------------
	 Multi-agent batch loss: -9.959327697753906 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.7818827629089355
		 value loss: 1.467654824256897
		 entropy bonus: 4.809628486633301
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.218398094177246
		 value loss: 26.986719131469727
		 entropy bonus: 2.713397264480591
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.1761285066604614
		 value loss: 0.8161017894744873
		 entropy bonus: 0.10378298163414001
		 -----------------
	 Multi-agent batch loss: -9.959972381591797 - Differentiable computation graph = True!
PPO iteration: 128/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.601823329925537
		 value loss: 1.0725313425064087
		 entropy bonus: 4.769449710845947
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.507979393005371
		 value loss: 18.267797470092773
		 entropy bonus: 2.6563620567321777
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.9649532437324524
		 value loss: 0.48675522208213806
		 entropy bonus: 0.12996025383472443
		 -----------------
	 Multi-agent batch loss: -8.952043533325195 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.6018588542938232
		 value loss: 1.0725313425064087
		 entropy bonus: 4.769381999969482
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.508258819580078
		 value loss: 18.267797470092773
		 entropy bonus: 2.656424045562744
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.9649756550788879
		 value loss: 0.48675522208213806
		 entropy bonus: 0.12981151044368744
		 -----------------
	 Multi-agent batch loss: -8.95237922668457 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.6019089221954346
		 value loss: 1.0725313425064087
		 entropy bonus: 4.769306182861328
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.508603572845459
		 value loss: 18.267797470092773
		 entropy bonus: 2.656498908996582
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.9649969935417175
		 value loss: 0.48675522208213806
		 entropy bonus: 0.12966881692409515
		 -----------------
	 Multi-agent batch loss: -8.95279312133789 - Differentiable computation graph = True!
PPO iteration: 129/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.5614601373672485
		 value loss: 1.3023632764816284
		 entropy bonus: 4.8067803382873535
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.195986747741699
		 value loss: 21.168365478515625
		 entropy bonus: 2.6944146156311035
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.0627375841140747
		 value loss: 0.6194140911102295
		 entropy bonus: 0.1748354136943817
		 -----------------
	 Multi-agent batch loss: -8.666043281555176 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.5582823753356934
		 value loss: 1.3023632764816284
		 entropy bonus: 4.806845664978027
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.196277141571045
		 value loss: 21.168365478515625
		 entropy bonus: 2.6944775581359863
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.062679409980774
		 value loss: 0.6194140911102295
		 entropy bonus: 0.17484088242053986
		 -----------------
	 Multi-agent batch loss: -8.66309928894043 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.5554472208023071
		 value loss: 1.3023632764816284
		 entropy bonus: 4.806883811950684
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 6.196640968322754
		 value loss: 21.168365478515625
		 entropy bonus: 2.6945290565490723
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.0626510381698608
		 value loss: 0.6194140911102295
		 entropy bonus: 0.17484241724014282
		 -----------------
	 Multi-agent batch loss: -8.660600662231445 - Differentiable computation graph = True!
PPO iteration: 130/150:
	 start solving instance: 124...
	 start solving instance: 79...
	 start solving instance: 66...
	 start solving instance: 81...
	 start solving instance: 46...
	 start solving instance: 1...
	 start solving instance: 118...
	 start solving instance: 98...
	 start solving instance: 103...
	 start solving instance: 93...
	 start solving instance: 33...
	 start solving instance: 18...
	 start solving instance: 47...
	 start solving instance: 99...
	 start solving instance: 31...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.88279390335083
		 value loss: 1.7633122205734253
		 entropy bonus: 4.811909198760986
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.681854724884033
		 value loss: 30.44188117980957
		 entropy bonus: 2.685356855392456
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.342866063117981
		 value loss: 0.9775609970092773
		 entropy bonus: 0.1008395105600357
		 -----------------
	 Multi-agent batch loss: -10.651668548583984 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.8871562480926514
		 value loss: 1.7633122205734253
		 entropy bonus: 4.811973571777344
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.681726932525635
		 value loss: 30.44188117980957
		 entropy bonus: 2.6853742599487305
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3428847789764404
		 value loss: 0.9775609970092773
		 entropy bonus: 0.10083799809217453
		 -----------------
	 Multi-agent batch loss: -10.655921936035156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 1.8897262811660767
		 value loss: 1.7633122205734253
		 entropy bonus: 4.812100410461426
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.68166446685791
		 value loss: 30.44188117980957
		 entropy bonus: 2.6853790283203125
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3429092168807983
		 value loss: 0.9775609970092773
		 entropy bonus: 0.10083602368831635
		 -----------------
	 Multi-agent batch loss: -10.658455848693848 - Differentiable computation graph = True!
PPO iteration: 131/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.5335144996643066
		 value loss: 2.0163774490356445
		 entropy bonus: 4.818702697753906
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.504958152770996
		 value loss: 23.73538589477539
		 entropy bonus: 2.7564804553985596
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3484795093536377
		 value loss: 0.6958887577056885
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -12.198226928710938 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.5378360748291016
		 value loss: 2.0163774490356445
		 entropy bonus: 4.818842887878418
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.504920959472656
		 value loss: 23.73538589477539
		 entropy bonus: 2.7564597129821777
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3484795093536377
		 value loss: 0.6958887577056885
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -12.202512741088867 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.5357460975646973
		 value loss: 2.0163774490356445
		 entropy bonus: 4.818913459777832
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.50496768951416
		 value loss: 23.73538589477539
		 entropy bonus: 2.756476879119873
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.3484795093536377
		 value loss: 0.6958887577056885
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -12.200469970703125 - Differentiable computation graph = True!
PPO iteration: 132/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.8365859985351562
		 value loss: 2.5764124393463135
		 entropy bonus: 4.859618186950684
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.771687507629395
		 value loss: 35.26760482788086
		 entropy bonus: 2.6016616821289062
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5052212476730347
		 value loss: 0.9825026988983154
		 entropy bonus: 0.08493294566869736
		 -----------------
	 Multi-agent batch loss: -13.800690650939941 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.8365859985351562
		 value loss: 2.5764124393463135
		 entropy bonus: 4.859618186950684
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.771677017211914
		 value loss: 35.26760482788086
		 entropy bonus: 2.601686716079712
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5052378177642822
		 value loss: 0.9825026988983154
		 entropy bonus: 0.08493031561374664
		 -----------------
	 Multi-agent batch loss: -13.800697326660156 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.8365859985351562
		 value loss: 2.5764124393463135
		 entropy bonus: 4.859618186950684
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.771724700927734
		 value loss: 35.26760482788086
		 entropy bonus: 2.6016976833343506
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5052850246429443
		 value loss: 0.9825026988983154
		 entropy bonus: 0.08492409437894821
		 -----------------
	 Multi-agent batch loss: -13.800792694091797 - Differentiable computation graph = True!
PPO iteration: 133/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.2335736751556396
		 value loss: 1.5609710216522217
		 entropy bonus: 4.854054927825928
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.5318474769592285
		 value loss: 18.527339935302734
		 entropy bonus: 2.527963638305664
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2239888906478882
		 value loss: 0.5993272066116333
		 entropy bonus: 0.1328466236591339
		 -----------------
	 Multi-agent batch loss: -10.857682228088379 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.2335736751556396
		 value loss: 1.5609710216522217
		 entropy bonus: 4.854054927825928
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.531984329223633
		 value loss: 18.527339935302734
		 entropy bonus: 2.5279645919799805
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2240592241287231
		 value loss: 0.5993272066116333
		 entropy bonus: 0.13284602761268616
		 -----------------
	 Multi-agent batch loss: -10.857889175415039 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.2335736751556396
		 value loss: 1.5609710216522217
		 entropy bonus: 4.854054927825928
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.532177925109863
		 value loss: 18.527339935302734
		 entropy bonus: 2.527963638305664
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2241698503494263
		 value loss: 0.5993272066116333
		 entropy bonus: 0.13285331428050995
		 -----------------
	 Multi-agent batch loss: -10.858194351196289 - Differentiable computation graph = True!
PPO iteration: 134/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.492560863494873
		 value loss: 2.0022406578063965
		 entropy bonus: 4.816171646118164
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.936714172363281
		 value loss: 25.84122085571289
		 entropy bonus: 2.6566085815429688
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.521120548248291
		 value loss: 0.8623075485229492
		 entropy bonus: 0.045102450996637344
		 -----------------
	 Multi-agent batch loss: -12.738516807556152 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.492560863494873
		 value loss: 2.0022406578063965
		 entropy bonus: 4.816171646118164
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.936965942382812
		 value loss: 25.84122085571289
		 entropy bonus: 2.656618595123291
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5211234092712402
		 value loss: 0.8623075485229492
		 entropy bonus: 0.045091234147548676
		 -----------------
	 Multi-agent batch loss: -12.738771438598633 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.492560863494873
		 value loss: 2.0022406578063965
		 entropy bonus: 4.816171646118164
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 8.937263488769531
		 value loss: 25.84122085571289
		 entropy bonus: 2.6566247940063477
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.521132230758667
		 value loss: 0.8623075485229492
		 entropy bonus: 0.04508272185921669
		 -----------------
	 Multi-agent batch loss: -12.7390775680542 - Differentiable computation graph = True!
PPO iteration: 135/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.3895468711853027
		 value loss: 1.9407060146331787
		 entropy bonus: 4.885307788848877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.4847517013549805
		 value loss: 19.903263092041016
		 entropy bonus: 2.7451672554016113
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2468470335006714
		 value loss: 0.6097606420516968
		 entropy bonus: 0.06871593743562698
		 -----------------
	 Multi-agent batch loss: -10.973600387573242 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.3895468711853027
		 value loss: 1.9407060146331787
		 entropy bonus: 4.885307788848877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.484926223754883
		 value loss: 19.903263092041016
		 entropy bonus: 2.7451508045196533
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.246886968612671
		 value loss: 0.6097606420516968
		 entropy bonus: 0.0686994269490242
		 -----------------
	 Multi-agent batch loss: -10.973814010620117 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.3895468711853027
		 value loss: 1.9407060146331787
		 entropy bonus: 4.885307788848877
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.485136032104492
		 value loss: 19.903263092041016
		 entropy bonus: 2.7451233863830566
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2469298839569092
		 value loss: 0.6097606420516968
		 entropy bonus: 0.06868160516023636
		 -----------------
	 Multi-agent batch loss: -10.974065780639648 - Differentiable computation graph = True!
PPO iteration: 136/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.847707748413086
		 value loss: 2.4854726791381836
		 entropy bonus: 4.869763374328613
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.361130714416504
		 value loss: 28.308156967163086
		 entropy bonus: 2.607551336288452
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4668986797332764
		 value loss: 0.8174852132797241
		 entropy bonus: 0.1021222397685051
		 -----------------
	 Multi-agent batch loss: -13.435420036315918 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.847707748413086
		 value loss: 2.4854726791381836
		 entropy bonus: 4.869763374328613
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.361295700073242
		 value loss: 28.308156967163086
		 entropy bonus: 2.6075210571289062
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.466881275177002
		 value loss: 0.8174852132797241
		 entropy bonus: 0.10211687535047531
		 -----------------
	 Multi-agent batch loss: -13.435567855834961 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.847707748413086
		 value loss: 2.4854726791381836
		 entropy bonus: 4.869763374328613
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.36149787902832
		 value loss: 28.308156967163086
		 entropy bonus: 2.6074986457824707
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4668768644332886
		 value loss: 0.8174852132797241
		 entropy bonus: 0.1021132543683052
		 -----------------
	 Multi-agent batch loss: -13.435765266418457 - Differentiable computation graph = True!
PPO iteration: 137/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.395369291305542
		 value loss: 1.6920464038848877
		 entropy bonus: 4.837409496307373
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.742120742797852
		 value loss: 19.333938598632812
		 entropy bonus: 2.4081430435180664
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2262543439865112
		 value loss: 0.5772970914840698
		 entropy bonus: 0.028426263481378555
		 -----------------
	 Multi-agent batch loss: -11.220451354980469 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.395369291305542
		 value loss: 1.6920464038848877
		 entropy bonus: 4.837409496307373
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.742520809173584
		 value loss: 19.333938598632812
		 entropy bonus: 2.4081287384033203
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.226255178451538
		 value loss: 0.5772970914840698
		 entropy bonus: 0.028427161276340485
		 -----------------
	 Multi-agent batch loss: -11.22085189819336 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.395369291305542
		 value loss: 1.6920464038848877
		 entropy bonus: 4.837409496307373
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 7.742974758148193
		 value loss: 19.333938598632812
		 entropy bonus: 2.4081192016601562
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.2262566089630127
		 value loss: 0.5772970914840698
		 entropy bonus: 0.028428534045815468
		 -----------------
	 Multi-agent batch loss: -11.221307754516602 - Differentiable computation graph = True!
PPO iteration: 138/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.9091460704803467
		 value loss: 2.3757123947143555
		 entropy bonus: 4.830199241638184
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.77436637878418
		 value loss: 27.36234474182129
		 entropy bonus: 2.5226337909698486
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5884655714035034
		 value loss: 0.8613587617874146
		 entropy bonus: 0.11199045926332474
		 -----------------
	 Multi-agent batch loss: -14.040632247924805 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.9091460704803467
		 value loss: 2.3757123947143555
		 entropy bonus: 4.830199241638184
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.774030685424805
		 value loss: 27.36234474182129
		 entropy bonus: 2.5226306915283203
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5884654521942139
		 value loss: 0.8613587617874146
		 entropy bonus: 0.11198779940605164
		 -----------------
	 Multi-agent batch loss: -14.04029655456543 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.9091460704803467
		 value loss: 2.3757123947143555
		 entropy bonus: 4.830199241638184
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.77386474609375
		 value loss: 27.36234474182129
		 entropy bonus: 2.5226387977600098
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.5884673595428467
		 value loss: 0.8613587617874146
		 entropy bonus: 0.11198224872350693
		 -----------------
	 Multi-agent batch loss: -14.040132522583008 - Differentiable computation graph = True!
PPO iteration: 139/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.7654333114624023
		 value loss: 2.204024314880371
		 entropy bonus: 4.772870063781738
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.289385795593262
		 value loss: 28.038043975830078
		 entropy bonus: 2.640955686569214
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4962587356567383
		 value loss: 0.782178521156311
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -13.314973831176758 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.7654333114624023
		 value loss: 2.204024314880371
		 entropy bonus: 4.772870063781738
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.289497375488281
		 value loss: 28.038043975830078
		 entropy bonus: 2.6409568786621094
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4962587356567383
		 value loss: 0.782178521156311
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -13.315085411071777 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.7654333114624023
		 value loss: 2.204024314880371
		 entropy bonus: 4.772870063781738
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.289710998535156
		 value loss: 28.038043975830078
		 entropy bonus: 2.6409406661987305
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4962587356567383
		 value loss: 0.782178521156311
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -13.315299034118652 - Differentiable computation graph = True!
PPO iteration: 140/150:
	 start solving instance: 123...
	 start solving instance: 22...
	 start solving instance: 144...
	 start solving instance: 125...
	 start solving instance: 118...
	 start solving instance: 103...
	 start solving instance: 74...
	 start solving instance: 37...
	 start solving instance: 38...
	 start solving instance: 1...
	 start solving instance: 140...
	 start solving instance: 101...
	 start solving instance: 56...
	 start solving instance: 6...
	 start solving instance: 18...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.973878860473633
		 value loss: 2.8826656341552734
		 entropy bonus: 4.819481372833252
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.255460739135742
		 value loss: 28.737548828125
		 entropy bonus: 2.560063123703003
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4940102100372314
		 value loss: 0.8535228371620178
		 entropy bonus: 0.08602908998727798
		 -----------------
	 Multi-agent batch loss: -13.473268508911133 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.973878860473633
		 value loss: 2.8826656341552734
		 entropy bonus: 4.819481372833252
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.255401611328125
		 value loss: 28.737548828125
		 entropy bonus: 2.560039758682251
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.4940215349197388
		 value loss: 0.8535228371620178
		 entropy bonus: 0.08602993935346603
		 -----------------
	 Multi-agent batch loss: -13.473220825195312 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.973878860473633
		 value loss: 2.8826656341552734
		 entropy bonus: 4.819481372833252
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 9.25539779663086
		 value loss: 28.737548828125
		 entropy bonus: 2.5600218772888184
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.494037389755249
		 value loss: 0.8535228371620178
		 entropy bonus: 0.08603091537952423
		 -----------------
	 Multi-agent batch loss: -13.47323226928711 - Differentiable computation graph = True!
PPO iteration: 141/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.214900016784668
		 value loss: 2.764028549194336
		 entropy bonus: 4.842128753662109
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 13.050636291503906
		 value loss: 47.716487884521484
		 entropy bonus: 2.941622018814087
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.276853084564209
		 value loss: 1.440826654434204
		 entropy bonus: 0.17439471185207367
		 -----------------
	 Multi-agent batch loss: -18.10275650024414 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.214900016784668
		 value loss: 2.764028549194336
		 entropy bonus: 4.842128753662109
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 13.058043479919434
		 value loss: 47.716487884521484
		 entropy bonus: 2.941577434539795
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.2768986225128174
		 value loss: 1.440826654434204
		 entropy bonus: 0.17440351843833923
		 -----------------
	 Multi-agent batch loss: -18.110210418701172 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.214900016784668
		 value loss: 2.764028549194336
		 entropy bonus: 4.842128753662109
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 13.058958053588867
		 value loss: 47.716487884521484
		 entropy bonus: 2.941498279571533
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.2769649028778076
		 value loss: 1.440826654434204
		 entropy bonus: 0.1744173765182495
		 -----------------
	 Multi-agent batch loss: -18.111190795898438 - Differentiable computation graph = True!
	 start solving instance: 25...
	 start solving instance: 9...
	 start solving instance: 87...
	 start solving instance: 19...
	 start solving instance: 68...
	 start solving instance: 75...
	 start solving instance: 138...
	 start solving instance: 40...
	 start solving instance: 79...
	 start solving instance: 39...
		 Computing losses for agent: outsourcing
		 policy loss: 0.618157684803009
		 value loss: 0.38943639397621155
		 entropy bonus: 3.155856132507324
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 2.0830118656158447
		 value loss: 4.92342472076416
		 entropy bonus: 1.4470908641815186
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 0.3123109042644501
		 value loss: 0.11752905696630478
		 entropy bonus: 0.0
		 -----------------
	 Multi-agent batch loss: -3.0052
PPO iteration: 142/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.0034992694854736
		 value loss: 2.4295358657836914
		 entropy bonus: 4.801558971405029
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.017576217651367
		 value loss: 40.297813415527344
		 entropy bonus: 2.9460744857788086
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.8787907361984253
		 value loss: 1.2495232820510864
		 entropy bonus: 0.13923336565494537
		 -----------------
	 Multi-agent batch loss: -15.53896713256836 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.0034992694854736
		 value loss: 2.4295358657836914
		 entropy bonus: 4.801558971405029
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.01785659790039
		 value loss: 40.297813415527344
		 entropy bonus: 2.9459121227264404
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.8787814378738403
		 value loss: 1.2495232820510864
		 entropy bonus: 0.13920854032039642
		 -----------------
	 Multi-agent batch loss: -15.539236068725586 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.0034992694854736
		 value loss: 2.4295358657836914
		 entropy bonus: 4.801558971405029
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.01819896697998
		 value loss: 40.297813415527344
		 entropy bonus: 2.9457385540008545
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.8787858486175537
		 value loss: 1.2495232820510864
		 entropy bonus: 0.1391845941543579
		 -----------------
	 Multi-agent batch loss: -15.539580345153809 - Differentiable computation graph = True!
PPO iteration: 143/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.4832136631011963
		 value loss: 3.4071145057678223
		 entropy bonus: 4.8229193687438965
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 14.793558120727539
		 value loss: 66.81999969482422
		 entropy bonus: 3.056195020675659
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.4697844982147217
		 value loss: 1.9421441555023193
		 entropy bonus: 0.3701534867286682
		 -----------------
	 Multi-agent batch loss: -20.107357025146484 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.4832136631011963
		 value loss: 3.4071145057678223
		 entropy bonus: 4.8229193687438965
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 14.79384994506836
		 value loss: 66.81999969482422
		 entropy bonus: 3.055999994277954
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.469768524169922
		 value loss: 1.9421441555023193
		 entropy bonus: 0.3701731562614441
		 -----------------
	 Multi-agent batch loss: -20.10763168334961 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.4832136631011963
		 value loss: 3.4071145057678223
		 entropy bonus: 4.8229193687438965
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 14.79421615600586
		 value loss: 66.81999969482422
		 entropy bonus: 3.055788993835449
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.469768762588501
		 value loss: 1.9421441555023193
		 entropy bonus: 0.3701940178871155
		 -----------------
	 Multi-agent batch loss: -20.107994079589844 - Differentiable computation graph = True!
PPO iteration: 144/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.955451726913452
		 value loss: 2.4408538341522217
		 entropy bonus: 4.782427787780762
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.776350975036621
		 value loss: 38.603187561035156
		 entropy bonus: 3.070058822631836
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.186805248260498
		 value loss: 1.3102478981018066
		 entropy bonus: 0.167610302567482
		 -----------------
	 Multi-agent batch loss: -16.575265884399414 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.955451726913452
		 value loss: 2.4408538341522217
		 entropy bonus: 4.782427787780762
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.776666641235352
		 value loss: 38.603187561035156
		 entropy bonus: 3.069896697998047
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.1868319511413574
		 value loss: 1.3102478981018066
		 entropy bonus: 0.16761308908462524
		 -----------------
	 Multi-agent batch loss: -16.575607299804688 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.955451726913452
		 value loss: 2.4408538341522217
		 entropy bonus: 4.782427787780762
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.777105331420898
		 value loss: 38.603187561035156
		 entropy bonus: 3.069735527038574
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.1868948936462402
		 value loss: 1.3102478981018066
		 entropy bonus: 0.16761241853237152
		 -----------------
	 Multi-agent batch loss: -16.576107025146484 - Differentiable computation graph = True!
PPO iteration: 145/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.627058744430542
		 value loss: 3.512807607650757
		 entropy bonus: 4.80819034576416
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 14.96979808807373
		 value loss: 62.521480560302734
		 entropy bonus: 3.0169224739074707
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.920154333114624
		 value loss: 2.391106128692627
		 entropy bonus: 0.47685086727142334
		 -----------------
	 Multi-agent batch loss: -20.9157772064209 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.627058744430542
		 value loss: 3.512807607650757
		 entropy bonus: 4.80819034576416
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 14.969865798950195
		 value loss: 62.521480560302734
		 entropy bonus: 3.0167837142944336
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.9202218055725098
		 value loss: 2.391106128692627
		 entropy bonus: 0.4768739640712738
		 -----------------
	 Multi-agent batch loss: -20.915910720825195 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.627058744430542
		 value loss: 3.512807607650757
		 entropy bonus: 4.80819034576416
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 14.969956398010254
		 value loss: 62.521480560302734
		 entropy bonus: 3.016658306121826
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.9203147888183594
		 value loss: 2.391106128692627
		 entropy bonus: 0.4769016206264496
		 -----------------
	 Multi-agent batch loss: -20.916093826293945 - Differentiable computation graph = True!
PPO iteration: 146/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.952056646347046
		 value loss: 2.5699615478515625
		 entropy bonus: 4.808236122131348
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.801382064819336
		 value loss: 44.165645599365234
		 entropy bonus: 2.9186768531799316
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.1415629386901855
		 value loss: 1.3478087186813354
		 entropy bonus: 0.06570218503475189
		 -----------------
	 Multi-agent batch loss: -16.492094039916992 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.952056646347046
		 value loss: 2.5699615478515625
		 entropy bonus: 4.808236122131348
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.801741600036621
		 value loss: 44.165645599365234
		 entropy bonus: 2.9185285568237305
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.14151930809021
		 value loss: 1.3478087186813354
		 entropy bonus: 0.06571269780397415
		 -----------------
	 Multi-agent batch loss: -16.492408752441406 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.952056646347046
		 value loss: 2.5699615478515625
		 entropy bonus: 4.808236122131348
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.802149772644043
		 value loss: 44.165645599365234
		 entropy bonus: 2.918368339538574
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.1414966583251953
		 value loss: 1.3478087186813354
		 entropy bonus: 0.06571810692548752
		 -----------------
	 Multi-agent batch loss: -16.4927921295166 - Differentiable computation graph = True!
PPO iteration: 147/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.7249972820281982
		 value loss: 3.9574568271636963
		 entropy bonus: 4.831327438354492
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 15.323554992675781
		 value loss: 74.6501235961914
		 entropy bonus: 2.873756170272827
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.5978078842163086
		 value loss: 2.0974795818328857
		 entropy bonus: 0.10017409920692444
		 -----------------
	 Multi-agent batch loss: -20.917362213134766 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.7249972820281982
		 value loss: 3.9574568271636963
		 entropy bonus: 4.831327438354492
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 15.315187454223633
		 value loss: 74.6501235961914
		 entropy bonus: 2.873708963394165
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.5978055000305176
		 value loss: 2.0974795818328857
		 entropy bonus: 0.10017465054988861
		 -----------------
	 Multi-agent batch loss: -20.908992767333984 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.7249972820281982
		 value loss: 3.9574568271636963
		 entropy bonus: 4.831327438354492
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 15.321444511413574
		 value loss: 74.6501235961914
		 entropy bonus: 2.8740181922912598
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.597834825515747
		 value loss: 2.0974795818328857
		 entropy bonus: 0.10016660392284393
		 -----------------
	 Multi-agent batch loss: -20.915281295776367 - Differentiable computation graph = True!
PPO iteration: 148/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.2049129009246826
		 value loss: 2.79378604888916
		 entropy bonus: 4.821992874145508
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.639251708984375
		 value loss: 39.68962478637695
		 entropy bonus: 3.017526149749756
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.7917790412902832
		 value loss: 0.9135281443595886
		 entropy bonus: 0.07675179839134216
		 -----------------
	 Multi-agent batch loss: -16.28113555908203 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.2049129009246826
		 value loss: 2.79378604888916
		 entropy bonus: 4.821992874145508
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.64108657836914
		 value loss: 39.68962478637695
		 entropy bonus: 3.017434597015381
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.7917931079864502
		 value loss: 0.9135281443595886
		 entropy bonus: 0.07675612717866898
		 -----------------
	 Multi-agent batch loss: -16.28298568725586 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.2049129009246826
		 value loss: 2.79378604888916
		 entropy bonus: 4.821992874145508
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 11.644861221313477
		 value loss: 39.68962478637695
		 entropy bonus: 3.0177102088928223
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 1.7918155193328857
		 value loss: 0.9135281443595886
		 entropy bonus: 0.07676296681165695
		 -----------------
	 Multi-agent batch loss: -16.286785125732422 - Differentiable computation graph = True!
PPO iteration: 149/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.9171581268310547
		 value loss: 2.3125178813934326
		 entropy bonus: 4.852432727813721
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 12.004348754882812
		 value loss: 41.29724884033203
		 entropy bonus: 3.1354517936706543
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.2120721340179443
		 value loss: 1.376357078552246
		 entropy bonus: 0.2163785994052887
		 -----------------
	 Multi-agent batch loss: -16.76576042175293 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.9171581268310547
		 value loss: 2.3125178813934326
		 entropy bonus: 4.852432727813721
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 12.007644653320312
		 value loss: 41.29724884033203
		 entropy bonus: 3.1354589462280273
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.2121684551239014
		 value loss: 1.376357078552246
		 entropy bonus: 0.21637281775474548
		 -----------------
	 Multi-agent batch loss: -16.769153594970703 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 2.9171581268310547
		 value loss: 2.3125178813934326
		 entropy bonus: 4.852432727813721
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 12.009262084960938
		 value loss: 41.29724884033203
		 entropy bonus: 3.1354129314422607
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.212296485900879
		 value loss: 1.376357078552246
		 entropy bonus: 0.21636256575584412
		 -----------------
	 Multi-agent batch loss: -16.770896911621094 - Differentiable computation graph = True!
PPO iteration: 150/150:
	 start solving instance: 54...
	 start solving instance: 34...
	 start solving instance: 68...
	 start solving instance: 10...
	 start solving instance: 36...
	 start solving instance: 96...
	 start solving instance: 54...
	 start solving instance: 8...
	 start solving instance: 8...
	 start solving instance: 115...
	 start solving instance: 33...
	 start solving instance: 11...
	 start solving instance: 4...
	 start solving instance: 104...
	 start solving instance: 110...
	 Optimization epoch: 1/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.090688467025757
		 value loss: 2.66953706741333
		 entropy bonus: 4.804075717926025
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 13.24015998840332
		 value loss: 52.098846435546875
		 entropy bonus: 3.0635271072387695
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.255734443664551
		 value loss: 1.4553899765014648
		 entropy bonus: 0.12709565460681915
		 -----------------
	 Multi-agent batch loss: -18.104291915893555 - Differentiable computation graph = True!
	 Optimization epoch: 2/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.090688467025757
		 value loss: 2.66953706741333
		 entropy bonus: 4.804075717926025
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 13.244531631469727
		 value loss: 52.098846435546875
		 entropy bonus: 3.0634822845458984
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.2556326389312744
		 value loss: 1.4553899765014648
		 entropy bonus: 0.1270507574081421
		 -----------------
	 Multi-agent batch loss: -18.108562469482422 - Differentiable computation graph = True!
	 Optimization epoch: 3/3
		 Computing losses for agent: outsourcing
		 policy loss: 3.090688467025757
		 value loss: 2.66953706741333
		 entropy bonus: 4.804075717926025
		 -----------------
		 Computing losses for agent: scheduling
		 policy loss: 13.244322776794434
		 value loss: 52.098846435546875
		 entropy bonus: 3.0632691383361816
		 -----------------
		 Computing losses for agent: material_use
		 policy loss: 2.2556352615356445
		 value loss: 1.4553899765014648
		 entropy bonus: 0.12705224752426147
		 -----------------
	 Multi-agent batch loss: -18.108352661132812 - Differentiable computation graph = True!
<======***--| END OF TRAINING |--***======>
===* END OF FILE *===
